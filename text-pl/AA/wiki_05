<doc id="1122" url="https://pl.wikipedia.org/wiki?curid=1122" title="Dystrybucja Linuksa">
Dystrybucja Linuksa

Dystrybucja Linuksa – uniksopodobny kompletny system operacyjny zbudowany na bazie jądra Linux. Znakomita większość dystrybucji zawiera dużo elementów projektu GNU, co sprawia, że są one dystrybucjami GNU/Linuksa. W skład dystrybucji, oprócz samego jądra, wchodzą podstawowe programy i usługi takie, jak powłoka, skrypty startowe, narzędzia konfiguracyjne, a także często duży zestaw aplikacji użytkowych. W obrębie dystrybucji używana jest jednolita organizacja plików konfiguracyjnych oraz wspólny mechanizm instalowania nowych aplikacji. Niekiedy terminem „dystrybucja” określa się także systemy zbudowane na bazie jąder innych niż Linux (np. GNU Hurd, czy jądro FreeBSD); szczególnie można tutaj wyróżnić klony dystrybucji uniksowych (np. Debian).
Historia.
Linux sam w sobie jest jedynie jądrem systemu operacyjnego stanowiącym warstwę pośrednią między aplikacjami a sprzętem. Od samego początku było ono wykorzystywane razem z aplikacjami opracowywanymi dla wolnego systemu operacyjnego GNU dzięki dostępności kodu źródłowego. Samodzielna budowa i kompilacja wszystkiego ze źródeł, a następnie organizowanie ich w działający system operacyjny było jednak czasochłonnym zajęciem, wymagającym dodatkowo dużej wiedzy na temat całego procesu, dlatego już kilkanaście miesięcy po publikacji pierwszych wersji Linuksa pojawiły się gotowe dystrybucje. Najstarszą wciąż aktywnie rozwijaną dystrybucją jest Slackware Linux – został on po raz pierwszy wydany 16 lipca 1993 roku, a zbudowano go na bazie wcześniejszej dystrybucji SLS. Miesiąc później Ian Murdock ogłosił na liście dyskusyjnej codice_1 powstanie projektu Debian, obecnie jednej z najbardziej wpływowych dystrybucji.
Początkowo dystrybucje były tworzone przede wszystkim dla wygody użytkowników, lecz z biegiem czasu wiele z nich przekształciło się w poważne przedsięwzięcia rozwijane przez firmy (np. Red Hat Enterprise Linux, Ubuntu) lub organizacje niekomercyjne (Debian).
Budowa.
Większość oprogramowania wchodzącego w skład dystrybucji Linuksa jest rozwijana przez osoby trzecie. Jego użycie w danym projekcie jest możliwe dzięki liberalnym licencjom takim, jak GNU General Public License zezwalającym na swobodną dystrybucję kodu źródłowego, dokonywanie w nim zmian oraz kompilację pod warunkiem udostępnienia ich dalszym użytkownikom na identycznych zasadach. Poszczególne dystrybucje mocno różnią się między sobą w kwestiach związanych z:
Cechą szczególną wyróżniającą dystrybucje Linuksa spośród innych systemów operacyjnych, a w szczególności systemów Microsoft Windows, jest sposób instalowania nowych aplikacji. Dystrybucje posiadają centralne repozytorium z pakietami reprezentującymi poszczególne programy zbudowane i przygotowane przez twórców dystrybucji pod kątem konkretnego systemu. Pakiet, oprócz binariów oraz wszystkich niezbędnych plików, zawiera dodatkowe informacje opisujące zawartość archiwum, wersję programu, zależności oraz dodatkowe skrypty niezbędne do poprawnej instalacji. Pakietami zarządza specjalny program zwany menedżerem pakietów, który potrafi zlokalizować najnowszą wersję danego pakietu w dostępnych repozytoriach, zainstalować program oraz znaleźć wszystkie niezbędne zależności. Liczba pakietów w typowej dystrybucji waha się od kilkuset do kilkunastu tysięcy.
Autorskie oprogramowanie stanowi niewielką część wszystkich aplikacji. Najczęściej jest to instalator, skrypty startowe, dodatkowe narzędzia konfiguracyjne specyficzne dla danej dystrybucji oraz menedżer pakietów, aczkolwiek w jego przypadku istnieją projekty menedżerów wykorzystywane przez kilka/kilkanaście dystrybucji, np. APT.
Rodzaje dystrybucji.
Dystrybucje Linuksa można klasyfikować według różnych kryteriów:
Instalacja.
Zazwyczaj dystrybucje są instalowane bezpośrednio na dysku twardym komputera. Istnieją jednak również dystrybucje, które da się uruchomić bezpośrednio z nośnika instalacyjnego. Początkowo dystrybucje instalowane były z dyskietek, lecz obecnie zostało to całkowicie zarzucone. Obecnie najpopularniejszym nośnikiem są płyty CD/DVD, które można zamówić, kupić lub utworzyć samodzielnie, wypalając dostępne w Internecie obrazy ISO. Coraz większą rolę odgrywa połączenie z Internetem, za pośrednictwem którego można zaktualizować system lub zainstalować dodatkowe oprogramowanie niedostępne na nośnikach instalacyjnych. Wiele dystrybucji daje możliwość instalacji systemu przez sieć, np. z wewnętrznego repozytorium firmy przy użyciu protokołu NFS lub z oficjalnych serwerów.
Wyjątkowa metoda instalacji cechuje dystrybucję Gentoo Linux. Pakiety nie są tutaj dostarczane w formie binarnej, lecz jako kod źródłowy, który podczas instalacji kompilowany jest na danym komputerze. Ma to zapewnić większą wydajność poprzez optymalizację pod kątem konkretnego sprzętu.
Najważniejsze dystrybucje.
10 najważniejszych dystrybucji Linuksa według DistroWatch.com:
Dystrybucje innych systemów i środowisk.
Z biegiem czasu termin "dystrybucja" przestał dotyczyć tylko Linuksa. Dystrybucja może obejmować dowolny zbiór oprogramowania: począwszy od klasycznych, pełnych systemów operacyjnych (z jądrem i aplikacjami), poprzez wszechstronne środowiska w rodzaju JDistro, a skończywszy na specjalizowanych zestawach aplikacji, np. AMP lub XAMPP, czyli zestaw do serwowania stron internetowych LAMP, ale przeznaczony dla różnych systemów operacyjnych.
Dystrybucje mogą być zupełnie samodzielne, np. JDistro i JNode (dystrybucje Javy), TrueOS (FreeBSD) czy SchilliX (OpenSolaris). Istnieją też podprojekty Debiana oparte na jądrach z rodziny BSD (GNU/kFreeBSD, GNU/NetBSD), jądrze Hurd (GNU/Hurd) czy nawet zbiór pakietów Debiana przeznaczony dla Microsoft Windows.

</doc>
<doc id="1123" url="https://pl.wikipedia.org/wiki?curid=1123" title="Debian">
Debian

Debian (wym. ) – projekt wolnej dystrybucji systemu operacyjnego GNU/Linux oraz GNU/kFreeBSD realizowany przez ochotników na całym świecie. Wewnątrz Debiana istnieją również projekty, mające na celu stworzenie dystrybucji systemu GNU/Hurd, inne odmiany BSD, a nawet dystrybucji wolnego oprogramowania na platformę Windows.
Debian cieszy się opinią stabilnego systemu o wysokiej jakości i łatwego do aktualizacji. Ze względu na dbałość o jakość i bezpieczeństwo dystrybucji, nowe wersje stabilne pojawiają się stosunkowo rzadko, często dochodzi też do opóźnień w ich wydawaniu.
Użytkownicy mogą zgłaszać błędy w projekcie przez pocztę e-mail lub za pomocą programu reportbug.
Historia Debiana.
Powstanie Debiana ogłosił 16 sierpnia 1993 r. na grupie comp.os.linux.development Ian Murdock, wówczas student uniwersytetu Purdue. Napisał on Manifest Debiana, w którym apelował o stworzenie otwartej dystrybucji w duchu Linuksa i GNU. Nazwa „Debian” jest zbitką imion Murdocka i jego dziewczyny (obecnie byłej żony) Debry. Dystrybucja ta została zbudowana na podstawie SLS. Wśród założeń Debiana było między innymi to, że będzie zawierał on najbardziej aktualne wersje oprogramowania.
Początkowo projekt Debian rozwijał się wolno. W latach 1994–1995 powstały pierwsze wersje 0.9x. W sierpniu 1995 rozpoczęto prace nad adaptacją systemu na inne architektury. Wersja 1.x została wydana w 1996.
Wiosną 1996 roku Bruce Perens zastąpił Iana Murdocka w roli koordynatora projektu. Zainicjował on stworzenie kilku ważnych dokumentów (umowy społecznej wraz z Wytycznymi Dotyczącymi Wolnego Oprogramowania) oraz instytucji prawnej (SPI).
Perens odszedł ze stanowiska w 1998, tuż przed wydaniem Debiana 2.0 (pierwszego bazującego na glibc). Uczestnicy projektu wybrali nowego lidera – Iana Jacksona – i wydali jeszcze dwie wersje Debiana 2.x (Debian 2.1 wydany 9 marca 1999 oraz Debian 2.2 wydany 14 sierpnia 2000). W okresie tym został stworzony APT oraz rozpoczęto pracę nad projektem Debian GNU/Hurd – pierwszą adaptacją systemu na jądro nielinuksowe.
19 lipca 2002 zostaje wydany Debian 3.0 „Woody”. Działa już na 11 różnych architekturach sprzętowych (włączając w to dodane wtedy IA-64, PA-RISC, MIPS oraz S/390), posiada około 8500 pakietów, a w rozwój dystrybucji jest już zaangażowanych ponad 900 deweloperów.
6 czerwca 2005 roku Projekt wydaje Debiana 3.1 ‘Sarge’, który korzysta już z własnego instalatora (debian-installer).
8 kwietnia 2007 roku został wydany Debian GNU/Linux 4.0 o nazwie kodowej Etch. Do wydania dołączono wersję na architekturę AMD64, natomiast zrezygnowano z m68k (chociaż nadal była dostępna w gałęzi wersji niestabilnej).
26 lipca 2008 roku wydano kolejną aktualizacją stabilnej wersji Debian GNU/Linux 4.0r4. Pierwszy raz w historii projektu oprócz poprawek związanych z bezpieczeństwem, dokonano aktualizacji pakietów podstawowych systemu (ang. "core packages") do wyższych wersji (m.in. jądro systemu oraz serwer grafiki X.Org) w celu wsparcia nowego sprzętu (m.in. karty graficzne, sieciowe). Dystrybucja ze zmienionymi pakietami podstawowymi otrzymała nazwę "etch-and-a-half" (etch-i-pół) odróżniając ją od stabilnej wersji bez tych aktualizacji.
27 lipca 2008 roku została zamrożona wersja testowa Debiana – Lenny, do czasu wydania stabilnej wersji.
14 lutego 2009 roku nowa wersja stabilna – Lenny została wydana. Wydanie cechuje się obsługą 12 architektur sprzętowych (nowa architektura armel), oraz 23000 gotowych do zainstalowania pakietów. Wydanie to zostało dedykowane Thiemo Seuferowi – aktywnemu członkowi zespołu (odpowiedzialnemu między innymi za wspieranie architektury MIPS), który 26 grudnia 2008 roku zginął w tragicznym wypadku samochodowym.
6 sierpnia 2010 roku została zamrożona wersja testowa Debiana – Squeeze, do czasu wydania stabilnej wersji.
6 lutego 2011 roku ukazało się kolejne stabilne wydanie – Squeeze. Nowa wersja posiada wsparcie dla 9 architektur sprzętowych (11 programowych) oraz ponad 36000 gotowych do zainstalowania pakietów. Po raz pierwszy oficjalnie pojawia się (jako "technical preview") adaptacja na jądro FreeBSD z narzędziami GNU – GNU/kFreeBSD dla architektur x86 oraz AMD64.
4 maja 2013 roku została wydana nowa wersja stabilna Debiana 7.0 – Wheezy. W nowym wydaniu pojawiła się obsługa wielu architektur jednocześnie (tzw. multiarch), która pozwala na instalację pakietów z wielu architektur na tej samej jednostce, a także uruchamianie zarówno 32 i 64-bitowych programów, ze spełnianiem wszystkich zależności. Nowy Debian wprowadza również szereg rozwiązań prywatnej chmury obliczeniowej (między innymi Xen Cloud Platform oraz OpenStack), ulepszony instalator systemu oraz kompletny zestaw multimedialnych narzędzi i kodeków, bez potrzeby korzystania z zewnętrznych repozytoriów. W procesie instalacji wprowadzono ulepszenia pozwalające osobom niewidomym na instalację przy użyciu syntezatora mowy. Instalator został przetłumaczony na 73 języki, z czego ponad 12 posiada obsługę syntezatora mowy. Debian Wheezy obsługuje 64-bitowe komputery z UEFI, jednak na dzień wydania nowej wersji dystrybucji bez obsługi „Secure Boot”.
13 maja 2013, Lars Wirzenius i Russ Allbery zaproponowali zmiany dotyczące planu wydawniczego, którego głównym założeniem jest jego przyspieszenie.
Rozwój Debiana.
Debian jest tworzony przez dużą grupę ochotników komunikujących się ze sobą poprzez szereg list dyskusyjnych (dostępnych również w Usenecie w hierarchii linux.debian.*) oraz system śledzenia błędów. Projekt Debian posiada rozbudowaną strukturę wewnętrzną: z wyborami, konstytucją, a także formalnymi dokumentami określającymi zasady postępowania.
Obecnie projekt ten nie jest związany z żadną firmą ani organizacją. Przez krótki okres był powiązany z Free Software Foundation (FSF), która nawet pokrywała część kosztów funkcjonowania projektu. Na bazie Debiana opartych zostało wiele innych dystrybucji, na przykład: Corel Linux (obecnie XandrOS), Knoppix, Morphix, Ubuntu, MEPIS, Cdlinux.pl i inne.
Wersje Debiana.
Gałęzie dystrybucji.
Debian jest rozwijany jako 4 równoległe gałęzie:
Tworzenie nowej wersji stabilnej polega na zamrożeniu gałęzi testowej. Następuje wtedy okres przejściowy, w którym, poza wyjątkowymi przypadkami, do gałęzi testowej nie są dodawane żadne nowe pakiety. Gdy liczba błędów w tak zamrożonej dystrybucji testowej zmniejszy się do akceptowalnego poziomu, wersja testowa jest przemianowywana na stabilną i otrzymuje swój numer wersji. Poprzednia dystrybucja stabilna staje się dystrybucją archiwalną, jednak wsparcie od strony bezpieczeństwa zapewniane jest jeszcze przez jakiś czas.
Ze względu na nacisk na bezpieczeństwo i specyficzny cykl rozwoju produktu, stabilne wersje Debiana pojawiają się relatywnie rzadko.
Nazwa kodowa dystrybucji niestabilnej – „sid” jest niezmienna – Sid to, w filmie Toy Story, chłopiec psujący zabawki. Można ją również rozwinąć w sformułowanie "Still In Development" (ang. "ciągle rozwijany").
Nazwy wersji Debiana.
Kolejne wersje Debiana, od początku projektu noszą nazwy będące imionami bohaterów filmu Toy Story.
Cykl życia pakietu.
Każdy pakiet w Debianie ma swojego opiekuna, który utrzymuje go w odpowiedniej wersji, a także dba o jego zgodność z polityką Debiana, utrzymuje zgodność z innymi pakietami i stara się, aby był on na odpowiednio wysokim poziomie. Użytkownicy zgłaszają błędy poprzez system zgłaszania błędów, a następnie opiekun stara się naprawić błędy w aplikacji. Zazwyczaj jeden opiekun zajmuje się jednym pakietem, jednak czasami niewielkie grupy deweloperów zajmują się jednym dużym pakietem lub grupą pakietów silnie ze sobą powiązanych.
Gdy opiekun chce wydać nową wersję pakietu najpierw wysyła go do katalogu „incoming” w archiwum pakietów Debiana. Serwer sprawdzi czy plik został poprawie wysłany i czy wszystkie wymagane pliki znajdują się w nim. Dla pewności sprawdza poprawność klucza OpenPGP opiekuna. Każdy z deweloperów Debiana posiada własny klucz prywatny, a na serwerze jest jego klucz publiczny. Pakiety są podpisywane, aby uniknąć wysłania aktualizacji pakietu przez nieuprawnioną do tego osobę, która mogłaby wprowadzić modyfikację kodu wywołującą obniżenie bezpieczeństwa systemu, bądź dodanie kodu łamiącego zasady Debiana lub licencji programu.
Jeżeli wysłany pakiet spełnił powyższe wymagania, zostaje przesunięty do obszaru nazwanego „pool”. Każdego dnia setki ze światowych mirrorów pobierają pakiety z tego katalogu. Wszystkie pobrane pakiety są dostępne tylko w niestabilnej gałęzi Debiana, która zawiera najnowsze wersje każdego pakietu.
Jednak nowy kod to także niesprawdzony kod, dlatego każdy pakiet z tej gałęzi jest udostępniany bez jakichkolwiek gwarancji bezpieczeństwa czy stabilności. Aby pakiet stał się kandydatem do następnego stabilnego wydania Debiana najpierw musi trafić do gałęzi testowej. Wymagania aby pakiet trafił do gałęzi testowej są następujące:
W ten sposób błąd krytyczny w jednym pakiecie od którego zależy wiele innych pakietów (np. biblioteka) może spowodować, że wiele pakietów nie trafi do testowej gałęzi.
Menadżer danego wydania stabilnego publikuje wytyczne dla deweloperów i decyduje o terminie wydania stabilnego. Jeżeli wszystkie ważne pakiety są we względnie nowych wersjach i są dostępne dla oficjalnie wspieranych architektur, a także wypełnione są założenia dla danego wydania, następuje wydanie nowej wersji stabilnej. W jednym czasie wszystkie pakiety z gałęzi testowej stają się częścią wydania stabilnego. Operacja ta jest poprzedzona tzw. zamrożeniem gałęzi (), w tym najważniejszych podsystemów (jądro, biblioteki, kompilatory, interpretery języków skryptowych itp.).
W czasie gdy gałąź testowa jest zamrożona, nie są w niej umieszczane żadne większe aktualizacje pakietów (w szczególności bibliotek od których zależy wiele innych pakietów), chyba że:
Jest możliwość, że stosunkowo stary, rzadko aktualizowany pakiet, będzie należał do więcej niż jednej gałęzi w tym samym czasie.
Gałęzie są prostą metodą przechodzenia pakietu z katalogu „pool” do stabilnego wydania.
Liderzy projektu.
Liderami Debiana byli kolejno:
Obsługiwane jądra systemów operacyjnych.
W ramach polityki tworzenia uniwersalnego systemu operacyjnego, projekt Debian przygotowuje porty dostępnego w tej dystrybucji oprogramowania dla wielu jąder systemów operacyjnych. Obecnie istnieją:
Istnieją również porty nieoficjalne, wśród nich:
Obsługiwane architektury sprzętowe.
Debian jest wydawany dla różnych architektur komputerowych. Obecnie w wersji stabilnej Jessie istnieją następujące adaptacje:
Dodatkowo prace trwają nad architekturami ARM big-endian (armeb), Hitachi SuperH (sh), PowerPC64 (ppc64), Renesas M32R (m32r).
Narzędzia do zarządzania pakietami.
Debian korzysta z pakietów deb. Podstawowym instalatorem pakietów jest dpkg – instalator niskiego poziomu obsługiwany z linii poleceń, lub jego bardziej zaawansowany odpowiednik – APT, w którym wiele czynności jest zautomatyzowanych (pobieranie pakietów, rozwiązywanie zależności między pakietami). Do wygodniejszego zarządzania pakietami, Debian dysponuje nakładkami na powyższe narzędzia – dselect, oraz nowszy – aptitude.
Programy do zarządzania pakietami w Debianie:

</doc>
<doc id="1124" url="https://pl.wikipedia.org/wiki?curid=1124" title="Dania">
Dania

Dania () – państwo położone w Europie Północnej (Skandynawia), najmniejsze z państw nordyckich. Wraz z Grenlandią oraz Wyspami Owczymi tworzy Wspólnotowe Królestwo Danii. Kontynentalna Dania graniczy od południa z Niemcami, zaś przez cieśninę Sund sąsiaduje ze Szwecją. Posiada też granicę z Kanadą na wyspie Hansa. Dania jest członkiem Unii Europejskiej, NATO oraz ONZ.
Nazwa państwa.
Nazwa państwa duńskiego pojawiła się po raz pierwszy ok. roku 955 w formie ᛏᛅᚾᛰᛅᚱᚴᛅ, co oznacza „graniczny las Duńczyków” (więcej na ten temat w haśle kamienie runiczne z Jelling).
Polityka.
Ustrój polityczny.
Dania jest monarchią konstytucyjną – głową państwa jest królowa Małgorzata II.
Władzę ustawodawczą sprawuje jednoizbowy parlament noszący nazwę Folketing (179 deputowanych) wybierany na 4-letnią kadencję.
Dania jest najstarszą europejską monarchią z zachowaną ciągłością dziedzicznej władzy monarszej. Obecnie na tronie duńskim zasiada królowa Małgorzata II, córka Fryderyka IX i królowej Ingrid, z dynastii oldenburskiej, linii Sonderburg-Glücksburg, zamężna z księciem Henrykiem. Następcą tronu jest starszy syn królowej, książę Fryderyk. Dania jest monarchią konstytucyjną od 5 czerwca 1849 roku.
Dziedziczenie tronu.
Według Aktu o sukcesji z 4 czerwca 2009 r. tron po zmarłej monarchini obejmuje najstarszy potomek. Przy braku potomka tron przechodzi na najstarszego brata lub siostrę. Jeżeli rodzeństwo zmarłego władcy nie żyje lub z innych powodów nie jest upoważnione do objęcia tronu, tron obejmuje najbliższa pokrewieństwem linia boczna panującej dynastii, lecz z ograniczeniem do potomków króla Chrystiana X. Brak możliwości zastosowania tych zasad prowadzi do elekcji nowego króla lub królowej przez parlament. Na tronie mogą zasiąść tylko spadkobiercy z legalnych związków małżeńskich i jeśli należą do Kościoła Ewangelicko-Luterańskiego. Związek małżeński króla musi zostać zaakceptowany przez Folketing, a małżeństwa zawarte przez pretendentów do tronu wymagają zgody królowej na forum Rady Państwowej. Tuż po wstąpieniu na tron monarcha lub monarchini składa przyrzeczenie na piśmie, że będzie przestrzegać postanowień konstytucji.
System partyjny.
Obecny system partyjny Danii jest systemem wielopartyjnym. Liczba partii reprezentowanych w parlamencie kształtuje się zwykle w granicach 8-10. Wśród ugrupowań socjalistycznych dominuje Partia Socjaldemokratyczna. Inne lewicowe ugrupowania to m.in. Socjalistyczna Partia Ludowa oraz Partia Jedności, „Związek Czerwono-Zielonych”. Rola łącznika pomiędzy centrum a prawicą przypada Partii Radykalno-Liberalnej. Innego rodzaju partią liberalną jest Duńska Partia Liberalna – „Venstre”. Coraz większe poparcie wyborców uzyskuje nacjonalistyczna Duńska Partia Ludowa. Interesy niemieckiej mniejszości reprezentuje Partia Szlezwiku, o wyraźnie regionalnym zasięgu. Poza ww. występują również inne partie, np. Konserwatywna Partia Ludowa czy Sojusz Liberalny.
Historia systemu partyjnego
Do 1849 roku ustrój Danii był autokratyczny. Konstytucja z tego samego roku przyznała swobody obywatelskie i obaliła strukturę dotychczasowych rządów, wprowadzając dwuizbowy parlament złożony z reprezentantów o określonym wieku (od 30. roku życia), wyłonionych w wyborach powszechnych. Pewna liczba ugrupowań pojawiła się w świeżo założonym parlamencie, Rigsdagu. Skrystalizowały się one do trzech grup głównych: Venstre (Lewica), Højre (Prawica) i Centrum.
1866 rok przyniósł nowelizację, w której izba wyższa (Landsting) złożona z przedstawicieli uprzywilejowanych właścicieli ziemskich zyskała pozycję dominującą. Stanowiło to czynnik zapalny walki politycznej, która oficjalnie dotycząca konfliktu bezpośrednio wybieranej izby, Folketingu, z mającym przewagę Landstingiem, była w rzeczywistości aspiracją Partii Lewicy (założonej i popieranej w większości przez rolników, ale po 1870 roku również robotników) dążącej do rozbicia monopolu władzy politycznej Partii Prawicy (składającej się z arystokracji, właścicieli ziemskich i wyższej klasy średniej).
W 1901, na skutek rosnącego niezadowolenia robotników, zrzeszających się w związki zawodowe, król Chrystian IX wezwał lewicę do utworzenia nowego gabinetu i od tego czasu akceptowano regułę, iż rząd powinien odzwierciedlać większość w Folketingu.
W 1905 roku nastąpił rozłam w Partii Lewicy. Jej odłam stał się partią centrową. Radykalni-Liberałowie pragnęli współpracować z Socjaldemokratami. 1913: Obie partie otrzymują większość w Folketingu, Radykalno-Liberalny rząd kieruje Danią do czasu I wojny światowej.
Nowa konstytucja przyjęta w 1915 roku zawierała warunek reprezentacji proporcjonalnej oraz prawo wyborcze dla wszystkich obywateli, zarówno mężczyzn, jak i kobiet, od 25. roku życia (zmiana w 1978 na 18. rok życia). W celu zmiany wizerunku, dawna Partia Prawicy przybrała nazwę Konserwatywnej. Od tego czasu ona i Umiarkowani Liberałowie (niegdyś Partia Lewicy), Radykalni-Liberałowie oraz Socjaldemokraci stanowili centrum duńskiej polityki. Socjaldemokraci krótko rządzili w 1924 i w 1929 r., w stowarzyszeniu z radykałami.
Podczas okupacji hitlerowskiej (1940–1945), powstał rząd koalicyjny, utworzony przez główne partie polityczne, jednak wzrastający powszechny opór duński w stosunku do nazistów, skłonił ich do przejęcia władzy wykonawczej. Partie faszystowskie nigdy nie odnotowały nikłego nawet poparcia. Od wyzwolenia 1945 do 1957 roku, Danią kierował rząd mniejszościowy, ze zmiennym wpływem socjaldemokratów z jednej strony i umiarkowanych liberałów oraz konserwatystów z drugiej, w zależności, od tego, którą z dwu grup, poparła Partia Radykalno-Liberalna. W 1953 r., nowa konstytucja obaliła Landsting, wprowadzając system jednoizbowy i powiększając liczbę deputowanych ze 151 do 179.
Główne partie popierały działania ONZ i NATO, ponadto zacieśniając współpracę między krajami skandynawskimi.
Ów okres, kiedy najbardziej wpływowe partie otrzymywały łącznie w kolejnych wyborach mniej lub więcej 90 procent mandatów, był dla pozostałych pasmem porażek. Ciesząca się dotychczas nieznacznym poparciem Partia Komunistyczna, w 1957 roku nie weszła do parlamentu. Wcześniej odłączyła się od niej Partia Socjalistyczno-Ludowa. Pewną rolę odegrała również Partia Jednolitego Opodatkowania, opierająca się na zasadach Henry’ego George’a, będąc w koalicji rządowej 1957–1960.
Industrializacja i rozwój sektora państwowego uczyniły partyjne podziały bardziej skomplikowanymi. Agresywna walka radykalnej Partii Socjalistyczno-Ludowej, o wyborców lewicy przyczyniła się do destabilizacji w zachowaniach wyborczych, które nastąpiły w roku 1973.
Trzy nowe partie otrzymały mandaty, Chrześcijańsko-Ludowa, Centrum Demokraci oraz Partia Postępu (na skutek rozłamu, jaki nastąpił w 1995, wywodzi się z niej populistyczna Duńska Partia Ludowa) z liderem Mogensem Glistrupem, ekspertem podatkowym. Partia Postępu, założona na początku 1973 roku, forsowała zniesienie podatku dochodowego i stopniową likwidację biurokracji państwowej. Socjaldemokraci, obecni u władzy, ponieśli znaczną porażkę w tych wyborach. Ich przewodniczący, Anker Jorgensen, zrezygnował ze stanowiska premiera. W środku grudnia, Poul Hartling został zaprzysiężony jako premier liberalno-demokratycznego gabinetu.
Kiedy stało się jasne w grudniu 1974, że parlament nie akceptuje drastycznego antyinflacyjnego programu Hartlinga, wybory powszechne zostały zwołane ponownie i odbyły się w styczniu 1975. Liberałowie niemal podwoili swoją reprezentację w Folketingu. Jednakże, ponieważ większość nie socjalistycznych partii utraciła poparcie oraz dlatego, iż trzy z czterech lewicowych partii równocześnie zyskały parlamentarne mandaty, utracono stałą większość, zatem Hartling podał się do dymisji. Po kilku próbach, koalicja Hartlinga i Ankera Jorgensena, późniejszy sojusz Socjaldemokratów z pozostałymi socjalistami ukierunkowane partiami mniejszości w końcu odniosły sukces w tworzeniu nowego rządu. Jorgensen pozostał premierem dzięki wyborom w 1977, 1979 i 1981 roku. Jednakże we wrześniu 1982, rozbieżność zdań wobec planu Jorgensena, aby podnieść podatki, utworzyć nowe miejsca pracy, zwiększyć subwencje dla rolników i zmniejszyć deficyt budżetowy, była powodem rozwiązania rządu.
Koalicja czterech partii na czele z Poulem Schlüterem, pierwszym Konserwatywnym premierem od 1901 roku, przejęła wówczas władzę, tworząc rząd mniejszościowy, a posiadając tylko 66 mandatów z 179. W 1984 roku parlament nie udzielił poparcia dla budżetu rządu Schlütera, który w konsekwencji domagał się nowych wyborów. Odbyły się one w styczniu 1984 i w rezultacie koalicja objęła 79 mandatów. Jednakże następne wybory wrześniowe 1987, przyniosły 70 mandatów koalicji.
Wybory roku 1994, wyłoniły koalicję trzech silnych partii: Socjaldemokratów, Centrum Demokratów i Partii Radykalno-Liberalnej (otrzymali w sumie 76 mandatów). Liczba mandatów konserwatystów, głównej siły prawicowej, zmalała z 31 do 28, podczas gdy Partia Liberalna odczuła wzrost poparcia od 15,8% do 23,3% i tym samym stała się największą partią opozycyjną. Centrolewicowa koalicja przetrwała rozstanie z Centrum Demokratami, w 1996, którzy odrzucili propozycję Prezesa Rady Ministrów Poula Nyrupa Rasmussena, aby szukać poparcia dla budżetu po lewej stronie izby. Krucha koalicja dwóch partii przeżyła wiele kryzysów w roku 1997.
Wybory w 1998 roku odbyły się pod gwiazdą powrotu liberalno-konserwatywnego gabinetu. W lutym 1998, Socjaldemokraci odnotowali wzrost poparcia i Nyrup Rasmussen zwołał nagłe wybory. Ich wyniki były następujące: Partia Socjaldemokratyczna-35,9% (65 mandatów), Partia Radykalno-Liberalna-3,9% (7 mandatów), Partia Centrum Demokraci-4,3% (8 mandatów), Partia Chrześcijańsko-Ludowa-2,5% (4 mandaty), Partia Socjalistyczno-Ludowa-7,6% (13 mandatów), Czerwono-zielone przymierze-2,7% (5 mandatów), Liberałowie-23% (43 mandaty), Konserwatyści-8,9% (17 mandatów), Partia Postępu-2,4% (4 mandaty) i Duńska Partia Ludowa-7,4% (13 mandatów). Koalicja Socjaldemokratów i radykalnych-Liberałów pozostała nienaruszona (z Nyrupem Rasmussen jako premierem). Konserwatyści ponieśli em z Konserwatystami (9,1%, 16 mandatów) utworzyły rząd mniejszościowy, na którego czele stanął Anders Fogh Rasmussen. Dwie radykalne partie prawicowe: Duńska Partia Ludowa i Partia Postępu odniosły sukces, przejmując głosy głównego nurtu prawicy. W marcu 2000 Nyrup Rasmussen dokonał zmiany członków gabinetu, a wprowadzając nowych ludzi, starał się zapoczątkować pewne zmiany w odpowiedzi na oskarżenia Duńskiej Partii Ludowej. Krytykowała ona rząd za zbyt „miękką” politykę imigracyjną.
Sprawy imigracyjne były zagadnieniem najważniejszym w debatach poprzedzających wybory 20 listopada 2001. Socjaldemokraci Nyrupa Rasmussena zyskali mniej niż oczekiwali, bo tylko 29,1% głosów, a zatem 52 mandaty. Centroprawicowe partie osiągnęły najwyższe poparcie od 1926 roku. Partia Liberalna otrzymała 31,3% głosów, co przełożyło się na 56 mandatów). Ów gabinet musiał liczyć się ze zdaniem Duńskiej Partii Ludowej (12% i 22 mandatów), która udzieliła mu swego wsparcia. Pozostałe partie z reprezentacją w Folketing to: Partia Socjalistyczno-Ludowa (6,4%, 12 mandatów); Partia Radykalno-Liberalna (5,2%, 9 mandatów); Czerwono-zielone przymierze (2,4%, 4 mandaty); Partia Chrześcijańsko-Ludowa (2,3%, 4 mandaty); oraz po dwóch reprezentantów Wysp Owczych i Grenlandii.
Obecny układ sił prezentuje się podobnie. W lutym 2005 i znowu w listopadzie 2007, Partia Liberalna (Venstre) wraz z koalicyjnym partnerem, Partią Konserwatywną, ponownie uzyskały przewagę. Od wyborów w 2001 roku Venstre była największą partią duńskiego parlamentu. Dziś władzę sprawują partie lewicowe skupione w Bloku Czerwonym.
Członkostwo w organizacjach międzynarodowych.
Dania jest państwem Unii Europejskiej, a także członkiem OECD, NATO, ONZ, Organizacji Bezpieczeństwa i Współpracy w Europie, Unii Nordyckiej (której siedziba znajduje się w stolicy Danii, Kopenhadze) i innych organizacji międzynarodowych. Dania jest członkiem założycielem Rady Europy
Konstytucja Danii przewiduje szczególną procedurę wyrażania zgody na przekazanie przez władze Królestwa Danii wykonywania przysługujących im uprawnień organom międzynarodowym. Dla podjęcia decyzji w takiej sprawie wymagana jest kwalifikowana większość 5/6, a w przypadku uzyskania poparcia jedynie zwykłej większości członków Folketingu na wniosek rządu rozstrzygnięcie następuje w drodze referendum.
Siły zbrojne.
Duńskie Siły Zbrojne (duń. "Det Danske Forsvar") dzielą się na Armię Danii, Marynarkę Wojenną, Siły Powietrzne i Obronę Terytorialną. Podstawowym zadaniem wojska jest obrona terytorium Danii, Wysp Owczych i Grenlandii przed zewnętrzną agresją. Wojsko podlega Ministerstwu Obrony, a jego najwyższym dowódcą jest królowa Małgorzata II. Dania od 1949 roku jest członkiem NATO.
Uzbrojenie sił lądowych Danii składało się w 2014 roku z: 57 czołgów, 700 opancerzonych pojazdów bojowych oraz 12 dział samobieżnych.
Wojska Danii w 2014 roku liczyły 25 tys. żołnierzy zawodowych oraz 63 tys. rezerwistów. W Danii służba wojskowa jest obowiązkowa dla mężczyzn i wynosi w zależności od specjalizacji od 4 do 12 miesięcy. Według rankingu "Global Firepower" (2014) duńskie siły zbrojne stanowią 43. siłę militarną na świecie, z rocznym budżetem na cele obronne w wysokości 4,4 mld dolarów (USD).
Podział administracyjny.
Od 1 stycznia 2007 roku Dania podzielona jest na 5 regionów, które z kolei dzielą się na 98 gmin.
"Zobacz też: podział administracyjny Danii do 2006."
Historia.
Pierwotnie obszar dzisiejszej Danii został zasiedlony przez plemiona germańskie: Cymbrów i Teutonów, a następnie Anglów, Jutów i Sasów. Te 3 plemiona w V i VI wieku po podbiciu części Wysp Brytyjskich (dzisiejsza Anglia) przemieściły się tam, a na ich miejsce napłynął północnogermański lud Duńczyków. W okresie VIII-IX wieku Duńczycy brali udział w morskich wyprawach na wybrzeża Wielkiej Brytanii, państwa Franków i wybrzeża Bałtyku. Postępowało jednoczenie kraju, a w IX wieku kraj został schrystianizowany. Duński król Kanut II Wielki władał państwem, które obejmowało obok Danii, także Anglię, Norwegię, południową Szwecję oraz część Finlandii. W XII wieku Dania rozpoczęła ekspansję w rejonie Morza Bałtyckiego, zajmując m.in. Estonię, Holsztyn i Inflanty. W roku 1397 Dania utworzyła z Norwegią i Szwecją Unię Kalmarską, która przetrwała do 1523 roku, a następnie do roku 1814 istniała unia Danii z Norwegią. W 1448 r. tron objął Chrystian I z dynastii Oldenburgów. W latach 1534–1536 w Danii trwała wojna domowa, w wyniku której religią państwową stał się luteranizm. W drugiej połowie XVI wieku kraj zaangażowany był w wyniszczające wojny o panowanie na Bałtyku ze Szwecją i w ich wyniku utracił mocarstwową pozycję. W wojnie trzydziestoletniej (1618–1648) król Danii Chrystian IV wziął udział po stronie protestantów. Dania była państwem, które zaprotestowało przeciwko likwidacji Polski po II rozbiorze. 
W okresie napoleońskim Duńczycy starali się zachować neutralność prowadząc handel z oboma obozami. Dania weszła do tzw. Ligi Zbrojnej Neutralności, co zostało uznane za akt wrogi przez Zjednoczone Królestwo i doprowadziło do brytyjskiego ataku na Kopenhagę oraz zniszczenia floty duńskiej. Wobec kłopotów ekonomicznych spowodowanych blokadą brytyjską w roku 1814 Dania zrzekła się na rzecz Szwecji kontroli nad Norwegią w traktacie kilońskim. Jednak zachowała norweskie posiadłości: Islandię, Wyspy Owcze i Grenlandię. Od roku 1849 Dania stała się monarchią konstytucyjną. Po wojnie duńskiej w 1864 roku z Austrią i Prusami Dania utraciła Szlezwik i Holsztyn, od tego momentu prowadziła politykę neutralności. Podczas I wojny światowej zachowała neutralność, a w roku 1920 w wyniku plebiscytu północny Szlezwik powrócił do Danii. Mimo swego statusu Dania została zaatakowana i szybko zajęta w 1940 r. przez hitlerowskie Niemcy. Przez kilka lat mimo niemieckiej okupacji Dania zachowywała formalną suwerenność – funkcjonował parlament i rząd, ale od roku 1943 rządy bezpośrednie sprawowali już Niemcy. W trakcie II wojny światowej w roku 1944 okupowana przez Brytyjczyków i Amerykanów Islandia zerwała unię personalną z Danią, ogłoszając się republiką. Dania została wyzwolona 5 maja 1945 roku przez wojska brytyjskie. 
W roku 1949 Dania stała się członkiem NATO. Od 1953 roku w Królestwie Danii obowiązuje nowa konstytucja (Konstytucja Królestwa Danii z 5 czerwca 1953 r.). W roku 1960 weszła w skład Europejskiego Stowarzyszenia Wolnego Handlu, a w 1973 stała się członkiem EWG. W roku 1992 w referendum Duńczycy odrzucili traktat z Maastricht, jednak rok później został on ostatecznie ratyfikowany.
Geografia.
Dania pod względem warunków naturalnych jest krajem przejściowym pomiędzy Europą Północną i Środkową. Geologicznie terytorium Danii związane jest z trzonem kontynentalnym Europy. Większa część powierzchni kraju ukształtowana została w okresie ostatniego zlodowacenia. Granicę krajobrazową wyznacza zlodowacenie Würm, które ciągnie się przez cały Półwysep Jutlandzki w kierunku południkowym. Górnokredowe wapienie i kreda tworzą krajobraz północnej Jutlandii i wybrzeża typu klifowego na wyspach Møn i Zelandia.
Dania jest krajem nizinnym – najwyższym punktem jest wzgórze Yding Skovhøj (172,54 m n.p.m. razem z kurhanem nagrobnym na szczycie, bez kurhanu 170,77 m n.p.m.).
70% powierzchni Danii przypada na Półwysep Jutlandzki (Jutlandię, "Jylland"). Reszta kraju położona jest na 406 wyspach, z czego zamieszkanych jest 79. Największe i najważniejsze wyspy to Zelandia 7031 km² ("Sjælland", na której znajduje się stolica kraju, Kopenhaga), Nørrejyske Ø 4685 km², Fionia ("Fyn") 2984 km², Lolland 1243 km², Bornholm 588,5 km², Falster 514,0 km², Morsø 363,3 km², Als 321,0 km², Langeland 284,0 km², Møn 237,5 km² i Rømø 128,9 km².
Największe miasta Danii to Kopenhaga (518,6 tys.), Århus (239,9 tys.), Odense, Ålborg i Esbjerg.
Roślinność.
Pierwotną roślinność kraju stanowiły lasy bukowo-dębowo-jesionowe oraz wrzosowiska. Obecnie znaczna ich większość została zastąpiona przez grunty orne oraz łąki i pastwiska. Lasy stanowią niespełna 12% powierzchni Danii i składają się głównie z sosen, jodeł, świerków i modrzewi, posadzonych przez człowieka.
Klimat.
Na obszarze Danii panuje klimat umiarkowany ciepły typu morskiego. Zimy są krótkie i łagodne, zaś lata – dość chłodne, z dużą ilością opadów. Średnia temperatura w styczniu wynosi od -0,5 do +0,5 °C, a w lipcu od +16 do +17 °C. Najwyższa zanotowana na terenie Danii temperatura to +36,4 °C. Absolutne minimum termiczne to –31,2 °C.
Opady występują głównie w postaci deszczu (śnieg pojawia się rzadko), zaś największe nasilenie opadów ma miejsce w lipcu i sierpniu. Średnia roczna suma opadów wynosi ok. 650 mm, przy czym istnieją w tym względzie spore różnice pomiędzy poszczególnymi częściami kraju, i tak na Zelandii jest to ok. 550 mm, a na Półwyspie Jutlandzkim – 800 mm.
Gospodarka.
Dania jest wysoko rozwiniętym krajem. Spośród krajów unijnych, ma najlepszy Wskaźnik Wolności i jest w pierwszej dziesiątce najbardziej wolnych na świecie. PKB per capita w 2005 roku wynosiło nominalnie 50 tys. 965 dolarów (8. miejsce na świecie), a po zmierzeniu parytetem siły nabywczej 36 tys. 549 dolarów (7. miejsce na świecie), co jest wynikiem pod obydwoma względami porównywalnym do Szwajcarii. Wskaźnik Giniego, czyli poziom rozpiętości w dochodach, wynosi 25 i jest najniższy na świecie obok wyniku pozostałych krajów skandynawskich. Podatki należą do najwyższych w UE i na świecie, stanowią one 49% PKB. Najwięcej zatrudnionych (blisko 70%) pracuje w szeroko rozumianej sferze usług. Na terenie kraju istnieje m.in. przemysł spożywczy, maszynowy, celulozowo-papierniczy, metalurgiczny i budownictwo.
Dużą rolę odgrywa wydobycie surowców energetycznych (ropy naftowej, gazu ziemnego, węgla brunatnego, oraz torfu). Dania jest samowystarczalna energetycznie. Wydobycie ropy i gazu dwukrotnie przekracza potrzeby własne, a nadwyżka jest eksportowana.
Znane przedsiębiorstwa duńskie to Maersk, jedna z największych na świecie firm kontenerowych, Lego i Carlsberg.
Dania posiada stosunkowo dobrze rozwiniętą sieć drogową. W 2006 jej łączna długość wynosiła 72 362 km a średnia gęstość 167,9 km/100 km². W 2007 istniało w tym kraju 2644 km linii kolejowych, ich średnia gęstość wyniosła 6,14 km/100 km².
Emisja gazów cieplarnianych.
Łączna emisja równoważnika dwutlenku węgla z obszaru Danii wyniosła w 1990 roku 70,66 Mt, z czego 53,645 Mt stanowił dwutlenek węgla. W przeliczeniu na mieszkańca emisja wyniosła wówczas 10,435 t dwutlenku węgla, a w przeliczeniu na 1 dolar PKB 309 kg. Emisja rosła do 1996, a następnie spadała. W 2018 roku emisja dwutlenku węgla pochodzenia kopalnego wyniosła 33,131 Mt, a w przeliczeniu na mieszkańca 5,758 t i w przeliczeniu na 1 dolar PKB 120 kg. Przez większość tego okresu główną branżą odpowiedzialną za tę emisję była energetyka, ale z czasem jej udział spadał, a przy prawie stałym poziomie emisji z transportu, ta branża stała się współdominująca w drugiej dekadzie XXI w. W całkowitej emisji gazów cieplarnianych dwutlenek węgla zawsze stanowił większość, na drugim miejscu zawsze były emisje metanu, niewiele od nich były emisje podtlenku azotu, a udział emisji gazów fluorowanych był mało zauważalny.
Rolnictwo.
Rolnictwo duńskie jest wysoko rozwinięte, nowoczesne o wysokim stopniu mechanizacji, cechuje się intensywnością i wysoką wydajnością (jedno z czołowych miejsc w świecie pod względem wydajności). Wytwarza się znaczną nadwyżkę żywności, trzykrotnie przewyższającą potrzeby kraju, która stanowi ważny towar eksportowy.
Dania ma jeden z największych w świecie odsetek gruntów ornych i sadów wynoszący 63% powierzchni kraju. Uprawa obejmuje głównie zboża (zwłaszcza pszenicę, a także jęczmień, żyto i owies), buraki cukrowe, ziemniaki oraz warzywa. Średnie plony są na poziomie: pszenica – 52 q/ha, jęczmień – 40 q/ha, owies – 38 q/ha. Hodowane jest przede wszystkim bydło (zarówno typu mlecznego, jak i mięsnego) i trzoda chlewna, sporą rolę odgrywa hodowla drobiu. Dania jest światową potęgą w produkcji i eksporcie mleka, mięsa, masła i serów. Udział duńskiego mięsa w handlu międzynarodowym sięga ok. 15% (1. miejsce w świecie), w przypadku masła odsetek ten wynosi 17% (2. miejsce w świecie). Istotną rolę, dzięki warunkom naturalnym, odgrywa rybołówstwo morskie, ponad 2/3 połowów przeznacza się na eksport. Największymi portami rybackimi są: Esbjerg, Skagen i Thyborøn. Produkcja ogrodnicza koncentruje się wokół dużych miast, najwięcej szklarni znajduje się na wyspach Fionii i Zelandii. Lasy pokrywają ok. 12% powierzchni kraju, a produkcja drewna zaspokaja 1/3 zapotrzebowania Danii.
Dania jest największym na świecie eksporterem futer zwierzęcych. W kraju istnieje ok. 1500 farm futrzarskich, które rokrocznie dostarczają ok. 19 mln skór norek, a także skóry lisie, szynszyle i królicze. Eksport sektora futrzarskiego przynosi ok. 1,2 mld EUR.
Handel zagraniczny.
Eksport jest bardzo ważnym czynnikiem w gospodarce Danii. Około 1/3 PKB kraju pochodzi właśnie z eksportu. Eksportowane są przede wszystkim takie dobra jak: części maszyn, metale surowe, produkty spożywcze, elektronika i gaz ziemny. Najważniejszymi partnerami handlowymi Danii są Niemcy (17%), Szwecja (12%), Wielka Brytania (8%) oraz Stany Zjednoczone (7%). W roku 2009 handel zagraniczny z Niemcami uległ pogorszeniu ze względu na kryzys finansowy w Europie.
W latach 60. Niemcy zdetronizowały Wielką Brytanię z pozycji głównego partnera handlowego Danii, jednakże Anglia dalej pozostaje jednym z najbardziej znaczących odbiorców duńskich produktów eksportowych. Handel z krajami Europy Wschodniej urósł na znaczeniu. Bilans handlowy Danii jest pozytywny; oznacza to, że eksport przewyższył import. Na początku lat 60. Głównymi towarami eksportowymi Danii były produkty mięsne oraz nabiał. Obecnie są to również produkty farmaceutyczne, maszyny, metale oraz części transportowe.
Lista regionów według wskaźnika rozwoju społecznego.
Lista regionów Danii według wskaźnika rozwoju społecznego w 2017 roku.
Turystyka.
Turystyka jest ważnym źródłem dochodowym Danii. Przemysł turystyczny w Danii kwitnie od lat i ciągle nabiera na sile. Dania jest szczególnie lubiana przez turystów z Niemiec, Szwecji oraz Norwegii. Szczególnie chętnie odwiedzanym miejscem jest stolica kraju, Kopenhaga.
W roku 1999 Danię odwiedziło ponad 2 miliony turystów z różnych krajów, przede wszystkim z innych krajów skandynawskich. Łącznie zyski w turystyce z tamtego roku wyniosły 3,31 mld dolarów.
Dania to spokojny i bezpieczny kraj, a jej główne atrakcje turystyczne to:
Tydzień pracy.
Dania ma jedną z najmniejszych liczb godzin do przepracowania w tygodniu. Według CNN jest druga po Holandii, a przeciętny tydzień pracy ma 33 godziny robocze tygodniowo.
Demografia.
Populacja: 5 756 170 mieszkańców (2016).
Grupy etniczne:
Struktura wieku (2006 r.):
Średnia wieku (2006 r.):
Przeciętna długość życia (2006 r.):
Współczynnik dzietności (2014 r.):
Języki:
Oficjalnym językiem Królestwa Danii jest język duński, który występuje w wielu regionalnych dialektach. Języki mniejszości to szwedzki oraz niemiecki. Na terytoriach zależnych Danii używane są też języki farerski i grenlandzki. Najpowszechniej znanym językiem obcym jest angielski.
Miasta Danii.
Religie:
Struktura religijna kraju w 2010 roku według Pew Research Center:
Wśród protestantów dominuje Kościół Luterański z 4,4 miliona wiernych. Wśród innych wyznań protestanckich największe stanowią: ruch zielonoświątkowy (20,5 tys. wiernych), baptyzm (8 tys.), Kościół Duńskiej Konwencji (3,3 tys.) i Kościół Adwentystów Dnia Siódmego (3,2 tys.). Przynależność do państwowego Kościoła luterańskiego jest oznaką nie tyle religijności, ile tożsamości narodowej. Duńczycy są jednym z najbardziej zsekularyzowanych narodów świata. Wiarę w Boga deklaruje mniej niż 1/3 Duńczyków (według Eurobarometru 31% w 2005 roku). Powszechna jest obojętność religijna, agnostycyzm i w mniejszym stopniu ateizm.
Oświata.
Obowiązek szkolny w Danii trwa dziewięć lat, obejmuje cały okres nauki w szkole podstawowej i może być realizowany na trzy różne sposoby: w szkołach państwowych, prywatnych lub w formie domowego nauczania. Wybór pozostawia się rodzicom.
Od roku szkolnego 2007/2008 duński system oceniania jest siedmiostopniowy, obejmujący oceny od -3 do +12/12. Aby zdać, należy osiągnąć odpowiednio 12, 10, 7, 4 albo 2 punkty. Egzamin niezdany jest wtedy, kiedy otrzyma się 0 bądź -3 punkty. Wartości, które znajdują się pomiędzy wymienionymi, nie decydują o zdaniu bądź niezdaniu egzaminu, lecz mają znaczenie podczas wystawiania ocen cząstkowych. Powodem, dla którego doszło do zreformowania skali ocen, była między innymi potrzeba, aby ustalono jasne granice pomiędzy pojedynczymi ocenami oraz umożliwienie, na ile to możliwe, międzynarodowego systemu oceniania. Poniższa tabela ilustruje poszczególne oceny z odpowiednią definicją wyjaśniającą tę ocenę w duńskim systemie szkolnictwa, jak również porównanie z punktami ECTS oraz niemieckim systemem oceniania.
Duński system ocen składał się wcześniej z 13–stopniowej skali, gdzie 00/0 oznaczało ocenę najgorszą, a 13 najlepszą. Porównując je z niemieckim systemem oceniania, wygląda to następująco: (oceny 1, 2, 4, jak również 12 nie było): (ocena duńska = ocena niemiecka) (00 = 6; 03 = 5–6, 05 = 5, 06 = 4; 07 = 3–4; 08 = 3; 09 = 2−; 10 = 1–2; 11 = 1; 13 = 1+).
Wszystkie duńskie kierunki studiów podlegają tak zwanemu Numerus clausus, który jest dokumentem centralnym, na podstawie którego ustala się miejsca na studiach według średniej ocen. Pewien procent miejsc na studiach przydzielany jest na podstawie kwestii socjalnych, przy czym można sobie zwiększyć szanse na dostanie takiego miejsca, wykonując prace socjalne. Podobnie jak w Niemczech niektóre przedmioty są chętniej i liczniej uczęszczane, dlatego też trudniej jest wtedy zdobyć wolne miejsce. (np. medycyna, psychologia czy prawo), podczas gdy na niektóre kierunki prawie nie ma zapotrzebowania i tam każdy kandydat zostaje przyjęty.
Sztuka duńska.
Jednym z najstarszych zabytków znalezionych na terenie Danii jest Fibula z Værløse datowana na III wiek, znaleziona w 1944 w Værløse na północ od Kopenhagi.
Duńskie malarstwo.
Duńskie malarstwo największe triumfy święciło w XIX w., a do jego najwybitniejszych przedstawicieli należą Christoffer Wilhelm Eckersberg i Christen Købke.
Muzyka.
Duży wpływ na duńską muzykę w czasach rządów króla Chrystiana IV (druga połowa XVI w., pierwsza połowa XVII w.) miała muzyka niemiecka, włoska oraz angielska. Kompozytorzy tacy jak John Dowland, Heinrich Schütz, którzy przez długi czas byli nadwornymi kompozytorami królewskimi, lub Dietrich Buxtehude, który był organistą w Helsingør, mieli możliwość kontaktu z duńskimi kompozytorami, przez co mieli wpływ na ich twórczość.
Do rozwoju duńskiej muzyki w dużym stopniu przyczynił się urodzony w Niemczech Friedrich Ludwig Æmilius Kunzen, który napisał operę „Holger Danske” (1787). Innym ważnym kompozytorem był Christoph Ernst Friedrich Weyse, który napisał operę „Ludams Hule” (1816).
Duńskimi reprezentantami epoki romantyzmu byli Niels Wilhelm Gade, Johan Peter Emilius Hartmann oraz Peter Heise.
Najważniejszym kompozytorem XX w. w Danii był Carl Nielsen, który dzięki swoim symfoniom i operom zyskał sławę również poza granicami kraju. Inni kompozytorzy z tego okresu to Poul Schierbeck, Knudåge Riisager, Jørgen Bentzon, Finn Høffding, Herman David Koppel, Vagn Holmboe, Niels Viggo Bentzon, Louis Glass, Paul von Klenau, Ludolf Nielsen, Hakon Børresen, Rued Langgaard, Poul Ruders oraz Per Nørgård.
Najbardziej znanymi duńskimi wykonawcami muzyki rozrywkowej są: zespół Aqua, Lars Ulrich (perkusista zespołu Metallica), Oh Land, Niels-Henning Ørsted Pedersen, Carpark North, Saybia, Kashmir, Nephew, Medina, Outlandish, D-A-D, Pretty Maids, Thulla, Poul Krebs, Kim Larsen, TV-2, Sorten Muld, Volbeat, Jakob Sveistrup, Sort Sol, King Diamond, Red Warszawa, Natasha Thomas, Laid Back, Hanne Boel, Anna David, Junior Senior, Under Byen, Raunchy, The Raveonettes, MØ oraz Trentemøller.
Literatura i filozofia.
Jednym z duńskich filozofów jest Søren Kierkegaard, który jest uznawany za jednego z prekursorów egzystencjalizmu. Innym filozofem jest Nikolai Frederik Severin Grundtvig (nauczyciel, pisarz, polityk, a także filozof, który odegrał ogromną rolę w kształtowaniu duńskiej świadomości narodowej) z Kirkegaardem. W czasach najnowszych filozofem jest Knud Ejler Løgstrup, który sam uważał się za kontynuatora dzieła Grundtviga. Jednym z duńskich pisarzy jest Hans Christian Andersen.
Kuchnia duńska.
Typowa duńska kuchnia jest połączeniem tradycyjnej kuchni Skandynawii z tradycjami kontynentalnymi. Posiłkowi towarzyszy koncepcja "hygge" (ciepłej i miłej atmosfery, odpowiedniego nastroju). Często spożywane są dania z ryb np.: makreli, śledzia (które bywają jadane w marynowanej słodkiej zalewie albo jako dodatek do kwaśnej śmietany i koperku). Bardzo popularne są kanapki tzw.: "smørrebrød", w których dodatkiem do pieczywa jest marynowana wieprzowina, duński bekon, surowa wołowina czy też marynowana na słodko czerwona kapusta. Jednym z najpopularniejszych dań typowo duńskich są "frikadeller", czyli kotlety mielone z mięsa wieprzowego i wołowego. Kolejnym słynnym daniem są smażone ziemniaki z cebulą i mięsem, zwane "biksemad".
Święta i uroczystości.
Urodziny.
Ważnym świętem każdego Duńczyka są jego własne urodziny. Początki tej tradycji sięgają XVI wieku. Duńska rodzina królewska przejęła ten zwyczaj od Niemców w 1536 roku, czyli 10 lat po przejściu Fryderyka I (ówczesnego króla Danii) na ewangelicyzm. Obchodzenie urodzin przez zwykłych obywateli zyskało popularność dopiero w XVIII wieku i różniło się pod pewnymi względami od świętowania, które znamy z czasów obecnych. Różnice te wynikają chociażby z tego, że tort (duń. Lagkage) oraz prezenty, bez których nie wyobrażamy sobie dzisiaj urodzin, pojawiły się w Danii dopiero pod koniec XIX wieku.
Tradycja ta jak widać jest mocno zakorzeniona w kulturze duńskiej oraz ma szczególne znaczenie, o czym świadczy fakt, że w dniu urodzin przed domem jubilata wiesza się duńską flagę ("DanneBrog)".
W noc poprzedzającą urodziny, gdy jubilat już śpi, wokół jego łóżka kładzione są prezenty, tak by były pierwszą rzeczą jaką zobaczy on zaraz po wstaniu. Jubilat budzony jest zazwyczaj przez członków rodziny urodzinową piosenką ("den danske fødselsdagsang"). Następnie cała rodzina udaje się do kuchni, by zjeść urodzinowe śniadanie. Na urodzinowym stole znajdziemy przede wszystkim "Boller" (kardamonowe bułeczki drożdżowe, w których ukryta jest malutka duńska flaga), "Brunsviger ("ciasto drożdżowe polane masłem z brązowym cukrem) oraz "Lagkage,", czyli tradycyjny tort ozdobiony małymi duńskimi flagami. W dniu urodzin śpiewa się również najprzeróżniejsze urodzinowe serenady, w tym najbardziej znaną, czyli "Tillykke."
Święto Trzech Króli.
Święto Trzech Króli zostało uznane oficjalnym dniem wolnym od pracy w 1770 roku po tzw. „Helligdagreformen” i wypada 6 stycznia. Wieczorem 5 stycznia Duńczycy spotykają się w gronie rodziny, aby zapalić specjalną świecę, która posiada 3 knoty. Po wypaleniu się świecy następuje trzask, który symbolizuje zakończenie okresu Bożego Narodzenia. Obecnie Święto Trzech Króli traci w Danii na znaczeniu, a 6 stycznia traktowany jest przez większość obywateli jako zwykły dzień.
Wielkanoc.
Wielkanoc (duń. Paske) w Danii jest postrzegana jako symbol zakończenia zimy. Święta Wielkanocne mogą rozpocząć się tutaj najwcześniej 22 marca, a najpóźniej 25 kwietnia i trwają od Wielkiego Czwartku do poniedziałku wielkanocnego.
W okresie świątecznym większość domów przystrojona jest w wiosenne kwiaty lub gałązki zdobione pisankami. Dzieje się tak nie bez powodu, bowiem jajka uważane są w tym kraju za najważniejszy symbol świąt. Duńczycy nie tylko obdarowują się nawzajem jajkami, ale również chowają je w ogrodzie.
Ze Świętami Wielkanocnymi w Danii związana jest szczególna tradycja pisania i wysyłania listów tzw. "gaekkebreve""." Każdy list jest bardzo indywidualny, różnorodny i co najważniejsze nie ma określonego wzoru. W liście pisze się rymowankę i wysyła ją do wybranej przez siebie osoby. Zadaniem adresata jest odgadnięcie od kogo "gaekkebrev" pochodzi. Jeżeli adresat nie odgadnie kto jest nadawcą listu, zostaje przezwany duńskim określeniem „gæk”, które można przetłumaczyć jako głupiec. Jeśli adresat odgadnie od kogo otrzymał list, to „gæk’iem” zostaje nadawca listu. Oczywiście „gæk” musi odpokutować swoje winy. W tym celu należy albo urządzić przyjęcie, albo podarować prezent osobie, z którą się przegrało.
W Danii na świątecznym stole znajdziemy przede wszystkim jajka przyrządzone w najprzeróżniejszych wariantach. W niektórych częściach Danii, jak np. na Jutlandii szczególnie popularne są jaja podawane z sosem musztardowym, tzw. "Skinde Æg". Dodatkowo na świątecznym stole nie może zabraknąć ciemnego pieczywa, śledzia, ryb, wędlin czy sera. Podczas świąt Duńczycy piją przede wszystkim sznapsa oraz specjalne „piwo” przyrządzane przez gospodynie domowe, które jest mocniejsze i przez to bardziej wyraziste w smaku od zwykłego piwa.
Boże Narodzenie.
Z całą pewnością grudzień można określić mianem wyjątkowego okresu w życiu Duńczyków. W tym miesiącu w wielu miastach odbywają się jarmarki świąteczne, ulice są barwnie ozdobione, a w ogródkach czy centralnych miejscach stoją choinki, które wprawiają mieszkańców w świąteczny nastrój. Zgodnie z tradycją, która trwa od 1914 roku, pierwsza oświetlona choinka w Danii musi zostać zapalona w Kopenhadze na Rådhuspladsen.
Grudzień jest również czasem, w którym Duńczycy wysyłają bliskim oraz znajomym kartki świąteczne, na których widnieje specjalny znaczek pocztowy tzw. "Julemærke". Każdego roku jest on inaczej zaprojektowany, a pieniądze z jego sprzedaży przekazywane są na cele charytatywne.
W grudniu Duńczycy zapalają specjalną świecę (duń. Kalenderlys), która składa się z 24 podziałek. Za jej pomocą odlicza się dni do Wigilii. Dodatkowo w większości domostw znajdziemy wieniec adwentowy zrobiony ze świerkowych gałązek, w którym umieszczone są 4 świece adwentowe. Świece adwentowe zapala się kolejno w 4 niedziele poprzedzające Boże Narodzenie.
Boże Narodzenie Duńczycy świętują w rodzinnym gronie. W Danii 23 grudnia określa się jako „Lille julaften”. Dzień ten uznawany jest również za dzień rozpoczynający święta.
Zgodnie z tradycją choinki ubierane są 24 grudnia. Ozdabia się je przede wszystkim małymi duńskimi flagami. Po przybraniu świątecznego drzewka układa się pod nim prezenty, które rozdawane są po wieczerzy wigilijnej. W odróżnieniu m.in. od państw europejskich, w Danii prezenty przynosi skrzat tzw. "Julenissen". Obecnie jest on jednak wypierany z duńskiej tradycji przez popularnego na całym świecie Świętego Mikołaja.
W Danii na wigilijnym stole nie może zabraknąć potraw takich jak m.in. pieczona kaczka (w niektórych wariantach również gęś) faszerowana suszonymi śliwkami i jabłkami, podawana z ziemniakami, czerwoną kapustą lub buraczkami i konfiturą z żurawiny, ryż a l’amande polany gorącym wiśniowym sosem oraz sałatka śledziowa. W tym dniu na stole nie może zabraknąć również deseru, z ukrytym migdałem. Osoba, która znajdzie migdał otrzymuje bowiem dodatkowy prezent. Z napojów popularne są przede wszystkim grzane wino tzw. "Glögg" oraz piwo „Julebryg”.

</doc>
<doc id="1125" url="https://pl.wikipedia.org/wiki?curid=1125" title="Direct Memory Access">
Direct Memory Access

Direct Memory Access, DMA (z ang. bezpośredni dostęp do pamięci) – technika, w której sprzęt komputerowy podłączony do płyty głównej, np. karta graficzna, karta dźwiękowa, karta sieciowa czy kontroler dysku twardego, mogą korzystać z pamięci operacyjnej RAM lub portów we-wy, pomijając przy tym CPU. Wymaga to niewielkiej współpracy ze strony procesora, który musi zaprogramować kontroler DMA do wykonania odpowiedniego transferu danych, a następnie na czas przesyłania danych zwolnić magistralę systemową (przejść w stan wysokiej impedancji). Natomiast sam transfer danych jest już zadaniem wyłącznie kontrolera DMA. Realizacja cykli DMA może być przejmowana przez dedykowany układ cyfrowy, tak jak np. w komputerach PC, lub być realizowana programowo przez dane urządzenie.
DMA ma za zadanie odciążyć procesor główny od przesyłania danych (np. z urządzenia wejściowego do pamięci). Procesor może w tym czasie zająć się innymi działaniami, wykonując kod programu pobrany uprzednio z pamięci RAM do pamięci podręcznej. Specjalizowane układy wspomagające DMA (np. te spotykane w PC), potrafią kopiować obszary pamięci dużo szybciej niż uczyniłby to programowo procesor główny.
Istnieje specjalna procedura DMA, "Scatter-Gather" (dosł.: „rozrzuć-zbierz”), pozwalająca przenosić dane do wielu obszarów pamięci w pojedynczym transferze. Pod względem skutków jest to równoważne połączeniu łańcuchowemu kilku transferów, jednak jest wyraźnie szybsze.

</doc>
<doc id="1126" url="https://pl.wikipedia.org/wiki?curid=1126" title="Dżul">
Dżul

 \right]&lt;/math&gt;
 |Wielkosc = pracy, energii, ciepła
 |WielkoscOzn = "W", "E", "Q"
 |SI-jedn = formula_1
 |CGS-jedn = formula_2
 |Imp-jedn = formula_3
 |Nazwisko = James Prescott Joule
 |Etymologia = 
 |JednPodstawowa = 
Dżul (J) (ang. "Joule") – jednostka pracy i energii – w tym ciepła – w układzie SI. Jeden dżul to praca wykonana przez siłę o wartości 1 N przy przesunięciu punktu przyłożenia siły o 1 m w kierunku równoległym do kierunku działania siły
Związek z mocą:
Nazwa "dżul" pochodzi od nazwiska angielskiego fizyka Jamesa Joule’a.
Przeliczenie 1 dżula na inne jednostki pracy, energii i ciepła:
Dżul a niutonometr.
Jednostką momentu siły jest N · m. Iloczyn niutona i metra to w układzie SI dżul, jednak – aby nie wprowadzać nieporozumień – jednostkę momentu siły nazwano niutonometrem (N · m) i nie zastępuje się jej dżulem.
Problem ten wiąże się z tym, że praca definiowana jest jako iloczyn skalarny siły i przemieszczenia, natomiast moment siły to iloczyn wektorowy siły i ramienia.
Przedrostki SI.
Wielokrotności i podwielokrotności jednostki (wyróżniono najczęściej używane):

</doc>
<doc id="1128" url="https://pl.wikipedia.org/wiki?curid=1128" title="Doktryna">
Doktryna

Doktryna (z łac. "doctrina" – nauczanie, wiedza) oznacza zespół twierdzeń, założeń i dogmatów religijnych, filozoficznych, politycznych lub wojskowych. System działania, myślenia.

</doc>
<doc id="1130" url="https://pl.wikipedia.org/wiki?curid=1130" title="Dywan Sierpińskiego">
Dywan Sierpińskiego

Dywan Sierpińskiego – fraktal otrzymany z kwadratu za pomocą podzielenia go na dziewięć (3x3) mniejszych kwadratów, usunięcia środkowego kwadratu i ponownego rekurencyjnego zastosowania tej samej procedury do każdego z pozostałych ośmiu kwadratów. Nazwa pochodzi od nazwiska Wacława Sierpińskiego.
Definicja formalna.
Niech formula_1 będzie kwadratem jednostkowym na płaszczyźnie kartezjańskiej formula_2 czyli formula_3
Dla danego formula_4 mając zbiór formula_5 będący sumą formula_6 kwadratów o bokach długości formula_7 i rozłącznych wnętrzach, definiujemy zbiór formula_8 będący sumą formula_9 kwadratów o bokach długości formula_10 i rozłącznych wnętrzach następująco:
każdy z kwadratów, których sumą jest zbiór formula_11 dzielimy na 9 kwadratów o bokach długości formula_10 i rozłącznych wnętrzach i usuwamy ze zbioru formula_11 wnętrza środkowych kwadratów.
Dywan Sierpińskiego D jest częścią wspólną ciągu zbiorów formula_14
Alternatywna definicja.
Dywan Sierpińskiego jest domknięciem zbioru punktów formula_16 takich że w rozwinięciu liczb formula_17 i formula_18 w trójkowym systemie liczbowym nigdzie nie występuje cyfra 1 na tym samym miejscu po przecinku.
Topologicznym dywanem Sierpińskiego nazywamy każdą przestrzeń topologiczną homeomorficzną z powyżej zdefiniowanym dywanem Sierpińskiego.
Własności dywanu Sierpińskiego.
skąd:

</doc>
<doc id="1131" url="https://pl.wikipedia.org/wiki?curid=1131" title="Druga zasada termodynamiki">
Druga zasada termodynamiki

Druga zasada termodynamiki – podstawowe prawo termodynamiki, stwierdzające, że w układzie termodynamicznie izolowanym istnieje funkcja stanu, która nie maleje z czasem.
Funkcja ta zwana jest entropią i oznacza się ją symbolem formula_1 Zmiana formula_2 tej funkcji spełnia więc nierówność formula_3 przy czym równość zachodzi wtedy i tylko wtedy, gdy proces jest odwracalny.
Definicja w terminach termodynamiki klasycznej.
Sformułowanie oparte na pojęciu entropii.
Matematyczny zapis tego faktu to następujące sformułowanie: zmiana entropii formula_2 w dowolnym procesie odwracalnym jest równa całce z przekazu ciepła formula_5 podzielonego przez temperaturę formula_6 W procesie nieodwracalnym natomiast zmiana entropii jest większa od tej całki. Forma całkowa II zasady termodynamiki wygląda następująco:
Różnica ta jest miarą nieodwracalności procesu i jest związana z rozpraszaniem energii. Oznaczenie formula_5 użyte do zapisu przyrostu ciepła ma na celu odróżnienie tego przyrostu od różniczki (ozn. formula_9), ponieważ przyrost ciepła nie jest różniczką żadnej funkcji. Gdyby był różniczką, ciepło byłoby funkcją stanu (jest zaś funkcją procesu).
Alternatywne sformułowania.
Druga zasada termodynamiki może być sformułowana na wiele równoważnych sposobów. Wiele z nich nie wymaga odwoływania się do abstrakcyjnych pojęć, takich jak entropia, umożliwiając łatwiejsze zrozumienie fizycznej istoty tego prawa.
Najszerzej znane alternatywne sformułowania pochodzą od Clausiusa:
oraz od Kelvina:
Można udowodnić równoważność tych stwierdzeń ze sformułowaniem podanym w rozdziale poprzednim.
Wprowadzając pojęcie perpetuum mobile drugiego rodzaju, jako silnik cieplny pobierający energię cieplną z układu i w całości przekształcający ją na pracę, można sformułować drugą zasadę termodynamiki w następujący sposób:
Trzy powyższe sformułowania odnoszą się do ograniczeń, jakie nakłada II zasady termodynamiki na maszyny cieplne.
Istnieje też ogólne fenomenologiczne sformułowanie II zasady termodynamiki abstrahujące od jakichkolwiek maszyn cieplnych, a zarazem nieodnoszące się do pojęcia entropii, podane na początku XX wieku przez Caratheodory’ego:
Można wykazać, że sformułowanie to jest równoważne sformułowaniu opartemu na pojęciu entropii.
Definicja w terminach termodynamiki statystycznej.
W przypadku połączenia tych części (np. zmieszanie płynów), entropia nie spełnia warunku addytywności.
Dowód.
Praca objętościowa.
Rozważmy pracę objętościową wykonaną przez układ termodynamiczny. Jest ona określana przez ilość pracy wykonaną w otoczeniu, więc odpowiednim ciśnieniem jest ciśnienie zewnętrzne otoczenia formula_12 Wtedy praca wykonana przez układ wynosi:
Jeżeli ciśnienie wewnętrzne układu jest większe niż ciśnienie zewnętrzne otoczenia: formula_14 wówczas zgodnie z mechaniką klasyczną układ będzie się rozszerzał względem otoczenia: formula_15 Dla przemiany odwracalnej ciśnienie wewnętrzne i zewnętrzne są równe: formula_16 a więc praca wykonana przez układ w procesie odwracalnym wynosi:
Z tego wynika, że:
Oznacza to, że ilość pracy wykonanej przez układ nad otoczeniem jest maksymalna w procesie odwracalnym. Połączenie tego wyniku z pierwszą zasadą termodynamiki daje:
Teraz definiujemy funkcję stanu formula_22 (zwaną entropią) jako:
Z poprzedniej nierówności dla odwracalnego ciepła:
Co kończy dowód.
Jest to kompletne matematyczne sformułowanie drugiej zasady termodynamiki. Można z niej wyprowadzić wszystkie jej konsekwencje, w tym stwierdzenie, że ciepło zawsze spontanicznie przepływa tylko od ciała cieplejszego do zimniejszego.
Brakuje jedynie udowodnienia, że entropia formula_22 jest funkcją stanu dla gazu doskonałego, ale można go znaleźć w każdym wstępnym omówieniu termodynamiki.
Mechanika statystyczna.
II zasadę termodynamiki można również udowodnić za pomocą mechaniki statystycznej.
Mając daną funkcję statystyczną Boltzmanna formula_26
oraz entropię Boltzmanna:
otrzymujemy:
a różniczkując powyższe:
Wiedząc, że formula_33 (z tego formula_34) oraz formula_35 (z tego formula_36),
wynika, że
czyli formula_38 (zmiana entropii Boltzmanna jest nieujemna), co kończy dowód.
Wnioski z II zasady termodynamiki.
Silnik cieplny nie może działać bez różnic temperatury.
Inne, równoważne sformułowanie drugiej zasady termodynamiki wiąże się z silnikiem cieplnym, czyli urządzeniem zamieniającym ciepło na pracę. Zgodnie z tym sformułowaniem spontaniczny przekaz ciepła może się dokonywać tylko od ciała cieplejszego do zimniejszego. Idealny silnik, pracujący w cyklu przemian odwracalnych, ma sprawność formula_39 ograniczoną różnicą temperatur ciał, pomiędzy którymi przekazywane jest ciepło:
gdzie ciepło jest przekazywane od ciała o temperaturze formula_43 do ciała o temperaturze formula_44 (grupa fizyków z Niemiec teoretycznie udowodniła, że powyższy wzór w pewnych szczególnych warunkach nie jest spełniony dla kwantowego cyklu Otto, co nie łamie jednak II zasady termodynamiki). Silnik spełniający tę regułę jest nazywany silnikiem Carnota.
Z II zasady termodynamiki zastosowanej do silników cieplnych wynika, że nie można ciepła zamieniać na pracę bez ograniczeń, choć jest to zgodne z I zasadą termodynamiki. Nie można bez wkładu pracy przesyłać energii termicznej między ciałami mającymi tę samą temperaturę. Oznacza to, że perpetuum mobile II rodzaju nie istnieje.
Prowadzi to do dalszego wniosku – nie da się w pełni kontrolować procesów statystycznych, np. nie można czerpać energii z przypadkowych ruchów cząstek, takich jak ruchy Browna (wykorzystywane w pomyśle zapadki brownowskiej). Z II zasady wynika, że przyrządy do czerpania tego rodzaju energii po pewnym czasie też zaczną się zachowywać przypadkowo, a więc staną się bezużyteczne. Miarą tej przypadkowości jest właśnie temperatura. Aby czerpać energię termiczną z układu, trzeba dysponować czymś zimniejszym niż ten układ.
Energia swobodna Helmholtza.
Energia swobodna Helmholtza formula_45 jest funkcją stanu odpowiadającą tej części energii wewnętrznej, która może być w danym procesie uwolniona na zewnątrz układu w formie pracy lub ciepła przy stałej temperaturze i objętości.
W pierwszej zasadzie termodynamiki możemy zastąpić zmianę ciepła formula_46 przez formula_47
Mając na uwadze drugą zasadę formula_49 otrzymujemy:
Dlatego praca maksymalna jest zawsze większa lub równa energii swobodnej Helmholtza. Innymi słowy, pewnej ilości energii wewnętrznej formula_52 nigdy nie można całkowicie zamienić na pracę, część jest zawsze tracona z powodu wzrostu entropii.
Ostatnią nierówność można przekształcić do postaci:
To wyrażenie przyjmuje maksymalną wartość, gdy przemiana jest odwracalna. W przypadku przemian nieodwracalnych:
co w sumie można zapisać:
Śmierć cieplna Wszechświata.
Z II zasady termodynamiki wynika też hipoteza tzw. śmierci cieplnej Wszechświata. Miałaby ona polegać na tym, iż po jakimś czasie Wszechświat, jako całość, dojdzie do stanu równowagi termodynamicznej, czyli będzie miał jednakową temperaturę w każdym punkcie i wymiana energii termicznej całkowicie zaniknie, a co za tym idzie zanikną wszelkie inne rodzaje wymiany energii, które w ten czy inny sposób są zawsze związane ze zmianą temperatury. Teoria śmierci cieplnej jest jednak nadinterpretacją, wynikającą z przeniesienia rozumowania pochodzącego z fizyki fenomenologicznej w dziedzinę przekraczającą zakres jej stosowalności – do kosmologii. II zasada termodynamiki odnosi się do układów w stanie równowagi pełnej lub niepełnej i nie ma zastosowania do rozszerzającego się Wszechświata, w którym zmianom ulega np. pole grawitacyjne.
Paradoks nieodwracalności.
Z interpretacją II zasady termodynamiki jest też związany swoisty paradoks. Z jednej strony wynika z niej, że wiele zjawisk obserwowanych w skali makroskopowej może być nieodwracalnych. Definiuje tak zwaną termodynamiczną (lub entropijną) strzałkę czasu. Z drugiej strony termodynamika statystyczna, z której ta zasada się wywodzi, zakłada, że każde jednostkowe zjawisko w skali mikroskopowej, czyli w skali pojedynczych cząstek jest odwracalne. Mimo że wszystkie zjawiska makroskopowe są sumą odwracalnych zjawisk mikroskopowych, przyjmuje się jednak – wbrew zdrowemu rozsądkowi – możliwość ich nieodwracalności. Paradoks ten przyczynił się do początkowego odrzucenia równania Boltzmanna, opisującego procesy nierównowagowe.
Ten paradoks wskazuje na ścisły związek między teorią a pomiarem w fizyce. Interpretacja pomiaru układów wielocząstkowych jest oparta na teoriach tworzonych dla układów makroskopowych. Można powiedzieć, że pomiary te dotyczą sum uśrednionych zjawisk mikroskopowych. Dla takich pomiarów koncepcja entropii jest niezbędna teoretycznie. Gdyby jednak dało się w jakiś sposób przejść do pomiaru tych zjawisk na poziomie pojedynczych cząstek, koncepcja entropii przestałaby być potrzebna. Liczba cząstek w rzeczywistych, makroskopowych układach doświadczalnych jest jednak bardzo duża (rzędu stałej Avogadra) i dlatego pomiar większości zjawisk fizycznych na poziomie mikroskopowym jeszcze długo pozostanie poza zasięgiem nauki.
Ściśle II zasada termodynamiki jest sprzeczna zarówno z mechaniką klasyczną, jak i kwantową, a dokładnie ze zjawiskiem tzw. dokładnego ożywienia funkcji falowej, jak też z twierdzeniem Poincaré o powrocie i najprawdopodobniej dlatego, że dotyczy ona jedynie pewnych początkowych stadiów ich ewolucji lub też że układy matematycznie perfekcyjnie izolowane z wyjątkiem całego wszechświata naprawdę nie istnieją. W prawie nieskończonej ewolucji klasycznej lub kwantowej izolowanego układu fizycznego entropia będzie maleć spontanicznie, kiedy będą one odtwarzać swój stan początkowy. Np. zgodnie z twierdzeniem Poincarégo zamknięty we wnęce rezonansowej silnik Carnota po wyrównaniu się temperatur i prawie nieskończonym czasie zacznie pracować magicznie wstecznie, tak że temperatura w zbiorniku A zacznie rosnąc, a w B maleć, aby cały układ wrócił do stanu początkowego dokładnie. Inaczej zgodnie z teorią mikroskopową, każdy proces w układzie termodynamicznie izolowanym jest infinitezymalnie dokładnie odwracalny i wartość entropii musi kiedyś wrócić do jej wartości początkowej malejąc.

</doc>
<doc id="1132" url="https://pl.wikipedia.org/wiki?curid=1132" title="Demografia">
Demografia

Demografia – dziedzina nauki zajmująca się powstawaniem, życiem i przemijaniem społeczności ludzkiej. Obejmuje m.in. takie zagadnienia jak: przyrost naturalny, migracje, struktura społeczna (wiek, płeć, przynależność zawodowa, narodowość, wyznanie) oraz ich rozmieszczenie przestrzenne i oddziaływania społeczne i socjologiczne.
Historia.
Początki demografii to XVII w. – w r. 1662 pojawiło się opracowanie Johna Graunta „Natural and Political Observations ... upon the Bills of Mortality” utrzymane w formie prymitywnych, matematycznych tabeli, podobnych do tych, które później tworzył Edmond Halley, jako podstawę obliczeń prawdopodobieństw dla tworzonych właśnie ubezpieczeń na życie. Pod koniec XVIII wieku Thomas Malthus twierdził, że niekontrolowany przyrost naturalny prowadzić będzie do wykładniczego wzrostu liczby ludności i związanej z tym klęski głodu, spowodowanej dyskrepancją pomiędzy wzrostem populacji a przyrostem produkcji żywności. (zobacz pułapka maltuzjańska, statyczna teoria zasobów). Thomas Malthus jest uważany za ojca teorii przeludnienia, która była rozwijana i urealistyczniana w późniejszych opracowaniach (np. Gompertza i Verhulsta).
Metodyka.
Demografia uzyskuje dane do swych badań z publikacji statystycznych, reprezentatywnych prób statystycznych i ze spisów ludności.
Do badań nad procesami demograficznymi używa się między innymi statystyk meldunkowych, z których uzyskuje się np. współczynnik urodzeń, współczynnik zgonów, współczynnik przyrostu naturalnego, współczynnik dzietności, saldo migracji, oczekiwaną długość życia itp.
Typowe dla demografii jest również graficzne obrazowanie danych (np. piramida płci i wieku).
W demografii historycznej, czyli przed rokiem 1850 używa się rejestrów parafialnych, kościelnych spisów wiernych, spisów podatkowych, rachunków dóbr wielkiej własności itp.
Rozwój demograficzny.
Modele transformacji demograficznej.
Model transformacji demograficznej (ang. "demographic transition"), zwany również przejściem demograficznym, nie jest teorią w znaczeniu ściśle naukowym, lecz opisem modelowym przejścia od wysokich do niskich współczynników śmiertelności i urodzeń oraz wynikającej z nich zmiany przyrostu naturalnego.
Pierwszymi, którzy stworzyli podstawy tego modelu, byli Thompson (1929) i Notestein (1945). Ich prace zostały później rozwinięte, zmodyfikowane i polepszone przez innych autorów.
Model transformacji znajduje zastosowanie np. przy:
Model 4-fazowy.
Pierwotny model transformacji był podzielony na 4 fazy:
Model 5-fazowy.
Dla lepszego zrozumienia i poprawy opisu zmian zachodzących w populacji stworzono "Model transformacji demograficznej" ("theory of demographic transition"). Model ten dzieli transformację (zmianę) zachodzącą w populacji na 5 faz. Są to:
Zmienny model transformacji demograficznej.
Empirycznie stwierdzona transformacja demograficzna (przechodzenie od wysokich do niskich wskaźników urodzeń i zgonów) nie przebiegała identycznie we wszystkich krajach Europy. W Anglii trwała ona np. ok. 200 lat, podczas gdy w krajach takich jak Holandia czy Niemcy – ok. 70–90 lat. Nie tylko czas trwania, lecz również rozbieżność (nożyce) pomiędzy wskaźnikami urodzeń i zgonów były spore. Wyjątek stanowiła np. Francja, gdzie obniżenie wskaźników urodzeń i zgonów przebiegło niemal równocześnie, co przejawiło się niemal stałą liczbą ludności, w przeciwieństwie do innych krajów Europy, gdzie notowano spore przyrosty i tym samym otwarcie nożyc.
By lepiej opisać tego typu odchylenia, rozwinięto w latach 1980. zmienny model transformacji demograficznej. Przedstawiając liczne krzywe dla urodzeń (u1, u2 i u3) i zgonów (z1, z2 i z3) o różnym nachyleniu, można na jednym modelu śledzić różne procesy transformacji demograficznej.
Przykładowo:
Regiony.
Polska.
W okresie kształtowania się państwowości Polska obejmowała swym zasięgiem ziemie o powierzchni ponad ćwierć miliona km² z przeszło milionem mieszkańców. Za czasów Kazimierza Wielkiego obszar państwa (około 270 tys. km²) zamieszkiwało ponad 2,5 miliona osób. Dopiero unia z Litwą przyniosła radykalny przyrost demograficzny i terytorialny. Za czasów Batorego obszar państwa zbliżył się do 1 miliona km², zaś ludność w końcu XVI wieku prawdopodobnie osiągnęła 9 milionów. W chwili utraty niepodległości wielonarodowościowe państwo liczyło co najmniej 13-14 milionów mieszkańców, przy czym przez cały okres wspólnej państwowości z Litwą znaczną część ludności stanowiły osoby posługujące się innym językiem niż polski (w końcu XVIII wieku było ich ok. 60%). Po odzyskaniu niepodległości w granicach Polski znalazło się kilka milionów osób o innej niż polska narodowości, tak więc Polska przed II wojną światową była krajem wielonarodowościowym, gdzie mniejszości stanowiły powyżej 1/3 ludności. W okresie między 1921 rokiem a wybuchem II wojny światowej, liczba ludności wzrosła z 27,2 mln do 35,2 mln. Jednak zmiany granic Polski po wojnie oraz przesiedlenia sprawiły, że obecnie Polska jest krajem nieomalże jednolitym etnicznie. Wszystkie mniejszości narodowe łącznie nie przekraczają 3% ludności.
Polacy należą do ludów słowiańskich. Posługują się językiem polskim, należącym do rodziny języków słowiańskich. Dla części Polaków językiem ojczystym jest blisko z nim spokrewniony język kaszubski. Język polski jest językiem urzędowym kraju, jakkolwiek prawo gwarantuje mniejszościom narodowym używanie ich własnych języków, zwłaszcza na obszarach, gdzie występują ich większe skupiska. Według Narodowego Spisu Powszechnego (2002) 97,8% mieszkańców Polski używa w domu języka polskiego. Najbardziej popularne języki mniejszości to: niemiecki, ukraiński, białoruski, cygański, rosyjski, litewski i łemkowski.
Według Światowej Organizacji Zdrowia (WHO), 2003:
Europa.
Europa z 724 mln (stan 2005) mieszkańców jest trzecim co do liczby ludności kontynentem po Azji i Afryce i należy do najgęściej zaludnionych części naszej planety. Średnia gęstość zaludnienia w Europie wynosi ok. 70 mieszkańców/km². Największą gęstość zaludnienia na kontynencie mają kraje Europy zachodniej, środkowej i południowej, maleje ona na północy i wschodzie kontynentu (kraje skandynawskie i Rosja).
Świat.
Z perspektywy światowej poważnym problemem jest zjawisko eksplozji demograficznej, co ostatecznie grozi przeludnieniem naszej planety. Źródłem problemu jest wysoki przyrost naturalny przy malejącym współczynniku zgonów w wielu krajach (szczególnie afrykańskich i azjatyckich). Niektóre z nich próbowały i próbują nadal prowadzić aktywną ogólnokrajową kontrolę urodzin (np. poprzez wysokie podatki za drugie dziecko w Chinach).
Dane statystyczne i prognozy.
Poniższa tabela przedstawia rozwój demograficzny ludności w poszczególnych regionach świata w latach 1750–2050 w tys., przy czym lata po roku 2005 podają wartości prognozowane.

</doc>
<doc id="1133" url="https://pl.wikipedia.org/wiki?curid=1133" title="Dewon">
Dewon

Dewon – termin o dwojakim znaczeniu:
Nazwa pochodzi od hrabstwa Devon (w południowo-zachodniej Anglii), skąd pochodzą pierwsze zbadane skały tego systemu. System dewoński wydzielili Roderick Murchison i Adam Sedgwick w 1839 roku.
Na mapach i przekrojach geologicznych skały dewońskie znaczy się barwą brązową.
Paleogeografia i geologia.
We wczesnym dewonie doszło do ostatecznego zamknięcia się oceanu Japetus wskutek zderzenia dwóch kontynentów: Laurencji i Bałtyki. W wyniku tego zderzenia powstał jeden duży kontynent – Laurosja – znajdujący się w położeniu równikowym, z pasmem górskim kaledonidów. Na półkuli północnej obecne były mniejsze kontynenty: Syberia i Chiny. Południową półkulę zajmował olbrzymi kontynent Gondwana, oddzielony od Laurosji oceanem Reik, a od Chin i Syberii oceanem Paleotetydą. Wszystkie kontynenty otaczał ocean Panthalassa. Dewon charakteryzował się ciepłym klimatem z ochłodzeniem pod koniec tego okresu.
Dla regionu europejskiego charakterystycznymi osadami dolnego dewonu są skały terygeniczne facji oldredowej (głównie zlepieńce, piaskowce). W dewonie środkowym i górnym występują najczęściej osady węglanowe facji płytkowodnej i rafowej (różne typy wapieni, czasami zdolomityzowane, także margle i łupki margliste).
Bogactwa naturalne.
Formacje dewońskie zawierają złoża pirytu, rud miedzi, rud cynku i ołowiu oraz surowce węglanowe (wapienie, margle, dolomity) i okruchowe (piaskowce kwarcytowe, łupki fyllitowe).
Flora.
W morzach rozwijają się glony. Prócz chryzofitów i zielenic występują w większej liczbie brunatnice, ramienice i krasnorosty. Spotyka się również więcej grzybów.
Na florę lądową dewonu wczesnego i środkowego składały się pierwotne rośliny naczyniowe: psylofity (ryniofity, trymerofity i zosterofilofity). Pojawiają się pierwsze mszaki, skrzypy, paprocie zarodnikowe, widłaki jednozarodnikowe. W późnym dewonie pojawiają się widłaki różnozarodnikowe, klinolisty i pierwsze rośliny nasienne (paprocie nasienne). Po raz pierwszy pojawia się również drzewiasty pokrój roślin naczyniowych. Pod koniec dewonu wymierają psylofity.
Fauna.
Wczesny dewon to ostatnia epoka życia planktonicznych graptolitów właściwych. Plankton tworzą tentakulity i małżoraczki o dużym znaczeniu biostratygraficznym. Rozwijają się rafy budowane przez koralowce (koralowce czteropromienne i denkowce), stromatoporoidy i gąbki. Rozwijają się znacznie ramienionogi (w tym rząd Spiriferida) i liliowce. Mniejsze znaczenie mają trylobity, pośród których w późnym dewonie wymierają Lichida, Odontopleurida i Phacopida. Pojawiają się pierwsze amonity (agoniatyty, goniatyty, wywodzące się z baktrytów, a w famenie – klymenie, które z końcem dewonu wymierają). Rozwijają się w dalszym ciągu konodonty, które razem z amonitami dostarczają najważniejszych skamieniałości przewodnich. Wśród stawonogów pojawiają się przodkowie kikutnic (Palaeopantopodida) i muszloraczki (Conchostraca). Pod koniec dewonu wymierają tentakulity i pęcherzowce (Cystoidea).
W dewonie następuje silny rozwój ryb. Prócz istniejących już w sylurze bezszczękowców (Agnatha), pierwszych szczękowych ryb fałdopłetwych (Acanthodii) i pierwszych ryb kostnochrzęstnych (Chondrostei) pojawiają się inne ryby chrzęstnoszkieletowe (prażarłacze Cladoselachii) oraz zrosłogłowe (Holocephali) – ryby pancerne (tarczowce; Placodermi). Zaczynają występować również pierwsze ryby mięśniopłetwe (Sarcopterygii): trzonopłetwe (Crossopterygii) i dwudyszne (Dipnoi), przystosowane do życia w środowiskach słodkowodnych. Pod koniec dewonu wymierają ryby pancerne.
We wczesnym dewonie pojawiają się pierwsze lądowe owady (skoczogonki, na przykład "Rhyniella"), wije i pajęczaki (między innymi roztocze i zaleszczotki). Natomiast w późnym dewonie pojawiają się formy przejściowe pomiędzy rybami a płazami ("Ichthyostega"), pochodzące od ryb trzonopłetwych, na przykład "Tiktaalika".
Na przełomie franu i famenu dochodzi do wielkiego wymierania – jednego z pięciu największych kryzysów biotycznych fanerozoiku.

</doc>
<doc id="1134" url="https://pl.wikipedia.org/wiki?curid=1134" title="Dante Alighieri">
Dante Alighieri

Dante Alighieri (ur. w maju lub czerwcu 1265 we Florencji, zm. 13 lub 14 września 1321 w Rawennie) – włoski poeta, filozof i polityk, charakteryzowany przez Fryderyka Engelsa jako „ostatni poeta średniowiecza i jednocześnie pierwszy poeta nowych czasów”.
Jego najwybitniejszym dziełem jest poemat "Boska komedia", uważany za arcydzieło literatury światowej i szczytowe osiągnięcie literatury średniowiecznej. Utwór jest w całości napisany po włosku.
Życiorys.
Urodził się we Florencji w drobnoszlacheckiej rodzinie. Nazwisko Alighieri pochodzi od gockiego Aldiger, które nosiła jego babka z Ferrary. Ród Dantego należał do partii gwelfów, on sam przystał do Białych – jednej z dwóch frakcji, na jakie dzieliło się stronnictwo. W 1289 roku wziął udział w bitwie pod Campaldino.
Studiował retorykę, gramatykę, filozofię, literaturę oraz teologię. Był członkiem ruchu poetyckiego Dolce stil novo. Znał i przyjaźnił się z wieloma jego członkami, między innymi Guido Cavalcantim, utrzymywał też kontakty z muzykiem Casellą i malarzem Giottem. Około roku 1285 ożenił się z Gemmą di Manetto Donati, z którą miał troje lub czworo dzieci. Wcześniej przeżył nieszczęśliwą miłość. Zakochał się w Beatrycze Portinari, po jej przedwczesnej śmierci w 1290 roku napisał swą pierwszą książkę, zatytułowaną "Vita nuova" ("Życie nowe"), w której w postaci zbioru poezji połączonych z pamiętnikiem opisuje dzieje swego uczucia. Książka została ukończona około 1294 roku. Swą ukochaną umieścił w "Boskiej komedii" – przeprowadza go przez Niebo.
W latach 1295–1300 zaangażował się politycznie, co zostało uwieńczone powołaniem go na urząd priora w roku 1300, wstąpił też do cechu lekarzy i aptekarzy, gdyż było to warunkiem rozpoczęcia kariery politycznej. Brał udział w zabiegach o odnowienie ligi miast gwelfickich, między innymi w poselstwie do papieża, który zatrzymał go jako zakładnika. Uchroniło go to od zemsty Czarnych, którzy zdobyli przewagę nad Białymi we Florencji. Został jednak oskarżony, skazany na grzywnę i dwa lata wygnania. Dante nie zapłacił grzywny, przez co ściągnął na siebie karę dożywotniego wygnania, a w przypadku powrotu – spalenie na stosie. Przez resztę życia błąkał się po różnych dworach Włoch i rozwijał talent pisarski. Nigdy jednak nie powrócił do swojej ojczyzny, choć oferowano mu amnestię. Zmarł w Rawennie w nocy z 13 na 14 września, wkrótce po zakończeniu pisania "Boskiej komedii".
"Boska komedia".
Najbardziej znanym utworem Dantego jest "Boska komedia", nad którą pracował od 1308 roku aż do śmierci w 1321. Jako pierwszy pisał w dialekcie toskańskim. Dante uważał, że utwory literackie należy pisać w językach narodowych, a łacinę powinno się ograniczyć do rozpraw naukowych.
Jest to wizjonerski poemat o podróży przez Piekło, Czyściec i Raj, zawierający kwintesencję średniowiecznej myśli kulturalnej i filozoficznej. Dzieło to zostało również nasycone licznymi współczesnymi wątkami z życia społecznego i politycznego. Dzieło pierwotnie nosiło tytuł "Komedia", którym w średniowieczu określano utwory o szczęśliwym zakończeniu. Dopiero Giovanni Boccaccio dodał do tytułu epitet "Boska".
Widoczna jest w "Boskiej komedii" fascynacja symboliką liczb, przede wszystkim liczbami 3 i 9. Zarówno Piekło, Czyściec, jak i Raj mają po 9 poziomów (3×3). Do "Piekła", I części "Boskiej komedii", nawiązuje związek frazeologiczny „sceny dantejskie”, oznaczający wydarzenia wstrząsające, straszne, budzące grozę; wyrażenie określa zazwyczaj zachowania się tłumu ogarniętego paniką, rozpaczą, w momencie katastrofy, kataklizmu.
Twórczość Dantego.
Wybrane prace Dantego:
Dante i muzyka.
Dante wielokrotnie wypowiadał się o muzyce z wielkim entuzjazmem. Jego poezja inspirowała wielu kompozytorów. W XVI w. do jego poezji komponowano liczne madrygały. W XIX i XX w. jego liryki, a przede wszystkim "Boska komedia", zainspirowały kilkadziesiąt utworów w różnych gatunkach, wśród nich "Symfonię Dantejską" Franciszka Liszta, fantazję symfoniczną "Francesca da Rimini" Piotra Czajkowskiego, poemat symfoniczny "Beatrycze" Feliksa Nowowiejskiego, operę "Francesca da Rimini" Siergieja Rachmaninowa, operę "Gianni Schicchi" Giacomo Pucciniego. Także w XXI wieku nie ustała fascynacja językiem staro-włoskim, czego przykładem jest francuska piosenkarka Emma Shapplin, której twórczość: płyty Carmine Meo i Etterna, nagrane w języku Dantego, rozeszły się w wielomilionowych nakładach.
Upamiętnienie w Polsce.
Od roku 1973 na terenie obecnej dzielnicy Bielany w Warszawie znajduje się ulica imienia Dantego. W 2012 roku nazwę uzupełniono o nazwisko Alighieri.

</doc>
<doc id="1135" url="https://pl.wikipedia.org/wiki?curid=1135" title="Dziwna wojna">
Dziwna wojna

Dziwna wojna (, – dosł. "udawana wojna", – dosł. "wojna na siedząco") – kolokwialna definicja sytuacji, jaka miała miejsce w pierwszym okresie II wojny światowej na froncie zachodnim po formalnym wypowiedzeniu przez Francję i Wielką Brytanię 3 września 1939 roku wojny III Rzeszy po zaprzestaniu faktycznych działań wojennych na lądzie (tzw. ofensywa w Saarze) w okresie od października 1939 r. do kampanii francuskiej w maju 1940 roku.
Geneza i podłoże.
Podłoże wydarzeń stanowiła decyzja podjęta 12 września 1939 przez Najwyższą Radę Wojenną francusko-brytyjską w Abbeville, o niepodejmowaniu generalnej ofensywy lądowej na froncie zachodnim i działań powietrznych RAF nad Niemcami i o, niedokonanym ostatecznie (aby nie prowokować Mussoliniego, z uwagi na niedużą odległość od Włoch), rozlokowaniu anglo-francuskich sił militarnych w pobliżu Salonik i Stambułu, skąd miała być przeprowadzona ofensywa w kierunku Niemiec i ZSRR.
Decyzja ta była złamaniem zobowiązań wynikających z umów sojuszniczych – konwencji wojskowej do sojuszu polsko-francuskiego (zobowiązującej sojusznika do ofensywy w ciągu piętnastu dni od ogłoszenia mobilizacji) i układu polsko-brytyjskiego z 25 sierpnia 1939 roku. Było to ponadto sprzeczne z deklaracjami złożonymi przez Francuzów i Brytyjczyków polskiemu ministrowi spraw wojskowych Tadeuszowi Kasprzyckiemu podczas misji do Londynu i Paryża wiosną 1939. Zdaniem m.in. Leszka Moczulskiego była to klasyczna felonia – zdrada sojusznika na polu bitwy. Ambasadorowie Rzeczypospolitej, w Wielkiej Brytanii – Edward Bernard Raczyński i we Francji – Juliusz Łukasiewicz, bezskutecznie próbowali wyegzekwować we wrześniu 1939 wywiązanie się krajów sojuszniczych z zobowiązań zaciągniętych wobec Polski.
Generał Louis Faury, który został mianowany szefem francuskiej misji wojskowej w Polsce i przybył do Polski w końcu sierpnia 1939, opisał później swą rozmowę z generałami Gamelinem i Georges’em, która odbyła się 22 sierpnia 1939, a więc jeszcze przed zawarciem paktu Ribbentrop-Mołotow. 
Na założeniu ofensywy sojuszniczej w piętnastym dniu od mobilizacji francuskiej oparty był plan obrony „Z” i strategia obrony terytorium Polski Edwarda Rydza-Śmigłego. Brak interwencji militarnej Brytyjczyków i Francuzów umożliwił siłom niemieckim i (od 17 września 1939 roku) sowieckim pokonanie wojsk polskich i rozbiór państwa polskiego.
Przebieg.
Do końca działań wojennych w Polsce III Rzesza nie była w stanie przerzucić z frontu polskiego na zachód żadnych jednostek bojowych (z wyjątkiem jednej dywizji górskiej). Był to jedyny okres, gdy alianci na froncie zachodnim, dzięki obronie Wojska Polskiego posiadali przewagę liczebną i strategiczną nad Wehrmachtem, poza lotnictwem, gdyż Niemcy pozostawili na froncie zachodnim dla celów obronnych dwie z czterech Luftflotten (Luftflotte 2. i Luftflotte 3). Okres ten został całkowicie niewykorzystany, co było podstawową przyczyną klęski wojsk francusko-brytyjskich w roku 1940, gdy III Rzesza mogła skupić wszystkie swoje siły wojskowe na jednym froncie – nie uzyskując mimo to ani przewagi liczebnej, ani materiałowej (z wyjątkiem lotnictwa) nad armiami francuską, brytyjską, belgijską i holenderską. 
Ian Kershaw:
Okres ów zyskał różne nazwy w wielu językach:
po francusku "la Drôle de Guerre", po angielsku "phony/phoney war", czyli "udawana wojna", po niemiecku "Sitzkrieg", czyli "wojna na siedząco" jako przeciwieństwo i nawiązanie do "Blitzkrieg" – wojny błyskawicznej, Brytyjczycy nazywali ją jeszcze czasem "Bore War", czyli "nudną wojną", co było żartobliwym nawiązaniem (grą słów) do wojen burskich (ang. "Boer Wars").
Liczne dywizje francuskie oczekiwały na działania Niemców, wierząc, że umocnienia Linii Maginota uchronią Francję przed podzieleniem losu Polski. Działania lądowe Francuzów ograniczały się do nielicznych patroli na przedpolu niemieckiej Linii Zygfryda. Niemcy z kolei zajmowali stanowiska na Linii Zygfryda, przygotowując wojska do dalszych działań ofensywnych po podbiciu Polski.
Jednocześnie Francuska Partia Komunistyczna po zawarciu paktu Ribbentrop-Mołotow rozpoczęła kampanię antywojenną, posuwając się do wzywania żołnierzy francuskich do dezercji. Sekretarz generalny Francuskiej Partii Komunistycznej Maurice Thorez, powołany do wojska zdezerterował, uciekł do ZSRR i został przez sąd wojenny Francji skazany na śmierć za dezercję. Konsekwencją działań FPK była oficjalna delegalizacja francuskiej partii komunistycznej jeszcze we wrześniu 1939 jako ugrupowania antypaństwowego. Propaganda FPK nie pozostała jednak bez skutku na morale armii francuskiej i postaw żołnierzy w czasie bitwy o Francję.
W tym okresie przybyły do Francji siły lądowe Brytyjskiego Korpusu Ekspedycyjnego. Działania na niewielką skalę prowadziło jedynie lotnictwo alianckie, bombardując przygraniczne fabryki oraz dokonując nieskutecznych nalotów na Kriegsmarine. Przez początkowy okres RAF zrzucało głównie ulotki nad miastami niemieckimi. Obie strony wykonywały loty rozpoznawcze, w czasie których dochodziło do walk powietrznych. Dochodziło też do walk na morzu (bitwa u ujścia La Platy, niemiecki atak podwodny na bazę Scapa Flow). 10 września 1939 Kanada wypowiedziała wojnę Niemcom.
W późniejszych dniach miały miejsce kolejne konferencje Najwyższej Rady Wojennej. 22 września w brytyjskim Hove miała miejsce druga konferencja, w której również podjęto decyzję o rozładowaniu wojsk alianckich w rejonie Grecji i Turcji, lecz działania ostatecznie nie zostały podjęte. Następne konferencje miały miejsce 17 listopada i 19 grudnia 1939 w Paryżu. W ich trakcie był brany pod uwagę brytyjski pomysł bombardowania zagłębia Ruhry, któremu jednak sprzeciwili się Francuzi, gdyż bali się odwetu Luftwaffe. Następna konferencja odbyła się 5 lutego 1940 w Paryżu, w jej trakcie Francuzi zaproponowali rozlokowanie wojsk w Petsamo w celu pomocy walczącej z ZSRR Finlandii, pomysłowi sprzeciwili się Brytyjczycy. Podjęto decyzję o rozlokowaniu wojsk w Narviku, lecz z uwagi na pokój Finlandii i ZSRR działania nie zostały podjęte. Podczas konferencji w Londynie 28 marca 1940 Brytyjczycy sprzeciwili się francuskiemu pomysłowi bombardowania radzieckich pól naftowych na Kaukazie w celu osłabienia niemieckich i sowieckich wojsk, lecz podjęta została decyzja o operacji Royal Marine, której celem było zaminowanie Renu. Operacja ta też była celem konferencji z 5 kwietnia, lecz wskutek ataku Niemiec na Norwegię 9 kwietnia 1940 działania nie zostały podjęte. 22 i 23 kwietnia 1940 w Paryżu podjęto decyzję o rozlokowaniu wojsk w Norwegii. Po ataku Niemiec na Francję miały miejsce następujące konferencje: 15 maja 1940 w Paryżu, 11 czerwca 1940 w Briare i 15 czerwca 1940 w Tours.
Okres dziwnej wojny Wehrmacht wykorzystał do przygotowania ofensywy na Zachodzie. Parokrotnie przekładana ofensywa rozpoczęła się 10 maja 1940, kiedy to Niemcy zaatakowali Holandię, Belgię i Luksemburg i w kilka dni obeszli umocnienia francuskie. Ofensywa prowadzona była zgodnie z planem Mansteina, przygotowanym jesienią 1939 i przeforsowanym przez Hitlera wbrew stanowisku Oberkommando der Wehrmacht.
Kontrowersje.
W środowisku historycznym nie ma konsensusu co do kwestii potencjalnej zdrady ze strony sojuszników Polski. Przedstawiciele stronnictwa przeciwnego tezie o zdradzie zwracają uwagę, że wojna obronna Polski znacznie odbiegała od pierwotnych planów i założeń, opracowywanych przed 1 września 1939 roku. Zgodnie z przedwojennym raportem generała Tadeusza Kutrzeby i podpułkownika Stefana Mossora Polska miała samodzielnie się bronić przez pierwsze 6 do 8 tygodni.
Łukasz Męczykowski, specjalizujący się w historii najnowszej powszechnej, twierdzi, że kiedy Brytyjczycy i Francuzi spotkali się 12 września 1939 roku na konferencji w Abbeville w celu podjęcia decyzji odnośnie szturmu na Linię Zygfryda sytuacja na froncie w żaden sposób nie odzwierciedlała tego, co strona polska im wcześniej prezentowała - siły niemieckie znajdowały się już pod Lwowem, zamykając tym samym pozostałe polskie dywizje w szczypce, zajęty został Centralny Okręg Przemysłowy i większość polskojęzycznych terytoriów. Zajęcie przez Niemcy obszarów, nazwanych w raporcie Kutrzeby i Mossora „tułowiem strategicznym Polski”, sprawiło, że z wojskowego punktu widzenia Polska już była nie do odratowania. Nadziei nie dodawała również ocena sytuacji wojskowej z 9 września, przygotowana przez pułkownika Józefa Jaklicza dla Brytyjczyków. Pułkownik stwierdzał w niej, że już jest za późno na reakcję i armia polska zmierza ku swojej własnej zagładzie. W obliczu powyższych faktów sojusznicy stwierdzili, że planowana ofensywa nie uchroni Polski przed rychłym upadkiem, a tylko przyniesie niepotrzebne straty i w zamian lepiej będzie przełożyć ofensywę na korzystniejszy czas, gdy obydwa kraje dokonają pełnej mobilizacji i koncentracji swoich sił.
Dodać należy, iż przeciwnicy tezy o zdradzie podkreślają także, że Linia Zygfryda, wbrew obiegowej opinii oraz norymberskim zeznaniom Alfreda Jodla, wcale nie była wymysłem propagandowym niestanowiącym większego problemu dla sił sojuszniczych, a jak najbardziej realnym systemem umocnień z przygotowanymi 22 tysiącami stanowisk ogniowych oraz schronów osłanianych przez pola minowe i „zęby smoka”, a do tego dochodziły stanowiska polowe. Wszystko to było obsługiwane przez 45 dywizji Grupy Armii C.
Historyk Andrzej Ceglarski twierdzi, że nie tylko nie było zdrady, ale nawet nie było żadnego sojuszu, ponieważ nie powstały żadne wiążące sojusznicze dokumenty, a w zamian były tylko niejasne obietnice ze strony Wielkiej Brytanii (w tym obietnica wypowiedzenia wojny, która została spełniona) i protokół wojskowy z paryskich rozmów, wręczony generałowi Kasprzyckiemu przez generała Gamelina, który wymagał jednak ratyfikacji przez parlament Francji i podpisania układu politycznego, żeby mógł wejść w życie, a do tego nigdy nie doszło, czego rząd II RP był świadomy. Dodatkowo nie istniały żadne formy kooperacji między sztabami wojskowymi Polski i Francji, nie było też koncepcji na to jak miałaby wyglądać stała pomoc lotnicza czy morska ze strony wojsk brytyjskich.

</doc>
<doc id="1136" url="https://pl.wikipedia.org/wiki?curid=1136" title="Digital Millennium Copyright Act">
Digital Millennium Copyright Act

DMCA (ang. "Digital Millennium Copyright Act") – ustawa z zakresu prawa autorskiego, obowiązująca od 1998 w USA zabraniająca tworzenia i rozpowszechniania technologii, przy użyciu których mogą być naruszone cyfrowe mechanizmy ograniczeń kopiowania.
Kanada.
Podobne regulacje wprowadzono w Kanadzie. Prace nad aktem C-61 zostały przerwane przez rozwiązanie Parlamentu (2008). Kolejną próbą zmiany kanadyjskiego prawa autorskiego na podobieństwo DMCA był akt C-32 (2010). Również w tym wypadku prace legislacyjne nie zostały zakończone ze względu na duży opór społeczny i polityczny. Konserwatywna Partia Kanady nadal dążyła do wprowadzenia zmian prawnych zawartych w tych aktach i 29 czerwca 2012 r. uchwaliła akt C-11 ("An Act to amend the Copyright Act").

</doc>
<doc id="1137" url="https://pl.wikipedia.org/wiki?curid=1137" title="Dobór naturalny">
Dobór naturalny

Dobór naturalny (selekcja naturalna) – jeden z mechanizmów ewolucji biologicznej, prowadzący do ukierunkowanych zmian w populacji zwiększających ich przeciętne przystosowanie, czyli adaptację do warunków środowiskowych, poza okresem wymierania.
Miarą sukcesu w doborze naturalnym jest dostosowanie (ang. "fitness"); można je rozpatrywać na poziomie osobników lub poszczególnych genów. Organizmy posiadające korzystne cechy mają większą szansę na przeżycie i rozmnażanie, co prowadzi do zwiększania częstości występowania korzystnych genów w populacji.
Pojęcie doboru naturalnego na określenie głównego mechanizmu, prowadzącego do kierunkowych zmian w procesie ewolucji, zostało zaproponowane przez Karola Darwina i Alfreda R. Wallace’a.
Stabilność populacji.
W każdym pokoleniu powstaje znacznie więcej organizmów potomnych, niż liczy pokolenie rodzicielskie. Obserwacje wykazały, że liczebność większości populacji pozostaje na stałym poziomie lub ulega oscylacjom wokół pewnej średniej. Zestawienie tych dwóch faktów prowadzi do wniosku, że w naturze ogromna większość osobników potomnych nigdy nie osiąga sukcesu reprodukcyjnego. Młode mogą zostać zjedzone przez organizmy z następnego ogniwa łańcucha pokarmowego, padając jednocześnie ofiarą:
Pomiędzy różnymi czynnikami negatywnymi występuje zjawisko dodatniego sprzężenia zwrotnego. Dla przykładu mała zdolność odnajdywania pokarmu ogranicza rozwój organizmu, który staje się bardziej podatny na choroby pogarszające jego stan. Osłabiony i chory osobnik staje się łatwym łupem drapieżników.
Różnorodność w populacji.
Szanse przeżycia i wydania potomstwa nie są równe, ponieważ osobniki w obrębie populacji cechuje zmienność genetyczna. Różne warianty genów nazywane allelami, powodują powstawanie odmienności. Dodatkową siłą wzmacniającą zróżnicowanie populacji jest dodawanie się wpływów różnych genów, które można obserwować poprzez pomiary cech ilościowych (wzrost, ciężar itp.). Dla stabilnych populacji rozkład intensywności cech ilościowych jest normalny. Oprócz genów na cechy organizmu mają wpływ również czynniki środowiskowe. Mogą to być zjawiska o charakterze fizycznym, takie jak klimat, czy warunki geograficzne itp. Duże znaczenia mają też oddziaływania ze strony drapieżników, pasożytów, konkurentów o pokarm itp. Wpływ środowiska powoduje zwykle zwiększanie szerokości na wykresie rozkładu intensywności cech ilościowych.
Rodzaje doboru.
Rodzaj doboru ze względu na kierunkowość:
Historia.
Pierwszy istnienie doboru naturalnego zauważył Epikur (341-270 p.n.e.). Niezależnie od niego koncepcje doboru naturalnego sformułował i wprowadził do biologii Charles Darwin, niektóre źródła wskazują na jego dziadka Erazma Darwina, inne na kreacjonistę Edwarda Blytha (1835).
Dowody.
Ćmy.
Jedną z pierwszych obserwacji działania doboru naturalnego w przyrodzie były prace H.B.D. Kettlewella nad rozprzestrzenianiem się melanistycznych form w populacjach ćmy krępaka nabrzozaka ("Biston betularia") na obszarach zanieczyszczonych przemysłowo w Anglii. Kettlewell udokumentował m.in., że ciemne ubarwienie formy melanistycznej jest dziedziczne (konieczny warunek dla ewolucji – patrz pierwsze założenie TE) oraz że forma melanistyczna jest mniej narażona na ataki ze strony ptaków w obszarach zmienionych przemysłowo, gdzie zaniknęła pokrywa porostowa na drzewach (warunek konieczny dla doboru naturalnego). Wielokrotnie podnoszono zastrzeżenia co do szczegółów metodologicznych badań Kettlewella, lecz późniejsze i bardziej dokładne eksperymenty potwierdziły jego wnioski bez wyjątku.
Zięby Darwina.
Inną klasyczną dokumentacją zachodzącego w naturze doboru naturalnego są wyniki badań nad ewolucją zięb Darwina na wysepce Daphne Major należącej do archipelagu Galapagos prowadzonych przez Petera i Rosemary Grantów.
Inne.
Proces doboru obserwowany był wielokrotnie w kontrolowanych eksperymentach laboratoryjnych. Klasyczne badania w tym kierunku przeprowadzone były przez Dobzhanskiego.

</doc>
<doc id="1138" url="https://pl.wikipedia.org/wiki?curid=1138" title="Dywiz">
Dywiz

Dywiz, czyli łącznik – znak pisarski oznaczony znakiem  -  w postaci krótkiej poziomej kreski (krótszej od pauzy i półpauzy) uniesionej ponad podstawową linią pisma. Inne nazwy dywizu to: znak przeniesienia, mała kreska oraz tiret (z fr. "tiré"). Łącznik nie jest znakiem interpunkcyjnym.
Charakterystyka dywizu.
W zestawie czcionek drukarskich lub też komputerowych fontów jest znakiem przeważnie o oczku w kształcie krótkiej kreski, najczęściej poziomej. W niektórych krojach, szczególnie historycznych, może być jednak w innej postaci, np. kreski biegnącej lekko ukośnie, klina itp., a nawet wypełnionego kółka. W odmianach pochylonych może mieć (częściej niż w wypadku obu znaków myślnika) postać spłaszczonego trapezu. W krojach szeryfowych, szczególnie ozdobnych, dywiz może mieć również dodane zakończenia.
Znak jest położony na wysokości w połowie lub nieco wyżej pomiędzy podstawową linią pisma a średnią linią pisma (jest dopasowany do wielkości małych liter bez wydłużeń, biegnąc w połowie ich wysokości lub nieco wyżej). 
Dywiz ma długość najczęściej od ok. 1/4 do ok. 1/3 firetu i jest najkrótszym spośród znaków pisarskich w postaci poziomej kreski (nie licząc niektórych znaków diakrytycznych). Dywiz przypomina znaki myślnika, leżąc na tej samej lub niemal na tej samej wysokości, ale w tekście pełni odmienną od nich rolę i oznaczany jest odrębnym znakiem typograficznym. Myślnik oznaczany jest dłuższą kreską – półpauzą ( – ) lub pauzą ( — ), dywiz oznaczany jest krótką kreską ( - ). Z racji swojej niewielkiej długości dywiz często kreślony jest nieco grubszą kreską niż znaki myślnika i minusa. Pod względem długości najbardziej podobny do dywizu jest znak kreski liczbowej (zazwyczaj nieco dłuższy, występujący tylko w części krojów), ale jego położenie i grubość są dopasowane do wyglądu cyfr w danym kroju. Kolejny podobny do dywizu – znak minusa (występujący częściej, ale też tylko w części krojów), jako symbol matematyczny, ma odmienne od dywizu nie tylko szerokość, ale także położenie – dopasowany jest bowiem do kształtu cyfr, tak jak symbole plusa, znaku równości czy kreski ułamkowej. Znak minusa bliższy jest typograficznie półpauzie niż dywizowi.
Dywiz wraz z półpauzą i pauzą należą do podstawowego zestawu znaków i występują praktycznie we wszystkich krojach literowych.
Funkcjonalne odmiany dywizu/łącznika – miękki dywiz (ukryty) i twardy łącznik (niedzielący) są typograficznie identyczne ze zwykłym dywizem.
Użycie dywizu.
Zasadniczo znaki dywizu i łącznika są tożsame z typograficznego punktu widzenia, natomiast z językowego punktu widzenia pojęcia dywizu i łącznika oznaczają odmienne zastosowania tego samego znaku do dzielenia lub łączenia.
Zgodnie z dobrą praktyką pisarską, przy przenoszeniu wyrazów złożonych zawierających łącznik zalecane jest dzielenie wyrazu na łączniku. Wtedy na końcu wcześniejszego wiersza wstawiany jest dywiz, a łącznik jest przenoszony do następnego wiersza. Unika się w ten sposób niejednoznaczności w interpretacji niektórych podobnie pisanych wyrazów, jak np. niebieskozielony (tj. kolor zielony o odcieniu niebieskim) i niebiesko-zielony (tj. kolor w połowie pomiędzy niebieskim i zielonym, lub w innym znaczeniu – dwukolorowy w rozumieniu częściowo niebieskiego, a częściowo zielonego). Należy jednak dodać, że wbrew temu ustalonemu zwyczajowi słowniki ortograficzne dopuszczają przy przenoszeniu pomijanie łącznika w drugim wierszu.
Użycie dywizu/łącznika jasno wskazuje, że nie jest on znakiem interpunkcyjnym, jak to się często mylnie sądzi. Zalicza się go do szerokiego pojęcia znaków tworzących słowa, czyli znaków ortograficznych (litery, znaki diakrytyczne i inne, jak np. apostrof).
Użycie dywizu/łącznika do oznaczania dialogów jest błędem, gdyż nie jest to zgodne z normami interpunkcji – winien być tam użyty myślnik (w postaci pauzy lub półpauzy). Przemawiają za tym również względy estetyczne, ponieważ łącznik jest wizualnie za krótki.
Natomiast nie jest błędem użycie łącznika jako kreski liczbowej stosowanej w zakresach liczbowych. Dopuszczalne jest to w wąskim składzie. 
Dywiz w systemach informatycznych.
Standard ASCII przewidywał wspólny znak dla łącznika, minusa i myślnika. Wspólny znak kreski poziomej w zestawie znaków ASCII znajduje się na pozycji 45 i określany jest jako łącznik-minus (ang. "hyphen-minus"). Z punktu widzenia typografii jest to rozwiązanie daleko niewystarczające, ale podyktowane było względami technicznymi ówczesnego poziomu rozwoju technik informacyjnych. Kolejne wprowadzane w komputerach osobistych zestawy znaków były zgodne ze standardem ASCII, jednak zwiększały liczbę dostępnych znaków. Stosowany w polskiej wersji systemu Windows zestaw Windows-1250 zawiera obok znaku łącznika-minusa (+) również znaki półpauzy (+) i pauzy (+). Wprowadzony później standard Unikod (ang. "Unicode") obejmujący wszystkie możliwe znaki wszystkich znanych języków, również zgodny ze standardem ASCII, zawiera znaki łącznika-minusa (U+002D), półpauzy (U+2013) i pauzy (U+2014), ale obok nich również znaki łącznika (U+2010) i minusa (U+2212). Typograficznie właściwym dla dywizu jest w Unikodzie znak (U+2010) 
Poziome zestawienie powyższych znaków w tej samej kolejności:
Podobnie jak większość zaawansowanych edytorów tekstów, standard Unicode przewiduje specjalne znaki dla specyficznych sytuacji, związanych z automatyzacją przetwarzania tekstu:
Dywiz charakterystyczny m.in. dla polskiej ortografii, tj. łącznik stawiany na końcu wiersza i powtarzany na początku następnego, jak w poniższym przykładzie:
można uzyskać przez kombinację miękkiego łącznika i łącznika niełamiącego.
Standard ISO-8859-15 (uaktualniona wersja ISO-8859-1 (Latin1)), dodaje znak dywizu (oznaczony w tabeli jako 'SHY'), na pozycji 0xAD, podobnie jak Unicode:
Aby pokazać efekt miękkiego łącznika w HTML, wyrazy następującego tekstu zostały oddzielone miękkimi łącznikami:
Margaret­Are­You­Grieving­Over­Goldengrove­Unleaving­Leaves­Like­The­Things­Of­Man­You­With­Your­Fresh­Thoughts­Care­For­Can­You­Ah­As­The­Heart­Grows­Older­It­Will­Come­To­Such­Sights­Colder­By­And­By­Nor­Spare­A­Sigh­Though­Worlds­Of­Wanwood­Leafmeal­Lie­And­Yet­You­Will­Weep­And­Know­Why­Now­No­Matter­Child­The­Name­Sorrows­Springs­Are­The­Same­Nor­Mouth­Had­No­Nor­Mind­Expressed­What­Heart­Heard­Of­Ghost­Guessed­It­Is­The­Blight­Man­Was­Born­For­It­Is­Margaret­You­Mourn­For
W przeglądarkach HTML obsługujących miękkie łączniki zmiana rozmiaru okna spowoduje ponowne podzielenie powyższego tekstu tylko na granicach wyrazów i wstawienie łącznika na końcu każdego wiersza.
LaTeX.
Znak dywizu występujący wewnątrz słowa, tak jak w powyższym przykładzie, w słowie K-219 uzyskujemy poprzez napisanie:
K-219
Należy jednak pamiętać, że system LaTeX nigdy nie dzieli słów zawierających cyfry bądź znaki niealfanumeryczne (podkreślenia, znaki procentu itp.).
W wypadku wyrazów złożonych musimy posłużyć się paczką hyphenat i wykorzystać makro codice_2:
Akademia Górniczo\hyp{}Hutnicza
Można również użyć pakietu polskiego poprzez umieszczenie codice_3 w preambule i użycie codice_4:
Akademia Górniczo\dywiz{}Hutnicza
Akademia Górniczo\dywiz Hutnicza % albo tak
Dywiz tak umieszczony daje również możliwość dzielenia długich wyrazów wieloczłonowych, przy czym znak łącznika zostanie powtórzony (w krótkiej formie) zarówno na końcu linii, jak i początku nowej linii.

</doc>
<doc id="1139" url="https://pl.wikipedia.org/wiki?curid=1139" title="Dębik ośmiopłatkowy">
Dębik ośmiopłatkowy

Dębik ośmiopłatkowy ("Dryas octopetala" L.) – gatunek roślin z rodziny różowatych. Nazwa rodzajowa, zarówno polska, jak i naukowa, pochodzi od kształtu liści podobnych do liści dębu (gr. "δρυς" – dąb, drzewo), nazwa gatunkowa od liczby płatków w koronie kwiatu (najczęściej 8). Od nazwy rodzajowej pochodzi młodszy dryas.
Zasięg geograficzny.
Na stanowiskach naturalnych występuje w Ameryce Północnej i Europie. W Ameryce Północnej występuje w regionach północnych i arktycznych (Alaska, Jukon, zachodnia Kanada) oraz w górach stanów Kolorado, Idaho, Oregon. W Europie występuje w tundrze na Półwyspie Skandynawskim, Islandii, wyspach Svalbard, Jan Mayen oraz w górach. W Polsce – niemal wyłącznie w Tatrach, jest tam pospolity. Poza Tatrami w 1953 r. opisano jedno stanowisko na północnej ścianie Smolegowej Skały w Pieninach. Jest uprawiany w wielu krajach świata.
Pochodzenie.
Jest reliktem polodowcowym (zob. młodszy dryas). Jego szczątki w dużych ilościach znajduje się we florze kopalnej z wczesnego holocenu. Wyparty w kierunku obszarów subpolarnych w wyniku ocieplania klimatu po ustąpieniu lądolodu. W Polsce przetrwał tylko w wysokich górach.
Zastosowanie.
Roślina ozdobna: uprawiana jako tzw. roślina okrywowa, szczególnie nadająca się do ogrodów skalnych, zwłaszcza na większe skarpy. Najlepsze jest próchniczno-żwirowe podłoże, umiarkowanie wilgotne i zawierające dużo wapnia. Dobrze jest wymieszać podłoże z wapiennym gruzem. Wymaga stanowiska słonecznego. Rozmnaża się wyłącznie wegetatywnie z sadzonek pędowych.

</doc>
<doc id="1140" url="https://pl.wikipedia.org/wiki?curid=1140" title="Deflate">
Deflate

Deflate – algorytm kompresji oparty na LZ77 i kodowaniu Huffmana, określony standardem .
Standardy oraz określają formaty używane do składowania danych skompresowanych za pomocą algorytmu deflate.
Algorytm ten stosowany jest m.in. w formacie PNG oraz programach do kompresji gzip i PKZIP, natomiast popularna wolnodostępna jego implementacja znajduje się w bibliotece zlib.

</doc>
<doc id="1141" url="https://pl.wikipedia.org/wiki?curid=1141" title="Dyskretna transformacja kosinusowa">
Dyskretna transformacja kosinusowa

Dyskretna transformacja kosinusowa, dyskretna transformacja cosinusowa (, DCT) – rodzaj blokowej transformacji wykonywanej na wartościach dyskretnych. Jest szczególnie popularna w dziedzinie stratnej kompresji danych.
Opis metody.
DCT przekształca skończony ciąg formula_1 liczb rzeczywistych formula_2 w ciąg liczb rzeczywistych formula_3 zgodnie z zależnościami:
gdzie:
Definiuje się również odwrotną dyskretną transformację cosinusową (IDCT) jako:
Zaletą stosowania transformaty DCT w kompresji jest fakt, że większość współczynników jest zwykle bliska 0 – po kwantyzacji wyzerują się one, co zredukuje liczbę bitów potrzebną do reprezentacji sygnału bez wprowadzania dużego błędu.
Przetwarzanie sygnałów wielowymiarowych wymaga zastosowania przekształcenia o odpowiedniej liczbie wymiarów. Ponieważ przekształcenie wielowymiarowe DCT jest separowalne, odpowiednie transformaty można uzyskać przez kolejne wykonanie jednowymiarowych przekształceń we wszystkich wymiarach. Na przykład przekształcenie bloków obrazu, czyli sygnału 2-wymiarowego, sprowadza się do obliczenia wyniku DCT we wszystkich wierszach danego bloku, a następnie przekształcenie tych współczynników kolejnym zestawem operacji DCT liczonych po wszystkich kolumnach – kolejność operacji jest dowolna.
DCT w multimediach.
DCT jest używana m.in. w kompresji JPEG i MPEG. Standardowy algorytm polega na podziale obrazu na bloki o stałych rozmiarach (np. 8×8), transformację tych bloków, kwantyzację i kompresję bezstratną.
Głównym problemem kodowania transformatowego opartego na blokach DCT są gwałtowne skoki wartości na granicach zrekonstruowanych bloków (tzw. efekt blokowy). Jednym ze sposobów minimalizacji tego zjawiska jest zastosowanie większych bloków (w przypadku mocno skompresowanych obrazów używane przez algorytm JPEG bloki 8×8 są stanowczo za małe, 16×16 lub nawet 32×32 byłyby bardziej odpowiednie). Innym sposobem jest używanie zmodyfikowanej dyskretnej transformacji kosinusowej (MDCT), która wykorzystuje nachodzące na siebie bloki lub transformaty falkowe.
Ze względu na to, że w przypadku dźwięków efekty blokowe byłyby słyszalne jako trzaski, DCT praktycznie nie jest używana do cyfrowego przetwarzania sygnałów dźwiękowych, natomiast bardzo popularna jest w tym przypadku transformacja MDCT.

</doc>
<doc id="1142" url="https://pl.wikipedia.org/wiki?curid=1142" title="Darwinizm">
Darwinizm

Darwinizm – ogólna teoria rozwoju życia sformułowana przez brytyjskiego przyrodnika Karola Darwina. Teoria stała się fundamentem nauki o ewolucji organizmów oraz wpłynęła na myśl filozoficzną. Twórców odwołujących się do teorii ewolucji Darwina w dziełach filozoficznych określa się jako darwinistów. Myśl filozoficzna odwołująca się do teorii ewolucji nie jest jednorodna. Poszczególni autorzy tworzą frakcje, a na łamach czasopism odbywa się dyskurs pomiędzy nimi. Teoria Darwina wpływa zarówno na naukę, jak i politykę. Kontekst społeczny i polityczny prowadzi do zakłócenia nauki ideologią, czego efektem jest odmienne przedstawianie poglądów w poszczególnych tradycjach narodowych. Interpretacja ewolucji biologicznej wzbogacona o osiągnięcia genetyki doprowadziła do powstania neodarwinizmu, koncentrującego się na zmianach w genotypie i fenotypie organizmu. Koncepcja ta jednak nie pozwoliła na pełne wyjaśnienie znanych biologii zjawisk. Rozwinięcie teorii Darwina określane jako nowoczesna synteza ewolucyjna () doprowadziło do dwóch ujęć nazwanych neodarwinizmem. Pierwsze z nich koncentruje się na działaniu genów i traktuje organizm jako replikator. Drugie poświęca więcej uwagi plastyczności organizmów i zmianom adaptacyjnym. Powstał także holistyczny darwinizm, który dostrzega ewolucję na wszystkich poziomach organizacji życia, w tym na poziomie superorganizmów, jakim są społeczeństwa. Paradygmat darwinizmu holistycznego wywołuje konsekwencje nie tylko w biologii, lecz także w naukach społecznych, szczególnie w ekonomii i politologii.
Geneza i rozwój.
Główna idea teorii ewolucji została przedstawiona przez Alfreda Wallace’a i Karola Darwina w roku 1858 na zebraniu Towarzystwa Linneuszowego. Do koncepcji doboru naturalnego obaj naukowcy doszli niezależnie. Szczegóły teorii Darwin przedstawił w dziele "O powstawaniu gatunków", którego pierwsze wydanie ukazało się w roku 1859. Ideą przewodnią darwinizmu jest koncepcja doboru naturalnego, nazywana walką o byt. Jednak zarówno Darwin, jak i Wallace wielokrotnie tłumaczyli, że sformułowania tego nie należy traktować dosłownie, lecz metaforycznie. Walka o byt polega więc na ciągłym współzawodnictwie osobników jednego gatunku albo osobnikami różnych gatunków lub też jest to walka z fizycznymi warunkami środowiska. Darwin podtrzymał też ogólnie koncepcję Lamarcka o ciągłych i stopniowych zmianach organizmów, odrzucając możliwość cudownej interwencji w ich powstaniu. Powstawanie gatunków uznał za efekt istniejących praw przyrody. W książce Darwina pojawiła się też ważna dla teorii ewolucji hipoteza o pochodzeniu wszystkich istniejących współcześnie organizmów od jednego przodka.
Część tez zostało (po licznych dyskusjach) przyjęte jeszcze za życia Darwina. Teoria doboru naturalnego zyskała potwierdzenie dzięki badaniom ekologicznym i biogeograficznym. Kluczowych dowodów na potwierdzenie monofiletyczności życia na Ziemi dostarczyła dopiero biologia molekularna.
Do sformułowania współczesnej teorii ewolucji, opartej na przemyśleniach Darwina, ale adekwatnej do stanu wiedzy w wieku XX, wybitnie przyczynił się Theodosius Dobzhansky swoją syntezą ewolucjonizmu Darwina z genetyką mendlowską opublikowaną w książce pt. "Genetics and the Origin of Species" (1937) i wielu innych.
W zakresie filozofii i światopoglądu konsekwencją idei ewolucji jest zakwestionowanie teoretycznych podstaw poglądów teocentrycznych i antropocentrycznych. Filozoficzne wizje historii naturalnej rozeszły się z wizjami teologii naturalnej, a status gatunku ludzkiego zrównał się ze statusem innych gatunków.
Implikacje społeczne darwinizmu.
Darwinizm zainspirował nauki społeczne do nowego sposobu myślenia. Zwrot do rasistowskiego myślenia nastąpił, kiedy zaczęto stosować teorię Darwina do społeczeństw ludzkich. Darwinizm społeczny został w tym kontekście stworzony przez Galtona, a następnie szeroko zaakceptowany w sferach akademickich. Ówczesne odkrycia naukowe przyczyniły do społecznego poparcia dla zastosowań darwinizmu w sferze życia społecznego. Rozkwitła eugenika. Od późnego XIX wieku, aż do końca II wojny światowej, eugenika miała silny wpływ na publiczne i zdrowotne ustawodawstwo w Europie i w USA.
Zdaniem Kennetha Millera ewolucja często bywała przesadnie stosowana (ang. "overapplied") i nadinterpretowywana ("over-interpreted"), wystarczy spojrzeć na eugenikę. Nadzieję daje to, że nauka koryguje się sama z czasem. Dave Wilson dodaje w tym kontekście, że korekcje w nauce możliwe są tylko, kiedy istnieje różnorodność opinii. Pomimo rozpowszechnionych sugestii, darwinizm nie daje podstaw do żadnej z form rasizmu, seksizmu, nacjonalizmu lub imperializmu ani moralnych przesłanek dla zwolenników hasła „przetrwania najlepszych”. Nie wyklucza, ani nie uznaje za nienaturalne współpracy i altruizmu. Współcześnie idee Darwina wykorzystywane są do tłumaczenia zjawisk społecznych, których wyjaśnieniem zajmują się nauki społeczne.
W dziele „O pochodzeniu człowieka” Darwin napisał:
Robert Richards (2013) potwierdził, że Darwin akceptował koncepcję hierarchii ras. Autor zaznacza jednak, że Darwin nie był twórcą tej koncepcji; hierarchie ras tworzyli autorzy działający jeszcze przed Darwinem, tacy jak Karol Linneusz, Johann Friedrich Blumenbach, Georges Cuvier i Carl Gustav Carus, a Darwin jedynie przyjął koncepcję powszechnie w jego czasach przyjmowaną w literaturze naukowej.
Teoria Piotra Kropotkina.
Piotr Kropotkin w książce "Pomoc wzajemna jako czynnik rozwoju" opublikowanej w roku 1902 skrytykował tezy darwinizmu społecznego. Odwołując się do swoich obserwacji, dokonanych na zwierzętach i ludziach, zauważa, że przedstawiona przez Darwina walka o byt wyraża się zarówno w konkurowaniu osobników jednego gatunku o ograniczone zasoby środowiska, jak i współpracą pomiędzy osobnikami. Swoje wnioski odniósł także do ludzi twierdząc, że tak jak wojny i eksterminacja są zjawiskami istniejącymi naturalnie i powszechnie tak samo powszechna jest wzajemna pomoc, która prowadzi do kreatywności i rozwoju. Kropotkin napisał:
Koncepcje współpracy przedstawione przez Kropotkina i innych neodarwinistów znalazły także potwierdzenie w królestwie roślin. W latach 80. XX wieku okryto istnienie sieci mikoryzowych, umożliwiających wzajemną pomoc pomiędzy osobnikami tego samego a nawet różnych gatunków (zob. nieantagonistyczne interakcje międzygatunkowe, biocenoza, struktura ekosystemu).

</doc>
<doc id="1143" url="https://pl.wikipedia.org/wiki?curid=1143" title="Dodawanie macierzy">
Dodawanie macierzy

Dodawanie macierzy – działanie dwuargumentowe w zbiorze macierzy formula_1 o ustalonych wymiarach formula_2 które elementowi o współrzędnych formula_3 wynikowej macierzy formula_4 przypisuje sumę elementów macierzy formula_5 i formula_6 o tych samych współrzędnych formula_7
Symbolicznie można to zapisać:
Jeśli elementy macierzy należą do pewnej grupy abelowej, to zbiór macierzy o tych samych wymiarach z działaniem dodawania tworzy grupę abelową.
Zgodnie z definicją, aby dodać dwie macierze, dodaje się do siebie elementy o tych samych współrzędnych:
W analogiczny sposób odejmuje się macierze.

</doc>
<doc id="1144" url="https://pl.wikipedia.org/wiki?curid=1144" title="Diagonalizacja">
Diagonalizacja

Diagonalizacja – sprowadzenie macierzy kwadratowej do postaci diagonalnej, a konkretniej rozkład macierzy formula_1 na iloczyn macierzy formula_2
gdzie formula_4 jest macierzą diagonalną.
Macierz formula_5 jest nazywana macierzą przejścia.
Współczynniki na głównej przekątnej macierzy diagonalnej formula_4 są równe kolejnym wartościom własnym macierzy formula_7 z kolei kolumny macierzy formula_5 stanowią kolejne wektory własne macierzy formula_9
Macierze kwadratowe, które można przedstawić w postaci diagonalnej, nazywamy diagonalizowalnymi.
Rozkład Jordana i rozkład wartości osobliwych to dwa różne uogólnienia diagonalizacji, działające dla dowolnych macierzy.
Zastosowanie.
Diagonalizacja ułatwia potęgowanie macierzy:
gdzie:
Własności.
Macierze symetryczne i hermitowskie są diagonalizowalne. Ogólniej, macierze normalne są diagonalizowalne unitarnie – tzn. istnieje dla nich unitarna macierz przejścia dla rozkładu diagonalnego.
W szczególności:
Jeśli dla pewnej macierzy formula_17 mamy rozkład diagonalny
wówczas:
Diagonalizacja Jacobiego.
Załóżmy, że formula_29 jest przestrzenią ortogonalną oraz formula_30 jest bazą formula_31 taką, że dla każdego formula_32 zachodzi formula_33 (wyznacznik Grama). Wtedy istnieje baza prostopadła formula_34
przestrzeni formula_35 w której formula_36 ma macierz:

</doc>
<doc id="1145" url="https://pl.wikipedia.org/wiki?curid=1145" title="Druga wojna światowa">
Druga wojna światowa



</doc>
<doc id="1146" url="https://pl.wikipedia.org/wiki?curid=1146" title="Dakota Południowa">
Dakota Południowa

Dakota Południowa (ang. "South Dakota", wym. ) – stan w środkowo-północnej części Stanów Zjednoczonych, na obszarze Wielkich Równin. Sąsiaduje od północy ze stanem Dakota Północna, od zachodu z Montaną i Wyoming, od południa z Nebraską, od wschodu z Minnesotą i Iowa.
Według spisu z 2020 roku liczy 886,7 tys. mieszkańców i jest jednym z najsłabiej zaludnionych stanów w USA. Stolicą jest Pierre, a największym miastem Sioux Falls.
Nazwa stanu pochodzi od zamieszkujących tam Indian Dakota (Siuksów).
Geografia.
Rzeźba terenu na ogół wyżynna, z głęboko wciętymi dolinami rzeki Missouri i jej dopływów. Na zachodzie Góry Czarne (ang. Black Hills) z najwyższym szczytem Harney Peak (2207 m n.p.m.). Znajduje się tam Kopalnia Homestake – największa niegdyś kopalnia złota w Ameryce Północnej, zamknięta w 2002 roku. 
Jest w dwóch strefach czasowych: i .
Klimat.
Dakota Południowa leży w strefie klimatu umiarkowanego ciepłego o kontynentalnej i suchej odmianie. Zimy są zimne i często mroźne, gdzie w wielu miejscach średnia dobowa może spaść do -12 °C. Lata są dość gorące co wiąże się z napływem gorących mas powietrza znad Meksyku. Średnie wartości letnie dochodzą do 32 °C. Średnie opady roczne około 500 mm. Najsuchsze regiony, leżące w południowo-zachodniej części stanu cechują się opadami rzędu od 150 do 300 mm rocznie, południowo-wschodnia część stanu to opady około 635 mm rocznie. Do częstych letnich zjawisk należą gwałtowne burze z silnym wiatrem. Czasami występuje gradobicie. Zimą zaś występują zawieje i zamiecie śnieżne.
Demografia.
Spis ludności z roku 2020 stwierdza, że stan Dakota Południowa liczy 886 667 mieszkańców, co oznacza wzrost o 72 487 (8,9%) w porównaniu z poprzednim spisem z roku 2010. Dzieci poniżej piątego roku życia stanowią 6,9% populacji, 24,5% mieszkańców nie ukończyło jeszcze osiemnastego roku życia, a 17,2% to osoby mające 65 i więcej lat. 49,5% ludności stanu stanowią kobiety.
Rasy i pochodzenie.
Według danych z 2019 roku, 84,1% mieszkańców stanowiła ludność biała (81,5% nie licząc Latynosów), 8,6% to rdzenna ludność Ameryki, 2,8% miało rasę mieszaną, 2,4% to czarnoskórzy Amerykanie lub Afroamerykanie, 1,3% to Azjaci, 0,23% to Hawajczycy i mieszkańcy innych wysp Pacyfiku. Latynosi stanowią 3,7% ludności stanu.
Największe grupy stanowią osoby pochodzenia niemieckiego (34,4%), norweskiego (12,8%), irlandzkiego (9,4%), Siuksowie (6,8%), angielskiego (5,9%), „amerykańskiego” (4,5%) i holenderskiego (4,3%).
Język.
W 2010 roku najpowszechniej używanymi językami są:
Religia.
W krajobrazie religijnym stanu dominują społeczności luterańskie (stworzone przez niemieckich i skandynawskich imigrantów), oraz katolicy. 
Dane z 2014 r.:
Gospodarka.
Rolnictwo jest kluczowym sektorem gospodarki Dakoty Południowej, podobnie jak bionauka, usługi biznesowe i profesjonalne, rekreacja na świeżym powietrzu, oraz przemysł naftowy i gazowy. Stan ma również rozwijający się przemysł turystyczny, a do ulubionych atrakcji należą góra Mount Rushmore i Park Narodowy Badlands. Produkcja obejmuje maszyny, chemikalia, wyroby metalowe i sprzęt transportowy. 
Rolnictwo.
Dziewięć dziesiątych powierzchni stanu pokrywają uprawy lub pastwiska. Prawie dwie piąte gospodarki rolnej stanu opiera się na hodowli bydła i świń. Dakota Południowa jest jednym z dziesięciu największych producentów kukurydzy w kraju, a obfite uprawy kukurydzy są częściowo wykorzystywane do tworzenia biopaliw. 
Zasoby.
Black Hills bogate są w minerały ze złożami złota, srebra, miedzi i ołowiu. W zachodniej części stanu znajdują się także skromne stanowe rezerwy ropy naftowej i gazu ziemnego. 
Energia.
Cztery z sześciu głównych zapór hydroelektrycznych na rzece Missouri znajdują się w Dakocie Południowej. Hydroelektrownie mają największy udział w produkcji energii elektrycznej w stanie (około połowy w 2020 roku). Pozostała produkcja pochodzi prawie w całości z wiatru, węgla i gazu ziemnego. Dakota Południowa nie posiada żadnych elektrowni jądrowych. 

</doc>
<doc id="1147" url="https://pl.wikipedia.org/wiki?curid=1147" title="Dakota Północna">
Dakota Północna

Dakota Północna (, ) – stan na północy Stanów Zjednoczonych, leżący w regionie Midwest, na obszarze Wielkich Równin. Nazwa stanu pochodzi od słowa Indian Siuksów (nazywanych także Dakotami) oznaczającego „przyjaciela”.
Od zachodu graniczy z Montaną, od południa z Dakotą Południową, od wschodu z Minnesotą, a od północy z kanadyjską prowincją Manitoba. Rzeźba terenu jest na ogół wyżynna. Dakota Północna jest uważana za najbardziej wiejski stan USA, ponieważ około 90% jej gruntów jest wykorzystywanych w celach rolniczych.
Pierwotnie obszar ten był zamieszkany przez plemiona Indian Wielkich Równin, Mandanów, Hidatsów i Arikara. Dziś jest domem dla pięciu plemion uznanych przez władze federalne, z których największymi są Czipewejowie i Dakotowie. Społeczności indiańskie stanowią 5% populacji stanu.
Stan ma jeden z najwyższych odsetków osób pochodzenia niemieckiego (34,8%), norweskiego (24,4%) i innego skandynawskiego. Przy czym osoby pochodzenia niemieckiego i norweskiego stanowią łącznie ponad połowę populacji.
Stolicą stanu jest miasto Bismarck, a największym miastem Fargo.
Demografia.
Spis ludności z roku 2020 stwierdza, że stan Dakota Północna liczy 779 094 mieszkańców, co oznacza wzrost o 97 503 (15,8%) w porównaniu z poprzednim spisem z roku 2010. Dzieci poniżej piątego roku życia stanowią 6,6% populacji, 24,0% mieszkańców nie ukończyło jeszcze osiemnastego roku życia, a 16,1% to osoby mające 65 i więcej lat. 48,6% ludności stanu stanowią kobiety.
Rasy i pochodzenie.
Według danych z 2019 roku, 85,8% mieszkańców stanowiła ludność biała (83,6% nie licząc Latynosów), 5,4% to rdzenna ludność Ameryki, 3,3% miało rasę mieszaną, 2,9% to czarnoskórzy lub Afroamerykanie, 1,4% to Azjaci, 0,4% to Hawajczycy i mieszkańcy innych wysp Pacyfiku. Latynosi stanowili 4,0% ludności stanu.
Do największych grup należały osoby pochodzenia niemieckiego (34,8%), norweskiego (24,4%) i irlandzkiego (6,4%). Do innych większych grup należały osoby pochodzenia angielskiego (29,3 tys.), francuskiego (27,3 tys.), szwedzkiego (25,1 tys.), „amerykańskiego” (24,7 tys.), meksykańskiego (20 tys.), polskiego (18,8 tys.), rosyjskiego (17,5 tys.), Czipewejowie (16,0 tys.), szkockiego lub szkocko–irlandzkiego (13,9 tys.), afrykańskiego lub arabskiego (12,8 tys.) i Dakotowie (12,7 tys.).
2,6% populacji deklaruje pochodzenie rosyjskie, co jest najwyższym odsetkiem w Stanach Zjednoczonych. Także większość Niemców pochodzi z terenów dzisiejszej Ukrainy, które w tamtym czasie należały do Imperium Rosyjskiego.
Język.
Najpowszechniej używanymi językami są:
Religia.
Struktura religijna w 2014 r.:
Według The ARDA, Dakota Północna posiada najwyższy odsetek społeczności luterańskiej w Stanach Zjednoczonych. W 2010 roku pod względem członkostwa do największych denominacji należały: Kościół katolicki (167,3 tys.), Kościół Ewangelicko-Luterański w Ameryce (163,2 tys.), Kościół Luterański Synodu Missouri (22,0 tys.), Zjednoczony Kościół Metodystyczny (17,3 tys.), oraz Zbory Boże (10,8 tys.)
Gospodarka.
Rolnictwo.
Stan jest największym w kraju producentem miodu, oraz upraw takich jak suszona jadalna fasola i fasola pinto. Stan dostarcza ponad 90% krajowej produkcji rzepaku i siemienia lnianego.
Do produktów rolnych przynoszących największy zysk należą (w nawiasach wielkość sprzedaży w 2021 roku): soja (1,8 mld $), pszenica (1,4 mld $), kukurydza (1,1 mld $), bydło (897,5 mln $), rzepak (448,7 mln $), sucha fasola (336,3 mln $), ziemniaki (217,6 mln $), buraki cukrowe (203,8 mln $), słoneczniki (192,1 mln $) i jęczmień (133,7 mln $).
Przemysł i energia.
Przede wszystkim przemysł wydobywczy (węgiel, sól, glina, piasek). Boom naftowy na polach Bakken sprawił gwałtowny rozwój stanu od 2012 roku. Dakota Północna stała się drugim stanem (po Teksasie) na liście największych producentów ropy naftowej w Stanach Zjednoczonych. Ponadto stan posiada bogate zasoby węgla i gazu ziemnego. Zachodnia część stanu posiada największe znane złoże węgla brunatnego na świecie.
Elektrownie węglowe odpowiadały za 57% produkcji energii elektrycznej w 2021 r. Pozostała część produkcji pochodziła przede wszystkim ze źródeł odnawialnych, w tym z energii wiatru (34% produkcji) i energii wodnej (5%). Gaz ziemny napędzał około 3% produkcji energii elektrycznej. Stan nie posiada elektrowni jądrowych.

</doc>
<doc id="1148" url="https://pl.wikipedia.org/wiki?curid=1148" title="Delaware">
Delaware

Delaware () – stan na wschodnim wybrzeżu Stanów Zjednoczonych, w regionie Stanów Środkowoatlantyckich, na Nizinie Atlantyckiej, nad zatoką Delaware. Na zachodzie i południu graniczy ze stanem Maryland, na północy ze stanem Pensylwania, a na północnym wschodzie z New Jersey. Jeden z trzynastu stanów pierwotnych. Leży na obszarze Niziny Nadbrzeżnej i obok Florydy jest najniżej położonym stanem Stanów Zjednoczonych. Nazwa stanu pochodzi od Thomasa Westa, barona De La Warr, angielskiego arystokraty i pierwszego gubernatora kolonialnego stanu Wirginia.
Delaware znajduje się w północno-wschodniej części półwyspu Delmarva. Jest drugim od końca (po Rhode Island) co do wielkości, szóstym od końca pod względem zaludnienia i szóstym pod względem gęstości zaludnienia stanem Stanów Zjednoczonych. Delaware dzieli się na trzy hrabstwa: New Castle, Kent i Sussex. W hrabstwach Sussex i Kent największą rolę w gospodarce odgrywa rolnictwo, natomiast w New Castle – przemysł.
Przed przybyciem Europejczyków w XVI w. Delaware był zamieszkany przez plemiona Lenni Lenape (na północy) i Nanticoke (na południu). W 1631 r. przybyli tu pierwsi Europejczycy, którymi byli Holendrzy. Zamieszkiwali obszar położony w pobliżu dzisiejszego miasta Lewes, który został przyłączony do kolonii Zwaanendael.
Duża część ziem uprawnych leży poniżej 18 m n.p.m. Na południu tereny bardziej piaszczyste i mniej urodzajne.
Delaware był pierwszym stanem, który ratyfikował Konstytucję Stanów Zjednoczonych, stąd przydomek: "First State".
Etymologia.
Pochodzi od nazwiska Thomasa Westa, barona De La Warr, pierwszego gubernatora Kompanii Wirginijskiej. Początkowo nazwano tak rzekę, później nazwę nadano zamieszkującemu te tereny plemieniu Indian.
Geografia.
Delaware jest drugim od końca pod względem wielkości stanem Stanów Zjednoczonych – jego długość wynosi 154 km, natomiast szerokość od 14 do 56 km, co daje powierzchnię 5060 km².
Granice Delaware są wyznaczone przez granicę ze stanem Pensylwania od północy, rzekę Delaware i Ocean Atlantycki od wschodu, a od zachodu i południa przez stan Maryland. Niewielkie obszary stanu są też usytuowane za wschodnią stroną estuarium rzeki Delaware, i te obszary graniczą na lądzie z New Jersey. Określenie północnej granicy stanu jest nietypowe. Większość z niego to łuk o okręgu o promieniu 12 mil (19.3 km) i środku w kopule budynku sądu w New Castle i jest znany jako "Twelve Mile Circle". Jest to jedyna zaokrąglona granica międzystanowa w Stanach Zjednoczonych.
Granica ta rozciąga się od brzegu stanu New Jersey, po czym biegnie łukiem o długości 19 km wzdłuż rzeki Delaware. W pobliżu doliny, w sąsiedztwie stanu Maryland, granica zmierza na zachód. Około kilometr dalej granica ta kieruje się na południe. W pobliżu drogi międzystanowej U.S. Route 50 granica kieruje się na wschód, do wybrzeża Oceanu Atlantyckiego w mieście Ocean City. Klin o powierzchni 3 km2, leżący w północno-zachodniej części stanu Delaware, przy zbiegu granic stanów Maryland i Pensylwania, na skutek problemów wiążących się z osiemnastowiecznymi technikami pomiarowymi stał się przedmiotem ciągnącego się przez wiele lat sporu pomiędzy otaczającymi go stanami, rozstrzygniętego na korzyść Delaware dopiero w 1921 roku.
Stan Delaware, razem z hrabstwami wschodniego wybrzeża należącymi do Maryland i dwoma hrabstwami Wirginii, tworzą Półwysep Delmarva, który rozciąga się wzdłuż Oceanu Atlantyckiego.
Topografia.
Ukształtowanie powierzchni stanu Delaware ma charakter równinny. Stan ten posiada najniższą średnią wysokość ze wszystkich stanów USA. Jego najwyższym wzniesieniem jest Ebright Azimuth, znajdujący się w pobliżu szkoły Concord High School – jego wysokość wynosi 137 m n.p.m. W północnym krańcu Delaware znajduje się płaskowyż Piedmont, charakteryzujący się pofałdowanym terenem oraz licznymi wzgórzami. Resztę obszaru Delaware zajmuje Nizina Atlantycka charakteryzująca się płaskim, piaszczystym i, w niektórych miejscach, bagnistym terenem. Granica między Piedmontem a Niziną Atlantycką biegnie wzdłuż drogi stanowej Delaware Route 2 biegnącej między miastami Newark i Wilmington. Wzdłuż zachodniej granicy Delaware biegnie grzbiet o wysokości od 23 do 24 metrów, który oddziela dorzecza rzeki Delaware od wschodu i zatoki Chesapeake.
Klimat.
Delaware znajduje się w strefie przejściowej między wilgotnym klimatem subtropikalnym i klimatem kontynentalnym. Pomimo niewielkich rozmiarów (ok. 160 km długości z północy na południe) istnieją znaczne różnice w średniej temperaturze oraz opadach śniegu między hrabstwami Sussex i New Castle. W południowej części stanu panuje łagodniejszy klimat i dłuższy okres wegetacyjny niż w jego północnej części. Najwyższa temperatura powietrza w Delaware, zanotowana 21 lipca 1930 r. w Millsboro, wynosiła 43 °C. Najniższa temperatura, zanotowana 17 stycznia 1893 r. również w Millsboro, wynosiła –27 °C.
Środowisko.
Przyroda stanu Delaware jest dosyć zróżnicowana. Hrabstwo New Castle jest porośnięte przez lasy nadbrzeżne północno-wschodnich Stanów Zjednoczonych (składające się głównie z lasów mieszanych) oraz mieszane lasy dębowe, typowe dla tej części Stanów Zjednoczonych. Hrabstwa Sussex i Kent są porośnięte przez środkowoatlantyckie lasy nadbrzeżne, składające się z lasów iglastych. Park stanowy Trap Pond jest jednym z najbardziej wysuniętych na północ miejsc w USA, gdzie rosną cypryśniki błotne.
Zarządzanie środowiskiem.
Stan Delaware zapewnia subwencję w celu odtworzenia środowiska skażonego przez odpady.
Demografia.
Spis ludności z roku 2010 stwierdza, że stan Delaware liczy 897 934 mieszkańców, co oznacza wzrost o 114 338 (14,6%) w porównaniu z poprzednim spisem z roku 2000. Dzieci poniżej piątego roku życia stanowią 5,7% populacji, 21,3% mieszkańców nie ukończyło jeszcze osiemnastego roku życia, a 18,1% to osoby mające 65 i więcej lat. 51,6% ludności stanu stanowią kobiety.
Rasy i pochodzenie.
Według spisu z 2010 roku, 69,7% mieszkańców stanowiła ludność biała (62,3% nie licząc Latynosów), 22,8% to Afroamerykanie, 4,1% to Azjaci, 2,6% miało rasę mieszaną, 0,6% to rdzenna ludność Ameryki, 0,1% to Hawajczycy i mieszkańcy innych wysp Pacyfiku. Latynosi stanowią 9,3% ludności stanu.
Największe grupy stanowią osoby pochodzenia irlandzkiego (18,8%), niemieckiego (16,5%), angielskiego (12,7%), włoskiego (10,2%) i polskiego (5,2%). Istnieją także duże grupy (ponad 10 tys.): Meksykanów, Szkotów, Portorykańczyków, Francuzów, Hindusów, Holendrów, Walijczyków i Afrykańczyków.
Język.
Najpowszechniej używanymi językami są:
Religia.
Dane z 2014 r.:

</doc>
<doc id="1150" url="https://pl.wikipedia.org/wiki?curid=1150" title="DVD">
DVD

DVD ("Digital Video Disc" lub "Digital Versatile Disc") – rozpowszechniony w roku 1995 standard zapisu danych na optycznym nośniku danych, podobnym do CD-ROM (te same wymiary: 12 lub 8 cm), lecz o większej pojemności uzyskanej dzięki zwiększeniu gęstości zapisu.
Płyty DVD dzielą się na przeznaczone tylko do odczytu DVD-ROM oraz umożliwiające zapis na płycie DVD-R, DVD-R DL, DVD-RW, DVD+R, DVD+R DL, DVD+RW, DVD-RAM.
Nazwa.
Ten skrótowiec rozwinięty był jako "Digital Versatile Disc" – "cyfrowy dysk ogólnego przeznaczenia". Nazwą oficjalną jest tylko DVD. Wymowa upowszechniona w języku polskim i angielskim to: "di-wi-di".
Technologia zapisu.
W zamyśle twórców format DVD powstał do cyfrowego zapisu materiałów wideo, jednak rosnące zapotrzebowanie przemysłu komputerowego na nośniki o większej pojemności sprawiło, że DVD stał się formatem uniwersalnym. Dzięki użyciu do odczytu płyt DVD wiązki światła lasera o krótszej długości fali niż ta używana do odczytu płyt CD, przy tej samej wielkości (średnicy) płyt DVD i CD możliwe stało się umieszczenie na płytach DVD większej ilości gęściej upakowanych ścieżek.
Format DVD, wynaleziony w roku 1995, na przełomie XX i XXI wieku stał się jednym z najpopularniejszych nośników materiałów wideo na świecie, a zarazem następcą popularnego pod koniec XX wieku amatorskiego formatu VHS, wynalezionego w roku 1976. Rozdzielczość VHS wynosiła 320x576 pikseli, natomiast rozdzielczość DVD to 720x576 pikseli. W związku z tym format DVD jest pierwszym w historii masowo rozpowszechnionym nośnikiem wideo, który dorównał jakością, a zarazem rozdzielczością, profesjonalnym nośnikom wideo, takim jak na przykład używane do produkcji tv Betacam SP (440x576 pikseli) z 1986 roku czy DigiBeta (rozdzielczość równa DVD) z 1993 roku. Format DVD to również pierwszy w historii popularny nośnik wideo, który zapewnił prawidłową ostrość obrazu, w przeciwieństwie do formatu VHS, który oferował gorszą ostrość niż profesjonalna kolorowa taśma magnetyczna do rejestracji materiałów audiowizualnych, wynaleziona przez firmę Ampex w 1958 roku, i używana tylko przez nadawców telewizyjnych. Jedną z głównych zalet i powodów popularności DVD jest także wyjątkowa trwałość, w przeciwieństwie do formatu VHS, którego nośniki ulegały ciągłej destrukcji wraz z upływem czasu przez rozmagnetyzowanie, a także przez każde kolejne odtwarzanie (poprzez stały kontakt głowicy odczytującej z taśmą), które mechanicznie zużywało i stopniowo niszczyło taśmę. Dodatkowa zaleta DVD to niewielkie rozmiary i bardzo prosta budowa.
Na płytach DVD zastosowano także dwie warstwy nałożone jedna na drugą, w których można dokonywać zapisu. Warstwa dolna jest warstwą półprzezroczystą. Wiązka lasera w zależności od długości fali i kąta nachylenia może czytać informacje zapisane na warstwie położonej niżej lub też z warstwy wyższej. Kolejną zmianą w stosunku do CD jest możliwość zastosowania krążków DVD o obustronnym zapisie.
W przeciwieństwie do CD, DVD musi zawierać system plików. System plików stosowany na DVD to UDF, będący rozszerzeniem standardu ISO 9660, który używany jest do zapisu danych na CD.
O tytuł następcy formatu DVD walczyły technologie HD DVD i Blu-ray, dyski optyczne o pojemności odpowiednio 15 GB na warstwę i 25 GB na warstwę. Zwycięzcą został format Blu-ray, zaś HD DVD nie przyjęło się na rynku.
Pojemność dysków.
Nośniki w zależności od typu mogą pomieścić od 4,38 GiB, czyli 4,7 GB (jednowarstwowe, jednostronne płyty, powszechnie znane jako DVD5) do ponad 17 GB danych (płyty dwuwarstwowe, dwustronne). Płyty mają średnicę 12 cm, natomiast grubość nośnika wynosi 1,2 mm.
Najbardziej obrazowo pojemność płyt DVD przedstawia poniższa tabelka:
Dodatkowo krążki -R i +R różnią się nieznacznie pojemnością (dane dla 12 cm):
Odtwarzacz DVD.
Urządzenie odtwarzające płyty DVD, spełniające standardy DVD-Video i DVD-Audio.
Większość odtwarzaczy DVD wymaga podłączenia do telewizora, ale istnieją również przenośne odtwarzacze DVD z wbudowanym niewielkim monitorem LCD.
Odtwarzacz DVD powinien również:
Większość odtwarzaczy DVD pozwala również na odtwarzanie płyt CD (CD-Audio, MP3 itp.) oraz Video CD (VCD) i zawiera dekoder kina domowego (np. Dolby Digital, Digital Theatre System (DTS)). Niektóre nowsze modele odtwarzają też pliki wideo w formacie MPEG-4 ASP (tzw. DivXy), spopularyzowane w Internecie, a polskie odtwarzacze umożliwiają odtwarzanie ich z dopasowanymi napisami w formacie *.txt.

</doc>
<doc id="1151" url="https://pl.wikipedia.org/wiki?curid=1151" title="DVD-Video">
DVD-Video

DVD-Video – standard definiujący zawartość dysków DVD przeznaczonych wyłącznie do odtwarzania filmów.
Definicja standardu.
Standard DVD-Video definiuje następujące elementy:
Możliwości.
Możliwości jakie oferuje DVD-Video:
Większość odtwarzaczy DVD oferuje dodatkowo opcje takie jak:

</doc>
<doc id="1152" url="https://pl.wikipedia.org/wiki?curid=1152" title="Digital Theatre System">
Digital Theatre System

Digital Theatre Systems (DTS) Digital Surround – system kompresji dźwięku, opcjonalnie stosowany w płytach DVD.
Technologia DTS pozwala zapisać sześć ścieżek dźwiękowych. DTS zostało wprowadzone do specyfikacji DVD w 1996.
System DTS oferuje lepszą jakość dźwięku w porównaniu z Dolby Digital dzięki wyższej prędkości przesyłu danych (maksymalnie 1,5 Mb/s; Dolby Digital – 640 kb/s), a także z powodu mniejszego stopnia kompresji (4:1 w stosunku do ok. 11:1 dla Dolby Digital).
W oparciu o DTS w 1999 roku powstał nowy format DTS-ES, który umożliwia rozszerzenia planu lokalizacji dźwięków do 360 stopni poprzez tylne głośniki efektowe. Jest on kompatybilny z konwencjonalnym formatem DTS.

</doc>
<doc id="1153" url="https://pl.wikipedia.org/wiki?curid=1153" title="Diagram Voronoi">
Diagram Voronoi



</doc>
<doc id="1154" url="https://pl.wikipedia.org/wiki?curid=1154" title="Notacja dużego O">
Notacja dużego O



</doc>
<doc id="1155" url="https://pl.wikipedia.org/wiki?curid=1155" title="Dalriada">
Dalriada

Dalriada (Dál Riata) – królestwo celtyckie (szkockie), rozciągające się na wybrzeżach Irlandii i dzisiejszej Szkocji, a właściwie Hebrydów Wewnętrznych i Argyll. 
Istniało już w V w n.e., pierwotnie jako podkrólestwo irlandzkie należące do królestwa Ulaid, a następnie rozprzestrzeniło się na Argyll i Hebrydy Wewnętrzne. Do Dalriady należała wyspa Iona. Dalriada walczyła z Piktami i Nortumbrią, a od VIII wieku broniła się też przed wikingami. Od najazdu Normanów na Irlandię (IX w n.e.) irlandzka część królestwa utraciła znaczenie, natomiast część szkocka rozwijała się, by w 843 roku, połączyć się (za sprawą króla Kennetha I) z Piktami tworząc królestwo Alby i dać podwaliny dzisiejszej Szkocji.

</doc>
<doc id="1156" url="https://pl.wikipedia.org/wiki?curid=1156" title="Dramat">
Dramat

Dramat (z gr. "drâma", czyli „działanie, akcja”) – jeden z trzech rodzajów literackich (obok liryki i epiki). Jest to właściwie rodzaj sztuki na granicy teatru i literatury.
Charakterystyka.
Dzieło dramatyczne zaliczane jest do literatury jedynie w warstwie słownej, natomiast w swojej realizacji widowiskowej należy do wielotworzywowej sztuki teatru. W dziele dramatycznym nie występuje podmiot literacki lub jego rola jest ograniczona do minimum, świat przedstawiony jest opisywany poprzez działania i wypowiedzi w pełni usamodzielnionych postaci. Akcja w klasycznych formach dramatu jest wyraźnie zarysowana i ma ustalony tok przebiegu (od przedstawienia, poprzez rozwinięcie, perypetię, punkt kulminacyjny, a skończywszy na rozwiązaniu).
Postacie występujące w dramacie są charakteryzowane poprzez czyny i słowa, które wypowiadają (charakterystyka pośrednia), a ich wzajemne relacje ustalane są poprzez ich udział w akcji. Obok tekstu głównego (dialogi i monologi dominujące w dramacie) mogą występować didaskalia (tekst poboczny), które wprowadzają różnego rodzaju uwagi odautorskie, dotyczące głównie sposobu inscenizacji dzieła.
Jako utwór literacki dramat charakteryzuje się przede wszystkim tym, że jest tworzony w celu realizacji scenicznej. Wyróżnia się przy tym również dramaty niesceniczne, nieprzeznaczone do wystawiania (np. ze względu na ograniczenia techniczne lub kompozycję utworu). Granice między dramatami scenicznymi i niescenicznymi są jednak płynne: pierwotnie uważano dramaty romantyczne za niesceniczne, podczas gdy dziś "Dziady" Adama Mickiewicza są jednym z najczęściej wystawianych dramatów.
Współczesny dramat zbudowany jest z aktów, które dzielą się na sceny i odsłony.

</doc>
<doc id="1157" url="https://pl.wikipedia.org/wiki?curid=1157" title="Dzielnik">
Dzielnik

Dzielnik – liczba całkowita, która dzieli bez reszty daną liczbę całkowitą. W matematyce elementarnej "dzielnikiem" liczby formula_1 nazywa się dowolną liczbę, przez którą liczba formula_1 się dzieli. W notacji matematycznej stwierdzenie „formula_3 jest dzielnikiem formula_4” zapisuje się jako formula_5.
Definicja.
Niech formula_6 będą niezerowymi liczbami całkowitymi. Liczba formula_7 jest dzielnikiem liczby formula_8 jeżeli istnieje taka liczba formula_9 że spełnione jest równanie
Mówi się wtedy, że formula_7 dzieli formula_12 bądź formula_12 jest podzielne przez formula_7 i zaznacza się symbolicznie formula_15 Liczbę formula_12 nazywa się z kolei wielokrotnością liczby formula_17
Nazwa "dzielnik" ma swoją motywację w operacji dzielenia arytmetycznego: jeżeli
to formula_12 nazywa się dzielną, formula_7 – dzielnikiem, a formula_21 – ilorazem.
Własności i dalsze definicje.
Prawdziwe są następujące reguły:
Każda liczba całkowita dzieli się przez samą siebie, liczbę do niej przeciwną, jedynkę i minus jedynkę. Swoisty wyjątek stanowi tutaj liczba zero, ponieważ dzielenie jej przez nią samą oraz liczbę do niej przeciwną (czyli w obu przypadkach przez zero) zostało uznane przez matematyków za działanie o nieoznaczonym wyniku (patrz: Dzielenie przez zero). Dzielniki formula_35 liczby formula_4 nazywa się "dzielnikami trywialnymi", wszystkie pozostałe nazywa się z kolei "nietrywialnymi"; liczby mające dzielniki nietrywialne nazywa się "liczbami złożonymi", zaś te, które nie mają nietrywialnych dzielników nazywa się "liczbami pierwszymi". "Dzielnikiem właściwym" liczby nazywa się każdy jej dodatni dzielnik, który jest od niej różny.
"Podwielokrotnością" liczby formula_4 nazywa się każdą taką liczbę formula_8 dla której formula_39 jest liczbą naturalną, w ten sposób formula_4 jest wielokrotnością formula_41 W przeciwieństwie do podwielokrotności, od dzielnika wymaga się zwykle, by był on liczbą naturalną.
Ogólnie definicję precyzuje się niekiedy dodatkowymi warunkami, np.:
Liczbę wszystkich dzielników dodatnich liczby określa funkcja formula_44 (zob. funkcja τ; stosuje się również oznaczenia formula_45 oraz formula_46), z kolei suma dzielników danej liczby wyznaczona jest za pomocą funkcji formula_47 (zob. funkcja σ).
Przykłady.
Liczba formula_48 dzieli liczbę formula_49 ponieważ formula_50
Dzielniki liczby formula_51 należą do zbioru formula_52 przy czym formula_53 są dzielnikami trywialnymi, zaś formula_54 są nietrywialne. Liczba formula_51 ma cztery dzielniki dodatnie, zatem formula_56 ich suma wynosi formula_49 dlatego formula_58
Uogólnienia.
Definicję można rozszerzyć na dziedziny całkowitości; dział teorii pierścieni zajmujący się badaniem podzielności w pierścieniach nazywa się teorią podzielności. Jeżeli formula_59 i formula_60 to elementy formula_1 oraz formula_62 nazywa się "stowarzyszonymi". Relacja stowarzyszenia zdefiniowana wzorem
jest relacją równoważności. Można to wyrazić również następująco:
gdzie formula_21 jest elementem odwracalnym ("jednością"; w istocie są to dzielniki jedynki), tzn. intuicyjnie: elementy stowarzyszone „różnią się” o czynnik odwracalny. Jest to równoważne stwierdzeniu, iż jeżeli formula_66 to dla dowolnej liczby formula_67 takiej, że formula_68 zachodzi również formula_69 Jest to powód dla którego wyróżnia się tradycyjnie w zbiorze dzielników pewne elementy (np. liczby dodatnie wśród liczb całkowitych): wtedy jeden z dzielników reprezentuje inne z nim stowarzyszone (w liczbach całkowitych odwracalne są wyłącznie formula_70 oraz formula_71). W ten sposób "dzielniki właściwe" można opisać jako dzielniki, które nie stowarzyszone z daną liczbą i niebędące przy tym jednościami. "Dzielniki nierozkładalne" to dzielniki niebędące jednością, który nie ma dzielników właściwych.
Największy dzielnik elementu formula_72 który jest równocześnie dzielnikiem formula_62 nazywa się "największym wspólnym dzielnikiem" tych elementów, przy czym jest on określony z dokładnością do stowarzyszenia.
Relację podzielności można zdefiniować w dowolnej półgrupie. Jeżeli ma ona element zerowy, to każdy element jest dzielnikiem zera (w szczególności w liczbach całkowitych formula_74 jest wielokrotnością dowolnej liczby i każda liczba jest jej dzielnikiem).

</doc>
<doc id="1158" url="https://pl.wikipedia.org/wiki?curid=1158" title="Dzielenie">
Dzielenie

Dzielenie – operacja matematyczna zdefiniowana w dowolnym ciele jako:
gdzie formula_3 jest elementem odwrotnym do formula_4
Ponieważ dzielenie definiujemy jako mnożenie przez odwrotność, nie można dzielić przez 0, gdyż nie istnieje liczba odwrotna do 0, tzn. nie istnieje liczba, która pomnożona przez 0, da element neutralny mnożenia, czyli 1.
W działaniu tym występują dwa operandy nazywające się dzielną i dzielnikiem. Wynik dzielenia nazywany jest ilorazem.
Podstawowe algorytmy dzielenia.
W ciele liczb rzeczywistych.
Gdy mianownik jest równy podstawie systemu pozycyjnego podniesionej do potęgi formula_6 to wynik dzielenia równy jest licznikowi, w którym przecinek jest przesunięty w lewo o formula_7 (dla dowolnego systemu pozycyjnego).
W ciele formula_8 (całkowitych reszt modulo liczba pierwsza formula_9).
Znajdujemy najmniejszą liczbę naturalną formula_10 taką że:
Wtedy:
Dzielenie ułamków.
Dzielenie ułamków możemy zamienić mnożeniem przez odwrotność drugiej liczby, czyli:
Dzielenie pisemne.
Poniżej podany jest przykład dla dwóch liczb naturalnych: formula_14 i formula_15
Zaczynamy od wypisania dzielnej i dzielnika, narysowania nad nimi oddzielającej kreski.
formula_16
5 jest większe od 4, więc patrzymy na kolejną cyfrę dzielnej. 5 mieści się w 48 9 razy, i formula_17
Dopisujemy więc odpowiednio: 9 nad kreską, bo 9 to maksymalna liczbą 5 „mieszcząca” się w 48, -45 pod 48, bo formula_17 Istotne jest, żeby utrzymać ostatnie cyfry w swoich „kolumnach”.
Tzn. jeśli w danym momencie patrzymy na 48, to piszemy te liczby tak, żeby ostatnie cyfry były w tej samej kolumnie, a reszta była równo oddzielona (w tym wypadku 4 pod 4).
formula_19
Dalej, odejmujemy 45 od 48 pisemnie. Cyfra z kolejnej kolumny „spada” na miejsce za ostatnią cyfrą po odejmowaniu.
formula_20
Teraz dzielimy liczbę powstałą po odejmowaniu przez 5 – w taki sposób, jak uprzednio 48: formula_21 piszemy 7 nad ostatnią cyfrą, czyli nad 7 (na niebiesko).
Kontynuujemy...
formula_22
Nie ma już więcej cyfr, które mogłyby „spaść”. Teraz, można od razu powiedzieć, że wynik dzielenia formula_23 czyli 975 z resztą 4. Ewentualnie formula_24
Można kontynuować dzielenie dopisując do dzielnej zera. Dopisanie pierwszego zera do dzielnej oznacza jednak dopisanie przecinka za ostatnią cyfrą, czyli w tym wypadku za 5.
formula_25
Otrzymujemy wynik równy formula_26 który jest zgodny z poprzednim uzyskanym wynikiem.
Po wyczerpaniu wszystkich cyfr dzielnej, 0 kończy dzielenie; w przypadku, gdy nie wszystkie cyfry dzielnej zostały „wyczerpane” (nie „spadły”), a „na dole” znajdują się same zera, dopisuje się zera do końca wyniku, tak, aby ostatnia kolumna wyniku zrównała się z ostatnią kolumną dzielnej.
formula_27
W przypadku, gdy do czynienia mamy z liczbami z rozszerzeniem dziesiętnym (cyfry po przecinku), możemy rozszerzyć ułamek tak, aby po dzielna i dzielnik były liczbami naturalnymi i kontynuować jak wyżej.
W przypadku, gdy jedna liczba jest ujemna, można wyciągnąć minus przed nawias i kontynuować jak wyżej.
Typografia.
Do zapisu operacji dzielenia używa się alternatywnie symboli formula_28 Unikod: U+2236 ∶ RATIO, U+002F / SOLIDUS, U+2044 ⁄ FRACTION SLASH (HTML &amp;frasl;), U+2215 ∕ DIVISION SLASH, U+00F7 ÷ DIVISION SIGN (HTML &amp;divide;).

</doc>
<doc id="1159" url="https://pl.wikipedia.org/wiki?curid=1159" title="Dyskryminacja">
Dyskryminacja



</doc>
<doc id="1160" url="https://pl.wikipedia.org/wiki?curid=1160" title="Dystans etniczny">
Dystans etniczny

Dystans etniczny – stopień izolowania się społeczeństwa czy tolerowanie przez nie grup mniejszościowych. Określa się go za pomocą skali dystansu społecznego stworzonej przez amerykańskiego psychologa Emory’ego Bogardusa, na której badana osoba może wyrazić opinię, czy zgodzi się:

</doc>
<doc id="1161" url="https://pl.wikipedia.org/wiki?curid=1161" title="Doktryna religijna">
Doktryna religijna

Doktryna religijna – poglądy dotyczące natury i cech charakterystycznych sfery sacrum. Jeden z elementów systemu religijnego. Można je podzielić na kilka aspektów:
Doktryny religijne przekazywane są przez mity, święte księgi, dogmaty, kapłanów, wyznawców.

</doc>
<doc id="1162" url="https://pl.wikipedia.org/wiki?curid=1162" title="Dżihad">
Dżihad

Dżihad (z języka arabskiego جهاد, ğihād – "zmaganie", ) – w kulturze islamu pojęcie pierwotnie oznaczające dokładanie starań i ponoszenie trudów w celu wzmocnienia wiary, by trafić do lepszego miejsca. W tradycji europejskiej termin ten często, choć nie do końca precyzyjnie, tłumaczy się jako „święta wojna”.
Źródłowo pojęcie to istniało na długo przed pojawieniem się Islamu, na terenach zamieszkałych przez Beduinów. Oznaczało ono głównie opiekę nad rodem, troskę o rodzinę, walkę o przeżycie. Wraz z pojawieniem się religii islamskiej zostało ono przetransponowane na grunt religijny.
Wielki i Mniejszy dżihad.
Po transpozycji pierwsze odniesienie dżihadu było do duchowości i mistyki. Oznacza on wszelki rodzaj wysiłku zmierzający ku bogu. Była to walka z pokusami, z samym sobą – niejako wojna osobista. Jest to pierwszy kontekst tzw. Wielkiego Dżihadu. Na Wielki Dżihad składają się także pomniejsze elementy takie jak dbanie o rodzinę, a także o ogół wiary.
Przejście z Wielkiego – a także uważanego za podstawowy – Dżihadu do Mniejszego ma związek zarówno z rozwojem mistyki jak i kontekstem historycznym. Co do duchowości oznaczało to po prostu objęcie troską całą wspólnotę wiernych. W kontekście historycznym rozwój Dżihadu Mniejszego przypada na okres walk o terytoria. Podobnie jak w przypadku Wielkiego Dżihadu tak i tu mamy dwa konteksty. Pierwszy oznacza walkę z najeźdźcą – sytuację w której wspólnota jest atakowana i ma obowiązek bronić swej wiary. W drugim oznacza poszerzenie zbrojne wiary o inne Państwa i nawracanie siłą niewiernych.
Mówiąc więc o Dżihadzie należy wziąć pod uwagę to co jest źródłem religijnym – ortodoksję, jej odróżnienie od fundamentalizmu jak i kontekst historyczny.
Istnieje co prawda pewna wątpliwość co do historycznego rozróżnienia i hadisów wątpliwej autentyczności, zachowanych w źródłach z przełomu X i IX wieku. Hadisy te zwykle uznawane są za słabe (da'if) a ich autentyczność za wątpliwą, w związku z czym i sam podział dżihadu na wielki i mały budzi wątpliwości. Niemniej jednak wśród społeczności duchownych i uczonych islamskich – nawet tych, wykształconych na zachodzie – rozróżnienie to jest przestrzegane.
Dżihad a kital.
Termin "dżihad" często jest zawężany do walki zbrojnej "kital". W rzeczywistości "kital", w tym walka zbrojna przeciwko „niewiernym” oraz heretykom i hipokrytom jest jednym z kilku rodzajów "dżihadu". Zbrojny "dżihad" może mieć charakter zarówno obronny ("dżihad al-daf’") jak i ofensywny ("dżihad talab"), kiedy to muzułmanie są stroną atakującą. Zgodnie z tradycją udział w "dżihadzie" jest jednym z najbardziej chwalebnych uczynków, jakich może dokonać muzułmanin a wierny, który zginie w jego trakcie jest uważany za męczennika i udaje się po śmierci do krainy szczęśliwości zwanej "dżannah".
Do zbrojnego "dżihadu" może wezwać (a nie „ogłosić” go) przywódca społeczności muzułmańskiej (według niektórych interpretacji tylko kalif). "Dżihad" prowadzony jest wysiłkiem całej wspólnoty, nie jest to bowiem obowiązek indywidualny, lecz zbiorowy, a biorą w nim udział tylko ci, którzy są w stanie to uczynić i w sposób dla nich właściwy.
Koncepcja "dżihadu" nie była skodyfikowana za czasów proroka Mahometa, lecz formowała się później, stąd różne jej interpretacje. Tylko jeden odłam islamu, charydżyzm (o małym zasięgu), wysuwał koncepcję "dżihadu" jako bezwzględnej walki zbrojnej przeciwko innowiercom, obowiązującej każdego muzułmanina, traktowanej nawet jako szósty filar wiary.
Nie ulega jednak wątpliwości, że w czasach Mahometa i bezpośrednio po jego śmierci rozumiano dżihad przede wszystkim jako walkę zbrojną i to właśnie prowadząc wojnę Mahomet zjednoczył Arabów wokół siebie, a po jego śmierci zaatakowali oni Cesarstwo Bizantyńskie i Persję, w ciągu nieco ponad stu lat podbijając całą Afrykę Północną, Półwysep Iberyjski, Bliski Wschód i znaczną część Azji Środkowej.

</doc>
<doc id="1163" url="https://pl.wikipedia.org/wiki?curid=1163" title="Operacja dukielsko-preszowska">
Operacja dukielsko-preszowska

Operacja dukielsko-preszowska (znana też jako "operacja karpacko-dukielska", "bitwa o Przełęcz Dukielską", "ofensywa dukielska" itp., słow. "Karpatsko-duklianska operácia") – wielka operacja wojskowa Armii Czerwonej we wrześniu i październiku 1944 r. w okolicach Przełęczy Dukielskiej, od okolic Dukli koło Krosna na północy po Preszów na Słowacji na południu, od okolic Polan na zachodzie po okolice Przełęczy Łupkowskiej na wschodzie.
Od świtu 8 września do 30 listopada 1944 teren ten stał się miejscem walk i pochówku około 99 tys. żołnierzy Armii Czerwonej głównie Ukraińców, Słowaków oraz żołnierzy niemieckich. Straty wojsk sowieckich wyniosły ok. 123 000 zabitych, rannych i zaginionych. Wojska czechosłowackie straciły ok. 6500 żołnierzy, natomiast straty niemieckie i węgierskie szacuje się na prawie 70 000 ludzi. Operację dukielską zaliczono do najbardziej krwawych epizodów II wojny światowej na ziemiach polskich, a jedno z miejsc walk w pobliżu Chyrowej, gdzie toczyła się krwawa bitwa pancerna, nazwano „Doliną Śmierci”.
Przyczyny i przygotowania.
Dowództwo niemieckie ściągnęło tu znaczne siły i umocniło teren, tworząc tzw. „Karpatenfestung” (zob. Linia Arpada). Wojska niemieckie dysponowały 18 dywizjami, w tym 3 pancernymi (w sumie ok. 100 tys. żołnierzy), 350 czołgami i dwoma tysiącami dział. Mimo że czołgi Armii Czerwonej już 22 lipca 1944 dotarły do Korczyny i na przedmieście Krosna, to jednak front zatrzymał się na północ od tego miasta. Niemcy do września mieli czas, aby obsadzić wzgórza i zająć dogodne pozycje.
Słowacja pod władzą nacjonalistycznego ugrupowania ludowców księdza Jozefa Tiso, formalnie niepodległa od 1939 r., była w rzeczywistości w pełni podległa Niemcom, którzy mieli czas i siły, by 29 sierpnia 1944 przekroczyć granicę słowacką i w ciągu paru dni zmusić powstańców słowackich do wycofania się w góry środkowej Słowacji. Dlatego w tej sprawie w Moskwie 31 sierpnia 1944 ambasador emigracyjnego rządu Czechosłowacji zwrócił się do rządu sowieckiego o pomoc militarną.
Dowódca I Frontu Ukraińskiego, marszałek Iwan Koniew, 2 września 1944 otrzymał rozkaz opracowania planu natarcia, który został zaakceptowany. Do operacji dukielsko-preszowskiej wyznaczono 38 Armię gen. Kiryła Moskalenki w składzie dziewięciu dywizji piechoty z I Frontu Ukraińskiego, wspieraną przez I Czechosłowacki Korpus Armijny (d-ca gen. J. Kratochvil zmieniony później przez gen. Svobodę), a od pd. dla wzmocnienia wyznaczono: 25. Korpus Pancerny, l Armię Gwardii gen. Andrieja Grieczki z IV Frontu Ukraińskiego (d-ca gen. Iwan Pietrow). Łącznie 120 tys. ludzi, ok. 1700 dział i moździerzy oraz 1000 czołgów.
Plan przewidywał uderzenie w stronę Słowacji. Drugiego dnia natarcia Rosjanie zamierzali osiągnąć szosę Dukla – Nowy Żmigród, natomiast piątego dnia piechota miała być w Muszynie, a kawaleria pancerna w Preszowie na Słowacji.
Przebieg.
W krwawych walkach 8 września została zdobyta Machnówka i Wrocanka, a 10 września Draganowa i Sulistrowa. Po 3 dniach walk, 11 września zdobyto Krosno, po czym rozpoczął się krwawy, wielodniowy bój o Duklę i strategiczne wzgórze Franków (534 m n.p.m.), dominujące nad drogą Dukla - Nowy Żmigród, gdzie Dywizja Kawalerii Gwardii gen. Baranowa zastosowała manewr oskrzydlający, wchodząc w dolinę największego ostrzału. W pobliżu Iwli i miejscowości Głojsce rozgorzała bitwa pancerna o drogę Dukla – Nowy Żmigród. Tej akcji towarzyszyło natarcie 2 Czechosłowackiej Brygady Desantowo-Szturmowej na wzgórze Franków od strony trasy leżącej w dolinie. W czasie walk wzgórze trzykrotnie zmieniało zdobywców. Ostatecznie zostało zdobyte przez czechosłowacki oddział por. Sochara. Pozwoliło to na atak: 31 i 4 Korpusu Gwardii i zdobycie Iwonicza, Lubatowej i Dukli. Dopiero po kilku dniach walk zdobyto 23 września Tylawę i Teodorówkę. Wielodniowe walki trwały o następne wzgórze Chyrowa (695 m n.p.m.), które zdobyto 29 września. Następnego dnia, rozpoczęły się walki o Przełęcz Dukielską w okolicach Barwinka. Korpus Czechosłowacki, posuwając się drogą w dolinie, stracił w niej wszystkie czołgi. Dopiero 6 października 1944, z rana (ok. godz. 8) udało się pierwszym żołnierzom, przekroczyć przełęcz i granicę swojej ojczyzny. Najcięższe walki trwały do 10 października 1944.
Przedsięwzięcie to miało na celu, oprócz zajęcia przełęczy karpackich, przyjście z pomocą rozpoczętemu powstaniu słowackiemu (słow. "Slovenské národné povstanie, SNP" – powstanie słowackie) – na terenie Słowacji od 29 sierpnia 1944 do 28 października 1944. Dopiero w styczniu 1945 wskutek zimowego natarcia Frontu Ukraińskiego⁣, a nie 38 Armii, Niemcy wycofali się na linię Ondavy. Operacja opóźniła się, chociaż pierwotnie zakładano, że cała akcja przeprowadzona zostanie błyskawicznie. Powstanie zostało po dwóch miesiącach (koniec października 1944) zdławione przez Niemców i armię wierną prezydentowi J. Tiso. Wcześniej powstańcy utworzyli w Bańskiej Bystrzycy ośrodek władzy przeciw kolaboranckiemu rządowi księdza Jozefa Tiso, gdzie urzędowała Słowacka Rada Narodowa skupiająca przedstawicieli wszystkich ugrupowań słowackich i mająca charakter demokratyczny. Powstanie na Słowacji nie przetrwało do czasu nadejścia pomocy, bo walki w rejonie Przełęczy Dukielskiej przedłużały się.
Skutki.
Straty Armii Czerwonej wpłynęły na zatrzymanie również ofensywy w kierunku na Jasło na kilka miesięcy. Niemcy zyskali czas na przygotowanie obrony na tym odcinku i wyburzenie w Jaśle wielu domów.
Sowiecka decyzja o podjęciu natarcia bezpośrednio na przełęczy jako osobisty rozkaz Stalina, który zaplanował i zrealizował tym samym ludobójstwo na własnych żołnierzach. Rozkaz nr 227 z 28 lipca 1942 roku Ludowego Komisarza Obrony, który znany jest również jako rozkaz „Ani kroku wstecz”, doprowadził wielokrotnie do masowej śmierci żołnierzy. W tym wypadku walki górskie były okazją do pozbycia się ludzi „niepewnych politycznie”, głównie Ukraińców i mieszkańców Kazachstanu oraz powstańców słowackich, których dowódca, gen. Rudolf Viest, był zrzutkiem z Londynu, gdzie działał legalny rząd czechosłowacki pod przewodnictwem prezydenta Edvarda Beneša.
W ataku na dwa miasta, Duklę i Jasło, Koniew utracił około 130 tys. żołnierzy, a jedynie zdobył Dukle i praktycznie nie uzyskał zamierzonych celów. Dla porównania, w całej kampanii wrześniowej w armii polskiej poległo około 70 tys. żołnierzy, a w operacji „Barbarossa” armie niemieckie, podczas zdobywania: Mińska, Kijowa, Smoleńska utraciły około 118 tys. żołnierzy.
Na terenie prawie przylegającym do obszaru działań, oddział Armii Krajowej złożony z 38 ochotników, 26 lipca 1944 wyzwolił Iwonicz-Zdrój nie ponosząc strat w ludziach i utrzymywał wolne państwo Rzeczpospolitą Iwonicką, aż do wejścia w dniu 20 września 1944 sił Armii Czerwonej.
Pamiątki.
Na Cmentarzu Wojennym w Dukli przy kościele Ojców Bernardynów spoczywa najwięcej z poległych podczas operacji dukielsko-preszowskiej. Znajdują się tu zbiorowe mogiły i pomnik upamiętniający żołnierzy, którzy zginęli w I i w II wojnie światowej.
W Barwinku (Vyšný Komárnik), po słowackiej stronie Pomnik – Mauzoleum, upamiętniający poległych żołnierzy w walkach o Przełęcz Dukielsko-Preszowską.

</doc>
<doc id="1164" url="https://pl.wikipedia.org/wiki?curid=1164" title="Doba">
Doba

Doba – astronomiczna jednostka miary upływu czasu związana z obrotem Ziemi wokół własnej osi (ale nie jest równa jednemu pełnemu obrotowi, który trwa 23 h 56 min 4,091 s). Jako urzędowa jednostka czasu zdefiniowana jest jako czas trwania 24 godzin = 1440 minut = 86 400 sekund. Początek doby astronomicznej może wypadać, w zależności od przyjętego założenia, w różnych porach ziemskiego dnia:

</doc>
<doc id="1165" url="https://pl.wikipedia.org/wiki?curid=1165" title="Dzień">
Dzień

Dzień – czas między wschodem a zachodem Słońca. Określenie to utożsamia się z dobą (np. jaki jest dzisiaj dzień? – pytanie to jest zadawane bez względu na to, czy czas jest dzienny, czy nocny).
Długość dnia różni się w zależności od szerokości geograficznej oraz deklinacji słońca.
Podział dnia.
Grecy i Rzymianie liczyli czas dzienny długością cienia ludzkiego. Do określania części dnia, odpowiadających zjawiskom przyrody, należały takie jak: północ "media nox", południe "meridies", zachód słońca "occasus solis", brzask "ante lucem", zmierzch "crepusculum", rano "mane", wieczór "vespera". Zjawiska życiowe zależnie od tych pór dnia i nocy mają też swoje określenia, np. pierwsze pianie koguta, zapalenie światła.
W średniowieczu powstał podział dnia na 7 godzin kanonicznych:
Po wieloletnich przekształceniach ustaliły się główne pory dnia o nazwach "prima, terti, nona i vespera".
Rzymianie dzielili także noc na cztery 3-godzinne wigilie do odbywania straży nocnych, co zostało przyjęte przez średniowieczne zakony dla odprawiania nabożeństw. Noc dzielono na 4 równe wigilie: 1) od 6 wieczór do 9, 2) 9-12, 3) 12-3, 4) 3-6.

</doc>
<doc id="1168" url="https://pl.wikipedia.org/wiki?curid=1168" title="Dolby Digital">
Dolby Digital



</doc>
<doc id="1169" url="https://pl.wikipedia.org/wiki?curid=1169" title="Dni sankiulotów">
Dni sankiulotów



</doc>
<doc id="1170" url="https://pl.wikipedia.org/wiki?curid=1170" title="Domain Name System">
Domain Name System

Domain Name System (DNS, pol. system nazw domen) – hierarchiczny rozproszony system nazw sieciowych, który odpowiada na zapytania o nazwy domen.
Dzięki DNS nazwa mnemoniczna, np. "pl.wikipedia.org" jest tłumaczona na odpowiadający jej adres IP, czyli "91.198.174.192". 
DNS to złożony system komputerowy oraz prawny. Zapewnia z jednej strony rejestrację nazw domen internetowych i ich powiązanie z adresami IP. Z drugiej strony realizuje bieżącą obsługę komputerów odnajdujących adresy IP odpowiadające poszczególnym nazwom. Jest nieodzowny do działania prawie wszystkich usług sieci Internet.
Nazwy domen.
Rozproszona baza danych DNS jest indeksowana nazwami domen, tworzącymi drzewiastą strukturę hierarchiczną. Węzły drzewa DNS posiadają etykiety tekstowe o długości od 1 do 63 znaków: pusta etykieta o zerowej długości zarezerwowana jest dla węzła głównego. Etykiety węzłów oddzielone kropkami czytane w kierunku od węzła do korzenia drzewa tworzą pełną nazwę domenową (np. „pl.wikipedia.org.”).
Domena jest poddrzewem hierarchii nazw, obejmującym zbiór domen (subdomen) o wspólnym sufiksie, nazwanym tak jak węzeł na szczycie (np. domena funkcjonalna com.pl grupująca nazwy zakończone .com.pl). Nazwy „hostów” są nazwami domen, do których przypisana jest informacja o konkretnych urządzeniach i zazwyczaj występują w liściach drzewa DNS (czyli nie mają swoich poddomen), ale ogólnie jedna nazwa może opisywać zarówno hosta (np. główny serwer WWW organizacji), jak i całą domenę.
Przykładowo, wewnątrz domeny najwyższego poziomu .pl utworzono wiele domen:
Dozwolone znaki.
Nazwy domen mogą zawierać litery, cyfry i znak '-'. W nazwach niektórych domen można używać znaków narodowych (IDN) takich jak 'ą' czy 'ż'. Trwają prace nad nowymi standardami odpowiadającymi DNS, które będą obsługiwać kodowanie Unicode, co pozwoli na umieszczanie w nazwach domen dowolnych znaków np. polskich albo chińskich równocześnie. .
Administracja DNS.
DNS, jako system organizacyjny, składa się z dwóch instytucji – IANA i ICANN. Nadzorują one ogólne zasady przyznawania nazw domen i adresów IP. Nie zajmują się jednak one przydzielaniem domen poszczególnym chętnym, jedynie rozdzielają domeny najwyższego poziomu (takie jak:.pl.gov.com.eu) pomiędzy kraje lub wybrane organizacje i przekazują im prawa do zarządzania tymi domenami. Te mogą dalej przekazywać nadzór nad całością bądź częścią swoich domen, i tak Rząd Polski przekazuje nadzór nad domeną .pl Naukowej i Akademickiej Sieci Komputerowej, która rozdziela poddomeny w obrębie domeny.pl pomiędzy zainteresowanych. Ci z kolei mogą rozdzielać te domeny pomiędzy poszczególne komputery lub dalej swoim klientom.
W wielu krajach domena internetowa przyznana przez system DNS staje się własnością tego, kto pierwszy ją kupi. W Polsce jest ona tylko wynajmowana na określony czas. Jeżeli ktoś zrezygnuje ze swojej domeny i zwróci ją administratorowi DNS, może ona trafić w inne ręce.
Instytucje administrujące DNS na świecie:
Instytucje administrujące DNS w Polsce:
Techniczna strona DNS.
Ogólny zarys.
Podstawą technicznego systemu DNS jest ogólnoświatowa sieć serwerów przechowujących informacje na temat adresów domen. Każdy wpis zawiera nazwę oraz odpowiadającą jej wartość, najczęściej adres IP. System DNS jest podstawą dla rozwiązywania nazw hostów w Internecie.
DNS to również protokół komunikacyjny opisujący sposób łączenia się klientów z serwerami DNS. Częścią specyfikacji protokołu jest również zestaw zaleceń, jak aktualizować wpisy w bazach domen internetowych.
Na świecie jest wiele serwerów DNS, które odpowiadają za obsługę poszczególnych domen internetowych. Domeny mają strukturę drzewiastą, na szczycie znajduje się 13 głównych serwerów ("root servers") obsługujących domeny najwyższego poziomu (TLD – top level domains), których listę z ich adresami IP można pobrać z ftp://ftp.rs.internic.net/domain/named.root
Serwery najwyższego poziomu z reguły posiadają tylko odwołania do odpowiednich serwerów DNS odpowiedzialnych za domeny niższego rzędu, np. serwery główne (obsługujące między innymi TLD.com) wiedzą, które serwery DNS odpowiedzialne są za domenę example.com. Serwery DNS zwracają nazwę serwerów odpowiedzialnych za domeny niższego rzędu. Możliwa jest sytuacja, że serwer główny odpowiada, że dane o domenie example.com posiada serwer dns.example.com. W celu uniknięcia zapętlenia w takiej sytuacji serwer główny do odpowiedzi dołącza specjalny rekord (tak zwany "glue record") zawierający także adres IP serwera niższego rzędu (w tym przypadku dns.example.com).
Najważniejsze cechy.
System DNS posiada następujące cechy:
RFC.
Podstawy protokołu DNS zostały opisane w 1982 roku w dokumencie przez Jona Postela i Zaw-Sing Su. Dokumenty z 1983 r. – i były oficjalną specyfikacją DNS aż do roku 1989. Nowa, aktualna specyfikacja DNS jest zawarta w i . W 1996 wydano jeszcze , które wprowadziło zasady „Internet Best Current Practices” oraz dodało do specyfikacji pulę adresów IP przeznaczoną na tzw. prywatne podsieci.
Główne serwery DNS.
DNS opiera się na 13 głównych serwerach, zwanych po angielsku root-servers, posiadającymi nazwy od "a.root-servers.net" do "m.root-servers.net". Nie może być ich więcej, ograniczenie wynika z tego, że pojedynczy pakiet UDP o standardowej wielkości 1500 bajtów mieści właśnie informacje o maksymalnie 13 serwerach. Ponieważ główne serwery DNS są podstawą działania Internetu i otrzymują ogromne ilości zapytań, zostały one skopiowane. Kopie głównych serwerów umieszczone są w różnych częściach świata (posiadają one te same adresy IP co serwery główne). Użytkownicy z reguły łączą się z najbliższym im serwerem. Przykładowo globalne węzły serwera "k.root-servers.net" zarządzanego przez organizację RIPE NCC umieszczone są w Amsterdamie, Londynie, Tokio, Delhi oraz Miami, podczas gdy jeden z jego polskich węzłów lokalnych znajduje się w Poznańskim Centrum Superkomputerowo-Sieciowym, a drugi w centrum przetwarzania danych Aplitt sp. z o.o. w Gdyni.
Protokół DNS.
Zapytania i odpowiedzi DNS są najczęściej transportowane w pakietach UDP. Każdy komunikat musi się zawrzeć w jednym pakiecie UDP (standardowo 512 oktetów, ale wielkość tę można zmieniać pamiętając również o ustawieniu takiej samej wielkości w MTU – "Maximum Transmission Unit"). W innym przypadku przesyłany jest protokołem TCP i poprzedzony dwubajtową wartością określającą długość zapytania i długość odpowiedzi (bez wliczania tych dwóch bajtów). Format komunikatu DNS został zdefiniowany w .
Format komunikatu DNS:
Forma nagłówka, który określa rolę całego komunikatu:
Sekcja nagłówka występuje zawsze. W sekcji zapytania zawsze znajduje się jedno zapytanie zawierające nazwę domenową, żądany typ danych i klasę (IN). Sekcja odpowiedzi zawiera rekordy zasobów stanowiące odpowiedź na pytanie.
Przykład działania systemu DNS.
Oto przykład działania systemu DNS. Użytkownik komputera wpisuje w swojej przeglądarce stron WWW adres internetowy "pl.wikipedia.org". Przeglądarka musi poznać adres IP komputera będącego serwerem WWW dla tej strony. Cały proces przebiega zgodnie z tabelą.
Typy rekordów DNS.
Najważniejsze typy rekordów DNS oraz ich znaczenie:
Inne typy rekordów dostarczają informacje o położeniu hosta (np. rekord LOC) lub o danych eksperymentalnych.
Narzędzia.
W systemach operacyjnych zapytania do DNS zwykle są wykonywane w sposób niewidoczny dla użytkownika przez dedykowany podsystem (ang. "resolver"). Do bezpośredniego odpytywania DNS np. w celach diagnostycznych, można się posłużyć programami nslookup, host lub dig, dostępnymi w wielu systemach operacyjnych.
Konfiguracja.
Zwykle dane o konfiguracji protokołu DNS w domowym komputerze przekazywane są przez dostawcę Internetu (ISP). Większość operatorów udostępnia w swojej sieci protokół DHCP. Dzięki niemu komputer może automatycznie pobrać konfigurację sieciową sugerowaną przez operatora, w tym adresy serwerów DNS. Adresy te z reguły – ale nie zawsze – wskazują na serwery dobrane relatywnie dogodnie dla użytkowników. Kiedy system automatycznego pobierania adresów serwera DNS nie działa, można je wprowadzić ręcznie. W systemach typu uniksowego służy do tego /etc/resolv.conf który zawiera listę serwerów DNS.
Jeżeli użytkownik chce w swojej sieci lokalnej uruchomić własny serwer DNS może posłużyć się programem BIND. Jednak jest on dosyć skomplikowany w użytkowaniu.
Bezpieczeństwo.
Należy zdać sobie sprawę, że system DNS został zaprojektowany wiele lat temu przez naukowców. Nie przewidzieli oni „trafienia internetu pod strzechy” i istnienia światowej sieci używanej do prowadzenia poważnych operacji. W Internecie pojawiła się grupa osób wykorzystująca luki w systemie DNS do łamania prawa.
Podstawową wadą DNS jest to, iż korzysta on z bezpołączeniowego protokołu UDP i nie zawiera żadnych mechanizmów autoryzujących. Pierwsza cecha może być używana w atakach DDoS – komputer atakujący może wysyłać zapytania DNS do różnych serwerów na świecie ze sfałszowanym adresem źródłowym, przedstawiając się jako komputer ofiara. Serwery te odpowiadają na zapytania, wysyłając odpowiedzi do komputera ofiary, bo tak wskazuje adres źródłowy pakietu. Konstrukcja protokołu DNS powoduje, że jedno małe zapytanie mieszczące się w pakiecie o wielkości poniżej 100 bajtów, może wygenerować odpowiedź o wielkości ponad dziesięciokrotnie większej. Atakujący komputer wysyłając strumień 1 Mbps takich zapytań może spowodować ponad 10 Mbps odpowiedzi przychodzących do komputera ofiary, zakłócając w ten sposób pracę jego łącza.
DNS łatwo też poddaje się atakom typu man in the middle, co pozwala na przysyłanie fałszywych odpowiedzi do komputera ofiary, zmuszając go do połączenia się z innym serwerem, co pozwala na przykład na kradzież haseł. Istnieje wiele innych możliwości ataków na infrastrukturę DNS, łącznie nawet z uruchamianiem fałszywych serwerów głównych. O słabościach protokołu DNS zdano sobie sprawę wcześnie i stworzono jego rozszerzenie oparte na podpisach cyfrowych nazwane DNSSEC, jednakże system ten nie został całkowicie zaakceptowany przez Internet, nie jest wspierany przez wiele narzędzi, w związku z czym w internecie praktycznie nie jest używany.

</doc>
<doc id="1171" url="https://pl.wikipedia.org/wiki?curid=1171" title="Dialekty judeo-romańskie">
Dialekty judeo-romańskie

Dialekty judeo-romańskie – dialekty lub języki, którymi posługują lub posługiwali się Żydzi wywodzący się z krajów romańskich - przede wszystkim Żydzi sefardyjscy wywodzący się z Półwyspu Iberyjskiego, ale także Żydzi włoscy i francuscy. Powstały one na bazie romańskiej z dodatkiem elementów hebrajskich i aramejskich. Najstarsze zabytki literatury w tych dialektach, zapisywane alfabetem hebrajskim pochodzą z XI wieku. 
Poza językiem ladino (judeohiszpańskim) dialekty judeo-romańskie są etnolektami wymarłymi lub na krawędzi wymarcia.
Najważniejsze języki judeo-romańskie to:

</doc>
<doc id="1172" url="https://pl.wikipedia.org/wiki?curid=1172" title="Dorzecze">
Dorzecze

Dorzecze – obszar lądu, z którego całkowity odpływ wód powierzchniowych do wód morskich następuje ciekami naturalnymi przez jedno ujście, estuarium lub deltę.
Dorzecza w Polsce.
Na terytorium Polski znajdują się w całości lub w części dorzecza:
oraz mniejszych rzek wpadających do Bałtyku, takich jak Pregoła, Wkra, Parsęta, Rega i inne.

</doc>
<doc id="1174" url="https://pl.wikipedia.org/wiki?curid=1174" title="Dobór grupowy">
Dobór grupowy

Dobór grupowy – mechanizm ewolucji biologicznej, w którym dobór naturalny oddziałuje na całe grupy osobników, a nie wyłącznie na pojedyncze osobniki lub geny.
Mechanizm.
Polega on na faworyzacji (a co za tym idzie – rozpowszechnianiu) alleli korzystnych dla populacji, pomimo ich szkodliwości dla osobnika (tzw. altruizm genetyczny) na skutek międzypopulacyjnej konkurencji wewnątrzgatunkowej.
Historia.
Koncepcja spopularyzowane m.in. przez Vero C. Wynne-Edwardsa.
Przez długi czas odrzucana w biologii ewolucyjnej, szukającej wyjaśnień w doborze osobniczym. Koncepcja zyskała na popularności w ostatnich dekadach w postaci "wielopoziomowego doboru grupowego".
Wielopoziomowy dobór grupowy.
Rozwinięciem koncepcji doboru grupowego jest wielopoziomowy dobór grupowy. Zakłada on wielopoziomowość ewolucji - osobniki konkurują między sobą w ramach grup, a grupy konkurują między sobą w ramach większych grup. Zgodnie z nim grupy złożone z altruistycznych osobników mogą być preferowane przez dobór przy istnieniu konkurencji między grupami, prowadząc do wzrostu częstości altruistycznych osobników w populacji. Analogiczny proces może zachodzić na wyższych szczeblach organizacyjnych (grupy grup). Koncepcja ta stosowana jest do wyjaśnienia ewolucji kulturowej zachowań sprzyjających spójności grupowej (religia, muzyka) i różnic międzygrupowych, a także formowania się państw i imperiów.

</doc>
<doc id="1175" url="https://pl.wikipedia.org/wiki?curid=1175" title="Dobór krewniaczy">
Dobór krewniaczy

Dobór krewniaczy (ang. "kin selection") – mechanizm ewolucji biologicznej, który prowadzi do adaptacji organizmów, polegającej na zwiększaniu szansy przeżycia osobników z nimi spokrewnionych. Istnienie doboru krewniaczego jest kontrowersyjną hipotezą, proponowane są alternatywne do niego modele.
Ewolucyjne wyjaśnienie altruizmu.
Dobór krewniaczy wyjaśnia pochodzenie zachowań altruistycznych w stosunku do osobników spokrewnionych. Został oryginalnie zaproponowany przez Karola Darwina jako wytłumaczenie istnienia sterylnych kast u owadów, lecz ogólną akceptację zyskał dopiero dzięki przełomowym pracom W.D. Hamiltona. Hamilton wprowadził koncepcję dostosowania włącznego (ang. "inclusive fitness"), która mówi, że dostosowanie danego organizmu jest sumą sukcesu reprodukcyjnego i wpływu tego organizmu na sukces reprodukcyjny jego krewniaków.
Do najprostszych przykładów doboru krewniaczego należy dobrowolne poświęcenie dla własnego potomstwa, co prowadzi do dobrowolnego pozbawienia się przez rodzica części pokarmu, a więc zmniejszenia swoich szans na przeżycie. Podobne zjawisko obserwuje się w organizmach wielokomórkowych, gdzie dla dobra całej istoty żywej niektóre komórki ulegają apoptozie.
Opis matematyczny.
Dla badania doboru krewniaczego wygodny jest "współczynnik pokrewieństwa", czyli liczba z przedziału od 0 do 1 mówiąca, jaką część genów dwa osobniki odziedziczyły po wspólnych przodkach lub jeden względem drugiego. Dla bliźniąt jednojajowych liczba ta wynosi 1; w relacji rodzic – dziecko 0,5; między pełnym rodzeństwem 0,5; między niepełnym (wspólny 1 rodzic) – 0,25; itd.
Częstość allelu w populacji może wzrosnąć, jeśli organizm-nosiciel danego allelu pomaga swoim krewnym, o ile korzyści odniesione przez krewniaków zgodne są z tzw. "zasadą Hamiltona":
gdzie:
Przykład pszczół.
Aby lepiej zrozumieć, jak współczynnik pokrewieństwa warunkuje ewolucję zachowań altruistycznych, można posłużyć się przykładem pszczół. Wśród innych owadów wyróżniają się one bardzo szczególnym systemem rozmnażania. Pszczele królowe są diploidalne (posiadają dwa zestawy genów), a trutnie haploidalne (tylko jeden zestaw). Komórki jajowe zawierają tylko jeden zestaw genów będący losową kombinacją obu zestawów genów królowej. Wszystkie plemniki zawarte w nasieniu jednego trutnia zawierają cały jego zestaw genów i są identyczne. Robotnice powstają w efekcie zapłodnienia komórki jajowej pochodzącej od królowej przez plemnik dostarczony przez jednego z trutni, z którym uprzednio kopulowała.
Taki system haplo-diploidalny powoduje, że współczynnik pokrewieństwa pomiędzy robotnicami w ulu wynosi (zakładając tego samego ojca, trutnia) 0,75. W rzeczywistości, ponieważ królowa-matka jest zapładniana przez nawet do 30 trutni, współczynnik pokrewieństwa robotnica-robotnica zawiera się w od 0,25 do 0,75.
Jeżeli wykonamy obliczenia dla pszczół, to okaże się, że gen nakazujący robotnicy oddanie życia (koszt 1 – zero szans na potomstwo) za dwie inne robotnice mające tego samego ojca (pokrewieństwo 0,75):
będzie rozprzestrzeniać się w populacji tych produkujących miód owadów. Co więcej, robotnica oddaje zwykle życie nie za dwie siostry, lecz za tysiące, co jeszcze zwiększa „zysk” jej genów. Po przeprowadzeniu tego rozumowania można pojąć, jak na drodze ewolucji mógł powstać gen nakazujący robotnicy samobójczy atak na każdego amatora miodu, aby obronić cały ul. Taki skrajny przejaw osobniczego altruizmu jest przejawem „egoizmu genów” (zob. Samolubny gen).

</doc>
<doc id="1176" url="https://pl.wikipedia.org/wiki?curid=1176" title="Dobór płciowy">
Dobór płciowy

Dobór płciowy – szczególny przypadek doboru naturalnego, gdzie o dostosowaniu decyduje postrzegana atrakcyjność dla płci przeciwnej. 
Postulat Darwina i teoria Anderssona.
Dobór płciowy został zaproponowany przez Karola Darwina jako wytłumaczenie pochodzenia ekstrawaganckich i kosztownych cech u organizmów żywych. Najlepszą strategią rozrodczą jest dobieranie dokładnie takich partnerów, jacy mają najlepsze z ekologicznego punktu widzenia cechy, ponieważ gusta wybierającego lub wybierającej jednocześnie same podlegają doborowi ze względu na trafność wyborów, do jakich dokonywania prowokują. To pozornie wykluczało możliwość powstawania w wyniku doboru naturalnego cech nieprzydatnych czy niekorzystnych. Tymczasem dobór naturalny od początku był teorią mającą wyjaśnić powstanie cech, które wydawały się niepotrzebne czy szkodliwe. Dopiero teoria handicapu (handicapizmu) rozwiązała ten pozorny paradoks. 
W związku z doborem płciowym istniało wiele teorii, zwykle trudno przekładalnych na język matematyki. Jednocześnie potwierdzenie eksperymentalne doboru płciowego i faktu, że opiera się on na preferencjach partnera seksualnego, było trudne. Idea doboru płciowego została ogólnie zaakceptowana jako teoria naukowa dopiero po ukazaniu się w 1982 r. przełomowej, eksperymentalnej pracy Malte Anderssona. Wykazała ona istnienie wyboru dokonywanego przez samicę i ukierunkowanego na drugorzędowe cechy samca, dokumentując tym samym zachodzenie doboru płciowego. Poprzez eksperymentalną manipulację długością piór ogonowych samców wikłacza olbrzymiego ("Euplectes progne"), ptaków z rodziny wikłaczowatych, Andersson udokumentował, że osobniki z dłuższymi piórami mają większe szanse na zdobycie samicy. Od tego czasu wykazano eksperymentalnie istnienie doboru płciowego u różnych gatunków.
Wyjaśnienie preferencji wobec cech obniżających przystosowanie.
Pojawiły się też rozmaite hipotezy wyjaśniające preferencje wobec cech obniżających przystosowanie do środowiska (np. jaskrawych barw, zwracających uwagę drapieżników, kosztownych w wytworzeniu ozdób, pogarszających zarazem zdolność ucieczki ich posiadacza, itp.). Do ważniejszych należą: 
O przyjęciu teorii handicapu i odrzuceniu wcześniejszej hipotezy atrakcyjnych synów zadecydowały trzy czynniki: 1) sprzeczność hipotezy atrakcyjnych synów z ogólną teorią doboru naturalnego 2) dane empiryczne 3) brak konkluzywności hipotezy atrakcyjnych synów.
Dobór płciowy człowieka.
Istnieją też badania nad doborem płciowym u człowieka; psychologia ewolucyjna wyjaśnia korzyści z określonych preferencji przekładające się na większe dostosowanie: np. preferowana jest symetria ciała (brak zaburzeń rozwojowych), wyższy wzrost (u mężczyzn), oznaki młodości, liczba dzieci, jakie może urodzić kobieta jest zależna od jej wieku, niska proporcja talii do bioder wskazująca, że kobieta nie jest już w ciąży i zwiększająca prawdopodobieństwo urodzenia wielu zdrowych dzieci itp.
Dobór płciowy związany jest z drugo- i trzeciorzędowymi cechami płciowymi.

</doc>
<doc id="1177" url="https://pl.wikipedia.org/wiki?curid=1177" title="David Hume">
David Hume

David Hume (ur. w Edynburgu, zm. 25 sierpnia 1776 tamże) – szkocki filozof, historyk i ekonomista. Był przedstawicielem sensualizmu, sceptycyzmu pragmatycznego i agnostycyzmu. Zakładał krytykę pojęcia substancji, przyczynowości i siły. W ekonomii popierał wolny handel i krytykował merkantylizm.
Urodzony w Szkocji, wychowany w Anglii, a żyjący we Francji i w Anglii. Za życia znany głównie jako historyk – popularyzator historii średniowiecznej Anglii. Od XIX w. jest pamiętany przede wszystkim jako filozof. Cenią go również socjolodzy i przedstawiciele innych nauk społecznych, głównie za jego przemyślenia dotyczące metodologii nauk empirycznych i rozróżnienie sądów o faktach i wartościach. Epistemologia Hume’a była podstawą późniejszego pozytywizmu w filozofii nauki – zwłaszcza II i III fali, tzn. empiriokrytycyzmu i pozytywizmu logicznego.
Jego największe dzieła filozoficzne to: "Traktat o naturze ludzkiej", "Badania dotyczące rozumu ludzkiego" oraz "Badania dotyczące zasad moralności".
Jego wszystkie dzieła ("opera omnia") umieszczone zostały w index librorum prohibitorum dekretami z 1761 i 1827 roku.
Życiorys.
David Hume urodził się 7 maja 1711 roku w Edynburgu. Pochodził ze średnio zamożnej ziemiańskiej rodziny spokrewnionej z hrabiami Home. Dzieciństwo spędził w majątku rodzinnym Ninewells w pobliżu Chirnside w południowo-wschodniej Szkocji (hrabstwo Scottish Borders). Uczył się w Edynburgu. Jako młodszy syn nie odziedziczył majątku, lecz otrzymywał niewielką pensję, która zapewniała mu skromne utrzymanie w trakcie studiów we Francji.
W latach 1734–1737 przebywał we Francji, w miejscowości Flèche w regionie Kraj Loary. Tam też stworzył swoje najważniejsze dzieło – zawarty w trzech tomach "Traktat o naturze ludzkiej". Dzieło to jednak zostało źle przyjęte przez ówczesną opinię publiczną, a śmiałe poglądy Hume’a na temat ludzkiej moralności zamknęły mu drogę do kariery uniwersyteckiej.
W czasie pobytu na francuskiej prowincji, stworzył Hume również szereg studiów etycznych i politycznych, które zostały wydane w roku 1744. Dwukrotnie bezskutecznie ubiegał się o katedrę na uniwersytetach: Najpierw w 1744 roku – o katedrę filozofii moralnej na Uniwersytecie w Edynburgu, a następnie w 1751 r. o katedrę logiki w Glasgow.
W latach 1752–1757, będąc bibliotekarzem w Edynburgu, zainteresował się pracą historyczną. Owocem jego zainteresowań było stworzenie „Historii Anglii” ("The History of England"), czyli dzieła składającego się z sześciu tomów – wydanych kolejno w latach 1754–1762. W roku 1748 Hume napisał pracę "Philosophical Essays concerning Human Understanding", później wydaną jako "Badania dotyczące rozumu ludzkiego".
W latach 1763–1766 był sekretarzem poselstwa w Paryżu. Okres ten jest w życiu filozofa okresem wielkich powodzeń w życiu politycznym i światowym – z osoby kontrowersyjnej i nieakceptowanej ze względu na poglądy, stał się lubiany i podziwiany. Po powrocie z Francji zajmował stanowisko podsekretarza stanu w ministerstwie spraw zagranicznych. Po roku 1769 odsunął się od życia politycznego i powrócił do Edynburga.
Poglądy filozoficzne.
David Hume, mimo że uznawany jest za filozoficznego kontynuatora Johna Locke’a, w gruncie rzeczy obalił w dużym stopniu wypracowane przez niego zasady czystego empiryzmu.
Filozofia Hume’a to przede wszystkim polemika z kartezjańskim racjonalizmem. Dotyczy to zarówno epistemologii, jak i etyki i filozofii politycznej. Zadeklarowanym we wstępie do "Traktatu o naturze ludzkiej" celem badań humowskich było oparcie całej wiedzy na doświadczeniu. Wśród badaczy myśli Hume’a toczy się dyskusja, czy ten cel został zrealizowany i na ile koncepcja Hume jest spójna. Można spotkać stanowisko, że Hume nie stworzył spójnego systemu filozoficznego, a podstawowa wartość jego analiz ma charakter negatywny (krytyczny).
Założenia empirystyczne.
Zagadnieniem, od którego wyszedł Hume, było założenie (najpierw za Lockiem), że cała dostępna człowiekowi informacja pochodzi z doświadczenia. Jednak cechą specyficzną tej informacji jest jej chaotyczność i zmienność. Dlatego świadoma wiedza powstaje w wyniku złożonych procesów przetwarzania informacji zmysłowej (impresji) w obrazy mentalne (idee).
Hume stwierdził, że nasz świadomy obraz świata jest kształtowany przez cztery rodzaje informacji – bezpośrednie impresje wywołane bodźcami (impresje zmysłowe), uświadomione odczucia zmysłowe (impresje reflektywne) oraz dwa rodzaje obrazów mentalnych: idee pamięci i idee wyobraźni.
Obrazy mentalne stanowią podstawowy „budulec” świadomej wiedzy: idee proste, których modyfikacje i połączenia, dokonywane przez władze umysłu (pamięć i wyobraźnię), tworzą złożony obraz świata w ludzkiej świadomości.
Hume podkreślał, że tworzenie świadomego obrazu świata zachodzi często pod wpływem nawyków oraz emocji, stąd jego koncepcja daje początek psychologii zachowań irracjonalnych.
Analiza idei złożonych.
Hume stworzył podstawy uniwersalnej epistemologii naukowej. Doszedł do wniosku, że wartościowa jest tylko taka wiedza, która dotyczy logicznych relacji między ideami (np. matematyczna) lub zjawisk obserwowalnych empirycznie (przyrodniczych, historycznych). Wiedza, która nie dotyczy ani jednego, ani drugiego jest iluzoryczna i zbędna.
Analiza pojęć metafizycznych, takich jak Bóg czy Absolut, przekonała Hume’a, że wszystkie one nie dotyczą ani empirycznej wiedzy, ani logicznych własności samego myślenia.
Jednak Hume sceptycznie analizuje także pojęcia materialistycznej metafizyki, takie jak: materia, energia, ciepłota. Jego perspektywa jest konceptualistyczna, tzn. Hume wskazuje na postrzeganie przez człowieka konkretnych zjawisk, a nie uniwersalnych własności. Np. na podstawie znajomości przedmiotów, które postrzegamy jako gorące, wytwarzamy w naszym umyśle pojęcie ciepłoty, którego uniwersalność jest jednak postulatem naszego umysłu, a nie uniwersalną własnością rzeczy.
Analiza idei przyczynowości.
Najciekawszą częścią tej analizy pojęć była krytyka idei przyczynowości. Hume słusznie zauważył, że to, co wiemy na temat dochodzących do nas bodźców, to tylko one same i ich następstwo czasowe. Jeśli np. bierzemy strzelbę i naciskamy cyngiel, to dochodzi do nas przez palec bodziec naciskania cyngla, a po chwili słyszymy huk i widzimy błysk wystrzału. Na tej podstawie tworzymy sobie ideę, że naciśnięcie cyngla spowodowało wystrzał.
Może się jednak tak złożyć, że złośliwy służący wyjął nam nabój ze strzelby, stanął za nami i huknął w momencie, gdy my nacisnęliśmy cyngiel. Będziemy wtedy mieli dokładnie to samo wrażenie, że to my spowodowaliśmy wystrzał, mimo że naprawdę będzie inaczej.
Dostrzegamy zjawisko, a następnie, dysponując ideą pamięci danego zjawiska, postrzegamy zjawisko inne, o którym domniemywamy, że jest skutkiem pierwszego. Jednak naraz obserwujemy tylko jedno zjawisko.
Zatem związku między przyczyną i skutkiem nie jesteśmy w stanie obserwować, gdyż znajdujemy się (jako obserwatorzy) tylko w jednym punkcie czasoprzestrzeni a związek przyczynowo-skutkowy ma charakter continuum łączącego kilka momentów czasowych.
Krytyka ówcześnie dominującej szerokiej definicji idei przyczynowości i wykazanie, że nie ma ona bezpośredniego odzwierciedlenia w faktach eksperymentalnych, była pierwszym w historii przykładem dogłębnej krytyki z pozoru tak oczywistego pojęcia. Tego rodzaju podejście krytyczne było następnie kontynuowane przez innych filozofów, od Immanuela Kanta przez przedstawicieli XIX-wiecznego empiriokrytycyzmu i XX-wiecznych pozytywistów logicznych.
Sceptycyzm.
Skoro każda idea powstaje na podstawie impresji, to także idea związku przyczynowego musi mieć odpowiadającą sobie impresję. Pierwszym ze źródeł szukanej idei może być świat zewnętrzny. Jednak nie odnajdujemy tam niczego, co mogłoby wyjaśnić działanie przyczyn i ich konieczność, czyli żadna impresja zewnętrzna nie jest źródłem dla idei związku przyczynowego; drugim ze źródeł, w którym Hume szuka idei, jest świat wewnętrznych impresji. Niestety obserwowany ruch np. ciała, który postrzegamy jako związany z naszą wolą, nie musi z niej koniecznie wynikać, bo tak jak w przypadku przedmiotów zewnętrznych, tutaj też nie możemy spostrzec żadnej siły, która mogłaby wyjaśnić związek impresji wewnętrznej ze światem zewnętrznym:
„Umysł ma dostęp jedynie do percepcji i niemożliwym jest, by kiedykolwiek nabył doświadczenia dotyczącego ich związku z przedmiotami”.
Skoro w żadnym ze źródeł impresji nie można odnaleźć podstaw dla idei związku przyczynowo-skutkowego, to znaczy, że znajduje się tylko w umyśle i nie można jej odnosić do faktów. Związek ten nie jest konieczny, bo wszystkie impresje są tylko połączone, ale nie są ze sobą jakkolwiek związane. Chociaż jedno ze zdarzeń nazywamy przyczyną, a drugie skutkiem, to nie dzieje się tak na mocy trwałego ich połączenia, lecz na podstawie przyzwyczajenia. Tylko nawyk umysłu sprawia, że na podstawie przeszłych doświadczeń oczekujemy powtórzenia skutków w przyszłości. W ten sposób Hume skrytykował konieczność idei związku przyczynowego, twierdząc, że podstawą wnioskowania o nim jest subiektywny nawyk i przyzwyczajenie.
Pojęciem, które ma podobną funkcję jak zasada przyczynowości, jest pojęcie substancji. Człowiek łączy w swoim umyśle występujące obok siebie idee w jedną całość, twierdząc, że jest obiektywna podstawa usprawiedliwiająca takie postępowanie, którą nazywa substancją. Niestety tak jak zasada przyczynowości, tak i substancja jest tylko ideą powstałą na podstawie przyzwyczajenia i nie ma żadnych logicznych racji dla swej konieczności.
W swojej teorii poznania Hume poddał też krytyce podmiot poznający. Tak samo jak w przypadku idei związku przyczynowego, musi być jakaś impresja, na podstawie której powstała idea. Oczywiście w rzeczywistości zewnętrznej nie ma takiej impresji, więc trzeba jej szukać w umyśle. W umyśle jednak znajdują się tylko pojedyncze, niczym niezwiązane impresje i idee:
„W związku z działaniami umysłu warto zwrócić uwagę na fakt, że chociaż uobecniają się nam one w najbliższy sposób, to kiedy stają się przedmiotem naszej refleksji wydają się niejasne; nasz wzrok nie potrafi odnaleźć linii i granic, które je wyróżniają i dzielą. Przedmioty te są zbyt zmienne, by pozostawać zbyt długo w jednym aspekcie czy sytuacji i trzeba je ująć bezpośrednio”.
Nie ma jednej, stałej impresji, która byłaby podstawą idei „ja”, co znaczy, że podmiot nie istnieje obiektywnie jako jedna całość. W swoich poglądach na poznanie Hume wyszedł od wiedzy doświadczalnej, jako tej, która mówi cokolwiek o rzeczywistości. Wiedza empiryczna jest pewna jedynie, gdy dotyczy samych impresji, w innych przypadkach jest tylko prawdopodobna. W tym miejscu Hume zrezygnował z platońskiej koncepcji episteme, dotyczącej relacji między ideami, która – jako wiedza rozumowa – chociaż całkowicie pewna, nie dotyczy rzeczywistości. Wiedza doświadczalna, jakkolwiek wartościowa, nie usprawiedliwia wniosków dotyczących relacji między faktami, ani dotyczących połączenia między umysłem a faktami. Wszelkie wnioski na ten temat są wynikiem nawyków umysłu i są całkowicie subiektywne.
W ten sposób Hume poddał konkluzywnej krytyce metafizyczną koncepcję „ja – poznającego” jako niezależnego od układu odniesienia obserwatora zdolnego do formułowania obiektywnych sądów. W konsekwencji tego dokonał w swojej teorii poznania zwrotu od metafizycznej koncepcji poznania z jasno wyodrębnionym podmiotem i przedmiotem do psychologicznej zasady względności poznania.

</doc>
<doc id="1178" url="https://pl.wikipedia.org/wiki?curid=1178" title="Device Filesystem">
Device Filesystem

Device Filesystem ("devfs") – wirtualny system plików stworzony dla Linuksa, zajmujący się tzw. plikami urządzeń znajdującymi się – jak w każdym Uniksie – w katalogu "/dev".
Głównym powodem wprowadzenia "devfs" było ograniczenie liczby "urządzeń" w poprzednich wersjach jądra, a także uporządkowanie spraw związanych z nazewnictwem, położeniem itd.
"Devfs" umożliwia "dynamiczne" tworzenie plików urządzeń – plik jest tworzony wtedy, kiedy moduł je obsługujący sobie tego zażyczy. Oprócz tego autor kodu może ustalić z góry uprawnienia i nazwę dla pliku swego urządzenia. Dodatkowym plusem jest pogrupowanie plików w podkatalogach /dev oraz tworzenie "symbolicznych linków", aczkolwiek tym dokładnie zajmuje się Devfsd.
"Devfs" jest używany od jąder 2.4 i nowszych, ale istnieją "backporty" dla linii 2.2. "Devfs" od jąder serii 2.6 został oznaczony jako przestarzały, zastąpił go udev.

</doc>
<doc id="1180" url="https://pl.wikipedia.org/wiki?curid=1180" title="Device Filesystem Daemon">
Device Filesystem Daemon

Device Filesystem Daemon – proces o nazwie codice_1 pracujący jako demon.
W systemach Linux zajmuje się obsługą Device Filesystem i zarządzaniem (poprzez mechanizm dynamicznej alokacji) symbolicznymi linkami w katalogu codice_2.
Uruchamianie codice_1 jest opcjonalne, aczkolwiek tworzy on wiele linków niezbędnych dla działania programów korzystających ze starej "nomenklatury". Jest on przeważnie uruchamiany przez skrypty startowe.
Informacje na temat codice_1 znajdują się w podręczniku systemowym w sekcji 8, a dodatkowe informacje zawiera opis codice_5 w sekcji 5.

</doc>
<doc id="1181" url="https://pl.wikipedia.org/wiki?curid=1181" title="Demeter">
Demeter

Demeter (także Demetra; Dēmḗtēr, Dḗmētra, ) – w mitologii greckiej bogini płodności ziemi, urodzaju, ziemi uprawnej, zbóż, rolnictwa; matka Kory-Persefony. Siostra Zeusa, Posejdona, Hadesa, Hestii i Hery. Kochanka Zeusa – miała z nim córkę Korę-Persefonę. Córka Rei i Kronosa.
Istota bóstwa.
Imię Demeter składa się z dwóch członów: „meter” "mḗtēr" oznacza matkę, zaś „de” "dē̂" (w dialekcie doryckim "da") to prawdopodobnie "gē̂", czyli ‘ziemia’. Taka interpretacja nie jest pewna z powodu braku potwierdzenia w źródłach pisanych. Demeter była jednym z pradawnych bóstw przyrody. Była czczona nad Morzem Śródziemnym, a jej kult został włączony przez Greków do ich religii. Demeter była nazywana „panią ziarna”, „panią zbóż” (gr. "(Sítōn) Pótnia"). Była połączona z "Kore" („Dziewczyna”), swoją córką, dlatego mówiło się o bóstwie w liczbie podwójnej: "tṑ Megála Theá" („dwie wielkie boginie”), "tṑ Théō" („dwa bóstwa”). Z czasem określono tożsamość córki Demeter, Persefony, której przypisano ojca, Zeusa.
Demeter w starożytnych wierzeniach.
Według "Teogonii" Hezjoda Demeter była drugim dzieckiem Kronosa i Rei, siostrą Hery, Hestii, Hadesa, Posejdona i Zeusa. Po urodzeniu została połknięta przez swego ojca, który według przepowiedni miał zostać pozbawiony władzy przez swojego potomka. Po tym, jak matka Demeter – Reja – podała Kronosowi napój wymiotny, Kronos wypluł połknięte potomstwo. Demeter została uwolniona przedostatnia. Zanim Zeus poślubił Herę, miał kilka wybranek, wśród których znalazła się Demeter. Według "Teogonii" została wybrana na kochankę po Metydzie, Temidzie i Eurynome. Ze związku Demeter i Zeusa urodziła się białoramienna Persefona.
Hymn "Do Demeter" z VII wieku p.n.e. zawiera opis porwania Persefony przez Hadesa i odzyskanie jej przez Demeter. Persefona została uprowadzona za przyzwoleniem Zeusa, jej ojca, przez swego wuja podczas zabawy z córkami Okeanosa (Oceanu). Prawdę o porwaniu wyjawił zrozpaczonej matce Helios, bóg słońca. Obrażona Demeter udała się do Eleusis, gdzie została przyjęta w pałacu Keleusa. Będąc w żałobie, przestała troszczyć się o urodzaje zbóż. Ziemię nawiedziła klęska głodu i ludzie zaprzestali składania ofiar bogom. Zeus nakazał Hadesowi zwracać matce Persefonę na sześć miesięcy w ciągu roku. Gdy córka powracała, uradowana Demeter przyozdabiała ziemię kwiatami, rozpoczynała się wiosna. Gdy Persefona musiała powracać do małżonka, na znak żałoby życie na ziemi zamierało.
Do opowieści o Demeter dodawane były w zależności od miejsca nowe szczegóły. Podczas wędrówki w poszukiwaniu córki Demeter przez jakiś czas przebywała w Sykionie, gdzie nauczyła mieszkańców uprawy roli i wynalazła młyn. Przypisywano jej rozpowszechnienie uprawy warzyw (bobu), drzew owocowych (drzewa figowego). Gościły ją pary królewskie Mysjos i Chrysantis w Argos oraz Trisaules i Damitales w Arkadii. Według jednego z opowiadań do Demeter zalecał się Posejdon. Bogini zamieniła się w klacz, żeby uniknąć zalotów. Posejdon jednak pokrył ją, przybierając postać ogiera. Z tego związku bogini urodziła konia Arejona i córkę Despojnę („Pani”).
W "Odysei" zawarta jest opowieść o małżeństwie Demeter i Iasjona, którego owocem był Plutos. Ponadto według innych mitów Demeter toczyła spór z Hefajstosem o Sycylię (spór wygrał Hefajstos, który w Etnie założył swoją kuźnię) oraz z Dionizosem o urodzajną w winorośl Kampanię.
Rzymianie około V wieku p.n.e. przejęli mit o Demeter i Persefonie, utożsamiając Demeter z Cererą, italską boginką urodzajów, a Persefonę z Prozerpiną. Według poetów łacińskich miejscem porwania Prozerpiny miała być Enna na Sycylii. Kult Cerery popularny był wśród plebejuszy. Na pamiątkę odzyskania córki przez matkę na dzień 12 kwietnia ustanowiono święto "Cerialia" lub "Ceriales".
Kult Demeter.
Demeter była przedstawiana jako poważna kobieta z wieńcem kłosów na głowie. W ręku trzymała sierp, pochodnię lub kosz owoców. Bogini poświęcone były kłosy, mak, złotogłów, żuraw, złotogłowia. W ofierze składano jej zazwyczaj krowę, miód lub owoce (w Rzymie natomiast kłosy, snopy żyta i maciorę). Zachowały się liczne posągi, przedstawiające Demeter, nieraz posiadające wartości artystyczne (np. posąg z Cherchel z okresu klasycznego). Niekiedy Demeter i jej córce usługiwały Hory, boginie czasu.
Hymn do Demeter z opisem uprowadzenia Persefony przez Hadesa, opisuje wydarzenia, które stały się motywem przewodnim misteriów eleuzyjskich, odbywających się na cześć bogini. W IV wieku p.n.e. Izokrates przypisał jej dwa dary, którymi obdarowała Ateńczyków: umiejętność uprawy roli i odprawiania misteriów. Ci, którzy zdecydowali się poddać obrzędom wtajemniczenia, otrzymywali nadzieję na lepszą wieczność. Misteria odbywały się w sanktuarium Demeter, w Eleusis, nieopodal Aten. Dopiero Teodozjusz I Wielki w 391 roku zakazał kultów pogańskich, co położyło kres misteriom eleuzyjskim. W 396 roku pożar wzniecony przez wojska Alaryka strawił sanktuarium.

</doc>
<doc id="1182" url="https://pl.wikipedia.org/wiki?curid=1182" title="Dionizos">
Dionizos

Dionizos (także Bakchos, Bachus; gr. Diṓnysos, Diónysos, Bákchos, łac. Dionysus, Bacchus) – w mitologii greckiej bóg płodności, dzikiej natury, winnej latorośli i wina, reprezentujący jego upajający i dobroczynny wpływ. Syn Zeusa i śmiertelniczki Semele. Kult Dionizosa przywędrował do Grecji ze Wschodu, z Tracji, około VI wieku p.n.e., choć jego imię w formie dopełniaczowej "di-wo-nu-so-jo" pojawia się już w zapisanych pismem linearnym B zabytkach mykeńskich z XIV-XIII w. p.n.e. Na cześć Dionizosa odbywały się Dionizje, jego kult sprawowały bachantki, które organizowały ekstatyczne misteria.
Kult.
Dionizos jest bogiem religijnych obrzędów, podobnych do tych, które odprawia się ku czci Demeter czy Persefony. W trackich misteriach miał na sobie skórę lisa, symbolizującą nowe życie. Jego misteria należały do najbardziej sekretnych. Wielu badaczy uważa, że Dionizos jest połączeniem lokalnego, greckiego bóstwa z innym, potężniejszym bogiem z Tracji lub Frygii, prawdopodobnie z Sabazjosem.
Narodziny.
Jego matką była śmiertelniczka Semele, córka Kadmosa, a ojcem Zeus. Żona Zeusa Hera była zazdrosna o jego kochanki. Kiedy Semele była w ciąży, bogini namówiła ją, by zmusiła Zeusa do ukazania swojej prawdziwej postaci. Semele nie wiedziała, kim naprawdę jest jej kochanek i z początku nie wierzyła Herze. Nakazała Zeusowi, by dowiódł swojej boskości. Śmiertelnicy nie mogą jednak oglądać prawdziwych postaci bogów i Semele spłonęła. Zeus uratował płód Dionizosa, zaszywając go sobie we własnym udzie. Kilka miesięcy później Dionizos się narodził.
Według innych źródeł był synem Zeusa i Persefony, królowej świata podziemnego. Zazdrosna Hera i w tej wersji chciała zabić dziecko: posłała tytanów, by rozszarpali niemowlę na kawałki. Zeus nie zdążył uchronić małego Dionizosa od śmierci. Zjedli oni wszystkie kawałki, oprócz serca, które uratowała Reja. Mając jego serce, Zeus chciał „odtworzyć” Dionizosa w łonie Semele, dlatego Dionizos nazywa się „podwójnie urodzonym”. Niektóre źródła podają, że Zeus nakazał Semele, by zjadła ona serce Dionizosa.
Dzieciństwo.
Mitologia mówi, że Zeus oddał młodego Dionizosa pod opiekę nimfom deszczu na górze Nysa. W nagrodę, Zeus umieścił je, już jako Hiady, pośród gwiazd.
Kiedy Dionizos dorastał, odkrył niezwykłe właściwości cennego soku z winorośli. Hera nie zapomniała jednak o nim i napiętnowała go obłędem, Dionizos wyruszył w wędrówkę po całym świecie w towarzystwie satyrów i menad. Najpierw udał się do Egiptu. W Libii spotkał Amazonki, z którymi wybrał się na wyprawę przeciwko tytanom, których udało im się pokonać. Następnie wyruszył w kierunku Indii. Po drodze starł się z królem Damaszku, z którego żywcem zdarł skórę. Dionizos podbił Indie, wprowadził uprawę winogron i założył wiele miast. W drodze powrotnej obróciły się przeciw niemu Amazonki, większość z nich zamordował. Lecz dwie z nich walczyły dalej i urwały mu rękę, zjadły ją i umarły przez boską krew Dionizosa.
Po powrocie do Europy Dionizos zawitał do Frygii, gdzie spotkał swoją babcię Reę, która wyleczyła go z obłędu i wprowadziła go w tajemnice swoich misteriów. Dionizos wyruszył potem do Azji, by rozprzestrzeniać tam kulturę wina, następnie przybył do Grecji, by tam dać początki kultu. Spotykał się tu nierzadko z oporem władców, ci jednak za każdym razem popadali w obłęd.

</doc>
<doc id="1183" url="https://pl.wikipedia.org/wiki?curid=1183" title="Dag Hammarskjold">
Dag Hammarskjold



</doc>
<doc id="1184" url="https://pl.wikipedia.org/wiki?curid=1184" title="Dag Hjalmar Agne Carl Hammarskjold">
Dag Hjalmar Agne Carl Hammarskjold



</doc>
<doc id="1185" url="https://pl.wikipedia.org/wiki?curid=1185" title="Dag Hammarskjöld">
Dag Hammarskjöld

Dag Hjalmar Agne Carl Hammarskjöld () (ur. 29 lipca 1905, zm. 18 września 1961) – szwedzki polityk, dyplomata, ekonomista i prawnik, od 10 kwietnia 1953 do 18 września 1961 sekretarz generalny Organizacji Narodów Zjednoczonych, przyczynił się do rozwiązania kryzysu sueskiego 1956.
Życiorys.
W czerwcu 1956 roku był gościem Międzynarodowych Targów Poznańskich, w czasie trwania których doszło do strajków robotniczych i krwawych starć ulicznych. Jako sekretarz ONZ zaprotestował przeciwko użyciu siły przez władze państwowe, które jednak nie wzięły pod uwagę jego protestu.
Zginął w katastrofie lotniczej w dżungli pod Ndola w Rodezji Północnej razem z 15 pasażerami. Oficjalną przyczyną katastrofy miał być błąd pilota. Istnieje jednak wiele hipotez przeczących oficjalnej wersji – najbardziej rozpowszechniona z nich, mówi, że samolot został zestrzelony przez rebeliantów Katangi, jako że celem misji, z jaką leciała delegacja Hammarskjölda było rozstrzygnięcie wojny domowej w Kongu, a tym samym ponowne zjednoczenie kraju. W latach 90. do spowodowania katastrofy przyznał się południowoafrykański tzw. Instytut Morski, stanowiący ukrytą agendę tajnych służb RPA – samolot z Hammarskjöldem został ostrzelany i strącony przez samolot myśliwski.
Po śmierci Daga Hammarskjölda znaleziono w jego nowojorskim mieszkaniu rękopis "Vägmärken" (Drogowskazy). Wydano go w 1963 (wydanie polskie w tłumaczeniu ks. Jana Ziei w 1967).
Odznaczenia i wyróżnienia.
Ordery:
W 1961 został pośmiertnie uhonorowany Pokojową Nagrodą Nobla.

</doc>
<doc id="1186" url="https://pl.wikipedia.org/wiki?curid=1186" title="Dobra prywatne">
Dobra prywatne

Dobra prywatne – każde dobro, które nie jest dobrem publicznym, tzn. które może nie być konsumowane przez wielu konsumentów bez uszczerbku dla któregokolwiek z nich.
Przykładem dobra prywatnego może być np. odzież, żywność.

</doc>
<doc id="1187" url="https://pl.wikipedia.org/wiki?curid=1187" title="Dobra normalne">
Dobra normalne

Dobra normalne – w ekonomii dobra, na które popyt rośnie pod wpływem wzrostu dochodów nabywców.

</doc>
<doc id="1188" url="https://pl.wikipedia.org/wiki?curid=1188" title="Dobra niższego rzędu">
Dobra niższego rzędu



</doc>
<doc id="1189" url="https://pl.wikipedia.org/wiki?curid=1189" title="Dochód">
Dochód

Dochód – wpływy osiągnięte w określonym czasie po potrąceniu kosztów ich uzyskania.
Stanowi podstawową kategorię ekonomiczną, wyrażającą dodatni efekt zastosowania czynników wytwórczych: ziemi, pracy, kapitału rzeczowego, kapitału finansowego w procesie gospodarowania. Dochód jest rezultatem połączenia wymienionych czynników wytwórczych oraz przedsiębiorczości człowieka. Dochód w formie pieniężnej jest wyrazem towarów i usług, które podmioty go posiadające mogą za niego nabyć.
W podejściu makroekonomicznym dochód społeczeństwa jest nadwyżką ekonomiczną, która może zostać wykorzystana do zaspokojenia potrzeb indywidualnych i zbiorowych, celów bieżących (konsumpcja) i celów rozwojowych (inwestycje).
Dochód w sensie ekonomicznym nie jest tożsamy z dochodem w sensie podatkowym, który w tym aspekcie definiuje się jako różnicę pomiędzy przychodami a kosztami ich uzyskania.
W praktyce różne podmioty w różny sposób określają swój dochód. Ponadto wobec niektórych grup podmiotów obowiązują definicje dochodu określone przepisami prawa (np. dochód osobisty do opodatkowania albo dochody obliczane dla potrzeb np. ustalenia zasiłków itp.).
Osoby fizyczne.
Dla celów podatkowych w przypadku osób fizycznych, co do zasady, dochodem ze źródła przychodów jest nadwyżka sumy przychodów z tego źródła nad kosztami ich uzyskania w roku podatkowym.
Osoby prawne.
W przypadku osób prawnych nie występuje kategoria źródeł przychodów. Zatem dochodem jest nadwyżka przychodów nad kosztami ich uzyskania osiągnięta z całej prowadzonej przez osobę prawną działalności w roku podatkowym.
Gospodarstwo rolne.
W rachunkowości pełnej gospodarstwa rolnego występują cztery różne miary mające w nazwie słowo dochód. Są to: dochód rolniczy, dochód ogólny, dochód gospodarstwa i dochód osobisty rolnika.
Jednostki administracji publicznej.
W przypadku jednostek administracji publicznej dochód jest w praktyce równy sumie wpływów (przychodów) z różnych tytułów, np. w budżecie gminy znajdujemy takie pozycje jak czynsze dzierżawne, opłaty za świadectwa, zaświadczenia i inne dokumenty, opłaty za zarząd, użytkowanie i użytkowanie wieczyste, wpływy z tytułu sprzedaży mienia komunalnego, odsetki za nieterminowe regulowanie należności, prowizje, wpływy z mandatów wystawionych przez straż miejską, z podatków, z opłat skarbowych, z opłat koncesyjnych, z subwencji i dotacji, z rekompensat, z opłat za niektóre usługi.

</doc>
<doc id="1190" url="https://pl.wikipedia.org/wiki?curid=1190" title="Deficyt budżetowy">
Deficyt budżetowy

Deficyt budżetowy – ujemne saldo w budżecie instytucji – sytuacja, w której wydatki w budżecie danej instytucji są wyższe niż jej dochody w danym okresie rozliczeniowym (roku budżetowym). Przeciwieństwem deficytu budżetowego jest nadwyżka budżetowa.
Typy deficytów budżetowych.
W związku z trudnością interpretacji treści deficytów budżetowych ekonomiści rozróżniają trzy typy deficytów:
W praktyce deficyty cykliczne zawsze różnią się od deficytów rzeczywistych i strukturalnych.
Deficyt budżetowy może wynikać z:
Problem stanowi także ustalenie źródeł finansowania deficytu. Instrumentami, które mogą być w tym celu wykorzystane, są:
Deficyt budżetowy a wydatki państwa i stopa podatkowa.
Wzrost wydatków państwa na dobra i usługi (a zatem nakładów na ochronę zdrowia, edukację, obronę itp.) prowadzi do zwiększenia produkcji zapewniającej równowagę. Konsekwentnie wzrastają też wpływy podatkowe. Deficyt budżetowy powiększy się (lub zmniejszy się nadwyżka budżetowa), jednak w stopniu mniejszym niż wzrost wydatków państwa.
Wzrost stopy podatkowej powoduje z jednej strony wzrost wpływów budżetowych, z drugiej jednak zmniejszenie produkcji i dochodu zapewniających równowagę. Zmniejsza się bowiem dochód rozporządzalny i konsumpcja. Dlatego deficyt budżetowy zmniejsza się (lub zwiększa nadwyżka budżetowa) jednak podobnie jak w przypadku wzrostu wydatków państwa – w stopniu mniejszym niż planowany na dany moment.
Deficyt a charakter polityki fiskalnej.
Wielkość deficytu budżetowego nie jest adekwatnym wskaźnikiem charakteru polityki fiskalnej państwa. Na jego podstawie nie można wnioskować, czy polityka ta ma charakter ekspansywny, czy też restrykcyjny. Po pierwsze, deficyt budżetowy może zmieniać się z przyczyn całkowicie niezwiązanych z polityką fiskalną. Na przykład zmiany w popycie inwestycyjnym (jak choćby zakłócenia nazwane przez Keynsa instynktem zwierzęcym, czyli spontaniczne zmiany pesymizmu i optymizmu inwestorów dotyczące zyskowności inwestycji) przy niezmienionych wydatkach państwa i stopie podatkowej powodują zmiany deficytu.
formula_1
Powyższy wzór to warunek równowagi w gospodarce zamkniętej. Potwierdza on, że jeśli zmniejszy się popyt inwestycyjny, ceteris paribus, lewa strona równania zwiększy się, zatem deficyt budżetowy (prawa strona równania) również się powiększy. Spowodowane jest to faktem, iż spadek popytu inwestycyjnego oznacza obniżenie dochodu narodowego i wpływów podatkowych.
Należy też zwrócić uwagę na to, że oprócz poziomu wydatków państwa i stopy opodatkowania, determinantą stanu budżetu jest poziom dochodu narodowego. Implikuje to zależność stanu budżetu od fazy cyklu koniunkturalnego. W czasie recesji, kiedy dochód jest niski, budżet będzie wykazywał większy deficyt niż w fazie ożywienia.
Budżet strukturalny.
Istnieje jednak sposób na wykorzystanie budżetu jako wskaźnika charakteru polityki budżetowej. Jest nim obliczenie budżetu strukturalnego, zwanego też budżetem pełnego zatrudnienia lub budżetem skorygowanym o wpływ wahań cyklu koniunkturalnego. Pokazuje on, jaki byłby stan budżetu w warunkach pełnego zatrudnienia i na poziomie produkcji potencjalnej.
formula_2
Może się okazać, że mając do czynienia z rzeczywistym deficytem budżetowym, deficyt strukturalny będzie wykazywał nadwyżkę. Przyczyną deficytu jest zbyt niska produkcja i dochód. Rząd powinien wręcz zwiększyć swoje wydatki lub obniżyć podatki, by pobudzić gospodarkę. Wbrew temu, co mógłby sugerować istniejący deficyt, polityka fiskalna nie jest ekspansywna.
Koncepcja budżetu strukturalnego stała się podstawą do sformułowania przez Gordona Browna złotej reguły finansów publicznych.
Sposoby ograniczania deficytu.
Deficyt budżetowy jest jednym z podstawowych kryteriów oceny polityki fiskalnej państwa. Deficyt budżetowy finansuje się przez zaciągnięcie jakiejś formy kredytu. Wysoki deficyt budżetowy państwa oznacza najczęściej konieczność emisji dużej ilości obligacji skarbowych, co wpływa z kolei na wzrost ich oprocentowania. Państwo, jako zazwyczaj wiarygodny kredytobiorca, ściąga z rynku środki finansowe, które mogłyby zostać przeznaczone np. na kredyty dla przedsiębiorstw prywatnych – efekt wypierania inwestycji prywatnych (efekt wypychania). Proces ten jest jednak znacząco ograniczony w sytuacji, gdy gospodarka znajduje się w fazie recesji, a planowane (prywatne) inwestycje spadają poniżej poziomu wyznaczonego przez planowane oszczędności.
Sposoby radzenia sobie z deficytem:
Problemy metodologiczne.
Porównania międzynarodowe i dyskusję nad zjawiskiem deficytu budżetowego utrudnia to, że szereg dochodów, wydatków i zobowiązań państwa jest realizowany poza budżetem państwa – różne są więc metodyki liczenia deficytu. Często używa się wtedy szerszego pojęcia: "deficyt sektora finansów publicznych". Dla przykładu w Polsce deficyt budżetowy liczony zgodnie z metodyką Międzynarodowego Funduszu Walutowego (GFS) stanowił w 1998 roku 1,1% PKB (deficyt całego sektora finansów publicznych 1,2%). Stosując metodę określoną przez ustawę o finansach publicznych, otrzymujemy inne dane: 2,4% PKB w przypadku deficytu budżetowego i 2,6% dla całego sektora finansów publicznych. Jeszcze inną metodę (metoda memoriałowa) liczenia deficytu stosuje się w Unii Europejskiej.
Wysokość deficytu budżetowego na świecie.
Budżety większości państw świata zakładają deficyt rzędu paru procent (jednak rzadko powyżej 5% PKB). W Polsce w 2015 r. deficyt budżetowy wyniósł 2,5% PKB.
Zgodnie z kryteriami konwergencji, państwa ubiegające się o wejście do strefy Euro muszą mieć deficyt finansów publicznych, w tym budżetu, niższy niż 3% PKB. Próg ten obowiązuje również kraje będące już członkami Unii Europejskiej, w przypadku przekroczenia progu 3% Komisja Europejska wszczyna procedurę nadmiernego deficytu.
Zdarza się, że podczas kryzysu gospodarczego państwa prowadzą politykę interwencjonistyczną, co może oznaczać znaczne zwiększenie deficytu budżetowego. Np. Stany Zjednoczone podczas zwalczania kryzysu finansowego od 2007, w roku 2009 zaplanowały deficyt budżetowy na poziomie 12,9% PKB (1,84 bln USD), a w 2010 deficyt w wysokości 10,6% PKB (1,56 bln USD).
W 2011 roku decyzją KE państwa członkowskie UE zostały zobowiązane do raportowania wielkości długu i deficytu publicznego według ujednoliconej metody obliczania, co miało na celu ograniczenie wpływu rozmaitych zabiegów fiskalnych stosowanych w celu jego ukrycia. Według tej metody dług publiczny Polski wynosił w 2011 roku 56,3% PKB, natomiast deficyt – 5,1% PKB.

</doc>
<doc id="1191" url="https://pl.wikipedia.org/wiki?curid=1191" title="Dolar">
Dolar

Dolar () – waluta wielu krajów świata. Dzieli się na 100 centów. Nazwa dolara – podobnie jak nazwa waluty Słowenii sprzed 1 stycznia 2007, tolar – pochodzi od dawnej srebrnej monety, talara. Dolar został oficjalną jednostką monetarną Stanów Zjednoczonych w 1785 roku. Jednak zarówno samo słowo angielskie, jak i pieniądze o takiej nazwie istniały już wcześniej.
Historia nazwy i symbolu.
Na przełomie XV i XVI wieku w Europie nie było waluty mogącej pełnić funkcję pieniądza światowego. W I połowie XVI wieku w Czechach, koło miejscowości Jachymów, odkryto duże złoża srebra, z których zaczęto bić nowe monety. Ze względu na silną germanizację czeskich terenów, na monetach wybijano nazwę mennicy w języku niemieckim – "Jachimstaler Münze". Od końcówki "taler" przyjęto nazwę monety, przekształcaną przez różne narodowości, na przykład w Polsce moneta nazywała się talar, a w Hiszpanii dollaro.
Po odkryciu pierwszych złóż srebra i złota w Ameryce, Hiszpania przeniosła część mennic na nowy kontynent, gdzie moneta stała się walutą podstawową w obu Amerykach. Walutę oznaczało się symbolem 8, ze względu na wartość monety – 1 dollaro było warte 8 reali. Ze względu na możliwość pomyłki z cyfrą 8, symbol zaczęto stylizować. Korzystano z zawijasa przypominającego literę S, z końcami połączonymi linią prostą. Symbol ten, pisany w sposób niedbały, wyewoluował w dzisiejszy znak dolara – $.

</doc>
<doc id="1193" url="https://pl.wikipedia.org/wiki?curid=1193" title="Dc (informatyka)">
Dc (informatyka)

dc – uniksowe narzędzie służące do wykonywania prostych obliczeń według poleceń podanych przy użyciu odwrotnej notacji polskiej. Jest to jedno ze starszych narzędzi napisanych dla tego systemu, obecnie nie jest już szerzej używane.
Działanie:
Programy można uruchamiać komendą: dc -e "program".
Przykłady programów:
[[Kategoria:Polecenia Unix|dc]]
[[Kategoria:Oprogramowanie matematyczne]]
[[Kategoria:Języki skryptowe]]

</doc>
<doc id="1194" url="https://pl.wikipedia.org/wiki?curid=1194" title="DC">
DC



</doc>
<doc id="1195" url="https://pl.wikipedia.org/wiki?curid=1195" title="Definicja">
Definicja

Definicja (z łac. "definitio"; od czas. "definire": "de + finire", „do końca, granicy”; od "finis": granica, koniec) – wypowiedź o określonej budowie, w której informuje się o znaczeniu pewnego wyrażenia przez wskazanie innego wyrażenia oddającego sens sformułowania. 
Za zakres nazwy „definicja” uważa się sumę zakresów wszystkich nazw, które można utworzyć ze słowa „definicja” wzbogaconego następującym po nim przymiotnikiem (np. kontekstowa, równościowa, cząstkowa, w stylizacji przedmiotowej, w stylizacji językowej).
Definicja jest narzędziem, które:
Budowa definicji.
Biorąc za przykład następującą definicję:
można zauważyć, że wszystkie definicje równościowe i niektóre cząstkowe zawierają następujące elementy:
Definicja realna i definicja nominalna.
Jednoznaczna albo niejednoznaczna charakterystyka jakiegoś pojęcia, którą można wypowiedzieć w dowolnym języku – na przykład "Bursztyn jest to żywica skamieniała".
Wypowiedź informująca o znaczeniu danego wyrażenia w danym języku – na przykład "Słowo „bursztyn” znaczy tyle, co „żywica skamieniała”".
Należy zauważyć, że wypowiedzenie definicji realnej danego przedmiotu informuje o znaczeniu słowa oznaczającego ten przedmiot w języku, do którego ta wypowiedź należy, a więc jest w tym języku definicją nominalną tego słowa. Przytoczona wyżej definicja realna bursztynu jest w języku polskim definicją nominalną słowa „bursztyn” – można powiedzieć, że podając cechy charakterystyczne pojęcia jednocześnie informuje o znaczeniu słowa w języku polskim.
Definicja równościowa i definicja cząstkowa.
Inne nazwy to: definicja normalna, definicja klasyczna. Definicja równościowa dostarcza kryteriów pozwalających na rozstrzygnięcie – z reguły wobec każdego przedmiotu – czy podpada on pod wyraz (zwrot) definiowany (definiendum), czy nie podpada. Inaczej jest to taka definicja, która przedstawia swoistą równość między wyrazem lub zwrotem, o znaczeniu którego informuje, lub typowym dla tego wyrazu (zwrotu) kontekstem a wyrażeniem, za pomocą którego o tym znaczeniu informuje.
Istnieją również definicje, które nie dostarczają kryteriów pozwalających na rozstrzygnięcie w stosunku do każdego przedmiotu, czy podpada on pod wyraz (zwrot) definiowany, czy nie podpada. Nie określają one w pełni znaczenia i zakresu definiowanego wyrazu, dają o nim jedynie informację niepełną, cząstkową. Tego rodzaju definicje, mające szerokie zastosowanie w nauce, w nauczaniu i w życiu codziennym, nazywa się definicjami cząstkowymi. Wskazać można dwa powody stosowania definicji cząstkowych:
Definicje równościowe.
Podstawowe podziały definicji równościowych.
Definicja w stylizacji przedmiotowej i definicja w stylizacji językowej.
Powyższa definicja informuje o znaczeniu wyrazu „bursztyn” w języku polskim w taki sposób, że: a) mówi o cechach bursztynu; i jednocześnie b) pokazuje, jak rozumieć ten termin zgodnie ze znaczeniem odpowiadającym mu w języku polskim.
Definicja ta nie mówi o bursztynie, lecz o nazwie (znaczeniu) pewnego przedmiotu – o nazwie (znaczeniu) przedmiotu bursztyn.
Definicja sprawozdawcza i definicja projektująca.
Przykład skorygowania wady niewyraźności:
Definicja projektująca jest definicją projektującą tylko do momentu, aż zostanie przyjęta przez jakąś grupę ludzi (np. wspólnotę uczonych). Od tego momentu jest ona definicją sprawozdawczą.
Podstawowe błędy w definiowaniu (Definicje równościowe).
Definicje fałszywe.
Koniecznym warunkiem prawdziwości definicji równościowej musi być tożsamość zakresowa jej członów – definiendum i definiens muszą być zakresowo tożsame. A zatem: Definicja fałszywa jest to taka definicja, w której nie zachodzi stosunek tożsamości zakresowej definiendum i definiensa.
Definicją fałszywą może być jedynie definicja sprawozdawcza, tylko ona bowiem podlegać może zarzutowi fałszu, ponieważ informacja, którą podaje, może nie być zgodna z zastanym znaczeniem wyrazu.
Definicja za wąska.
Definicja jest za wąska, gdy definiens jest zakresowo podrzędny względem definiendum.
Definicja za szeroka.
Definicja jest za szeroka, gdy definiens jest zakresowo nadrzędny względem definiendum.
Definicja, której człony krzyżują się zakresowo.
Jest to definicja, w której definiendum i definiens krzyżują się zakresowo.
Definicja zawierająca błąd przesunięcia kategorialnego.
jest to taka definicja, której człony (definiendum i definiens) pozostają do siebie w zakresowym stosunku wykluczania.
Definicje nieinformujące.
Definicja nieinformująca to taka definicja, która nie spełnia co najmniej jednego z następujących trzech warunków:
Jej podstawowe odmiany to:
Definicja zawierająca błąd "ignotum per ignotum".
Pogwałcenie warunku pierwszego: Błąd "ignotum per ignotum" (nieznanego przez nieznane) jest to błąd polegający na tym, że zarówno definiendum jak i definiens są wyrażeniami niezrozumiałymi.
Definicja myląca.
Pogwałcenie warunku drugiego: Błąd ten polega na tym, że niewłaściwe zrozumienie członu definiującego (definiensa) pociąga za sobą niewłaściwe rozumienie definiendum.
Definicja tautologiczna.
Pogwałcenie warunku trzeciego: Definicja tautologiczna to taka definicja, w której definiensie powtórzone jest definiendum (w której zwrot definiujący powtarza zwrot definiowany). Powtórzenie w definiensie nie przyczynia się do lepszego zrozumienia definiendum, jest bowiem wyłącznie powtórzeniem definiendum. Występuje ona w dwóch odmianach:
Definicja zawierająca błąd "idem per idem".
Definicja zawierająca błąd "to samo przez to samo", nazywana jest również "definicją wyraźnie tautologiczną". Ma taki schemat: p jest to p.
Definicja zawierająca błąd "circulus in definiendo".
Definicja zawierająca błąd "koło w określaniu" ("koło w definiowaniu"), zwana również "definicją pośrednio tautologiczną" przebiega według następującego schematu: Wyrażenie P definiujemy przy pomocy wyrażenia Q, które z kolei definiujemy przy pomocy wyrażenia P. (W ciągu definicji tworzących błędne koło może występować oczywiście więcej niż dwa wyrażenia, np. wyrażenie P definiujemy przy pomocy wyrażenia Q, wyrażenie Q przy pomocy wyrażenia R, a wyrażenie R przy pomocy wyrażenia P, itd.)
Definicje cząstkowe.
Definicje równościowe dostarczają kryteriów pozwalających na rozstrzygnięcie, w zasadzie w stosunku do każdego przedmiotu, czy podpada on pod wyraz (zwrot) definiowany, czy nie podpada. Obok nich istnieją definicje, które nie dostarczają w pełni tego typu informacji – nie określają one w pełni znaczenia i zakresu definiowanego wyrazu. Tego rodzaju definicje, mające szerokie zastosowanie w nauce, w nauczaniu i w życiu codziennym, to właśnie definicje cząstkowe.
Podstawowe odmiany definicji cząstkowej.
Definicja ostensywna (deiktyczna).
Najbardziej ogólnie rzecz biorąc, definicja ostensywna jest to definicja informująca o znaczeniu (sposobie rozumienia) danego terminu przez wskazanie w jakiś sposób (np. gestem wskazującym) konkretnego egzemplarza (konkretnych egzemplarzy) przedmiotu będącego desygnatem definiowanego terminu.
Definicje ostensywne (z łac. "ostendo" – wskazuję) stanowią istotny element metody dydaktycznej (stosowanej np. w nauczaniu: języków obcych, jak też niemowląt pierwszego języka) zwanej metodą poglądową. Ta forma definiowania daleka jest od ścisłości, dlatego też kwestia uściślania przekazywanej przy pomocy tej definicji informacji jest bardzo istotna. Jedną z takich najstarszych i zarazem najbardziej skutecznych metod jest pokazywanie (wskazywanie na) jak największej liczby wzorców pozytywnych – przy użyciu wypowiedzi typu:
Z jednej strony zawodność, a z drugiej skuteczność tej metody definiowania, unaocznić można poprzez wyobrażenie sobie sytuacji, że znaleźliśmy się wśród ludzi, którzy w ogóle nie mówią naszym językiem, my nie znamy ich języka, oraz nie znamy (my i oni) wspólnie żadnego innego języka. O lokalnych nazwach konkretnych przedmiotów dowiadywać się będziemy wyłącznie drogą wskazywania na ich egzemplarze – oczekując, że ktoś wypowie ich nazwę.
Definiowanie poprzez rodziny znaczeniowe.
Nie zawsze jest tak, że gdzie dana jest jedna nazwa, tam musi być również dana jedna wspólna własność rzeczy pod tę nazwę podpadających. Istnieje spora grupa nazw, którymi się posługujemy, a które nie poddają się definicji równościowej, bowiem klasa przedmiotów, do których się one odnoszą, jest nie tylko bardzo rozległa, ale i niejednolita. Pojęcia tego typu nazywane są „otwartymi”. (Najpopularniejsze przykłady nazw z tej klasy to: „gra”, „piękno”, „wartość estetyczna”, „sztuka”, „nauka”, „technika”.) Charakterystyczne dla nich jest to, że:
O każdym z takich pojęć powiedzieć możemy, że ma jedynie tzw. „podobieństwo rodzinne”. Znaczenie tego terminu oddać można odwołując się (stąd zresztą pomysł Wittgensteina) do pojęcia „rodzina” w sensie zbioru ludzi powiązanych ze sobą więzami krwi i matrymonialnymi. W skład tak rozumianej rodziny wchodzi wiele rodzin – jedne ze strony matki, drugie ze strony ojca. Odnosząc uwagi te do pojęcia „gra”, zauważyć możemy przykładowo, że: dla sporej części gier wspólną cechą będzie współzawodnictwo, którego brakuje np. przy pasjansie, dla sporej części gier istnieje wygrana i przegrana, czego brakuje np. wtedy, gdy sami odbijamy piłkę od ściany, dla sporej liczby gier liczy się zręczność, której brakuje np. w szachach – ale wszystkie one w jakiś sposób są ze sobą spokrewnione. "Widzimy skomplikowaną siatkę zachodzących na siebie i krzyżujących się podobieństw; podobieństw w skali dużej i małej". (Wittgenstein)
Metoda przykładów paradygmatycznych Wittgensteina.
Krok pierwszy: Celem określenia znaczenia nazwy układa się listę typowych przykładów (tzw. paradygmatów desygnatów), które na mocy przyjętych konwencji kulturowych podpadają pod jej zakres.
Krok drugi: Listę taką można modyfikować na bazie nowych informacji i konwencji. Modyfikacja polega na rozszerzeniu o nowe przypadki oraz na redukcji przypadków niewłaściwych. To, który przypadek jest niewłaściwy, okazuje się przy bliższym sprawdzeniu – określeniu podobieństwa rodzinnego. Z biegiem czasu osiągnięta zostaje lista minimalna, czyli taka, której zredukować nie można, ponieważ jej wszystkie desygnaty dotyczyć będą danego pojęcia.
Krok trzeci: Listę taką można poszerzać dalej w oparciu o nowe przypadki. Lista taka to lista paradygmatów desygnatów, na podstawie której buduje się znaczenie pojęcia.
Definicja alternatywna Tatarkiewicza.
Definicja alternatywna powstała na bazie metody przykładów paradygmatycznych. Jest ona zdaniem sprawy z tego, jak pojmowano znaczenie poszukiwanego pojęcia na przestrzeni dziejów, drogą wskazania na historycznie powstałe desygnaty – paradygmaty tego pojęcia i połączeniem ich przy pomocy spójnika alternatywy.
Zdania warunkowe.
Jedną z odmian definicji cząstkowej stanowią zdania warunkowe, przedstawiane w dwóch postaciach:
Godnym odnotowania jest tu fakt, że gdyby wszystkie przedmioty x spełniały albo warunek W, albo warunek E, to para definicji Wx→Px oraz Ex→~Px stanowiłaby definicję równościową terminu definiowanego P. Nie zawsze się tak dzieje, dlatego obie łącznie tworzą jedynie definicję cząstkową.
Jako okres warunkowy wyrażenia te podają tylko niektóre kryteria stosowalności niezbędne dla stosowania terminów: „orbita planety” i „osoba dorosła”.
Odmianą zdań warunkowych są definicje redukcyjne.
Definicja redukcyjna.
Definicja redukcyjna służy do definiowania terminów teoretycznych (czyli takich, które nie są spostrzeżeniowymi, i do spostrzeżeniowych pozostają w określonych stosunkach definicyjnych). Pojęć (predykatów) dyspozycyjnych nie daje się definiować równościowo w oparciu o terminy spostrzeżeniowe, czyli terminy, których konotację stanowi cecha obserwowalna zmysłowo (np. jakiś kolor, dźwięk, itp.). Predykaty te przypisują pewnym obiektom dyspozycje do reagowania tak a nie inaczej w określonych warunkach (np. „rozpuszczalny w wodzie”, „odporny ma mróz”, „kochliwy”). Na podstawie analizy predykatu „rozpuszczalny w wodzie” przedstawić można ten sposób definiowania. Predykat ten wprowadzić można przy pomocy tzw. obustronnego zdania redukcyjnego R:
Generalizując problem, terminy dyspozycyjne definiować można w następujący sposób. Chcąc zdefiniować jakiś predykat Q3 przy pomocy predykatów Q1, Q2, Q4, Q5, tworzymy w tym celu parę redukcyjną składającą się z dwóch zdań:
Para R1, R2 określa sens empiryczny, czyli zakres empirycznej stosowalności, terminu Q3. Gdy spełniono Q1 oraz Q2 wtedy Q3 ma zastosowanie. Gdy spełniono Q4 oraz Q5 na mocy R2 zdanie Q3 nie ma zastosowania. O ile testy Q1 lub Q4 nie zostały wykonane, predykat Q3 pozbawiony jest empirycznego sensu. Możliwe jest również rozbudowywanie par redukcyjnych i przekształcenie ich w koniunkcyjnie lub alternatywnie połączone tzw. łańcuchy redukcyjne, jak również budowę tzw. obustronnych zdań redukcyjnych, tj. gdy: Q1 ≡ Q4 oraz Q2 ≡ ~Q4
Definicja operacyjna.
Definicje operacyjne najczęściej tworzone są przy pomocy zdań redukcyjnych. Definicja operacyjna to taka definicja cząstkowa, w której znaczenie definiowanej nazwy określane jest drogą podania czynności (operacji) niezbędnych do określenia znaczenia tej nazwy.
Przy takim rozumieniu znaczenia nazwy "definicja operacyjna" należy mieć na względzie, że:
Definicje operacyjne najczęściej przedstawia się za pomocą zdania redukcyjnego o postaci:

</doc>
<doc id="1196" url="https://pl.wikipedia.org/wiki?curid=1196" title="Dywizorek">
Dywizorek

Dywizorek – przyrząd w kształcie długich, wąskich widełek, przytrzymujący kartkę z rękopisem, maszynopisem lub wydrukiem na tenaklu (podstawce, utrzymującej kartkę w pozycji dogodnej do czytania przez zecera, tj. osobę zajmującą się składem tekstu). Czasem nazwą tą obejmowano zestaw obu przyrządów, tj. tenakiel wraz z dywizorkiem.
Oprócz przytrzymywania kartki na tenaklu dywizorek służył również do zaznaczania czytanego miejsca. Funkcję tę realizowano przesuwając dywizorek z biegiem pracy do kolejnych wierszy tekstu. W tej roli przyrząd oddziela w składanym tekście część już złożoną i część czekającą na złożenie, stąd jego nazwa ( – ten, który dzieli).

</doc>
<doc id="1197" url="https://pl.wikipedia.org/wiki?curid=1197" title="Domitian">
Domitian



</doc>
<doc id="1198" url="https://pl.wikipedia.org/wiki?curid=1198" title="Didius Julianus">
Didius Julianus



</doc>
<doc id="1199" url="https://pl.wikipedia.org/wiki?curid=1199" title="Druzus">
Druzus



</doc>
<doc id="1200" url="https://pl.wikipedia.org/wiki?curid=1200" title="Domicjan">
Domicjan

Domicjan, "Domitianus", "Titus Flavius Domitianus", "Imperator Caesar Domitianus Augustus" (ur. 24 października 51, Rzym – zm. 18 września 96, Rzym) – syn Wespazjana i Domitilli Starszej, brat Tytusa Flawiusza i Domitilli Młodszej, cesarz rzymski z dynastii Flawiuszy panujący od 14 września 81 do 18 września 96 roku n.e.
Życiorys.
W początkach swojego panowania w roku 82 osobiście poprowadził siłami 9 legionów wyprawę wojenną przeciwko germańskim plemionom Chattów, których pokonał i odepchnął w głąb Germanii, rozszerzając Agri Decumates, odbył z tego tytułu uroczysty triumf i przyjął przydomek Germanicus w roku 85. 
Także w tym roku Dakowie najechali na prowincję Mezję. Po sprowadzeniu posiłków, w tym jednego legionu z Brytanii, Rzymianie ruszyli do kontrnatarcia zakończonego klęską (zniszczony cały legion V Alaude). Na teren wojny przybył osobiście Domicjan (rok 88), lecz wobec groźby najazdu plemion Jazygów, Markomanów, Kwadów oraz buntu, który wzniecił Saturninus, namiestnik Górnej Germanii, został zmuszony do zawarcia pokoju z władcą Daków w roku 89. Uznał go za króla, obiecał coroczne subsydia pieniężne, specjalistów od fortyfikacji obronnych, licząc na nich jako sojuszników przeciwko innym agresywnym plemionom. Decebal miał zwrócić jeńców wojennych oraz wydać część broni, czego nie uczynił. 
W roku 92 cesarz przeprowadził wyprawę przeciwko Jazygom, Kwadom i Markomanom. 
Przeprowadził reformy w administracji państwa, na wysokie stanowiska w kancelariach cesarskich powołując zamiast wyzwoleńców ekwitów, do pobierania podatków wyznaczył państwową służbę z prokuratorami do ich pilnowania i zakończył działalność prywatnych spółek publikanów pobierających podatki. Wyższe stanowiska w armii powierzał również ekwitom, pomijając senatorów. Dokończył budowę Koloseum.
Był dwukrotnie żonaty z Domicją Longiną. Został zamordowany w pałacu cesarskim w Rzymie, w wyniku spisku pretorianów, cesarskiego szambelana i cesarzowej Domicji.

</doc>
<doc id="1201" url="https://pl.wikipedia.org/wiki?curid=1201" title="Dioklecjan">
Dioklecjan

Dioklecjan, (ur. 22 grudnia 244 w Salonie, zm. 3 grudnia 313 lub 316 w Spalatum) – cesarz rzymski od 20 listopada 284 do 1 maja 305.
Był niezamożnym człowiekiem niskiego pochodzenia, przez całe życie związany z armią. Wybrany przez żołnierzy na cesarza w 284 roku, a następnie zatwierdzony przez senat rzymski, po dwóch latach podzielił się władzą z Maksymianem. Jego panowanie zapoczątkowuje w dziejach Rzymu okres dominatu, wprowadzający w istocie monarchię opartą na armii i na scentralizowanej biurokracji.
W 293 roku Dioklecjan stworzył tetrarchię, czyli system rządów, w którym władzę równocześnie sprawowało czterech panujących nad różnymi obszarami rozległego imperium: Dioklecjan (wschodnie wybrzeże Morza Śródziemnego), Maksymian (Italia, Afryka i Hiszpania), Galeriusz (dolina Dunaju i Bałkany) i Konstancjusz I Chlorus (Brytania i Galia). Mający najwyższą pozycję Dioklecjan kazał uznawać się za potomka Jowisza, natomiast boskim przodkiem Maksymiana miał być Herakles – co miało podkreślać ich szczególny prestiż w nowym układzie rządzenia cesarstwem.
Z żoną Pryską miał córkę Galerię Walerię – drugą żonę cesarza Galeriusza.
Młodość i służba wojskowa.
Pochodził on z rzymskiej Dalmacji, z rodziny niższego urzędnika, wyzwoleńca senatora Annulinusa; jego matką była Diokleja. Według Timothy’ego Barnesa dokładna data urodzin Dioklecjana to 22 grudnia 244 roku. Drogą do awansu społecznego stała się dla niego służba wojskowa, w toku której doszedł do stanowiska dowódcy wojsk rzymskich w Mezji. Za rządów Karusa awansował na dowódcę straży przybocznej (). Uczestniczył w wyprawie tego cesarza na Persję w 283 roku, gdy w trakcie kampanii mezopotamskiej zdobyto Seleucję i Ktezyfon.
Dojście do władzy.
Podczas odwrotu wojsk rzymskich po śmierci Karusa, jego syn i następca Numerian zmarł w niejasnych okolicznościach (lub został zamordowany). Zgon jego przez dłuższy czas ukrywano, gdyż od syryjskiej Emesy cesarz stale podróżował w zamkniętej lektyce. Dopiero w okolicach Nikomedii fakt ten ujawniono po odkryciu rozkładającego się ciała Numeriana; Diokles oskarżył o zbrodnię swego rywala – prefekta pretorianów Apra, którego zgładził publicznie, a następnie został 20 listopada 284 obwołany nowym cesarzem przez wojsko, przyjmując imię Dioklecjana. 
Jego rola w usunięciu Numeriana wraz z możliwym udziałem w spisku Apra nie jest całkiem jasna. Późniejsza propaganda cesarska, jak i opis tego wydarzenia przez Flawiusza Wopiskusa w "Historia Augusta", nie ułatwiają wyjaśnienia tej kwestii. Natychmiast po proklamowaniu go władcą Dioklecjan wyruszył z wojskiem na zachód przeciw bratu-współrządcy Numeriana i pokonał cesarza Karynusa w bitwie nad rzeką Margus w Mezji (maj 285). W czerwcu 285 roku jako nowy władca dotarł do Rzymu.
Wczesne kampanie i współrządy z Maksymianem.
21 lipca 285 roku w Mediolanie powołał na współrządcę Maksymiana, podnosząc go do godności cezara, a 1 marca 286 roku uczynił go augustem. Wkrótce potem Maksymian został wysłany do Galii dla stłumienia powstania bagaudów pod wodzą Amandusa. W 286 lub 287 Dioklecjan i Maksymian przyjęli tytuły "Iovius" i "Herculius". Nowa koncepcja władzy cesarskiej stanowiła, że augustowie są braćmi, przy wyższej pozycji Dioklecjana (jako pochodzącego od Jowisza). Jeszcze w 285 Dioklecjan odniósł sukces w walce przeciw Sarmatom, a w 287 podczas pobytu na wschodzie przyjął dary od pokojowego poselstwa króla sasanidzkiej Persji Bahrama II. Zachodnia część Armenii została włączona do Cesarstwa Rzymskiego, a nad resztą objął rządy Tiridates III, władca w pełni zależny Rzymu.
Powstanie bagaudów zostało szybko stłumione przez Maksymiana Herkuliusza, ale na jesieni 286 roku Karauzjusz, oficer któremu powierzono zadanie zwalczania frankońskich i saskich piratów, przywłaszczył sobie łupy z kampanii. Zagrożony przez Maksymiana karą śmierci, ogłosił się augustem, opanowując Brytanię i nadbrzeżne części Galii. W tym czasie (286–287) Maksymian przekroczył Ren i poprowadził kampanię przeciw niepokojącym Galię Burgundom i Alamanom. W 288 nastąpiło spotkanie augustów, na którym zapadły ustalenia dotyczące walki z Karauzjuszem. Maksymian zaczął rozbudowywać flotę, a działania wojenne przeciw Frankom nad Renem scedował na swych podwładnych, m.in. na swego zięcia i oficera Konstancjusza Chlorusa. W 289 Dioklecjan powtórnie pokonał Sarmatów, a następnie wyruszył na wschód dla odnowienia przyjaznych związków z plemionami z Pustyni Syryjskiej i zwalczania Saracenów. Nakazał budowę umocnień i fortów w Syrii, Egipcie i wokół Circesium w Mezopotamii. W 290 Maksymian poniósł klęskę w bitwie morskiej z Karauzjuszem i utracił flotę. W tym samym roku w Mediolanie doszło do kolejnego zjazdu cesarzy połączonego z wystawnymi ceremoniami, które miały propagandowo podkreślać siłę państwa rzymskiego i jedność władzy wynikającą ze zgody panujących (). Dioklecjan przyjął w Mediolanie delegację rzymskiego Senatu. Podjęto też w tajemnicy szereg ważnych decyzji politycznych i wojskowych.
Dioklecjan podróżował głównie po wschodniej części Cesarstwa, kształtując zasadę „gdzie cesarz tam Rzym”. Wiadomo np. że odwiedził Emesę dnia 10 maja 290, albo Sirmium 1 lipca 290 roku. Po wprowadzeniu tetrarchii jego stolicą była Nikomedia.
Powstanie tetrarchii.
W 293 komendę nad wojskami walczącymi z uzurpatorem Karauzjuszem powierzył Dioklecjan Konstancjuszowi Chlorusowi. Na wiosnę tego roku Konstancjusz oraz zięć i prefekt pretorianów Dioklecjana, Galeriusz, zostali podniesieni do rangi cezarów. Pierwszy z nich był odpowiedzialny za działania wojskowe w Galii i Brytanii, drugiemu powierzono obronę granicy wschodniej imperium. Cezarowie stali się adoptowanymi synami augustów. Każdy z władców odpowiedzialny za obronę określonego terytorium, wkrótce zaczął też dysponować własnym dworem, administracją i wojskiem. Synowie Konstancjusza i Maksymiana, Konstantyn i Maksencjusz przebywali na dworze Dioklecjana w Nikomedii. W taki sposób powstała tetrarchia („czwórwładza”). Nie był to jednak system idealnie symetryczny; np. w Cesarstwie było tylko dwóch prefektów pretorianów. W miastach takich jak Sirmium, Antiochia, Trewir, Mediolan czy Nikomedia powstały cesarskie rezydencje.
W 294 roku Dioklecjan odbył kampanię przeciw Sarmatom i umocnił granicę na Dunaju polecając budowę wielu fortów, przyczółków, mostów i umocnionych miast, które złożyły się na linię obrony znana jako "Ripa Sarmatica". Reformy podatkowe wywołały niezadowolenie w Górnym Egipcie, które spowodowało najpierw powstanie stłumione przez Galeriusza w 295 roku, a potem uzurpację Domicjusza Domicjana, który ogłosił się augustem w 297 roku. Dioklecjan wyruszył do Egiptu i najpierw stłumił rebelię w Tebaidzie, a potem obległ Aleksandrię, której po śmierci uzurpatora bronił jego następca Aureliusz Achilleus. Po zdobyciu miasta udało mu się spacyfikować prowincję i zreorganizować jej administrację. W 296 roku Konstancjusz Chlorus zaatakował wojska Karauzjusza zgromadzone w Gesoriacum (Boulogne) i zdobył miasto. Po zbudowaniu floty wojennej wyprawił się do Brytanii, gdzie po śmierci Karauzjusza władzę przejął Allektus. Na jesieni 296 roku Konstancjusz pokonał uzurpatora i zdobył Londinium.
W 294 roku na tronie perskim nastąpiła zmiana, która przyniosła wojnę z Rzymem. Bahrama III zastąpił Narses. W 295 roku wybuchł konflikt między Persją a cesarstwem o Armenię. Narses najechał zachodnią część kraju należącą do Rzymu, a następnie skierował się z wojskami do północnej Mezopotamii. Wojska pod dowództwem Galeriusza poniosły ciężkie straty w bitwie pod Callinicum w 296 roku i musiały wycofać się do Antiochii. W rejon działań wojennych niezwłocznie przybył Dioklecjan z posiłkami z armii znad Dunaju; Galeriusza ukarał za nieudolność, każąc mu biec przed swym rydwanem podczas wjazdu do Antiochii. Galeriusz wyruszył z wojskami do Armenii Mniejszej i ustanowił bazę w Satali. Pokonano Narsesa, który wystąpił przeciw wojskom rzymskim; Rzymianie zajęli obóz perski wraz ze skarbcem i haremem. Galeriusz wkroczył następnie do Medii i Adiabene. Na przełomie 296 i 297 roku jego wojska zeszły na równinę Mezopotamii i w końcu zdobyły Ktezyfon. Na wiosnę 299 roku rozpoczęto rokowania pokojowe. Podpisany przez Dioklecjana i Narsesa traktat był korzystny dla Rzymian: odzyskano Armenię, Iberia Kaukaska wróciła do strefy wpływów cesarstwa, poszerzono posiadłości rzymskie w Mezopotamii. W rzymskiej domenie znalazły się Nisibis, Bezabde i Amida.
Reformy Dioklecjana.
Wojsko.
Dioklecjan wprowadził istotne zmiany w organizacji armii rzymskiej. Przypisuje się mu istotne zwiększenie liczebności wojska. Zapoczątkował proces tworzenia okręgów militarnych pokrywających się z prowincjami i podległych wodzom ("duces"). Utworzył wiele nowych legionów obdarzonych przydomkami Iovia, Herculia, Diocletiana, Maximiana. Prawdopodobnie były one dużo mniejsze niż jednostki z czasów pryncypatu (ich liczebność szacuje się na 500–1000 żołnierzy). Według późniejszego historyka Agatiasza, armia Dioklecjana miałaby liczyć łącznie 645 tys. ludzi. Dioklecjan zreorganizował też system aprowizacji armii, zaopatrując ją w niezbędną żywność ściąganą od ludności Cesarstwa w naturze ("anonna militaris" lub "capitus"). 
Ponadto władca wprowadził w życie program umacniania granic: szeroko zakrojone prace budowlane prowadzono w Syrii, nad Dunajem, w Egipcie, w Brytanii. Np. wysuniętą placówkę w Palmyrze wzmocniono stworzeniem tzw. Obozu Dioklecjana przy wykorzystaniu miejskich budowli wcześniej zrujnowanych przez wojska Aureliana. Na Bliskim Wschodzie powstała linia twierdz, fortów i obozów legionowych rozciągająca się od Morza Czerwonego do Eufratu, zwana "Strata Diocletiani". "Limes" ten wraz z ważnymi szlakami (np. Via Diocletiana wiodąca do Palmyry) przetrwał epokę bizantyńską aż do nadejścia Arabów w VII wieku. Założeniom tym towarzyszyły budowle podkreślające niesłabnącą potęgę cesarstwa i twórczy rozmach imperium: termy Dioklecjana w Rzymie, warowna rezydencja w Spalatum, łuki Dioklecjana w afrykańskiej Sufetuli czy na nilowej wyspie File. W ówczesnej architekturze (także w rzeźbie) poczęła się zaznaczać typowa później dla dominatu skłonność do okazałych konstrukcji i surowych form monumentalnych.
Administracja.
Istotnym zmianom za panowania Dioklecjana uległ system administracji imperium. Około 293 roku prowincje zgrupowano w 12 większych jednostek organizacyjnych, zwanych diecezjami i zarządzanych przez wikariuszy ("vicarii"), natomiast diecezje podzielono między 4 prefektury (Galii, Italii, Ilirii, Orientu). Liczbę samych prowincji zwiększono z około 50 do ok. 100 i wprowadzono podział na zarządców cywilnych ("praesides", "correctores", "consulares", prokonsulowie) oraz wojskowych "duces". Rozbudowano centralną biurokrację, w której pojawili się liczni urzędnicy dworscy, tacy jak: "magister officiorum" (kanclerz, odpowiedzialny za ceremoniał dworski, transport i tajną policję), "quaestor sacri palatii" (sekretarz cesarski), "praepositus sacri cubiculi" (naczelnik dworu). Powstało wiele urzędów związanych z zarządzaniem finansami ("rationales", "magistri rei privatae", "comes sacrarum largitionum" – odpowiedzialny za kopalnie, mennice i podatki). Dla podniesienia cesarskiego autorytetu Dioklecjan wprowadził paradny ceremoniał dworski (w większości przejęty z sasanidzkiej Persji) i skomplikowany system rang, a sam cesarz przybrał wyszukany, barwiony purpurą strój z jedwabiu wraz z diademem. Cesarska tytulatura, w której szczególnego znaczenia nabrał tytuł "dominus noster", uległa dalszemu rozwinięciu, a wszystko, co dotyczyło osoby władcy, zaczęto określać jako boskie lub święte. Podniesieniu prestiżu władcy i podkreśleniu jego splendoru miał również służyć kompleks pałacowy wybudowany na adriatyckim wybrzeżu w Spalatum, który łącząc w sobie funkcje wojskowe, religijne i mieszkalne, stał się wyjątkowym przykładem sztuki architektonicznej. 
Finanse i gospodarka.
Dioklecjan był pierwszym cesarzem, który rozpoczął ściąganie podatków z ziem Italii. Na posiadaczy ziemskich nałożył podatek progresywny, którego wysokość uzależniona była od jakości i areału posiadanej ziemi oraz od liczby zatrudnionych pracowników. Wskutek wysokiej inflacji pobierano go w naturze. Co 15 lat przeprowadzano spis w celu weryfikacji wysokości pobieranego podatku. System ten głównie miał na celu sprawniejsze uzyskiwanie środków na utrzymanie rozrastającego się wojska i biurokracji. Efektem tej reformy miała być stabilizacja gospodarcza wraz z opanowaniem inflacji. Zmieniono przy tym absolutną i względną wartość monet wartościowych (aureusa i argenteusa) oraz nominałów brązowych. W gospodarce kierowano się odgórnymi rozporządzeniami, czego przykładem stał się znany edykt o cenach maksymalnych () z 301 roku, który szczegółowo ustalał nieprzekraczalne ceny produktów i usług. Pomimo że za jego naruszenie groziła nawet kara śmierci, prawo to nie było respektowane i nie przyniosło oczekiwanych rezultatów. Edykt o cenach maksymalnych wkrótce został anulowany. 
Polityka religijna, prześladowania.
Dioklecjan znalazł ideologiczne i propagandowe oparcie swej władzy w umocnieniu rzymskiej religii i odwoływaniu się do obyczajów przodków ("mos maiorum"). Chciał wspierać rzymskie wartości i kultywować starą religię. Władza tetrarchów miała pochodzić od tradycyjnych bogów rzymskiej religii, zwłaszcza Jowisza, Herkulesa i Marsa oraz od Sol Invictus. Propaganda podkreślała boską naturę cesarzy. W 297 roku Dioklecjan wydał edykt przeciw manichejczykom skazujący wyznawców na śmierć, bądź dożywotnie roboty w kopalniach, a przywódców manichejskich na spalenie żywcem wraz z księgami. Wedle listu Dioklecjana do prokonsula Afryki manicheizm był religią nową, obcą i wrogą mieszkańcom świata rzymskiego.
W 302 roku usunięto chrześcijan z wojska i urzędów państwowych, pod zarzutem zakłócania przebiegu oficjalnych uroczystości religijnych.
Prześladowanie chrześcijan rozpoczęło się 23 lutego 303 roku, gdy urzędnicy i żołnierze na rozkaz cesarza zniszczyli kościół w Nikomedii. Następnego dnia wydano edykt nakazujący zburzenie świątyń chrześcijańskich i spalenie świętych ksiąg oraz pozbawienie stanowisk chrześcijan sprawujących funkcje publiczne. Klauzule edyktu były przestrzegane w różnym stopniu na różnych obszarach Cesarstwa. W Egipcie prefekt Sozjanus Hierokles zmuszał do składania ofiar bóstwom pogańskim i likwidował kościoły. Na zachodzie Konstancjusz Chlorus wprowadzał te zarządzenia w bardzo niewielkim stopniu. Drugi edykt, z lata 303 roku nakazywał uwięzienie chrześcijańskich przywódców w całym Imperium. Jesienią 303 roku został wydany trzeci edykt, który głosił, że wszyscy, którzy odejdą od chrześcijaństwa, zostaną uwolnieni, oporni natomiast mogli być torturowani. W następstwie tego we wschodniej części Cesarstwa wielu biskupów i „zwykłych wierzących” uwięziono i zabito. Biskup Antym z Nikomedii został ścięty.
Z czasów tych właśnie prześladowań zachowało się wiele przekazów męczennikach czczonych do dziś przez Kościoły chrześcijańskie. Niemniej zdecydowana większość chrześcijan uniknęła prześladowań. Akcji nie prowadzono systematycznie i z tym samym natężeniem. Istniały różnice w wykonywaniu zarządzeń podyktowane warunkami lokalnymi. Dokładna liczba ofiar prześladowania nie jest znana – zgładzono minimum kilkuset, a prawdopodobnie około 2500–3000 osób. Wiadomo, że w Syrii-Palestynie wydano 44 wyroki śmierci, a 42 osoby skazano na wygnanie. Ustawodawstwo rzymskie nakazywało stosować tortury wobec wszystkich wrogów władzy państwowej; nie wymyślono ich specjalnie dla chrześcijan. Prześladowania sprowokowane zostały przez Galeriusza, który jako syn kapłanki Romuli był nieprzejednanym wyznawcą politeizmu rzymskiego. Ustały one w 311 roku, gdy wydany został edykt tolerancyjny Galeriusza przyzwalający chrześcijanom kultywować ich praktyki religijne.
Obraz prześladowań chrześcijan za czasów panowania cesarza Dioklecjana może być wypaczony, ponieważ posiadamy relacje jedynie jednej strony – prześladowanej. Z wypowiedzi różnych pisarzy kościelnych oraz dalszego rozwoju wypadków wynika jednak, że liczba odstępców od wiary była bardzo duża. Znaleźli się wśród nich nawet biskupi. Głośna stała się sprawa biskupa Rzymu (papieża) Marcelina, a także biskupa Piotra Aleksandryjskiego.
Dalsze rządy i abdykacja.
W 303 roku Dioklecjan obchodził "vicennalia" (dwudziestą rocznicę panowania) i dziesięciolecie tetrarchii. Z tej okazji w Rzymie 20 listopada 303 roku odbyły się wielkie uroczystości. 1 stycznia 304 Dioklecjan powtórnie objął urząd konsula w Rawennie. Następnie uczestniczył w kampanii Galeriusza przeciw Karpom, lecz jego stan zdrowia stale się pogarszał i zmuszony był podróżować w lektyce. 28 sierpnia 304 ponownie przebywał w Nikomedii; na przełomie 304 i 305 roku przeszedł tam najcięższy okres choroby, gdy ludność miasta była przekonana, że cesarz niebawem umrze. Pojawił się publicznie dopiero 1 marca 305 roku. 1 maja zwołał zgromadzenie oficerów i żołnierzy w okolicach Nikomedii, w pobliżu miejsca, gdzie w 284 roku obwołano go cesarzem; na wiecu obecni byli także Galeriusz i Konstantyn. Dioklecjan mianował augustem Galeriusza, cezarami Maksymina Daję i Sewera II, a sam zrzekł się godności augusta, uzasadniając decyzję swym wiekiem, stanem zdrowia i przemęczeniem.
Były cesarz, który stopniowo wycofywał się z życia publicznego, osiadł w pałacu wybudowanym w Spalatum niedaleko Salony na dalmackim wybrzeżu. Jeszcze w 308 pełnił konsulat wraz z Galeriuszem; jesienią tego roku spotkał się z nim i Maksymianem na zjeździe w Carnuntum, gdzie omawiano przyszłość tetrarchii. Odmówił powrotu do władzy, do czego chciano go nakłonić. Pod koniec życia miał wedle tradycji zajmować się głównie uprawą jarzyn w pałacowym ogrodzie. 
Data i przyczyna śmierci Dioklecjana nie jest pewna. Rozmaite hipotezy badawcze umieszczają zgon cesarza pomiędzy 311 a 316 rokiem.

</doc>
<doc id="1202" url="https://pl.wikipedia.org/wiki?curid=1202" title="Domitilla Starsza">
Domitilla Starsza

Flavia Domitilla, Domitylla Starsza (ur. przed 20, zm. przed 69) – córka Flawiusza Liberalisa, skryby kwestorskiego z Ferentium. Była oficjalną kochanką jednego z afrykańskich książąt, a od ok. 38 żoną cesarza rzymskiego Wespazjana. Była matką Tytusa Flawiusza, Domicjana i Domitilli Młodszej.
Zmarła zanim jej mąż został cesarzem rzymskim.

</doc>
<doc id="1204" url="https://pl.wikipedia.org/wiki?curid=1204" title="Domitianus">
Domitianus

 Domitianus (Domicjan II) – uzurpator galijski z 3 ćwierci III w. n.e. Znany jedynie z dwóch odnalezionych przypadkowo monet wybitych w jego imieniu. Utożsamiany ze wspomnianym przez starożytnych autorów wodzem Domitianusem, który za rządów cesarza Galiena (253-268 n.e.) pokonał syryjskich uzurpatorów Makrianów.
Do niedawna dyskutowano jego istnienie jako wątpliwe, kwestionując autentyczność unikatowej monety znalezionej (1900) w skarbie z Cléons (Francja). Znalezienie w Anglii (2003) drugiego egzemplarza w tzw. II skarbie z Chalgrove potwierdziło nie tylko autentyczność pierwszego, lecz pozwoliło też na uściślenie chronologii tych numizmatów obejmującej lata 269-272 n.e.
Prawdopodobne, iż wówczas Domicjan II mógł mieć udział w usunięciu uzurpatora Wiktoryna (269-271) i tym samym stał się rywalem Tetryka (271-274), z którym widocznie przegrał walkę o panowanie w "Imperium Galliarum". Buntownicze obwołanie go przez wojska cesarzem mogło nastąpić w przymusowej sytuacji zagrożenia najazdami barbarzyńskimi w początkach rządów Aureliana.
"Historia Augusta" trzykrotnie wspomina Domicjana, który pokonał obu Makrianów, jako „najdzielniejszego i najenergiczniejszego” z wodzów Aureolusa (zbuntowanego później przeciw Galienowi), i wywodzącego swe pochodzenie od cesarza Domicjana i Domitylli ("Tir. trig." 12, 13 ; 13, 3 ). Jest to zapewne ten sam dowódca, o którym w innym miejscu mowa, iż „ogłosił się cesarzem jako przeciwnik Galiena” ("Vit. Gal." 2, 6). Zosimos wymienia go wśród planujących bunt przeciw Aurelianowi ("Historia nova" I 49,2), co byłoby zgodne z datowaniem obu monet na początek 271 r., tj. czas kampanii Aureliana przeciw germańskim Alamanom i Jutungom po klęsce pod Placentią.
Niekiedy mylony z uzurpatorem Domicjanem ("Lucius Domitius Domitianus"), który krótkotrwale (296-297 n.e.) przejął władzę w Egipcie.

</doc>
<doc id="1205" url="https://pl.wikipedia.org/wiki?curid=1205" title="Domicjusz Domicjan">
Domicjusz Domicjan

Domitius Domitianus ("Lucius Domitius Domitianus") – rzymski uzurpator, wywołał powstanie przeciwko Dioklecjanowi w czerwcu/lipcu 297 (296?) roku w Egipcie. Zmarł w grudniu 297 roku.

</doc>
<doc id="1206" url="https://pl.wikipedia.org/wiki?curid=1206" title="Decencjusz">
Decencjusz

Decencjusz, "[Flavius] Magnus Decentius" (? – 18 sierpnia 353) – cezar i współrządca Magnencjusza w zachodniej części cesarstwa.
W 351 roku został mianowany cezarem przez swego brata Magnencjusza, który powierzył mu namiestnictwo Galii dla obrony jej terytorium oraz linii Renu. Klęska w wojnie z Konstancjuszem II skłoniła go do samobójstwa, wskutek czego powiesił się w sierpniu 353 roku.

</doc>
<doc id="1207" url="https://pl.wikipedia.org/wiki?curid=1207" title="Drusus">
Drusus



</doc>
<doc id="1208" url="https://pl.wikipedia.org/wiki?curid=1208" title="Druzus Starszy">
Druzus Starszy

Decimus Claudius Nero Drusus Germanicus (ur. 14 stycznia 38 p.n.e.; zm. 14 września 9 p.n.e.). 
Syn Tyberiusza Klaudiusza Nerona i Liwii, brat cesarza Tyberiusza. Urodzony już po rozwodzie Liwii z Tyberiuszem Klaudiuszem Neronem i ślubie z Augustem. 
Charakterystyka.
Druzus był jednym z wybitniejszych ludzi swoich czasów. Jego przyjazne maniery, ujmujący wygląd, a przede wszystkim błyskotliwe talenty militarne zapewniły mu uznanie i przywiązanie legionistów. Był wybitnym wodzem, co wykazał licznymi zwycięstwami odniesionymi nad Germanami. Jawnie okazywana sympatia dla zasad republikańskich zjednała mu uznanie w szerokich kręgach. Uważano, że może się przyczynić do przywrócenia republiki.
Kampania nad Dunajem.
W 15 p.n.e. bracia Tyberiusz i Druzus poprowadzili udaną kampanię przeciw galickim plemionom Retów i Windelików. Retowie zamieszkiwali Alpy pomiędzy rzekami Renem i Inn, a Windelikowie zajmowali terytoria na północ od nich aż do samego Dunaju. Po uciążliwych walkach w górskim terenie wojska rzymskie odniosły ostateczne zwycięstwo. Na podbitym obszarze zorganizowano nową prowincję – Recję, której stolicą zostało później miasto Augusta Vindelicorum (dzisiejszy Augsburg).
Namiestnictwo w Galii.
W 13 p.n.e. cesarz August opuszczając Galię zostawił tam Druzusa jako swego zastępcę i namiestnika nowozorganizowanej prowincji Trzech Galii. Narastające niezadowolenie w prowincji zażegnał on przeprowadzając ponowne naliczenie podatków i zwołując zebranie przedstawicieli plemion galijskich w Lugdunum (dzisiejszym Lyonie) dla rozpatrzenia skarg. W sierpniu 12 p.n.e. podczas wielkiej ceremonii, przed ołtarzem poświęconym Romie i Augustowi zgromadzili się przedstawiciele wszystkich plemion galijskich i złożono uroczystą ofiarę. Pacyfikacja nastrojów w Galii miała doniosłe znaczenie, dając Rzymianom możliwość skoncentrowania się na walkach z Germanami.
Pierwsza kampania w Germanii.
W 12 p.n.e. zamieszkujący prawy brzeg Renu Sugambrowie przekroczyli rzekę. Druzus odrzucił ich z powrotem i spustoszył ich własne terytoria. Płynąc następnie w dół Renu podporządkował sobie Fryzów. Dla ułatwienia operacji wojskowych rozkazał zbudowanie kanału łączącego Ren z zalewem Zuyder See. Flota rzymska wypłynęła na Morze Północne posuwając się wzdłuż wybrzeża na wschód. U ujścia rzeki Ems w bitwie morskiej rozbito flotę Brukterów, a u ujścia Wezery spustoszono ziemie plemienia Chauków. Nadchodząca zima zakończyła kampanię. Wracająca flota ugrzęzła na mieliznach, lecz z pomocą Fryzów zdołano ją uwolnić. Druzus wrócił do Rzymu w chwale pierwszego dowódcy, który dotarł do wybrzeży Morza Północnego.
Kolejne walki w Germanii.
W 11 p.n.e. ponownie poprowadził wojska za Ren. Pokonał plemiona Usipetów, Sugambrów, Chattów i doszedł do Wezery, gdzie odniósł zwycięstwo nad Cheruskami. W drodze powrotnej założył pierwsze za Renem stałe forty rzymskie. W 10 p.n.e. Chattowie i Sugambrowie znów się zbuntowali. Po odniesieniu kilku pomniejszych sukcesów Druzus wraz z Tyberiuszem i Augustem powrócił do Rzymu, gdzie wybrano go konsulem na następny rok. Jednakże już jesienią był z powrotem przy legionach zimujących nad Renem, przygotowując się do kampanii w roku następnym.
Ostatnia kampania.
Wiosną 9 p.n.e. Druzus, tym razem jako konsul, znów poprowadził wojska w głąb Germanii. Zaatakował i pokonał Chattów, Szwabów, Markomanów i Cherusków. Przekroczył Wezerę i dotarł do Łaby. Był to najdalszy punkt na terenie Germanii, do jakiego kiedykolwiek dotarła rzymska armia. Dla utrwalenia zdobyczy podjął wiele środków: budował fortece wzdłuż Łaby, Wezery i Mozy, zorganizował stałą flotyllę na Renie. Podobno od przekroczenia Łaby odwiodło go tylko widzenie, w którym nadnaturalnej wielkości zjawa kobiety przepowiedziała mu zbliżającą się śmierć. W drodze powrotnej uległ wypadkowi: upadek z konia spowodował złamanie nogi. Po 30 dniach zmarł w obecności brata, Tyberiusza, który na wieść o wypadku szybko podążył do obozu. Eskortował potem mary ze zwłokami brata, które przewieziono do Rzymu. Prochy złożono w Mauzoleum Augusta.
Potomkowie.
Mąż Antonii Młodszej (córki triumwira – Marka Antoniusza i siostry cesarza Augusta – Oktawii). Miał z nią troje dzieci:

</doc>
<doc id="1209" url="https://pl.wikipedia.org/wiki?curid=1209" title="Drusilla">
Drusilla



</doc>
<doc id="1210" url="https://pl.wikipedia.org/wiki?curid=1210" title="David Hilbert">
David Hilbert

David Hilbert (ur. 23 stycznia 1862 w Królewcu (Prusy Wschodnie), zm. 14 lutego 1943 w Getyndze) – niemiecki matematyk.
W zakres jego badań naukowych wchodziły:
Dokonania.
Hilbert był profesorem uniwersytetu w Getyndze, jednego z najważniejszych wówczas ośrodków myśli matematycznej na świecie. Początkowo pracował nad teorią niezmienników algebraicznych. Udowodnił w 1888 roku kluczowe dla tej teorii twierdzenie o istnieniu skończonej bazy dla układu niezmienników. W 1893 udowodnił podstawowe dla geometrii algebraicznej twierdzenie o zerach.
Hilbert zajmował się podstawami geometrii. Jego badania w tym zakresie ukazały nowe spojrzenie na tę tematykę. Wyniki swych badań opublikował w książce" Grundlagen der Geometrie" z 1899 roku ("Podstawy geometrii"), w której podał formalne aksjomatyczne ujęcie geometrii klasycznej. Ta przełomowa książka (do dziś wielokrotnie wznawiana i tłumaczona na inne języki) odcisnęła się na spojrzeniu współczesnych matematyków na geometrię i stanowi fundament geometrii aksjomatycznej oraz fundament filozoficzny geometrii.
Hilbert prowadził badania również w zakresie rachunku wariacyjnego oraz teorii równań całkowych. Doprowadziły one do powstania pojęcia przestrzeni Hilberta oraz innych pojęć analizy funkcjonalnej, w szczególności aparatu matematycznego mechaniki kwantowej.
W kręgu jego zainteresowań znajdowała się także teoria liczb. Na przykład w 1909 roku rozwiązał postawiony w 1770 roku problem Waringa.
W listopadzie 1915 wyprowadził (kilka dni przed Einsteinem) równania pola w ogólnej teorii względności. Nie były one „naprawdę ogólnie kowariantne”, w przeciwieństwie do równań teorii Einsteina, „która obejmowała wszystkie formy ruchu”.
Hilbert dążył do uniezależnienia logicznych systemów formalnych od ich strony znaczeniowej, do formalnej poprawności matematycznej. Przedstawił program sformalizowania logiki matematycznej – szukał sposobu zagwarantowania zupełności i niesprzeczności układu aksjomatów teorii matematycznej. Kurt Gödel wykazał w 1931 roku, że ten program jest niemożliwy do zrealizowania.
Znane są do dziś problemy Hilberta (które nadały nowe kierunki rozwoju XX-wiecznej matematyki i odegrały ogromną rolę w ukształtowaniu współczesnej problematyki badawczej matematyki) – przedstawił je Hilbert w 1900 roku na Międzynarodowym Kongresie Matematyków w Paryżu.
Hilbert był wszechstronnym matematykiem, poważnie traktującym swoje obowiązki dydaktyczne profesora uniwersytetu. Potwierdza to lista wykładów, które wygłosił w latach 1895–1930:
Hilbert miał wielu uczniów. Byli to, między innymi:
Prace Hilberta wywarły ogromny wpływ na rozwój nowoczesnej matematyki. Główne prace Hilberta to:
Na jego nagrobku jest napisane "Musimy wiedzieć, będziemy wiedzieć" (w języku niemieckim), słowa które wypowiedział podczas jednego z wykładów.

</doc>
<doc id="1211" url="https://pl.wikipedia.org/wiki?curid=1211" title="Diduch">
Diduch

Diduch (dosł. "dziad"), okłót – w tradycji wschodniosłowiańskiej i góralskiej pierwszy skoszony podczas żniw snop pszenicy i owsa lub niemłóconego żyta, ustawiany kłosem do góry w kącie izby na Szczodre Gody, a obecnie na Boże Narodzenie. Uważany był za wróżbę urodzaju w następnym roku i traktowany jako swego rodzaju talizman przeciw złym mocom.
Trzymano go w domu do Trzech Króli, a następnie rytualnie palono. W niektórych tradycjach (por. informacje w artykule Święto Godowe) trzymano go do wiosny, młócono i z jego ziaren dokonywano pierwszego wiosennego zasiewu.
Na Lubelszczyźnie zwany też królem. Na południu Małopolski w Gorcach i okolicy zwany w gwarze Białych Górali łokótem (staropolski okłót/okłot).
Zwyczaj ustawiania snopa w chacie na Święto Godowe wywodzi się jeszcze z czasów przedchrześcijańskich i związany był z kultem przodków. Symbolizował ducha opiekuńczego domu. Został zaadaptowany przez chrześcijaństwo na terenie Ukrainy jako zwyczaj bożonarodzeniowy.

</doc>
<doc id="1212" url="https://pl.wikipedia.org/wiki?curid=1212" title="Dziwożona">
Dziwożona

Dziwożona (także "boginka", "mamuna") — demon żeński z wierzeń dawnych Słowian.
Etymologia i regionalizmy.
Wyraz „dziwożona” ("dzika żona/kobieta") jest w języku polskim pożyczką z języka słowackiego: „diva lena”/ „divá žena” oznaczała „dziką kobietę”, a polski odpowiednik spopularyzowany został przez wydaną w 1855 powieść „Dziwożona” autorstwa Zygmunta Kaczkowskiego.
W języku czeskim wyraz ten występuje jako "diva żena," u Hucułów istniała "dykaja żena," u Łużyczan "wódna żona". Z kolei na terenach Rusi Czerwonej do opisu dziwożon pasuje wyraz "bohynie" („boginie”).
W źródłach dziwożona jest często wymiennie stosowana z "mamuną" i — przede wszystkim — z "boginką". Wyraz „dziwożona” szczególnie stosowany był u górali tatrzańskich, z kolei wyraz "diva lena", ale też "runa" (nawiązanie do "mamuna") był w użytku u górali słowackich.
Wygląd i działanie.
Dziwożony przedstawiane były jako szkaradne, garbate kobiety, o długich splątanych włosach, czasem z ozdobioną paprocią czerwoną czapeczką na głowie oraz z długimi piersiami lub patologicznie wydłużonymi sutkami, które zarzucały sobie na plecy i którymi nawet prały bieliznę. Mieszkały w osypiskach skalnych, w jeziorach (np. Jezioro Żabie) lub w pieczarach górskich (np. pieczara w okolicach wsi Łopuszna). Żywiły się zielem „słodyczką”.
Wierzono, że dziwożony porywały młode dziewczęta i młode mężatki. Poza tym porywały dzieci z kołysek, podmieniając je na własne: brzydkie odmieńce, z widocznymi ułomnościami lub niepełnosprawnością umysłową/rozwojową. Sposobem na odzyskanie dziecka miało być wyniesienie odmieńca na pole/granicę lub śmietnik, tam obicie dziecka rózgą, dodatkowo oblewając je lub pojąc wodą ze skorupki jajka i wypowiadając słowa: "Odbierz swoje, oddaj moje". Wtedy dziwożona, poruszona płaczem własnego dziecka, wracała po nie, oddając porwanego noworodka.
Od dziwożon można było się uwolnić albo je odstraszyć, używając kwiatu dziurawca ("popul". „dzwonek”, "reg". „zwonka”). Ten opis zachowań dziwożon i metod ochrony przed nimi jest tożsamy z zapisami wierzeń z różnych terenów odnoszącymi się do boginek.
Regionalne warianty opowieści o dziwożonach, oprócz typowych sytuacji podmiany dziecka lub porwania młodej mężatki/matki, zawierają także opowieści w rodzaju:

</doc>
<doc id="1214" url="https://pl.wikipedia.org/wiki?curid=1214" title="Drukarka">
Drukarka

Drukarka – urządzenie współpracujące z komputerem oraz innymi urządzeniami, służące do przenoszenia danego tekstu czy obrazu na różne nośniki druku (papier, folia, płótno itp.). Niektóre drukarki potrafią pracować bez komputera, np. drukować zdjęcia wykonane cyfrowym aparatem fotograficznym (po podłączeniu go do drukarki lub po włożeniu karty pamięci z zapisanymi zdjęciami do wbudowanego w drukarkę slotu). Obecnie produkowane są także urządzenia wielofunkcyjne, które są połączeniem drukarki, kserokopiarki, skanera, czy też faksu.

</doc>
<doc id="1215" url="https://pl.wikipedia.org/wiki?curid=1215" title="Didiusz Julianus">
Didiusz Julianus

Marcus Didius Severus Iulianus (ur. 30 stycznia 133 w Mediolanie, zm. 1 czerwca 193 w Rzymie) – cesarz rzymski w roku 193.
Życiorys.
Didiusz Julianus urodził się w rodzinie ekwickiej, która wzbogaciła się na handlu ale nie poszedł w ślady swych przodków i wybrał karierę urzędniczą i wojskową. Był prawdopodobnie galijskiego pochodzenia, jego zromanizowaną rodzinę łączyło też pokrewieństwo z matką cesarza Marka Aureliusza w której domu się wychowywał. Matka Didiusza do swych krewnych zaliczała także Salwiusza Juliana, słynnego prawnika z czasów cesarza Hadriana. Żoną Didiusza Julianusa była Manlia Skantylla, z którą miał córkę Didię Klarę.
Didiusz dzięki poparciu matki Marka Aureliusza i jego samego, zawdzięczał pierwsze godności, urzędy oraz miejsce w senacie. Najpierw sprawował pewne funkcje u boku namiestników Afryki i Grecji. Później dowodził XXII legionem nad Renem i pokonał tam germański lud Chattów. Następnie przez kilka lat zarządzał prowincją Gallią Belgicą, gdzie odparł najazd germańskich Chauków. Dzięki tym sukcesom został w roku 175 konsulem. Był namiestnikiem Dalmacji, gdzie pokonał plemiona górskie oraz Germanii Dolnej. Za rządów cesarza Kommodusa objął stanowisko prefekta funduszów alimentacyjnych w Rzymie – w tym czasie oskarżono go o udział w spisku przeciwko cesarzowi, który przychylnie potraktował Didiusza i uznał go za niewinnego, skazując na śmierć żołnierza floty rzymskiej, który był oskarżycielem. W związku z tym Didiusz osiadł na krótki czas w Mediolanie, by potem zostać namiestnikiem Pontu i Bitynii w Azji Mniejszej, a następnie Afryki.
Pod koniec 192 zginął cesarz Kommodus, a w marcu 193 pretorianie zabili jego następcę Pertynaksa. Według historyka Kasjusza Diona, Didiusz dowiedział się o tym na uczcie. Podpity senator postanowił sam sięgnąć po cesarską purpurę. Udał się w tym celu do koszar pretorianów, licząc na ich poparcie w zamian za obietnicę wysokiego stipendium. W koszarach przelicytował prefekta Rzymu Flawiusza Sulpicjana, oferując każdemu żołnierzowi gwardii 25 tysięcy sestercji. Dnia 28 marca 193 złożono mu przysięgę na wierność, a on zobowiązał się przywrócić obalone posągi Kommodusa i nie prześladować Flawiusza Sulpicjana co też uczynił. Senat przyjął uchwałę i uznał Didiusza Julianusa za cesarza z woli wojska, senatu, ludu ale nowy cesarz nie cieszył się poparciem ludu i senatu.
Na początku kwietnia przeciwko Didiuszowi wystąpili i obwołali się cesarzami namiestnicy Panonii – Septymiusz Sewer, Brytanii – Klodiusz Albinus i Syrii – Pescenniusz Niger, mianowani przez swoich żołnierzy. Najenergiczniej postępował Septymiusz Sewer, którego legiony naddunajskie znajdowały się najbliżej Italii. Sewer ruszył na czele swoich legionów na Rzym; po drodze wiele miast otwierało przed nim swoje bramy, a mieszkańcy wiwatowali na jego cześć z gałązkami wawrzynu w dłoniach.
Cesarz Didiusz Julianus ogłosił Sewera wrogiem publicznym, wysłał oficera-zabójcę z zadaniem zabicia rywala, stosował magię i wydał rozkaz fortyfikowania Rzymu. Pretorianie przeszli jednak na stronę Sewera, kiedy ten obiecał, że nie spotka ich nic złego, jeśli wydadzą zabójców cesarza Pertynaksa. Septymiusz Sewer zdobył Rzym, a Didiusz Julianus został zamordowany przez pretorianów w pałacu 1 czerwca 193. Kasjusz Dion podaje, że Didiusz umierając rzekł: „I co ja zrobiłem tak strasznego?”.

</doc>
<doc id="1216" url="https://pl.wikipedia.org/wiki?curid=1216" title="DVD-ROM">
DVD-ROM



</doc>
<doc id="1217" url="https://pl.wikipedia.org/wiki?curid=1217" title="Dieta">
Dieta

Dieta (z "diaita" – „styl życia”) – sposób odżywiania. Potocznie używane nieprawidłowo, w stosunku do diet odchudzających.
Termin dieta, stosowany w nauce o żywieniu człowieka ma różne znaczenia. Ogólnie wyróżnia się 4 rodzaje diet:
Wyróżnia się również dietę modyfikowaną lub inaczej dietę podstawową modyfikowaną. Jest to dieta, która zawiera wszystkie składniki odżywcze i energetyczna, ale zmieniona jest jej konsystencja na przykład: dieta papkowata, dieta płynna oraz dieta do żywienia przez zgłębnik lub przetokę.
Diety alternatywne.
Pewną popularnością cieszą się alternatywne diety niskowęglowodanowe, zalecające większe spożycie tłuszczów i białek. W Polsce jest to tzw. dieta Kwaśniewskiego (zwana też przez zwolenników "żywieniem optymalnym"), w innych krajach popularna jest podobna dieta Atkinsa. Diety te stoją jednak w ostrej sprzeczności z powszechnie akceptowanymi przez większość ośrodków naukowych zajmujących się kwestiami zdrowego odżywiania, zasadami prawidłowej diety. Np. Komitet Terapii Wydziału VI Nauk Medycznych Polskiej Akademii Nauk uważa, że dieta Kwaśniewskiego jest „wybitnie szkodliwa dla zdrowia”.
Rodzaj diety ma wpływ na rozwój próchnicy. Dieta bogata w węglowodany zwiększa ryzyko niekorzystnych reakcji chemicznych w obrębie płytki nazębnej, co zwiększa kariogenność. Najlepszymi pokarmami minimalizującymi ryzyko próchnicy są pokarmy twarde (sery, orzechy, warzywa), oraz nie zawierające sacharozy - zamiast tego lepsze są zastępcze słodziki. Wbrew jednak temu, dowiedziono, że rodzynki (wyjątkowo bogate w węglowodany), mogą hamować rozwój próchnicy. Niewykluczone że w odniesieniu do innych owoców suszonych zachodzi podobna sytuacja.
Jedną z popularnych diet jest dieta wegańska, ściśle związana z ogółem diet wegetariańskich, zakładająca odrzucenie wszelkich produktów pochodzenia zwierzęcego. Niskotłuszczowa dieta wegańska bardzo korzystnie wpływa na kontrolę stężenia glukozy we krwi, oraz na cały układ krwionośny (m.in. znaczny spadek "złego" cholesterolu LDL) osób z cukrzycą. Jest skuteczniejsza niż diety zwykle polecane dla takich osób. Zostało to wielokrotnie potwierdzone badaniami klinicznymi.
Istotną czynnością dla każdej diety jest jej zbilansowanie, zatem dieta powinna zawierać wszystkie składniki odżywcze niezbędne dla prawidłowego funkcjonowania organizmu. W przypadku diet eliminujących całe grupy składników odżywczych (np. nabiał w diecie paleolitycznej) istnieje wysokie ryzyko niedoborów niezbędnych składników odżywczych. Z tego powodu modne diety sezonowe zwykle nie należą do zbilansowanych, a ich długie stosowanie może prowadzić do patologicznych niedoborów, a nawet chorób (np. anemia, osteomalacja, szkorbut).

</doc>
<doc id="1218" url="https://pl.wikipedia.org/wiki?curid=1218" title="DivX">
DivX

DivX – stratna metoda kompresji obrazu filmowego, w nowszych wersjach zgodna z MPEG-4 część 2, pozwalającą zapisać na zwykłej płycie kompaktowej filmy o długości ok. 90 min i jakości niewiele ustępującej DVD-Video. Wykorzystywana także do przesyłania filmów przez Internet.
Do odtwarzania wymagany jest układ komputerowy posiadający odpowiednio wydajny procesor do dekodowania programowego (np. komputer osobisty lub konsola) lub dekoder sprzętowy (np. w niektórych odtwarzaczach DVD).
Pierwotnie pod nazwą "DivX ;-)" występowała nielegalnie udostępniona, zmodyfikowana wersja kodeka MPEG 4 autorstwa Microsoftu. Dokonał tego francuski haker Jérôme Rota (ur. 1973 w Montpellier). Warto jednak zauważyć, że kodek ten, pomimo sugerującej to nazwy, nie jest zgodny ze standardem MPEG-4 (tak samo DivX 3) – Microsoft nazwał go tak, ponieważ myślał, że zostanie on właśnie wybrany jako ten standard. Ponieważ tak się nie stało, kolejne wersje tego kodeka nosiły już nazwę Windows Media Video. Autorzy DivX-a postanowili jednak stworzyć własną implementację kodeka MPEG-4. W ten sposób powstał Project Mayo, z którego następnie wykształcił się obecny, komercyjny DivX oraz otwarty XviD. Wersje DivX od 4 do 6.x są zgodne ze standardem MPEG-4 ASP. Wersja 7 jest zgodna ze standardem MPEG-4 AVC.

</doc>
<doc id="1219" url="https://pl.wikipedia.org/wiki?curid=1219" title="Druzus Młodszy">
Druzus Młodszy

Druzus Młodszy ("Tiberius Claudius Drusus Castor"; "Drusus Iulius Caesar") (ur. 13 p.n.e. – zm. 14 września 23 n.e.) – syn cesarza rzymskiego Tyberiusza i Wipsanii Agrypiny. 
Sprawował urząd konsula w 15 i 21 r. Od 22 roku posiadał władzę trybuńską. Został otruty przez swoją żonę Liwillę w wyniku intrygi prefekta pretorianów Lucjusza Sejana. Pochowano go w Mauzoleum Augusta.
Wywód przodków:
Tablica potomków:

</doc>
<doc id="1220" url="https://pl.wikipedia.org/wiki?curid=1220" title="Działo samobieżne">
Działo samobieżne

Działo samobieżne – działo umieszczone na podwoziu wyposażonym w napęd (podwoziu czołgu lub innego pojazdu mechanicznego), w odróżnieniu od działa holowanego. Pierwszym gąsienicowym działem samobieżnym była powstała w 1917 angielska konstrukcja o nazwie Gun Carrier Mark I.
Ze względu na rodzaj podwozia działa samobieżne zazwyczaj dzieli się na gąsienicowe, półgąsienicowe (w przedniej części pojazdu są zainstalowane koła, w tylnej są zainstalowane gąsienice) i kołowe. Ze względu na stopień opancerzenia zazwyczaj dzieli się na odkryte (uzbrojenie nie jest osłonięte pancerzem, półodkryte (uzbrojenie jest osłonięte jedynie pancerzem bocznym) i zakryte (uzbrojenie jest całkowicie osłonięte pancerzem).
Historia.
Wraz z wprowadzeniem do uzbrojenia czołgów i wyposażeniem piechoty w transportery opancerzone pojawiła się konieczność dostosowania artylerii do zwiększonych szybkości przemieszczania się oraz możliwości pokonywania trudnego terenu, tak aby artyleria mogła wspierać mobilne wojsko. Najprostszą koncepcją było osadzenie typowego wyposażenia artyleryjskiego na podwoziu, najczęściej gąsienicowym lub kołowym, czasami półgąsienicowym. Opancerzenie chroniło przed odłamkami pocisków artyleryjskich, bomb lotniczych, jak też ostrzałem ręcznej broni piechoty.
Głównym uzbrojeniem działa samobieżnego mogła być zarówno armata, jak i haubica, czasami nawet moździerz. W takiej roli działo samobieżne podążało za jednostkami czołowymi, wspierając je w razie potrzeby ogniem artyleryjskim. Znaczna część dział samobieżnych nie posiadała obrotowej wieży i zmiana kierunku prowadzenia ognia wymagała przestawiania całego działa.
Początkowo działa samobieżne występowały głównie jako samobieżne działa polowe, wspierając własne jednostki ogniem artyleryjskim z pewnej odległości, czasami znacznej, za pierwszą linią. Z tej koncepcji wyewoluowało też działo pancerne, silnie opancerzona odmiana działa samobieżnego przeznaczona do bezpośredniego wsparcia jednostek na pierwszej linii, np. do towarzyszenia piechocie w trakcie szturmu. Znakomicie radziło sobie z małymi celami punktowymi, takimi jak silnie okopane karabiny maszynowe, działa przeciwnika czy schrony bojowe, które niszczyło strzałami bezpośrednimi z małej odległości. Inną specjalistyczną odmianą działa samobieżnego był niszczyciel czołgów (działo przeciwpancerne), uzbrojony w działo przeciwpancerne. Różnica między działem samobieżnym, działem pancernym a niszczycielem czołgów bywa często umowna, gdyż decydują tu nie cechy konstrukcyjne, a sposób użycia.
Ważną odmianą działa samobieżnego jest samobieżne działo przeciwlotnicze, przeznaczone do osłony przeciwlotniczej własnych jednostek. Ze względu na specyfikę obrony przeciwlotniczej miało obrotowo osadzone działka.

</doc>
<doc id="1221" url="https://pl.wikipedia.org/wiki?curid=1221" title="Działo">
Działo

Działo – broń palna kalibru co najmniej 20 mm. Ogólna nazwa artyleryjskiej broni palnej bez względu na kaliber.
Wczesne działa miały lufy oprawione najczęściej w łoża klockowe. Już w XVI wieku zaczęto stosować łoże dwuścienne, które z modyfikacjami przetrwało do XIX wieku. 
Współczesne działo dzieli się ze względu na:

</doc>
<doc id="1222" url="https://pl.wikipedia.org/wiki?curid=1222" title="Domicja Longina">
Domicja Longina

Domicja Longina, "Domitia Longina" (ur. ok. 53, zm. po 126) – żona cesarza rzymskiego Domicjana. Jej ojcem był senator Gnejusz Domicjusz Korbulon, a matką prawdopodobnie Kasja Longina, pochodząca ze starej rzymskiej "nobilitas".
Wydana w bardzo młodym wieku za senatora Lucjusza Eliusza Lamię (przyszłego konsula), w roku 70 nawiązała romans z 19-letnim Domicjanem, młodszym synem cesarza Wespazjana, który poślubił ją w tym samym roku. W 73 roku urodził się ich syn, zmarły w dzieciństwie.
Gdy w 81 roku Domicjan został cesarzem, Domicja otrzymała tytuł augusty. W roku 83 wdała się w burzliwy romans z aktorem Parysem, wskutek czego cesarz wygnał ją ze stolicy. Wydaje się jednak, że wobec silnego uczucia nie zniósł długiej rozłąki i wkrótce sprowadził ją z powrotem do Rzymu, przywracając wszystkie przywileje należne jej godności.
W 96 roku prawdopodobnie uczestniczyła (lub była go świadoma) w spisku przeciwko małżonkowi, którego przeżyła o 30 lat, tytułowana jednak do końca "Domitia Domitiani" – „Domicją, żoną Domicjana”.
W zbiorach warszawskiego Muzeum Narodowego znajduje się wykonana w latach 82-92 n.e. wyrazista rzeźba portretowa cesarzowej (nr inw. 142717MNW), pochodząca z gołuchowskiej kolekcji Działyńskich i uważana za najlepszy portret rzymski w zbiorach polskich. 

</doc>
<doc id="1223" url="https://pl.wikipedia.org/wiki?curid=1223" title="Deka">
Deka

Deka (da) (z gr. "δέκα" [deka] oznaczającego "dziesięć") – przedrostek jednostki miary oznaczający mnożnik 10 = 101. Przed wprowadzeniem w Polsce układu SI w 1966 roku funkcjonował skrót "dk". Przedrostek ten (podobnie jak decy) jest stosowany dość rzadko w porównaniu z niektórymi innymi . Przykładowo, używany jest wraz z niutonem jako daN do oznaczania ciężaru z przyczyn praktycznych, bowiem 1 daN odpowiada w przybliżeniu 1 kG (kilogram-siła).
Deka funkcjonuje też jako potoczny skrót jednostki masy dekagram (również w krytykowanym wariancie deko).

</doc>
<doc id="1224" url="https://pl.wikipedia.org/wiki?curid=1224" title="Decy">
Decy

Decy (d, do 1966 dc; – „dziesięć”) – przedrostek jednostki miary oznaczający mnożnik 0,1 = 10-1 (jedna dziesiąta).
Przedrostek "decy" (podobnie jak deka) jest stosowany dość rzadko w porównaniu z niektórymi innymi przedrostkami jednostek miary i ma zastosowanie typowo praktyczne.

</doc>
<doc id="1226" url="https://pl.wikipedia.org/wiki?curid=1226" title="Decylion">
Decylion

Decylion – liczba 1060, czyli jeden i sześćdziesiąt zer w zapisie dziesiętnym. W krajach byłego ZSRR i Stanach Zjednoczonych, decylion oznacza 1033.

</doc>
<doc id="1227" url="https://pl.wikipedia.org/wiki?curid=1227" title="DOS">
DOS

DOS (od ) – pierwszy przenośny (dyskowy) system operacyjny w mikrokomputerach lat osiemdziesiątych, zawierający między innymi rozszerzenia programowe procedur sprzętowych BIOS-u oraz interpreter poleceń. W systemie DOS zapożyczono i rozwinięto niektóre elementy z systemów klasy CP/M.
W komputerach osobistych DOS nie ma wbudowanych mechanizmów ochrony pamięci (nie istnieją mechanizmy ochrony pamięci w trybie rzeczywistym procesora x86, w którym pracuje DOS) – z tego względu nie jest systemem bezpiecznym dla danych i procesów wymuszanych sztucznie wielopotokowo lub sieciowo. W zamyśle był to jednowątkowy system operacyjny i nie przewidywano w nim uruchamiania więcej niż jednego procesu (programu) jednocześnie. Była jednak możliwość uruchamiana programów w tle, np. do obsługi urządzeń.
Programy DOSowe mogą być uruchamiane w systemie Windows, OS/2, Linux (poprzez program DOSBox lub DOSemu). Istnieją obecnie darmowe implementacje tego systemu, na przykład FreeDOS. Ponieważ od systemu Windows XP programy DOS-owe są uruchamiane na tak zwanej wirtualnej maszynie DOS-owej (VDM), która nie pozwala na bezpośredni dostęp programu do sprzętu i posiada jeszcze inne ograniczenia, to działają wyłącznie te, które takich odwołań nie wykonują i nie ingerują zbytnio w system. Do nich należą głównie programy użytkowe, przykładowo edytory tekstu, i bazy danych.
Ważniejsze systemy tej klasy:
Nazwę DOS nosiły też od lat sześćdziesiątych systemy niezwiązane technicznie z późniejszym DOS-em dla komputerów x86, na przykład:

</doc>
<doc id="1229" url="https://pl.wikipedia.org/wiki?curid=1229" title="D (ujednoznacznienie)">
D (ujednoznacznienie)



</doc>
<doc id="1230" url="https://pl.wikipedia.org/wiki?curid=1230" title="Demon">
Demon

Demon ( "daimon", "nadprzyrodzona potęga", "dola"; ) – istota występująca w wielu wierzeniach ludowych, mitologiach i religiach, która zajmuje pozycję pośrednią między bogami a ludźmi, między sferą ziemsko-ludzką, materialną a sferą boską, czysto duchową; istota o cechach na wpół ludzkich, na wpół boskich; najczęściej nieprzyjazny człowiekowi duch, związany pierwotnie z pojęciem nieczystości sakralnej.
Wierzenia.
W historii religii można zaobserwować, że często demonami stawały się zdegradowane bóstwa politeistyczne wyparte w toku rozwoju wierzeń z panteonu głównych bóstw. Często też podporządkowywano obcych bogów własnemu Bogu (w religiach monoteistycznych), degradując ich do poziomu demonów (dobrym przykładem takiego zjawiska jest „zdemonizowanie” Baala w Starym Testamencie).
W religii greckiej demon to początkowo nieosobowa moc nadprzyrodzona, którą z czasem zaczęto wyobrażać sobie w postaci różnych duchów podrzędnych bogom. Pierwotnie pojęcie to miało charakter ambiwalentny, stanowiło zarówno pozytywne jak i negatywne określenie nadludzkiej istoty – demony bywały groźne, ale i dobrotliwe (jako takie pełniły na przykład funkcję duchów opiekuńczych – w takim rozumieniu pisali o demonach m.in. Platon, Sokrates, Heraklit). Od czasów Ksenokratesa, wraz z rozwojem koncepcji dualizmu, demony zaczęto utożsamiać przede wszystkim ze złem, bowiem wszelkie uwikłanie w materię uważano za złe (więc i istoty powiązane z materią choćby częściowo).
Na kształtowanie się demonologii w judaizmie (a za judaizmem w chrześcijaństwie i islamie) wielki wpływ miały irańskie wierzenia: manicheizm, mazdaizm i zaratusztrianizm. Demony w tych religiach także zajmują pośrednią pozycję między ludźmi a Bogiem. Od czasów św. Augustyna uznano je za istoty jednoznacznie złe i zidentyfikowano z diabłami.
W wierzeniach słowiańskich najczęściej występujące typy demonów to: rusałki, południce, północnice, strzygi, topielice, latawce, płanetnicy, ubożęta i skrzaty oraz tzw. bobo. 
Według założeń spirytyzmu demon to określenie ducha trzeciego rzędu. 
Wyobrażenia.
Sposoby przedstawiania demonów odzwierciedlały lęki oraz przekonanie o niebezpieczeństwach mających grozić człowiekowi z ich strony, ale także nadzieje i sposoby obrony przed zagrożeniami (w przypadku demonów dobrotliwych). Jedno z najczęstszych wyobrażeń to postać drapieżnego zwierzęcia (otwarta paszcza z wielkimi zębami, ogromne oczy, ostre pazury), pojawiająca się w nocy w miejscach budzących grozę. Taki demon miał napadać jak dzikie zwierzę, przynosząc śmierć, zagrożenie, niszcząc materialne podstawy bytu. Czasem demony w takiej postaci utożsamiane są z groźnymi zjawiskami przyrody oraz niebezpiecznymi impulsami wypływającymi z wewnętrznej natury człowieka (głównie z agresją i popędem seksualnym, wykraczającymi poza normy kulturowe; przykładem może być kozioł-diabeł jako symbol nieokiełznanej seksualności).
Demony niejednokrotnie w ludzkich wyobrażeniach pełnią funkcję strażników, chroniących określone terytorium w imieniu jego „pana”. Takie demony często przedstawiano w postaci pół ludzkiej, pół zwierzęcej. Początkowo tak przedstawiano sobie cherubiny, strażników raju. Wiele wyobrażeń demonicznych odwołuje się do postaci, które ogólnie mają być człowiekowi życzliwe a szkodzić jedynie w słusznym gniewie. Demony wiążą się niejednokrotnie z postaciami zmarłych, niebezpiecznymi duchami przodków.
W różnych wierzeniach sposobami ochrony przed demonami bywają m.in. amulety, zaklęcia, rytuały czy ofiary błagalne.

</doc>
<doc id="1231" url="https://pl.wikipedia.org/wiki?curid=1231" title="Daleki Wschód">
Daleki Wschód

Daleki Wschód – nazwa stosowana na określenie obszaru wschodniej Azji, ciągnącego się wzdłuż wybrzeży Pacyfiku. Najczęściej do tego regionu zalicza się Japonię, Koreę Południową, Koreę Północną, Republikę Chińską (Tajwan) oraz wschodnie tereny Chińskiej Republiki Ludowej. Niekiedy włącza się również Mongolię, kraje Azji Południowo-Wschodniej położone na Archipelagu Malajskim i Półwyspie Indochińskim, wschodnie obszary Rosji oraz rzadko Tybet.
Daleki Wschód jest najludniejszym regionem świata: na obszarze ponad 5 mln km² zamieszkuje tu blisko 2,1 mld osób (2012).

</doc>
<doc id="1232" url="https://pl.wikipedia.org/wiki?curid=1232" title="Deb">
Deb

deb – format pakietu instalacyjnego używanego przez system operacyjny Debian GNU/Linux – jedną z najstarszych, rozwijanych dystrybucji Linuksa. Wszystkie pakiety w tym formacie posiadają rozszerzenie .deb. Jest to skrót od „Deborah” (inaczej: „Debora”), imienia byłej żony twórcy Debiana, Iana Murdocka.
Pakiet deb (i jego instalator dpkg) posiada zaawansowaną kontrolę powiązań i zależności pomiędzy poszczególnymi składnikami systemu – programami i używanymi przez nie bibliotekami. Dzięki temu instalując nowy program ma się pewność, że nie będzie miał miejsca konflikt z innymi zainstalowanymi programami. W przeciwnym wypadku instalowany program mógłby przerwać funkcjonowanie z powodu braku poszczególnych składników, które są wymagane do prawidłowego działania.
Pakiety deb, które znajdują się na dysku lub płycie CD-ROM, można zainstalować w systemie Debian GNU/Linux i pochodnych (Progeny, Ubuntu, Corel) za pomocą polecenia dpkg. Można je instalować również bezpośrednio z repozytoriów w Internecie za pomocą programu apt-get. 
Większość współczesnych dystrybucji zawiera narzędzia instalacyjne z graficznym interfejsem użytkownika, np. GDebi, Synaptic. W systemie Debian istnieje kilka wygodnych programów do zarządzania zainstalowanymi pakietami. Najczęściej używane z nich to aptitude, oraz starsze podobne narzędzie dselect.
Pakietów deb używają także aplikacje Cydia oraz Icy, działające na platformie iPhone.
Binarnie pakiet deb to archiwum ar z trzema składnikami (plikami) w kolejności:
Pliki codice_2 oraz codice_4 mogą być w archiwum bez kompresji – rzadko stosowany zabieg, ale przydatny dla danych słabo kompresowalnych (np. pliki graficzne jpg, mapy do gier).

</doc>
<doc id="1233" url="https://pl.wikipedia.org/wiki?curid=1233" title="Dom (ujednoznacznienie)">
Dom (ujednoznacznienie)



</doc>
<doc id="1236" url="https://pl.wikipedia.org/wiki?curid=1236" title="De revolutionibus orbium coelestium">
De revolutionibus orbium coelestium

De revolutionibus orbium coelestium () – dzieło polskiego astronoma Mikołaja Kopernika, które zawiera wykład heliocentrycznej i heliostatycznej budowy wszechświata. Na owe czasy stanowiło przewrót w nauce i ówczesnym światopoglądzie. Ukazało się drukiem w Norymberdze w 1543. Składa się z sześciu ksiąg.
W 1999 autograf "De revolutionibus orbium coelestium" został wpisany na listę UNESCO Pamięć Świata.
Historia powstania.
W 1514 rozpoczęło się spisywanie Księgi I "De revolutionibus orbium coelestium".
W 1533 roku poglądy Mikołaja Kopernika wyłożone w rękopisie jego dzieła "De Revolutionibus" zreferowano papieżowi Klemensowi VII.
Teolog norymberski, Andreas Osiander, usunął przedmowę Kopernika i dopisał własną niepodpisaną, z której wynikało, że jest to tylko hipoteza, dzięki której można skonstruować efektywne modele matematyczne opisujące ruch planet. Zmienił także tytuł z "De revolutionibus" na "De revolutionibus orbium coelestium".
W roku 1542 pierwsze dwa arkusze "De revolutionibus" wyszły spod prasy drukarskiej. Mikołaj Kopernik wysłał do Norymbergi napisaną przez siebie przedmowę dedykowaną papieżowi Pawłowi III. Rozdziały 13 i 14 Księgi I ukazały się drukiem w Wittenberdze pod postacią osobnej książki "De lateribus et angulis triangulorum..." ("O bokach i kątach trójkątów"), z przedmową Retyka, który od roku 1541 był w posiadaniu rękopisu dzieła "De revolutionibus orbium coelestium" ("O obrotach sfer niebieskich").
Dalsze dzieje rękopisu.
Po śmierci Kopernika rękopis otrzymał wieloletni przyjaciel astronoma, biskup warmiński Tiedemann Giese. Ten przekazał autograf dzieła jedynemu uczniowi Kopernika, astronomowi Retykowi. Ten przekazał w testamencie swojemu uczniowi Valentinowi Otto. Kolejnymi właścicielami byli astronom z Heidelbergu Jacob Christmann, Jan Ámos Komenský, gdański astronom Jan Heweliusz, następnie ślad się urywa, by w końcu w XIX wieku wylądować w zbiorach rodu Nostitz w Czechach.
Po II wojnie światowej majątek Nostitzów znacjonalizowano, a rękopis Kopernika w 1953 władze czeskie wypożyczyły do Polski z okazji obchodów 410. rocznicy śmierci astronoma. Autograf pozostał już w Polsce, a oficjalnie został podarowany przez władze czeskie polskiemu rządowi 25 lipca 1956. W zamian strona polska przekazała rękopiśmienną Biblię w języku czeskim z XV wieku.
25 września 1956 na Wawelu, podczas uroczystej sesji inauguracyjnej walnego zjazdu Stowarzyszenia Historyków Sztuki, Muzeum Narodowe w Warszawie przekazało rękopis Bibliotece Jagiellońskiej do Działu Rękopisów, gdzie znajduje się do dziś.

</doc>
<doc id="1237" url="https://pl.wikipedia.org/wiki?curid=1237" title="Dewiacja seksualna">
Dewiacja seksualna



</doc>
<doc id="1239" url="https://pl.wikipedia.org/wiki?curid=1239" title="Druk wklęsły">
Druk wklęsły

Druk wklęsły (druk wgłębny) – jeden z trzech podstawowych sposobów druku (obok druku płaskiego i druku wypukłego), stosowany zarówno w grafice warsztatowej, jak i poligrafii.
Druk wklęsły polega na tym, że miejsca drukujące są położone poniżej miejsc niedrukujących. Farba drukowa pokrywa najpierw całą formę drukową, po czym z miejsc niedrukujących jest zabierana raklem, a następnie farba pozostawiona w zagłębieniach jest przenoszona na podłoże drukowe.
Ogólnie rzecz biorąc, w technikach druku wklęsłego formy drukowe mają większą wytrzymałość w porównaniu z technikami z dwu pozostałych podstawowych sposobów druku, a co za tym idzie, możliwe jest drukowanie większych nakładów z jednej formy drukowej a często jest ono także szybsze.
Do druku wklęsłego zaliczane są następujące techniki graficzne

</doc>
<doc id="1240" url="https://pl.wikipedia.org/wiki?curid=1240" title="Druk płaski">
Druk płaski

Druk płaski – jedna z podstawowych technik druku, obok druku wklęsłego i wypukłego, stosowana w technikach graficznych i poligraficznych. Forma drukowa w druku płaskim charakteryzuje się tym, że jest równa, to znaczy miejsca drukujące i niedrukujące znajdują się na tym samym poziomie. Ogólnie techniki druku płaskiego dzieli się na dwa rodzaje:
W litografii (jest to odmiana grafiki warsztatowej, czyli odmiana artystycznej formy druku) formą drukową jest kamień litograficzny. Technika ta wykorzystuje zjawisko fizykochemiczne przyciągania lub odpychania cząsteczek wody. Na formie drukowej wykonuje się rysunek tłustym tuszem (lub kredką), a następnie zwilża wodą, która zatrzymuje się na miejscach niezatłuszczonych (niedrukujących). W czasie druku farba przylega tylko do miejsc zatłuszczonych i tylko te miejsca odbijają się na papierze. Wynalazcą litografii jest Alojz Senefelder.
We współczesnym przemyśle poligraficznym zasady podobne do litografii wykorzystywane są w technice offsetowej, która wykorzystuje właściwości oleofilowe (a co za tym idzie, hydrofobowe) miejsc z obrazem drukowym oraz właściwości dokładnie odwrotne (oleofobowe i hydrofilowe) miejsc pozbawionych tego obrazu.
Przemysłową techniką druku płaskiego o ograniczonym zastosowaniu jest światłodruk. Matrycę w światłodruku stanowi płyta ze szkła lub metalu, powleczona warstwą kopiową (najczęściej żelatyny uczulonej dichromianem amonu lub potasu) z wytworzonymi w niej, za pomocą procesów fotochemicznych, miejscami drukującymi i niedrukującymi. Charakterystyczną cechą światłodruku jest brak rastra.

</doc>
<doc id="1241" url="https://pl.wikipedia.org/wiki?curid=1241" title="Druk wypukły">
Druk wypukły

Druk wypukły, wypukłodruk – jedna z podstawowych, oprócz druku wklęsłego i płaskiego, technik graficznych, w której odbitka powstaje poprzez odbicie farby nałożonej na częściach wypukłych formy drukowej. Jest to najstarsza technika graficzna.
Obecnie z technik druku wypukłego przemysłowo stosuje się przede wszystkim fleksografię oraz, szczególnie do zastosowań specjalnych, typografię. Zespoły fleksodrukowe są także stosowane do lakierowania. Typografia była powszechnie stosowaną techniką druku przed upowszechnieniem się urządzeń do naświetlania, które umożliwiły łatwe stosowanie druku offsetowego (druk płaski), który pozwala na uzyskanie lepszej jakości odbitek i jest bardziej ekonomiczny z innych względów.
Materiały w druku wypukłym.
W tradycyjnych technikach graficznych formę drukową (matrycę) przygotowuje się w drewnie (drzeworyt), linoleum (linoryt), metalu (metaloryt) czy płycie gipsowej (gipsoryt). Jednak zastosowanie znajdują też płyty paździerzowe, tektura, rozmaite tworzywa sztuczne, np. szkło akrylowe (pleksi). W poszukiwaniu nowych efektów stosuje się różne metody opracowania matrycy dla wypukłodruku – zamiast wycinać, wypala się lub wytapia płaszczyzny i linie (jak np. w technice pirografii).
W poligraficznych technikach przemysłowych, formy przygotowywane są z metali i tworzyw sztucznych.

</doc>
<doc id="1242" url="https://pl.wikipedia.org/wiki?curid=1242" title="Drzeworyt">
Drzeworyt

Drzeworyt – technika graficzna należąca do druku wypukłego.
Do wykonania drzeworytu wykorzystuje się deskę, na którą nanosi się rysunek, a następnie przy pomocy specjalnych narzędzi wycina się tło, które na odbitce będzie białe. Pozostawione wypukłe miejsca będą drukowały. Klocek pokrywa się farbą drukarską i odbija na papierze.
Rodzaje drzeworytu.
Drzeworyt dzieli się na kilka rodzajów ze względu na sposób przygotowania deski oraz narzędzia wykorzystywane do wycinania:
Inne rodzaje drzeworytu:
Historia drzeworytu.
Drzeworyt należy do najstarszych technik graficznych. Po raz pierwszy zastosowano go w VI w. w Chinach. Służył do powielania znaków pisma. Innym krajem Dalekiego Wschodu, w którym wykorzystywano drzeworyt, była Japonia. Miało to miejsce w VIII w. W Europie technika cięcia w drewnie pojawiła się dopiero w XIV w. Możliwe, że czegoś podobnego do drzeworytu używano do odbijania ilustracji już w I w. p.n.e w Rzymie. Najstarsze udokumentowane europejski prace pochodzą z około 1400 roku. Znajdują się w muzeum Albertiny w Wiedniu.
Chiny.
W Chinach prawdopodobnie najwcześniejszą techniką proto-druku był estampaż, polegający na wykonywaniu odbitek z kamiennych steli. Techniki drzeworytnicze do druku zastosowali na szeroką skalę buddyści, potrzebujący wielu odbitek do celów misyjnych. Produkowali oni odbitki ilustrowanych sutr – najwcześniejszą zachowaną kopią jest zwój z zaklęciami z pierwszej połowy VIII w., przechowywany w Korei, w klasztorze Pulguksa w Gyeongju. Z tej samej sutry w 764 roku w Japonii wykonano ok. miliona odbitek.
Pierwszą zachowaną w całości drukowaną książką jest wydanie "Sutry Diamentowej" z 868 roku. Jest to książka blokowa – w tym samym klocku wycięte są zarówno tekst, jak i ilustracje. W taki sposób drukowano książki w Chinach przed wynalezieniem czcionki drukarskiej (w Chinach eksperymentowano z czcionką ruchomą w XI w., początkowo ceramiczną, potem także drewnianą, ale nie znalazła szerszego zastosowania – natomiast zachowały się takie czcionki w Turfanie, gdzie wykorzystywano je do pisma ujgurskiego, a dokąd technologia ta zawędrowała szlakiem jedwabnym). W X w. druk drzeworytniczy miał charakter masowy – niektórych druków z tego okresu zachowało się do dziś ponad 100 tys. kopii (pierwotny nakład musiał liczyć miliony egzemplarzy). W X w. zastąpiono druk na zwoju drukiem stronicowym i książką w formie kodeksu.
Na początku XII w. zastosowano w Chinach druk wielobarwny, w szczególności do banknotów, ale znana jest barwna kopia sutry z XIV w. Z pierwszej połowy XII w. zachował się najstarszy druk czterobarwny.
Japonia.
W okresie Kamakura, od XII w. do XIII w., wiele książek było wydawanych przez mnichów buddyjskich w klasztorach na terenie miasta Kioto i Kamakura. Główną techniką graficzną, jaką się posługiwali był drzeworyt. Masowa produkcja druków drzeworytniczych rozpoczęła się w okresie Edo (od XVII w. do XIX w.). Przyczyniła się do tego popularność prywatnych szkół nazywanych "terakoya". Dużym zainteresowaniem cieszyły się księgarnie, w których klienci mogli nie tylko kupić, ale i wypożyczać książki. Najliczniej sprzedawały się: poradniki podróżnicze, ogrodnicze, książki kucharskie (kibyōshi), krótkie nowele satyryczne (sharebon), opowiadania o życiu miejskim (kokkeibon), nowele humorystyczne (ninjōbon). Najpopularniejszymi książkami okresu Edo były: "Życie miłosne pewnego mężczyzny" ("Kōshoku ichidai otoko", 1682) Saikaku Ihara. "Nansō Satomi Hakkenden -" Bakin Kyokutei. "Tōkaidōchū Hizakurige" - Ikku Jippensha. Książki te wielokrotnie przedrukowywano od XVII w. do XIX w. Popularnym nurtem w japońskiej sztuce drzeworytniczej był Ukiyo-e. Dotyczył on świeckich tematów. Drzeworyty w tym stylu cieszyły się popularnością i tworzono je masowo. Do głównych motywów przewodnich należą: aktorzy teatralni Kabuki, zawodnicy sumo, atrakcyjne kobiety, pejzaże, opowieści historyczne itp. Najbardziej znani artyści Ukiyo-e to: Hokusai i Hiroshige Andō. W XVIII w. Harunobu Suzuki wynalazł technikę drzeworytu umożliwiającą druk wielokolorowy, zwany Nishiki-e. Ukiyo-e inspirował europejskie nurty japonizmu oraz impresjonizmu. Na początku XX-wieku narodził się kierunek zwany shin-hanga, który łączył w sobie tradycyjne techniki ukiyo-e z technikami malarstwa zachodniego. Międzynarodową popularność zyskały prace Hasuiego Kawase i Hiroshiego Yoshidy.
Europa.
W Europie drzeworyt zaczęto stosować w XIV wieku. Najstarszy datowany drzeworyt europejski pochodzi z 1424 roku i został odnaleziony w austriackim klasztorze Buxhein.
W 2. połowie XV wieku w drzeworycie pojawiło się cieniowanie przy pomocy szrafowania; wcześniej zaznaczano tylko kontury, bez uwzględnienia światła i cienia. Początkowo drzeworyty kolorowano ręcznie, od XVI w., kolor wprowadzono mechanicznie poprzez zastosowanie kilku matryc. Pod koniec XV i na początku XVI w. tą techniką tworzyli drzeworytnicy, tacy jak: Albrecht Dürer, Lucas Cranach Starszy, Albrecht Altdorfer, Hans Burgkmair. W technice tej wykonywane były ilustracje, kalendarze, karty do gry i inne druki o charakterze użytkowym. Z czasem drzeworyt ustąpił miedziorytowi, który pozwala na lepsze ukazanie szczegółów.
Drzeworyt, stosowany do końca XVIII wieku, to tzw. drzeworyt wzdłużny. Z wynalezieniem przez Thomasa Bewicka około 1790 roku drzeworytu sztorcowego technika drzeworytnicza odrodziła się. Drzeworyt sztorcowy pozwolił bowiem rytować we wszystkich kierunkach (wzdłużny, ze względu na budowę deski, posiadał w tym względzie pewne ograniczenia) i uzyskać bardziej malarskie efekty. Drzeworyt poprzeczny jest także bardziej precyzyjny, gdyż umożliwia osiągnięcie cieńszej kreski. W XIX wieku był powszechnie stosowany jako technika ilustracyjna dla prasy, ponieważ można go drukować razem z tekstem z jednego składu, co dawało mu przewagę nad innymi technikami (w Polsce m.in. „Tygodnik Illustrowany”, „Kłosy”, „Wędrowiec”, „Mucha”), a także jako drzeworyt reprodukcyjny, odtwarzający dzieła malarskie.
Na przełomie XIX i XX wieku drzeworyt ustąpił miejsca innym technikom, ale nadal był wykorzystywany (i jest także dziś) przez artystów, np. Emila Nolde, Paula Gauguina, Edvarda Muncha, Pawła Stellera, Władysława Skoczylasa.

</doc>
<doc id="1243" url="https://pl.wikipedia.org/wiki?curid=1243" title="Dłuto">
Dłuto

Dłuto – narzędzie ręczne wykonane zwykle ze stali narzędziowej lub niestopowej używane do obróbki drewna przez snycerzy, rzeźbiarzy, stolarzy i drzeworytników. Odpowiedniej konstrukcji dłuta, zwane przecinakami, używane są również do obróbki kamienia przez kamieniarzy i rzeźbiarzy, a także przy pracach budowlanych.
Dłuto do drewna składa się ze stalowego (hartowanego i odpuszczonego) ostrza zakończonego z jednej strony wylotem z krawędzią tnącą, a z drugiej kołnierzem ze sztyftem (lub piórem) służącym do osadzenia w drewnianym trzonku.
    Dłuto w gnieździe trzonka osadza się przez uderzanie trzonka pobijakiem.

</doc>
<doc id="1244" url="https://pl.wikipedia.org/wiki?curid=1244" title="Druk">
Druk

Druk ( ‘nacisk’) – wielokrotne odbicie obrazu z formy drukowej na podłoże drukowe (np. na papier drukowy). Potocznie nazywana "drukiem" jest również każda kopia, czyli odbitka drukowa.
Za druk uważa się również rozmaite techniki powielania tekstu i grafiki zarówno metodami tradycyjnymi, z użyciem maszyn drukarskich, jak i nowoczesnymi metodami komputerowymi z użyciem komputerowych urządzeń peryferyjnych, jak drukarki, plotery itp. – choć poprawnie tego rodzaju odbitki powinno nazywać się wydrukami.
Wprowadzenie do drukarń technik komputerowych i druku cyfrowego, sprawiły, że coraz częściej przez druk rozumie się również wydruk dokonywany na skalę przemysłową za pomocą przystosowanych do tego maszyn drukarskich.
Techniki druku.
Przemysłowe techniki druku.
Podział według normy ISO 12637-1:
Artystyczne techniki druku.
Ze względu na artystyczne techniki druku, czyli grafikę warsztatową druk można podzielić na
Inne podziały druku.
Druk można dzielić ze względu na różne jego aspekty.
Ze względu na sposób przenoszenia obrazu.
Podział ten jest stosowany w analogowych technikach poligraficznych

</doc>
<doc id="1246" url="https://pl.wikipedia.org/wiki?curid=1246" title="Dongting Hu">
Dongting Hu

Dongting Hu (chiń. 洞庭湖; pinyin "Dòngtíng Hú"; Wade-Giles "Tung-t’ing Hu") – jezioro na południowym wschodzie Chin w prowincji Hunan na Nizinie Cianghańskiej (część Niziny Środkowego i Dolnego Jangcy). Drugi co do wielkości zbiornik słodkowodny Chin, dawniej o powierzchni 3900 km² i głębokości do 31 m. Leży na wysokości 34,5 m n.p.m.
Dongting Hu jest naturalnym zbiornikiem retencyjnym, który zapobiega wylewaniu wpadających do niego rzek, w tym największej: Jangcy.
Jezioro w przeszłości znajdowało się w obrębie wielkiej krainy bagien zwanej Yunmong. Kiedyś jezioro było znacznie większe i było największym jeziorem słodkowodnym Chin. Stopniowo zaczęło się kurczyć w wyniku zasypywania osadami rzecznymi, a proces ten znacząco przyśpieszył od 1949 r. w wyniku wzrostu melioracji bagien Yunmong i ich osuszania pod pola uprawne – od tego czasu region jeziora nawiedzają powodzie. Największa w 1998, po której rząd Chin rozpoczął akcję "ziarno za wodę", polegającej na przenoszeniu upraw w inne rejony, dzięki tej akcji jezioro ponownie powiększyło się o 20%.
Jezioro kurczy się bardzo szybko. W 1949 miało powierzchnię 4350 km², a w 1976 już tylko 1840 km². We wrześniu 2009 roku miało 1338,57 km², w połowie października jego powierzchnia zmniejszyła się o około 40% do 537,84 km². Od 2001 roku powierzchnia zbiornika zmniejsza się o około 16 km² rocznie. W latach 70. przy powierzchni 2820 km² miało głębokość 31 m.

</doc>
<doc id="1247" url="https://pl.wikipedia.org/wiki?curid=1247" title="Diadumenian">
Diadumenian

Diadumenian, "Marcus Opellius Antoninus Diadumenianus" (ur. 14 września 208, zm. czerwiec 218) – syn rzymskiego cesarza Makryna, współrządzący z nim od maja do czerwca 218.
Jako zaledwie dziewięcioletni chłopiec obwołany został przez wojska cezarem w Zeugmie w maju 217. Senat zaakceptował tę decyzję i nadał mu tytuł patrycjusza oraz przywódcy młodzieży ("princeps iuventutis"). Ojciec dodał mu nazwisko "Antoninus" w nawiązaniu do wielkich cesarzy z dynastii Antoninów i zamordowanego Antonina Karakalli, który był ulubieńcem wojska oraz naśladował podobną praktykę Septymiusza Sewera wobec jego synów. W maju 218 Makrynus uczynił Diadumeniana współwładcą nadając mu tytuł augusta. Było to okazją do pozyskania lojalności żołnierzy, którzy otrzymali dary ("donativa") w wysokości 5000 drachm; zapewnienie jej było istotne wobec pojawienia się uzurpatora Heliogabala.
Po klęsce poniesionej przez Makrynusa pod Antiochią w bitwie ze zbuntowanymi zwolennikami Heliogabala, do której doszło 8 czerwca 218, Diadumenian został wysłany przez ojca w asyście Marka Aureliusza Epagatusa do króla Partów Artabanusa IV. Podczas ucieczki z Antiochii został pojmany przez centuriona Klaudiusza Polliona w Zeugmie przed przekroczeniem granicy i w czerwcu 218 poniósł śmierć.
W "Historia Augusta" Eliusz Lampridiusz poświęcił mu osobną biografię ("Diadumenus Antoninus"), choć o niskiej wartości jako źródło, gdyż wzbogaconą zmyślonymi dodatkami. Kasjusz Dion parokrotnie wspomina o nim tylko ubocznie w opisie rządów Makryna ("Historia rzymska" LXXIX, 17-40). 

</doc>
<doc id="1248" url="https://pl.wikipedia.org/wiki?curid=1248" title="Diocletian">
Diocletian



</doc>
<doc id="1249" url="https://pl.wikipedia.org/wiki?curid=1249" title="Domicjusz Aleksander">
Domicjusz Aleksander

Domicjusz Aleksander, "Lucius Domitius Alexander" (zm. 311) – rzymski uzurpator w Afryce w czasach IV tetrarchii. 
Był wysokiej rangi administratorem (propretor) Kartaginy. W opozycji do Maksencjusza żołnierze latem 308 roku ogłosili go cesarzem. Wstrzymanie przez niego dostaw zboża z prowincji afrykańskiej doprowadziło do groźnych rozruchów w samym Rzymie. W 311 wysłane przeciw niemu wojska Maksencjusza pokonały jego oddziały, a on poniósł śmierć.

</doc>
<doc id="1250" url="https://pl.wikipedia.org/wiki?curid=1250" title="Domitius Alexander">
Domitius Alexander



</doc>
<doc id="1251" url="https://pl.wikipedia.org/wiki?curid=1251" title="Kwas deoksyrybonukleinowy">
Kwas deoksyrybonukleinowy

Kwas deoksyrybonukleinowy, DNA (z ), "kwas dezoksyrybonukleinowy" – wielkocząsteczkowy organiczny związek chemiczny z grupy kwasów nukleinowych. U eukariontów zlokalizowany jest przede wszystkim w jądrach komórek, u prokariontów – bezpośrednio w cytoplazmie, natomiast u wirusów – w kapsydach. Pełni rolę nośnika informacji genetycznej organizmów żywych oraz wirusów.
Skład i budowa.
DNA jest liniowym, nierozgałęzionym biopolimerem, którego monomerami są deoksyrybonukleotydy. Ich cząsteczki zbudowane są z pięciowęglowego cukru deoksyrybozy, którego grupa hydroksylowa znajdująca się przy ostatnim atomie węgla (5′) jest zestryfikowana resztą fosforanową, a pierwszy atom węgla (1′) połączony jest wiązaniem "N"-glikozydowym z jedną z czterech zasad azotowych, dwóch purynowych – adeniną (Ade lub A) i guaniną (Gua lub G) – oraz dwóch pirymidynowych: cytozyną (Cyt lub C) i tyminą (Thy lub T). Zasady te łącznie z deoksyrybozą tworzą deoksynukleozydy, odpowiednio dA, dG, dC i T.
Powszechnie spotykaną modyfikacją DNA jest występowanie 5-metylocytozyny ("m5C") w wyniku metylacji cytozyny. W DNA niektórych wirusów, na przykład bakteriofagów PBS2, zamiast tyminy występuje uracyl ("Ura"), tworząc nukleozyd 2′-deoksyurydynę ("dU"). 2′-Deoksyurydyna powstaje też w wyniku deaminacji "Cyt" do "Ura".
W skład cząsteczki DNA zwykle wchodzą dwa łańcuchy (DNA dwuniciowy – dsDNA), które biegną antyrównolegle (to znaczy koniec 5′ jednej nici leży naprzeciw końca 3′ drugiej nici). Łańcuchy zwijają się wokół wspólnej osi i tworzą prawoskrętną (A-DNA lub B-DNA) lub rzadziej lewoskrętną (Z-DNA) podwójną helisę. Reszty cukrowe i fosforanowe, połączone ze sobą wiązaniem 5′-3′ fosfodiestrowym, znajdują się na zewnątrz helisy, natomiast zasady skierowane są do wnętrza i tworzą komplementarne pary zasad połączone według schematu:
Zasady połączone są wiązaniami wodorowymi, a strukturę DNA stabilizują dodatkowo pomiędzy sąsiednimi zasadami nukleinowymi.
Długość.
Po hipotetycznym całkowitym „rozpakowaniu” z chromosomów i połączeniu cząsteczek DNA w jedną nić, ludzkie DNA w przeciętnej komórce somatycznej miałoby około 2–2,4 m. Wynika to z rachunku: odległość pomiędzy parami zasad wynosi średnio 0,34 nm (0,34 m), liczba par zasad w jądrze komórki diploidalnej wynosi w przybliżeniu 6–7 mld par zasad (jest to podwojona liczba par zasad komórki haploidalnej wynosząca 3–3,5), przemnożenie tych dwóch wartości daje wynik około 2 m. Najdłuższa rzeczywista cząsteczka DNA, chromosom 1, która zawiera 2,49 par zasad, ma długość około 8 cm.
Upakowanie w komórce.
Z powodu znacznej długości cząsteczek DNA konieczne jest ich upakowanie – do tego celu służą białka histonowe (u eukariontów) lub białka histonopodobne (u prokariontów). U eukariontów możliwe jest bardzo ścisłe upakowanie DNA w postaci chromosomu metafazowego, który jest formą najbardziej skondensowaną. DNA występuje w niedzielącej się komórce eukariotycznej w postaci chromatyny, nazywanej niekiedy włóknem 30 nm.
Każda z nici DNA ma na jednym końcu (oznaczanym jako koniec 5′), przy ostatnim nukleotydzie trzy grupy fosforanowe przy węglu 5′ deoksyrybozy, a na drugim końcu (oznaczanym jako koniec 3′) ostatni nukleotyd posiada wolną grupę hydroksylową przy węglu 3′ deoksyrybozy. Ze względu na to, że helisa dwóch nici DNA jest spleciona w ten sposób, że jedna z nici zaczyna się od końca 5′, a druga od końca 3′, mówi się, że obie nici są względem siebie antyrównoległe.
Łańcuch nici DNA zawiera informację genetyczną:
Sekwencja aminokwasów kodowana jest w postaci trójek nukleotydowych odpowiadających odpowiednim aminokwasom oraz kodonom terminacyjnym, podczas biosyntezy białka.
Zgodnie z pracą z 2016 roku informacja genetyczna w DNA jest zapisana nie tylko za sprawą sekwencji nukleotydów, ale także poprzez ułożenie nici DNA w nukleosomach.
Rodzaje DNA.
DNA rozróżnia się pod względem:
Najważniejsze z nich przedstawiono w tabeli:
Historia poznania.
DNA zostało odkryte w roku 1869 przez Fryderyka Mieschera, lecz przez prawie 100 lat jego struktura pozostawała zagadką. Autorami modelu podwójnej helisy DNA są James Watson i Francis Crick, na podstawie zdjęć z rentgenowskich badań strukturalnych wykonanych przez Rosalind Franklin oraz Maurice’a Wilkinsa. Pracowali oni wtedy w Medical Reserch Council Unity w Cavendish Laboratory w Cambridge. Za odkrycie w roku 1953 struktury DNA Watson, Crick i Wilkins otrzymali w 1962 Nagrodę Nobla (Rosalind Franklin zmarła na raka w 1958).
W 1961 miało miejsce odkrycie zasad kodu genetycznego przez Holleya, Khoranę i Nirenberga, a w roku 1977 opracowanie metody sekwencjonowania DNA przez zespoły badawcze Waltera Gilberta i Fredericka Sangera.
Porównanie DNA za pomocą RFLP jest obecnie powszechnie stosowane w kryminalistyce. Po raz pierwszy profil DNA w kryminalistyce został wykorzystany w roku 1986 przez brytyjską policję i podejrzany został uniewinniony. Pierwszym skazanym na podstawie dowodu w postaci DNA był w roku 1987 brytyjski piekarz Colin Pitchfork.
Zobacz też.
Zagadnienia dotyczące budowy, struktury i funkcji DNA:
Zagadnienia genetyczne:
Eksperymenty:
Inne:

</doc>
<doc id="1252" url="https://pl.wikipedia.org/wiki?curid=1252" title="Deizm">
Deizm

Deizm – nurt religijno-filozoficzny, którego cechą wspólną jest przekonanie, że racjonalnie można uzasadnić istnienie jedynie boga bezosobowego, będącego konstruktorem świata rozumianego jako mechanizm oraz źródłem praw, według których ten mechanizm świata działa. Tak rozumiany bóg nie ingeruje w stworzony świat. Deizm nie jest zwartym systemem ani szkołą filozoficzną. Rozpowszechnił się głównie w Europie, a także w Ameryce Północnej.
Istnienie i natura boga.
Deiści twierdzą, iż o istnieniu stwórcy można wnioskować w sposób pośredni, fizykalno-teologiczny. Refleksja polega na odkrywaniu porządku świata w rozumieniu praw fizyki rządzących materią. Według deistów o istnieniu duchowej siły sprawczej świadczy racjonalny porządek świata materialnego. Bóg-Stwórca jest swego rodzaju konstruktorem przyrody, dla której ustanawia prawa i dalej już nie ingeruje w jej rozwój przyrodniczy, społeczny czy osobniczy.
Negacja objawienia.
Deiści nazywani niekiedy bywają agnostykami poznawczymi z uwagi na to, że wyznawali pogląd, iż bezpośrednie poznanie duchowej siły sprawczej nie jest dostępne dla człowieka. Immanuel Kant, który jest klasycznym przedstawicielem tego nurtu, zanegował w "Krytyce czystego rozumu" możliwość rozumowego wyjścia poza zjawiska fizyczne. W konsekwencji nie uznawał metafizyki za naukę. Dowodzenie istnienia Boga na drodze rozumowania przy pomocy pojęć metafizycznych było według niego nienaukowe. W miejsce metafizyki Kant upowszechniał wiedzę matematyczną i przyrodniczą.
Według D. Diderota, który inspirował się poglądami G. Bruno, deizm neguje całkowicie objawienie, inaczej niż teizm, który uznaje naturalne objawienie Boga w przyrodzie, nie zaś przez Pisma natchnione itp.
Również pojęcie Opatrzności Bożej nie mieści się w systemie deistycznym, gdyż zakłada on, że Stwórca, stworzywszy świat, pozostawił go samemu sobie. Z kolei inni twierdzą, że Bóg, znając wolę i modlitwy człowieka jeszcze niestworzonego, mógł dobrać cechy i determinizm świata, oraz aktywność Syna i Ducha Świętego już w momencie jego tworzenia.
Deizm a chrześcijaństwo.
Deizm wyrósł w epoce poreformacyjnej, kiedy spory między różnymi odłamami chrześcijaństwa dotyczyły m.in. osiągnięcia zbawienia i eschatologii. Deiści przyjmowali najczęściej, że zbawienie można zapewnić sobie przez prawe życie, zgodne z nakazami religii naturalnej. Niektórzy, należący do mniej radykalnej grupy, uznawali też w drugiej kolejności przydatność wychowawczą przykazań np. Dekalogu. Był to boczny nurt zwany "deizmem chrześcijańskim". Główny nurt odrzucał jednak objawioną moralność, co doprowadziło do wypracowania autonomicznej etyki racjonalistycznej. Deizm zanegował twierdzenia chrześcijańskiej wiary o tym, że natura ludzka jest zraniona przez grzech, zepsuta. Odrzucił doktrynę o grzechu pierworodnym.
Religia deistów zawierała więc wiarę w Boga bezosobowego, rozumianego jako przyczynę metafizyczną świata, oraz cnoty moralne i nieśmiertelność. Dogmatom przeciwstawiono wolne rozumowanie i psychologię. Religia taka była "wolna od duchowieństwa" i wszelkich elementów, które uznano za mitologiczne, magiczne i spekulatywno-teologiczne. Odrzucono Kościół jako taki i Pismo Święte jako tekst natchniony. Zamiast tego inspirowano badanie historyczności tekstów biblijnych i rozległe racjonalistyczne interpretacje jej poszczególnych części. Niektórzy, jak D. Hume, twierdzili, że chrześcijaństwo, zanim powstał kanon Nowego Testamentu i Kościół, było religią naturalną.
Krytyka z pozycji katolickich.
Podejście deistyczne do badań nad Pismem Świętym na potrzeby Kościoła katolickiego spotyka się ze zdecydowaną krytyką biblistów katolickich i Magisterium Kościoła. Według Benedykta XVI badania historyczno-krytyczne promowane przez środowiska deistyczne mają wartość „niezaprzeczalną”, jednak nie wystarczą, by właściwie (z punktu widzenia katolicyzmu) odczytać przesłanie Biblii. Inaczej Biblia staje się jedynie „tekstem z przeszłości”, egzegeza zamienia się w historię literatury, tracąc wymiar teologiczny. Postawa, która usuwa teologiczne podejście z badań biblijnych, tym samym przyjmuje hermeneutykę laicką, dla której „element Boski nie istnieje”. Gdy Biblia mówi o rzeczywistości duchowej, cudach i nadprzyrodzonych wydarzeniach, według takiej postawy interpretacyjnej trzeba je wyjaśnić w inny sposób i sprowadzić do elementu czysto ludzkiego. Przeciwstawianie badań historycznych refleksji teologicznej zamiast harmonizowania tych dwóch rodzajów interpretacji Biblii według Benedykta XVI ma destruktywne oddziaływanie na życie Kościoła:
Przedstawiciele deizmu.
Pewną formę deizmu reprezentowali w judaizmie saduceusze, którzy nie wierzyli w istnienie świata duchowego poza samym Bogiem (Dzieje Apostolskie 23:8) oraz w zmartwychwstanie (Mateusza 22:23), odrzucając prawdopodobnie tym samym wiarę w Sąd Ostateczny i życie pozagrobowe.
Elementów deizmu można także doszukiwać się w różnych szkołach filozoficznych starożytnej Grecji. Za najstarszą filozoficzną szkołę, która wyznawała deizm, trzeba uznać epikurejczyków, którzy uznawali, iż bogowie istnieją, lecz nie są zainteresowani losem świata ani człowieka i nie ingerują w dzieje świata. Według nich nie ma potrzeby bać się gniewu bogów ani oddawać im czci.
Jednak zasadniczy nurt deizmu powiązany jest z XVIII-wieczną Europą. Jednym z pierwszych teoretyków deizmu był irlandzki wolnomyśliciel John Toland (zm. 1722). Do nurtu tego zaliczyć można także: J. Locke’a, D. Hume’a, Voltaire’a, D. Diderota oraz M. Robespierre’a.
Wpływ deizmu można dostrzec także u takich myślicieli, jak: J.J. Rousseau, I. Kant, G. Lessing, B. Franklin, G. Washington, D.F. Strauss, F.Ch. Baur, jak również St. Staszic i Jan Śniadecki.
Charakter deistyczny ma Wielki Architekt Wszechświata, wiarę w którego deklarują członkowie anglosaskiej loży masońskiej. Masoneria była jedną z grup, które kształtowały oblicze Europy oświeceniowej.
Pod koniec swojego życia do grona deistów dołączył filozof Anthony Flew.
Zdeklarowanym deistą był Tadeusz Kościuszko.

</doc>
<doc id="1253" url="https://pl.wikipedia.org/wiki?curid=1253" title="Domitilla Młodsza">
Domitilla Młodsza

Flavia Domitilla, Domitylla Młodsza (ur. ok. 45, zm. ok. 66) była jedyną córką cesarza Wespazjana i Domitilli Starszej. Jej dwaj bracia: Tytus Flawiusz i Domicjan, zostali cesarzami. 
Jej mężem był Quintus Petillius Cerialis. Jej córka, również Flavia Domitilla, żona Flawiusza Klemensa, była chrześcijanką i została świętą.

</doc>
<doc id="1254" url="https://pl.wikipedia.org/wiki?curid=1254" title="Decimus Caelius Balbinus">
Decimus Caelius Balbinus



</doc>
<doc id="1255" url="https://pl.wikipedia.org/wiki?curid=1255" title="Diadumenianus">
Diadumenianus



</doc>
<doc id="1256" url="https://pl.wikipedia.org/wiki?curid=1256" title="Diokletian">
Diokletian



</doc>
<doc id="1257" url="https://pl.wikipedia.org/wiki?curid=1257" title="Diocles">
Diocles



</doc>
<doc id="1258" url="https://pl.wikipedia.org/wiki?curid=1258" title="Dekalog">
Dekalog

Dekalog ( "dekalogos", "dziesięć słów") inaczej Dziesięć przykazań (w tradycji żydowskiej Dziesięć Oświadczeń עשרת הדיברות, "Aseret ha-Dibrot") – zbiór podstawowych nakazów moralnych obowiązujących pierwotnie wyznawców judaizmu, a następnie przyjęty w zmienionej formie przez chrześcijan.
Historia.
Zgodnie z przekazem biblijnym tekst Dekalogu, zapisany w Księdze Wyjścia (Drugiej Księdze Mojżeszowej), słowo po słowie został podyktowany przez Boga Jahwe Mojżeszowi na górze Synaj (w Księdze Powtórzonego Prawa (Piątej Księdze Mojżeszowej) góra ta nazwana jest Horeb) w trakcie wędrówki Izraelitów z Egiptu do Kanaanu.
Na płaszczyźnie historycznej w Dekalogu można zaobserwować pewne treści pojawiające się również w 42 negatywnych oświadczeniach oraz kulcie egipskiej bogini Maat.
Według Biblii, treść Dekalogu i innych słów Boga wygłoszonych na górze została spisana przez Mojżesza (Wj 24,4), natomiast to Bóg – nie Mojżesz – wyrył przykazania na kamiennych tablicach (Wj 24,12 oraz Wj 32,16 oraz Wj 34,1).
Tekst Dekalogu musiał zostać wyryty na kamiennych tablicach dwukrotnie, gdyż pierwsze tablice z Dekalogiem Mojżesz rozbił w gniewie widząc, jak lud zaczął pod jego nieobecność czcić złotego cielca (Wj 32:19) – za drugim razem Mojżesz musiał już sam sporządzić dwie tablice. Zgodnie z przekazem biblijnym drugie tablice z Dekalogiem były przechowywane w Arce przymierza aż do czasu zburzenia pierwszej Świątyni Jerozolimskiej.
Treść.
Wyznawcy judaizmu, prawosławia i większości kościołów protestanckich oraz wschodnich przyjmują tekst Dekalogu z Księgi Wyjścia (Drugiej Księgi Mojżeszowej). Jednak zdaniem Kościoła katolickiego tekst z Księgi Wyjścia nie jest pierwotny, skoro tekst z Księgi Powtórzonego Prawa, także znajdujący się w Biblii, różni się w pewnym stopniu od tekstu Księgi Wyjścia (główne różnice dotyczą motywacji nakazu obchodzenia szabatu oraz wyeksponowania żony w zakazie pożądania). Mimo to w Katechizmie Kościoła Katolickiego cytowana i omówiona jest wersja biblijna, nie skrócona.
Tekst biblijny i sposób podziału.
Tekst Dekalogu został zachowany w Biblii w dwóch, nieznacznie różniących się wersjach:
Zasadniczy podział przykazań to podział na przykazania określające stosunek ludzi do Boga oraz na przykazania regulujące zasady życia we wspólnocie.
Sposób podziału biblijnego tekstu na konkretne przykazania zależy od przyjętej tradycji. Zasadniczo wyróżnia się ich cztery i większość wyznań przyjmuje jedną z nich:
"a" – starożytny podział żydowski uznawany jest za najstarszy, zawarty jest w stosowanej przez pierwszy Kościół Septuagincie, był stosowany już w czasach Chrystusa; używali go już w I wieku m.in. Józef Flawiusz i Filon z Aleksandrii. Charakteryzuje się rozdzieleniem przykazania dotyczącego posiadania innych bogów od przykazania dotyczącego kultu przedmiotów. Choć obecnie porzucony przez judaizm na rzecz późniejszego podziału talmudycznego, jego tradycja pozostaje wciąż żywa w większości wyznań chrześcijańskich. Za obowiązujący uznają go Cerkiew prawosławna, Kościoły orientalne, protestanckie (z wyjątkiem luteran), anglikańskie i restoracjonistyczne.
"b" – podział talmudyczny jest powszechnie uznanym we współczesnym judaizmie; jego tradycja sięga III wieku n.e.
"c" – podział augustyński, wywodzący się od św. Augustyna z Hippony, sięga tradycją V wieku n.e. Charakteryzuje się sposobem podziału, który eksponuje różnicę między pożądaniem cielesnym a pożądaniem dóbr drugiego człowieka oraz włączeniem przykazania dotyczącego zakazu kultu przedmiotów do przykazania dotyczącego zakazu posiadania innych bogów. Stosowany jest w Kościele katolickim i kościołach starokatolickich.
"d" – podział luterański, wywodzący się z piśmiennictwa Marcina Lutra, pochodzi z XVI wieku. Stanowi niewielką modyfikację podziału augustyńskiego. Jedyna różnica leży w sposobie podziału przykazania dziewiątego i dziesiątego, gdzie dziewiąte dotyczy pożądania domu drugiego człowieka, a dziesiąte obejmuje pozostałe rodzaje pożądania.
Ewangelicko-Augsburska wersja katechetyczna.
W Kościele ewangelicko-augsburskim wersja katechetyczna Dekalogu znajduje się w Małym Katechizmie Marcina Lutra. Każde przykazanie ma w Małym Katechizmie swoje objaśnienie.
Katolicka wersja katechetyczna.
W Kościele katolickim, oprócz opublikowanej i omówionej w Katechizmie Kościoła Katolickiego wersji biblijnej (KKK 2083-2534), najczęściej stosowaną jest jednak tzw. wersja katechetyczna Dekalogu, opublikowana m.in. w katechizmie kardynała Gasparriego oraz w katechizmie dla dzieci:
Dekalog w Księdze Mormona.
Księga Mosjasza 13,12-24:
Nauki dekalogu w Koranie.
Muzułmanie uznający Mojżesza jako proroka, przyjmują również na podstawie Koranu nauki pokrewne Dziesięciu Przykazaniom. Choć sam dekalog nie znajduje się w Koranie, to jednak każdemu przykazaniu można przyporządkować odpowiednią aję:
Interpretacja i wykorzystanie.
W historii przykazania były różnie rozumiane i różnie interpretowane. Na przykład przykazania dosłownie w języku hebrajskim brzmiące „nie morduj” przetłumaczono na „nie zabijaj”.
Dekalog zajmuje szczególne miejsce w nauce wielu chrześcijańskich kościołów i jest podstawą głoszonej przez nie moralności. Istnieje pogląd, że Dekalog jest podstawowym elementem Nowego Przymierza, jego wartość i znaczenie podkreślone zostały przez Jezusa Chrystusa w kazaniu na górze, które zawiera esencję jego nauki i jest rozwinięciem 10 przykazań, dotyczy życia i prawa Bożego. Niemniej jednak wiele wyznań chrześcijańskich uważa Dekalog za część Starego Przymierza i nie uważa, aby obowiązywały one chrześcijan. Często doceniana jest jednak praktyczna ich przydatność jako wskazówek moralnych.
Kościół katolicki.
Kościół katolicki wyraził pogląd, że uzupełnieniem Dekalogu jest tajemnica paschalna Jezusa Chrystusa (Por. Mt 5,17-19), a uświadomienie sobie jej treści jest powodowane wiarą w zmartwychwstanie Chrystusa. Stała się ona dostępna dla Kościoła poprzez Zesłanie Ducha Świętego (por. Dz 2) na modlących się Maryję i Apostołów w Jerozolimie podczas żydowskiego Święta Tygodni Szawuot – dorocznej uroczystości upamiętniającej przekazanie przez Boga Mojżeszowi Dekalogu na górze Synaj. Duch Święty jest Nowym Prawem „Nowego Przymierza, przymierza nie litery, lecz Ducha” (2 Kor 3,6; Por. Rz 2,29 oraz 7,6;), wypisanego nie na kamiennych tablicach, lecz „na żywych tablicach serc” (por. 2 Kor 3,2).
Kościół katolicki jest także zdania, że ludzie, którzy doświadczają Syna Bożego poprzez Ducha Świętego, otrzymują wyróżnienie, „by stali się dziećmi Bożymi” (J 1,12; por. Rz 8,14-15) i dzięki miłości powodującej oddanie swojego życia za przyjaciół (por. J 15,14; Mt 5,44), w sposób doskonalszy niż sprawiedliwość opisana w Starym Testamencie (por. Mt 5,20), realizują świętość Ludu Bożego, którą Bóg ukazał Izraelowi: „Świętymi bądźcie, bo Ja jestem święty!” (Kpł 19,2). Apostołowie po otrzymaniu mocy od Ducha Świętego (por. Dz 1,8; Łk 1,78n) doszli do doskonałej miłości Boga i innych ludzi, która jest wykończeniem Dekalogu (por. Mk 12,28-34; Łk 10,27n). Dziesięć Przykazań najlepiej wypełnia się poprzez ubóstwo ze względu na miłość do ludzi biednych: „Jednego ci brakuje: idź sprzedaj wszystko co masz i rozdaj ubogim...” (Mk 10,21 i paral.: Mt 19,16-22; Łk 18,18-23). „Błogosławieni ubodzy w duchu” (Mt 5,3; Łk 6,20).
Kościoły protestanckie.
W protestantyzmie prawo Boże jest obok Ewangelii, jedną z dwóch postaci Słowa Bożego, które są różne co do ról w procesie zbawienia.
Świadkowie Jehowy.
Świadkowie Jehowy uważają, że Prawo Mojżeszowe, w tym Dekalog, zostało zastąpione „prawem Chrystusowym”, które obejmuje wszystko, czego Jezus uczył swoich naśladowców. Jednak analiza Dziesięciu Przykazań może przynieść korzyści, bo ujawnia sposób myślenia Jehowy Boga i opiera się na zasadach, które zawsze będą aktualne.

</doc>
<doc id="1259" url="https://pl.wikipedia.org/wiki?curid=1259" title="Dupondius">
Dupondius

Dupondius – moneta rzymska wartości 2 asów, bita początkowo z brązu, później mosiężna.
Wprowadzona w czasach republiki po modyfikacji systemu monetarnego pod koniec III wieku p.n.e. i orientacyjnie oznaczana na rewersie symbolem II. W cesarstwie po reformie Augusta emitowana bez oznaczeń, o wadze normatywnej 13,64 g (½ uncji); dla odróżnienia od miedzianego asa bita z mosiądzu zwanego "orichalcum". Wskutek gwałtownie postępującej dewaluacji pieniądza emisji dupondiusów zaprzestano w drugiej połowie III wieku n.e.
W systemie miar rzymskich terminem tym określano również miarę długości równą 2 stopom ("pes").

</doc>
<doc id="1260" url="https://pl.wikipedia.org/wiki?curid=1260" title="Drachma">
Drachma



</doc>
<doc id="1261" url="https://pl.wikipedia.org/wiki?curid=1261" title="Denarius">
Denarius



</doc>
<doc id="1262" url="https://pl.wikipedia.org/wiki?curid=1262" title="Denar">
Denar

Denar (łac. "dēnārǐŭs", l.mn. "denarii", stgr. "δηνάριον") – dawna moneta srebrna, pierwszy raz wybita w Rzymie około 215–211 roku p.n.e. Nazwa pochodzi z łac. "deni" („po dziesięć”), gdyż wówczas miała wartość dziesięciu brązowych asów.
W okresie republiki.
Denar jako monetę obiegową zaczęto bić w okresie II wojny punickiej (218–201 p.n.e.). Pierwotnie jego normatywna waga wynosiła 4,55 g, tj. 1/72 rzymskiej libry, czyli funta. Pierwsze denary miały na awersie głowę bogini Romy i znak wartości X, tj. 10 asów, zaś na rewersie konne postacie Dioskurów (Kastora i Polluksa) oraz napis „ROMA”. Za bezpośredni poprzednik denara uważany jest kwadrygat z pokrewnymi wyobrażeniami symbolicznymi awersu i rewersu. Natomiast bigat był jedynie rodzajem republikańskiej monety denarowej z charakterystycznym przedstawieniem rewersowym.
Pod koniec II wieku p.n.e., w czasach Gajusza Grakcha (ok. 123 roku p.n.e.) zmieniono relacje denara, którego wartość wynosiła teraz 16 asów. W Rzymie republikańskim emitowano również techniczną odmianę tej monety, jaką był tzw. serratus, czyli denar nacinany na obrzeżu. Inną odmianą był denar suberatus, czyli jedynie pokrywany srebrem, a będący produktem fałszowania obiegowego pieniądza.
W okresie cesarstwa.
Za rządów Oktawiana Augusta (27 p.n.e.–14.n.e) denar ważył 3,89 g i odpowiadał 4 sestercjuszom, 8 dupondiusom (dwuasom), 16 asom i 64 kwadransom (ćwierćasom). Cesarz Neron (54–68 n.e.) w wyniku reformy z 64 r. obniżył jego wagę z 3,89 do 3,43 grama, czyli do 1/96 funta. Poważną dewaluację w latach 193–196 n.e. trzykrotnie przeprowadził cesarz Septymiusz Sewer, obniżając ilość srebra w monecie z 81% do 54%. Reformy te spowodowały, że denar odtąd stał się właściwie pieniądzem kredytowym; jedynie moneta złota miała charakter pełnowartościowy.
W III stuleciu pogłębiający się kryzys polityczny i ekonomiczny imperium odbił się mocno na systemie monetarnym, doprowadzając go do ruiny. W połowie III w. denar zawierał jedynie ok. 2–3% srebra, stając się właściwie monetą miedzianą. Emisji jego praktycznie zaniechali następcy cesarza Gordiana III (238–244). Na krótko przywrócono go za Aureliana (270–275), ale tylko jako drobną rozmienną monetę z brązu o wadze ok. 2,6 g, w której zawartość srebra wynosiła teoretycznie 2,5 proc.. Mimo to, jako pieniądz obrachunkowy ("denarius communis") stosowany był aż do reform Dioklecjana w końcu III stulecia. Nieudaną próbą odnowienia wartościowego denara było wprowadzenie wówczas srebrnego argenteusa.
Denar w kontekście biblijnym.
W Nowym Testamencie rzymski denar wymieniany jest niejednokrotnie jako dobrze znany miernik wartości. W Ewangelii św. Mateusza stanowi on równowartość dziennej pracy robotnika (Mt 20,2.9–10.13); tyle wynosił w czasach Jezusa coroczny podatek na rzecz cesarza, w literaturze umownie zwany „groszem czynszowym” (Mt 22,19–21 ; Mk 12,15 ; Łk 20,24), zaś danina na rzecz świątyni – 2 denary (Mt 17,24–27). Opiekę nad rannym w gospodzie zapewniano za 2 denary (Łk 10,35), ale flakon (bądź funt) wonnego olejku z nardu wart był aż trzysta (Mk 14,5 ; J 12,5). W denarach wyliczany jest też dług (Łk 7,41) oraz ilość chleba potrzebna dla ludzkiej gromady (Mk 6,37 ; J 6,7).
Pod koniec I wieku n.e. św. Jan prorokował o czasie po wielkiej wojnie, kiedy za jednego denara można będzie nabyć kwartę pszenicy lub 3 kwarty jęczmienia (Ap 6,6). Za życia Jezusa miał on w Palestynie wartość około 1 drachmy, co odpowiadało ¼ szekla.
W mennictwie i tradycji europejskiej.
W średniowieczu od X aż do ok. połowy XIII w. denarem nazywano niemal każdą monetą srebrną w wielu nowo powstałych chrześcijańskich państwach Europy, kierując się tradycją odziedziczoną po Rzymianach i nawiązując do prestiżu imperium rzymskiego. Do czasu zastąpienia go groszem denar był podstawową srebrną jednostką monetarną w całej Europie zachodniej i środkowej. Przy tak ogromnym rozprzestrzenieniu zyskał swoiste nazwy miejscowe: pens (penny) w Anglii, pfennig (fenig) w Niemczech, a we Francji denier (łac. "novus denarius").
Jako pierwszy bił go frankoński Pepin Mały (751–768), ale szerzej wprowadził na zachodzie Europy pod koniec VIII wieku Karol Wielki. Jego funt ("livra" czyli "libra") o wadze ok. 408 g, dzielił się na 20 solów (solidów), każdy po 12 denarów. W ten sposób zgodnie z karolińską stopą menniczą wybijano 240 denarów (wagi ok. 1,7 g i średnicy ok. 21 mm) z funta czystego srebra. Późniejsze srebrniki Karola (812–814 r.) nosiły na wzór rzymskich napis IMP[erator] AVG[ustus] i portret władcy w wieńcu laurowym. Waga ich potem obniżyła się do 1–1,5 g ; za Filipa I (początek XII w.) do monety dodawano trzecią część miedzi. Za rządów Ludwika Grubego (1108–1137) była to już tylko w połowie moneta srebrna. Bito ją jednak (jako niewielki miedziak) do czasu panowania Ludwika XVI, kiedy to emisji zaniechano ostatecznie. 
W Anglii, naśladując denar karoliński, dość wcześnie wprowadzono pens za rządów króla Offy (757–794). W XII–XIV w. pensy znane były też pod nazwą sterlingów (easterlingów) – stąd późniejsze określenie funt szterling. W wiekach średnich była to główna angielska moneta obiegowa i przetrwała ona (choć jako niski nominał) do czasów Jerzego I (1714–1727), ostatecznie zamieniona (1797) na miedziak. Do 1971 r. pens przez wieki oznaczano tradycyjnie symbolem „d” – od denarius. Na wzór angielskich bito penningi w krajach skandynawskich; zachowały się do końca 2001 roku tylko w walucie fińskiej (pennia = pens). W angielskim systemie monetarnym karolińska stopa mennicza przetrwała dłużej niż gdziekolwiek na świecie, bo aż do początku lat 70. XX wieku.
Niemieckie fenigi (ok. 1,2 g) wypuszczano od X w., też wedle stopy karolińskiej, jednakże waga i próba tej monety były niejednakowe w różnych częściach Niemiec. Ponadto z upływem czasu zawartość srebra w monecie wraz z jej wagą obniżała się (np. w końcu XV wieku – tylko ok. 0,3 g). W XVII wieku fenig bito już z miedzi. Nazwa przez stulecia przetrwała jednak w walucie niemieckiej nawet po wprowadzeniu srebrnej marki Rzeszy (1871), podzielnej na 100 fenigów, a także po wszystkich jej transformacjach w XX stuleciu – zarówno w okresie międzywojennym, jak i po II wojnie światowej.
W Hiszpanii ślad tej tradycyjnej nazwy zachował się dotąd w języku jako ogólna nazwa pieniędzy ("dinero") ; podobnie w Portugalii ("dinheiro") i we Włoszech ("danaro" albo "denaro"). W Europie XX wieku antyczna nazwa znalazła (jako dinar) odbicie w walucie Jugosławii (od 1920 r.) i ostatnio (1993) – Macedonii. 
Poza Europą.
Na arabskim Bliskim Wschodzie nazwę starożytnego denara przeniesiono na monetę złotą wagi 4,25 g, wartą początkowo 10 srebrnych dirhemów, a wprowadzoną za kalifa Abd el-Malika na wzór bizantyjskiego solida i zwaną dinarem. Miano to, mocno utrwalone w arabskiej tradycji, w czasach nowożytnych dało początek nazwom jednostek monetarnych wielu nowo powstałych muzułmańskich państw Bliskiego Wschodu i Maghrebu: Iraku (1932), Jordanii (1950), Tunezji (1958), Algierii (1964), Libii (1971), Jemenu, Bahrajnu, Kuwejtu, a także Iranu.
Denar na ziemiach polskich.
Na przełomie X/XI w. większość monet w obiegu miała przeciętną wagę ok. 1,3 g. 
Według badań Stanisława Suchodolskiego, monety wiązane dotąd z osobą Mieszka I (960–992) pochodziły od jego wnuka Mieszka II (1025–1034) i są o około 30 lat późniejsze (ok. 1013-1025) niż dotąd uważano. Mieszko II, syn Bolesława Chrobrego (992–1025) bił monetę jeszcze za życia ojca – jako następca tronu. Emisje te historycy łączyli przedtem z osobą jego dziadka noszącego to samo imię – Mieszka I. 
Pierwszymi zatem monetami polskimi były nie denary Mieszka I, lecz jego następcy – Bolesława Chrobrego (ok. 995). Przy średnicy 16–21 mm ważyły około 1,5 grama (według badań Suchodolskiego: monety ciężkie - waga średnia rzędu ok. 1,5-1,7 g, monety lżejsze - ok. 1 g). Denary mieszkowe przy średnicy 19-20 mm ważyły średnio ok. 1,5 g (1,38-1,629 g). Przeciętna średnia waga monet obu władców: ciężkie - ok. 1,46-1,75 g, lekkie - 0,745-1,15 g. Początkowo denary odpowiadały 1/240 grzywny. 
Denary Bolesława Śmiałego (1058–1079) wahały się wagą od ok. 0,4 do 1,1 g (według stopy menniczej – 0,9 g) przy bardzo zmiennej próbie srebra, mając też średnicę zmniejszoną do 11–15 mm. Podstawą ich był nie funt karoliński, lecz grzywna krakowska (ok. 210 g). Za Władysława Hermana (1079–1102) pojawiły się monety lekko wklęsłe, o kształcie miseczkowatym. Natomiast wypuszczane samowolnie przez wojewodę Sieciecha są pierwszą polską obiegową monetą prywatną kursującą na równi z książęcą. 
Mieszko Stary (1173–1202) wprowadził do obiegu nowe cienkie denary o większej średnicy, ale mniejszej wadze (0,35–0,85 g). Z czasem ich wagę oraz próbę obniżano tak, że na przełomie XIV/XV wieku ważyły zaledwie ok. 0,15–0,25 g. Służyło temu praktykowanie zapożyczonej z zachodu Europy tzw. renowacji monety ("renovatio monetae"), polegające na przymusowej okresowej wymianie całej krążącej masy monetarnej na nowy pieniądz. Przy stosowanym niekorzystnym kursie wymiennym (mniej otrzymanych monet z gorszego srebra za więcej zwróconych starych z lepszego kruszcu) oznaczało to ukrytą szybką dewaluację denara, który już wówczas nie był pełnowartościowy.
W XIII w. większość denarów bitych przez polskich książąt miała postać cienkiej, łamliwej blaszki – brakteata (na Śląsku upowszechniła się forma brakteata guziczkowego). Na Śląsku mającym większe zasoby srebra i lepsze możliwości rozwoju gospodarczego, ok. 1290 r. wprowadzono do obiegu kwartniki, tj. denary kwartnikowe ("denarii quartenses") o wysokiej zawartości kruszcu (do 0,940) i zwiększonej wadze (1,8–2 g). „Reforma kwartnikowa była samodzielnym dziełem władców śląskich i miała charakter pionierski”. Niską wartość miały denary emitowane w państwie krzyżackim (zwane też fenigami), gdzie z grzywny chełmińskiej (200 g) wybijano ich 720 o wadze ok. 0,28 g. 
W okresie po reformie groszowej (przeprowadzonej na ziemiach polskich przez Wacława II Przemyślidę, 1300–1305) znaczenie denara – szczególnie w większych transakcjach – zmalało na rzecz grosza, tym niemniej wciąż wybijano go w dużych ilościach. Mimo że na przełomie XIV–XV wieku waga denara wynosiła już tylko 1/10 tego, co we wczesnym średniowieczu, nigdy nie zmieniono jego nazwy. Jedynie na Pomorzu Zachodnim oraz na Śląsku stosowano określenia "Slavicales" lub "parvi" na określenie monet odbiegających swą wartością od innych współczesnych denarów będących w obiegu. Na Śląsku od XIV w. denar zwano halerzem.
Za Kazimierza Wielkiego (1333–1370) dodatkowo pojawiły się półdenary, czyli obole. Jagiellonowie emitowali denarki jako najmniejszą swoją monetę. Wiele ich wybijali zwłaszcza Władysław Jagiełło i Kazimierz Jagiellończyk.
Denary wypuszczano jeszcze przez cały wiek XVI, już jako najdrobniejszą monetę wartości zaledwie 1/10 – 1/18 grosza. Z czasów Zygmunta III Wazy ostatnie emisje pochodzą z 1624–1626 roku (na Litwie emitowano do 1582 r.). Jednak była to już faktycznie moneta miedziana o wadze 0,33 g i na jeden grosz przypadało 18 denarów. Za rządów Jana II Kazimierza, w latach 1652–1653 wybito w niewielkich ilościach denar o wadze 0,53 grama. Natomiast w obrachunkach pojęcie denara (zwanego u nas w późniejszych czasach pieniążkiem) zachowało się aż do początków XIX stulecia.

</doc>
<doc id="1263" url="https://pl.wikipedia.org/wiki?curid=1263" title="Dźinizm">
Dźinizm

Dźinizm (też dżinizm, sanskryt जैन धर्म – trl. "jaina dharma", trb. dźajna dharma) – nonteistyczny system filozoficzny i religijny, który powstał w Indiach około VI wieku p.n.e. w reakcji na silnie zrytualizowany braminizm.
Etymologia.
Wyraz sanskrycki जिन o transliteracji "dźina" i transkrypcji dźina posiada znaczenia "zwycięzca", "pogromca".
Historia.
Za twórcę tej religii uważany jest Parśwa żyjący w VIII w. p.n.e., znacząco zreformował ją jednak Wardhamana Mahawira, który stworzył zbiór zasad regulujących życie wyznawców dźinizmu. Są to:
Zasady te podkreślają wielki szacunek wyznawców dźinizmu dla wszystkich istot żywych. Dźiniści wierzą w możliwość wyrwania się z kręgu samsary – kołowrotu wcieleń, i osiągnięcia stanu wyzwolenia – mokszy. Droga do tego celu wiedzie poprzez "trzy klejnoty", czyli:
Liczbę wyznawców dźinizmu ocenia się na ok. 4,5–5 mln (z czego 97–98% w Indiach).
Wyznawcy dźinizmu wierzą, że świat nigdy nie powstał ani nigdy się nie skończy. Przechodzi on przez cykle wznoszące lub opadające, składające się z 4 wieków. Wyższy, urdhwaloka, to świat niebiański (loka), składający się z siedmiu niebios. Świat ziemski, madhjaloka, to kraina potępiona, obejmująca siedem piekieł, piętrzących się jedno na drugim niczym połączone ze sobą parasole.
Podział.
Współcześnie istnieją dwie główne gałęzie dźinizmu:
W XVIII w., w związku z wpływami hinduizmu na dźinizm, powstał nowy odłam odrzucający kult wizerunków i głoszący potrzebę powrotu do pierwotnego dźinizmu. Członkowie tego odłamu zwani byli Sthanakawasi (dhundhija, bawis), a jego założycielem był Lumpaka (Lankasza) żyjący w XVI w. n.e. Powstała także grupa, w której naśladuje się niektóre sposoby oddawania czci praktykowane przez hindusów – zwani są oni Murtipudźaka.
W XVIII w. wyodrębnił się także odłam Terapanthi ("Ścieżka Trzech") założony przez Bhikandźi, który starał się połączyć wszystkie dźinijskie nurty w jeden.
Teksty święte.
Zbiór religijnych ksiąg dźinizmu – "Agama" ("Siddhanta") składa się z ok. 45 tekstów dotyczących doktryny, rytuału, biografii świętych oraz różnorodnych dziedzin wiedzy świeckiej. Każda ze szkół posiada własny kanon pism i komentarzy.
W V wieku n.e. na synodzie w Walabhi pod przewodnictwem śwetambarów ustalono nowy (większość starych pism zaginęła), ostateczny kanon pism dźinijskich.Najważniejsze z nich to:
Tirthankara – ubóstwiani mistrzowie dźinijscy.
Według tradycji jest ich dwudziestu czterech: dwudziestu dwóch uważanych za mitycznych a Parśwa i Mahawira – za historycznych:

</doc>
<doc id="1264" url="https://pl.wikipedia.org/wiki?curid=1264" title="Dinar">
Dinar

Dinar – złota moneta arabska, bita od VII do XV wieku, używana głównie w handlu międzynarodowym. Początkowo moneta ważyła około 4,25 grama.
Historia.
Słowo „dinar” jest transliteracją arabskiego słowa ("dīnār"), które zostało zapożyczone poprzez syryjskie "dīnarā" z greckiego δηνάριον ("denárion"), które zaś pochodzi od łacińskiego "dēnārius". Złoty dinar był jedną z pierwszych islamskich monet, będącą odpowiednikiem bizantyjskiego "denarius auri". Złota moneta znana jako "dīnāra" została również sprowadzona do Indii przez Królestwo Kuszanów w I wieku. Następnie została przejęta przez Imperium Guptów i ich spadkobierców aż do VI wieku. Obecnie część osób w Indonezji, Malezji, a także na terenach tzw. Państwa Islamskiego opowiada się za wprowadzeniem współczesnego złotego dinara, który byłby bilonem bitym z kruszcu.
Środek płatniczy.
Państwa wykorzystujące dinary w przeszłości.
W 774 roku anglosaski król Offa wybił kopie abbasydzkich dinarów kalifa Al-Mansura z napisem „OFFA REX” („KRÓL OFFA”) umieszczonym w centrum rewersu. Mincerz wybijający monety prawdopodobnie nie znał arabskiego, gdyż arabski tekst zawiera wiele błędów. Monety te produkowano prawdopodobnie celem wykorzystania ich w handlu w muzułmańskiej Hiszpanii.

</doc>
<doc id="1265" url="https://pl.wikipedia.org/wiki?curid=1265" title="Dur brzuszny">
Dur brzuszny

Dur brzuszny (łac. "typhus abdominalis", ), zwany dawniej tyfusem lub tyfusem brzusznym – ogólnoustrojowa choroba bakteryjna wywołana Gram-ujemnymi pałeczkami "Salmonella enterica", serotyp Typhi ("Salmonella" Typhi). Wywołują ją bakterie z grupy salmonelli, które w temperaturze 60 °C giną już po kilkunastu minutach. Źródłem zakażenia może być brudna woda, nieumyte owoce, a także nieczystości zawierające w sobie pałeczki "Salmonella "Typhi. Charakteryzuje się gorączką (powoli narastającą, aż do osiągnięcia ok. 40 stopni), krańcowym wyczerpaniem, bólami brzucha, objawami zatrucia endotoksyną (splątanie) i różową wysypką, tak zwaną „różyczką durową”, czyli rumieniową wysypką plamisto-grudkową zlokalizowaną na skórze klatki piersiowej lub nadbrzusza. Tym objawom towarzyszy także powiększenie wątroby, śledziony i węzłów chłonnych szyi oraz zapalenie spojówek. Pomimo gorączki występuje względne spowolnienie pracy serca – jest to objaw Fageta.
Profilaktyka.
Dokładne mycie owoców i warzyw przed spożyciem, a także picie tylko czystej wody z pewnego źródła i unikanie kontaktu z nieczystościami skażonymi bakteriami. Bardzo ważne jest mycie rąk przed jedzeniem i po wyjściu z ubikacji, ponieważ dur brzuszny (podobnie jak np. czerwonka) należy do tzw. chorób brudnych rąk (chory na dur brzuszny wydala zarazki z kałem). Możliwe też przyjęcie szczepionki uodparniającej; odporność zyskuje się po jednej dawce na okres około 3 lat. Na rynku polskim dostępne są dwie szczepionki: "Ty" i "Typhim Vi" (szczepionka polisacharydowa).
Leczenie.
Wymaga leczenia antybiotykiem.
Stosowane antybiotyki to: ampicylina (8 g/dobę) przez okres gorączki, a także kilka dni po jej ustąpieniu. Alternatywne antybiotyki: ciprofloksacyna, cefoperazon. Stosowany z powodzeniem może być również sulfametoksazol z trimetoprimem (kotrimoksazol) i furazolidon. Konieczne jest wyrównanie poziomu płynów i elektrolitów.
Rokowanie.
Rokowanie dobre, jeżeli wcześnie leczony, przed wystąpieniem powikłań, a ogólny stan i odporność chorego przed chorobą nie jest upośledzona.

</doc>
<doc id="1266" url="https://pl.wikipedia.org/wiki?curid=1266" title="DWT">
DWT



</doc>
<doc id="1267" url="https://pl.wikipedia.org/wiki?curid=1267" title="Dżuma">
Dżuma

Dżuma (czarna śmierć, mór, zaraza morowa) – ostra bakteryjna choroba zakaźna gryzoni i (rzadziej) innych drobnych ssaków, a także człowieka (zoonoza). Choroba ta wywołana jest infekcją względnie beztlenowych pałeczek z rodziny Enterobacteriaceae (G(-)) nazwanej "Yersinia pestis".
Postacie i droga szerzenia.
Wyróżnia się trzy zasadnicze postacie dżumy:
Najczęściej występuje (zarówno wśród zwierząt, jak u ludzi) dymienicza forma dżumy. Do zakażenia dochodzi zwykle w wyniku pokąsania przez pchły (głównie pchły szczurze, "Xenopsylla cheopis") uprzednio zainfekowane w wyniku kąsania chorych szczurów, wiewiórek, nieświszczuków czarnoogonowych lub innych małych ssaków. W następstwie infekcji bakterie migrują wraz z krwią i chłonką do węzłów chłonnych, co po około pięciu dniach objawia się regionalnym powiększeniem tych narządów (tzw. dymienicą). Postać dymienicza dżumy wywołana może być także spożyciem skażonego pokarmu lub wody (rzadkie u ludzi).
Postać septyczna jest zazwyczaj powikłaniem dżumy dymieniczej. U części chorych rozwija się, z pominięciem postaci dymieniczej, od razu pierwotna sepsa.
Płucna postać dżumy może występować zarówno jako zakażenie pierwotne (w tym przypadku dochodzi do niego drogą kropelkową, bezpośrednio od chorej osoby, z wyłączeniem wektora zakażenia w postaci pchły lub szczura) lub jako wtórne, dżumowe zapalenie płuc, będące komplikacją postaci dymieniczej. Postać tę cechuje bardzo wysoka zaraźliwość (nieznane nauce są jednak przypadki zakażeń dżumą płucną poprzez np. system wentylacyjny).
Czynnik etiologiczny.
Dżumę wywołuje nieruchoma pałeczka, barwiąca się ujemnie przy wykorzystaniu metody Grama, nieprzetrwalnikująca, "Yersinia pestis". Bakteria ta posiada zespół genów nazywanych "Yop virulon" wytwarzających szczególne wypustki białkowe na powierzchni komórek bakteryjnych oraz endotoksyny. Dzięki tym wypustkom rozpoznawane są fagocyty zainfekowanego organizmu oraz wprowadzane są do cytoplazmy fagocytów endotoksyny bakteryjne (YopE, YopH i YopT), które blokują fagocytozę. Patogen ten wrażliwy jest na popularne środki dezynfekcyjne (środki chemiczne i wysoką temperaturę). Wykazuje względnie dużą oporność na niskie temperatury. W środowisku przeżywa zwykle od miesiąca do pół roku.
Patogeneza, objawy i rozpoznawanie.
Objawy dżumy dymieniczej (łac. "pestis bubonica") pojawiają się w okresie od dwóch dni do tygodnia od ukąszenia. W początkowym okresie, pierwszych 6–8 godzinach, występują objawy nieswoiste, takie jak wysoka gorączka (powyżej 38 °C), poty, dreszcze, rozszerzenie naczyń krwionośnych, ból głowy i znaczne osłabienie.
Później pojawia się powiększenie węzłów chłonnych (nawet do ok. 10 cm), zwłaszcza pachwinowych, rzadziej pachowych, szyjnych lub innych oraz objawy zapalenia naczyń chłonnych. Powiększone węzły chłonne stają się bolesne (czasem wywołując przykurcze kończyny), miękkie (z powodu martwicy o mechanizmie zawału i zmian ropnych w centralnych jego częściach), ich zawartość może ulec opróżnieniu przez samoistne przetoki. W lekkich przypadkach dżumy dymieniczej (łac. "pestis minor") proces chorobowy ogranicza się do jednej grupy węzłów chłonnych, nawet bez wytworzenia przetoki. Zwykle jednak powstają dymienice wtórne (zajmowane są kolejne grupy węzłów chłonnych). W rzadkich przypadkach zmiany dymienicze powstają tylko w głęboko położonych węzłach chłonnych. Są to przypadki bardzo trudne do rozpoznania, przypominające przebiegiem ciężkie postacie duru brzusznego lub cięższej postaci – dżumy septycznej.
Postać septyczną (łac. "pestis septica") cechuje, poza objawami nieswoistymi, duża bakteriemia. W wyniku zakażenia uogólnionego, jako reakcja makroorganizmu, pojawia się uogólniony zespół odczynu zapalnego (łac. "sepsis"). W jej wyniku powstają mikrozatory bakteryjne w końcowych naczyniach krwionośnych palców rąk i stóp oraz nosa, czego skutkiem jest zgorzel (objawiająca się czarnym zabarwieniem tkanek). Objawy te są zbliżone do opisów epidemii „czarnej śmierci” w średniowieczu. W tej postaci rokowanie jest bardzo poważne.
W postaci płucnej (łac. "pestis pneumonica") występują objawy ciężkiego, wysiękowego zapalenia płuc, z krwiopluciem, dusznością i sinicą. Rokowanie jest znacznie poważniejsze niż w postaci dymieniczej. Postać płucna charakteryzuje się niezwykłą zaraźliwością drogą kropelkową (bez pośrednictwa pcheł).
Zapalenie płuc w dżumie ma charakter krwotocznego, odoskrzelowego zapalenia z odczynem włóknikowym w opłucnej.
Wczesna diagnostyka opiera się na wywiadzie epidemiologicznym i badaniu klinicznym. Do potwierdzenia dżumy stosuje się hodowle bakteriologiczne materiału z węzłów limfatycznych, krwi lub plwociny. Duże znaczenie mają także metody serologiczne oraz PCR. Ostatecznego potwierdzenia dokonuje się w laboratoriach o wysokiej (3, 4 stopień) klasie bezpieczeństwa biologicznego.
Leczenie.
Leczenie polega na pozajelitowym podawaniu antybiotyków. Bakterie wykazują wrażliwość na streptomycynę, gentamycynę, chloramfenikol (te dwa pierwsze antybiotyki są tzw. lekami z wyboru w leczeniu dżumy. Chloramfenikol, mimo bardzo dużej skuteczności, stosowany jest obecnie jako antybiotyk „drugiego rzutu”, ze względu na częste i niebezpieczne działanie uboczne), ciprofloksacynę, cefalosporyny (w dżumie uogólnionej i płucnej) i niektóre tetracykliny, najczęściej doksycyklinę (w łagodnych przypadkach). Duże znaczenia ma leczenie wspomagające; konieczność chirurgicznego opracowania dymienic jest rzadkością.
W Polsce chorzy na dżumę podlegają przymusowej hospitalizacji.
Rokowanie.
W przypadkach nieleczonych, na podstawie danych z różnych epidemii, śmiertelność z powodu postaci dymieniczej szacuje się na kilkanaście do nawet 80%.
Nieleczona postać septyczna (posocznicowa) jak i płucna dżumy jest prawie zawsze śmiertelna (śmierć w postaci płucnej następuje najczęściej w ciągu kilku dni, w postaci posocznicowej nawet w ciągu 48 godzin).
Prawidłowa i odpowiednio wcześnie rozpoczęta antybiotykoterapia pozwala obniżyć śmiertelność w postaci dymieniczej poniżej 5%, w postaci septycznej i płucnej poniżej 20% (pod warunkiem, że leczenie zostanie podjęte podczas pierwszej doby po wystąpieniu objawów choroby).
Profilaktyka.
Profilaktyka polega na unikaniu kontaktu z dzikimi martwymi zwierzętami oraz sytuacji, w których może dojść do pogryzienia przez gryzonia (np. podczas karmienia); używaniu środków przeciw pchłom u zwierząt domowych.
Pierwszą szczepionkę przeciw dżumie opracowano w 1890 roku.
Na rynku dostępna jest szczepionka przeciw dżumie, która zawiera bakterie zabite formaliną. Zapewnia ona ochronę przed postacią dymieniczą, jednak jej skuteczność w zapobieganiu postaci płucnej jest niewielka.
Dla każdej postaci poza płucną izolacja osób z kontaktu nie jest konieczna, podobnie jak profilaktyka antybiotykowa.
Dżuma jako broń biologiczna.
Bakterie dżumy są zaliczane do „klasycznego” arsenału broni biologicznej. Ich znaczenie wynika z rzadkiego występowania dżumy w krajach rozwiniętych, dość dużej śmiertelności i powszechnej wrażliwości populacji. Pierwszym znanym przypadkiem ich wykorzystania jest oblężenie krymskiego portu Kaffa (obecnie Teodozja) przez Tatarów w 1346 r. Oblegający za pomocą katapult wrzucali za mury miasta zwłoki zmarłych na tę chorobę (uciekinierzy z tego miasta roznieśli epidemię na całą Europę). Zbrodnicze eksperymenty z dżumą jako bronią bakteriologiczną prowadzili japońscy wojskowi w latach 1937–1945 w jednostce „731” na terenie Mandżurii, dowodzonej przez lekarza wojskowego, gen. Shirō Ishiiego (1892–1959). W jednostce tej m.in. opracowano specjalne bomby porcelanowe przeznaczone do rozsiewania zakażonych pcheł. W okresie zimnej wojny były prowadzone przez ZSRR i Stany Zjednoczone badania nad odmianami pałeczki dżumy mogącymi mieć zastosowanie jako broń biologiczna.
Historia.
Pierwotnie łacińskie słowo "pestis" było jednym z licznych, ogólnych określeń „zarazy” lub „masowego nieszczęścia”, „zguby”. Dopiero w XV–XVI w. zaczęto rozróżniać różne rodzaje chorób powodujących masowe schorzenia epidemiczne ze skutkiem śmiertelnym. Wyraz ten ma niejasne pochodzenie, być może jest pokrewny łac. "perdo" – „zgubić, zniszczyć, zmarnować”, łac. "perditus" – „stracony, nieuleczalny, beznadziejny”.
Istnieją spory, czy jeden z pierwszych opisów epidemii podany przez Tukidydesa, tzw. „dżumy ateńskiej” w 430 p.n.e., był rzeczywiście dżumą (niewykluczone, że był to dur, denga, ospa lub wirus gorączki krwotocznej). Od czasów starożytnych, poprzez średniowiecze, aż do czasów nowożytnych opisano kilkadziesiąt dużych epidemii (najprawdopodobniej) dżumy, zwanej także „czarną śmiercią” (od pojawiających się rozległych zmian martwiczo-zgorzelinowych w skórze, przyjmujących ciemną barwę).
Największe z nich przetoczyły się przez kraje europejskie w połowie VI wieku, tzw. dżuma Justyniana oraz w latach 1348–1352. Epidemia czarnej śmierci wybuchła w Azji Środkowej, być może w Chinach, skąd przez jedwabny szlak w 1346 dostała się na Krym, a stamtąd rozprzestrzeniła się na basen Morza Śródziemnego i całą Europę, roznoszona prawdopodobnie przez pchły pasożytujące na szczurach śniadych zamieszkujących ówczesne statki handlowe. Ta epidemia w niektórych rejonach zmniejszyła populację nawet o 80% ludności i spowodowała daleko idące konsekwencje demograficzne, kulturowo-społeczne i polityczne. Symbolem dżumy stał się charakterystyczny ubiór ochronny noszony w XVI–XVIII w. przez lekarzy w czasie epidemii, z maską w kształcie dzioba, gdzie wkładano wonne olejki tłumiące fetor rozkładających się zwłok. Prócz ubioru, chroniono się przed dżumą także specjalnymi antidotami: najcenniejszym z nich była driakiew, ale stosowano też "ocet siedmiu złodziei" (ocet winny, w którym przez 12 dni moczono bylicę piołun, rutę zwyczajną, rozmaryn lekarski, szałwię lekarską i inne zioła zawierające olejki eteryczne, o silnych właściwościach bakteriobójczych) i „driakiew ubogich” – czosnek pospolity.
Czynnik bakteryjny powodujący dżumę zidentyfikowali w 1894 r. niezależnie od siebie japoński bakteriolog Shibasaburō Kitasato (1852–1931) oraz francuski bakteriolog Alexandre Yersin (1863–1943) podczas epidemii w Hongkongu, natomiast rolę pcheł szczurzych w szerzeniu się tego zarazka odkrył japoński badacz Masaki Ogata (1864–1919) w 1897 r.
Na przełomie XX i XXI wieku część mikrobiologów (m.in. Christopher Duncan i Susan Scott) wysunęli teorię, zgodnie z którą opisywane epidemie w Atenach (V w. p.n.e.), dżuma Justyniana (VI–VII w. n.e.) oraz nawracające zarazy w latach 1348–1672 nie miały podłoża bakteryjnego (dżuma dymienicza – "Yersinia pestis"), lecz wirusowe. Zgodnie z tezami głoszonymi przez wymienionych naukowców, byłaby więc to choroba zbliżona do gorączek krwotocznych wywoływanych przez wirusy Ebola, Marburg, ale o okresie inkubacji ok. 32 dni.
Stosując analizę DNA w materiale pobranym z zębów osób pochowanych na średniowiecznym cmentarzu w Aschheim w Bawarii, stwierdzono, że Dżuma Justyniana była spowodowana przez inne szczepy bakterii niż te, które spowodowały epidemię czarnej śmierci w XIV–XVII wieku i niedawną epidemię dżumy w XIX–XX wieku.
Obecnie dżuma istnieje w kilku rejonach endemicznych w Azji i Afryce (w latach dziewięćdziesiątych XX wieku jej wybuchy odnotowano w Wietnamie, Zambii i Indiach). W XXI wieku odnotowano epidemie w Algierii, Demokratycznej Republice Konga i na Madagaskarze. Jak podaje Departament Zdrowia hrabstwa Navajo w Arizonie, ostrzega się społeczność i zachęca do podjęcia wszelkich środków ostrożności w celu zmniejszenia ryzyka zakażenia dżumą, którą przenoszą pchły, gryzonie, króliki i inne zwierzęta, które żywią się wymienionymi.

</doc>
<doc id="1269" url="https://pl.wikipedia.org/wiki?curid=1269" title="Dy">
Dy



</doc>
<doc id="1270" url="https://pl.wikipedia.org/wiki?curid=1270" title="Dirhem">
Dirhem

Dirhem (dirham) – jednostka wagi pierwotnie ustalona w Arabii jako 2/3 drachmy attyckiej. Także srebrna moneta krajów arabskich bita od VII do XI wieku.
Obecnie w użyciu są następujące waluty o nazwie nawiązującej do "dirhema":
W użyciu są również jako zdawkowe jednostki monetarne:

</doc>
<doc id="1271" url="https://pl.wikipedia.org/wiki?curid=1271" title="Dublon">
Dublon

Dublon – złota moneta hiszpańska o wartości 2 escudo, wprowadzona w 1537 r. przez cesarza Karola V na wzór pistola włoskiego i francuskiego, przedstawiająca w momencie wprowadzenia tarczę herbową z jednej i krzyż z drugiej strony. Od połowy XVIII w. krzyż został zastąpiony popiersiem. 
Bito również 2 oraz 4 dublony. W Europie często podwójne hiszpańskie pistole zwano "dublonami", a czterodublonowe monety – "kwadruplami".
Ostatnie "dublony," o wartości 100 reali, wybito w 1864 r.

</doc>
<doc id="1272" url="https://pl.wikipedia.org/wiki?curid=1272" title="Dariusz I Wielki">
Dariusz I Wielki

Dariusz I Wielki (staropers. 𐎭𐎠𐎼𐎹𐎺𐎢𐏁 "Dārayava(h)uš"; ur. ok. 550 p.n.e., zm. 486 p.n.e.) – trzeci szachinszach Imperium Achemenidów, rządzący w latach 522–486 p.n.e. Pod jego władzą perskie imperium osiągnęło największy w swojej historii zasięg terytorialny. W 490 p.n.e. dowodził wyprawą przeciwko Grecji, która ostatecznie zakończyła się klęską. Dariusz I zorganizował sprawną administrację w swoim państwie, ujednolicił system monetarny, a także uczynił z aramejskiego oficjalny język w imperium. Był monoteistą i oddanym czcicielem Ahura Mazdy, w swych inskrypcjach nigdy nie wspominał z imienia innych bogów. Stworzona z jego polecenia inskrypcja z Behistunu, okazała się ważnym świadectwem języka staroperskiego i walnie przyczyniła się do odczytania pisma klinowego. Perski władca wymieniony jest w biblijnych księgach: Aggeusza, Zachariasza i Ezdrasza.
Etymologia imienia.
"Dārīus" i "Dārēus" są łacińskimi formami greckiego "Dareîos" (Δαρεῖος), pochodzącego od staroperskiego "Dārayauš" (𐎭𐎠𐎼𐎹𐎢𐏁), które jest skróconą formą od "Dārayava(h)uš" (𐎭𐎠𐎼𐎹𐎺𐎢𐏁).
Pierwsza część imienia "dāraya", to „posiadacz”, natomiast "vau", oznacza „dobroć”.
Młodość i objęcie tronu.
Dariusz urodził się około 550 p.n.e. jako najstarszy z pięciu synów Wisztaspy. Inskrypcja z Behistunu podaje, że ojciec Dariusza był satrapą Baktrii. Według Herodota Wisztaspa zarządzał prowincją Persyda w dzisiejszym Iranie, co francuski iranista Pierre Briant uważa za błąd. Z pewnością jednak ojciec Dariusza był ważnym arystokratą na dworze Cyrusa II Wielkiego.
Zgodnie z informacjami podawanymi przez Herodota Dariusz miał uczestniczyć w podboju Egiptu przez Kambyzesa II.
Istnieje wiele różnych relacji opisujących okoliczności dojścia Dariusza do władzy. Miało się to stać po usunięciu poprzedniego samozwańczego władcy Persji Bardiji (nazywanego przez Greków Smerdisem).
Herodot przytacza w "Dziejach" historię, w myśl której ów obalony władca miał nie być prawdziwym Bardiją, synem Cyrusa i bratem Kambyzesa, lecz jedynie jego sobowtórem, podstawionym przez medyjskiego maga w ramach spisku magów dążącego do odebrania panowania Persom na rzecz podporządkowanych Medów. Dariusz stanąć miał na czele tajemnego sprzysiężenia siedmiu mężów, mającego na celu obalenie uzurpatora. Wedle relacji Herodota to sam Dariusz zgładził uzurpatora, przebijając go mieczem.
Dariusz od początku reprezentował w Sprzysiężeniu Siedmiu frakcję dążącą do utrzymania w Persji jedynowładztwa. Przedstawiał się więc jako kontynuator dzieła Cyrusa i, jak się wydaje, po uzyskaniu władzy faktycznie prowadził politykę zgodną z zapoczątkowanymi przez niego wzorcami. Potwierdzenie stanowi przytaczana przez Herodota mowa:
Po obaleniu uzurpatora członkowie Sprzysiężenia za radą Dariusza postanowili obrać spośród siebie nowego króla. Dokonali tego w drodze wróżby: sześciu mężów (Otanes zrezygnował dobrowolnie, niezainteresowany koroną) dosiadło o świcie koni. Nowym władcą Persów zostać miał ten z nich, którego koń pierwszy zarży. Dariusz zapewnił sobie zwycięstwo dzięki pomocy koniuszego Ojbaresa, mianowicie – jak podaje Herodot – wykorzystując w jakiś sposób zapach klaczy sprowokował swego konia by zarżał.
Wojny i podboje.
Dariusz umocnił hegemonię perską w Azji obalając bunt Babilonii oraz Powstanie jońskie. Powiększył też tereny imperium, przyłączając Gandharę, Dolinę Indusu, Chorezm, Pamir, kaukaskie wybrzeże Morza Czarnego i Trację. Narzucił zwierzchnictwo królowi Macedonii. Jego imperium sięgało po Indus, Morze Śródziemne, Zatokę Perską, Półwysep Arabski, Egipt i Kaukaz.
Stłumienie buntu w Babilonii.
Zaraz po uzyskaniu przez Dariusza władzy miał miejsce bunt w Babilonii (gdzie władzę próbowali przejąć samozwańcy Nabuchodonozor III i Nabuchodonozor IV).
Herodot podaje, że był on zapewne przygotowywany już podczas zamieszania poprzedzającego wstąpienie Dariusza na tron perski. Babilończycy według "Dziejów" gotowi byli dzięki potężnym murom i zgromadzonym zapasom na długie oblężenie. Herodot stłumienie powstania przypisuje następującej wyroczni oraz podstępowi.
Herodot podaje, że Dariusz nakazał zrównanie z ziemią jego potężnych murów, czego wcześniej zaniedbał Cyrus. Ponieważ mieszkańcy, szykując się do oblężenia, wymordowali większość swoich kobiet, by nie zjadały zapasów, Dariusz dostarczył do miasta nowych kobiet z okolicznych wsi. Na czele zdobytego miasta postawił bohaterskiego Zopyrosa, miał jednak powiedzieć, że „wolałby raczej widzieć Zopyrosa wolnym od okaleczenia, niż żeby mu do obecnego Babilonu jeszcze dwadzieścia innych przybyło”.
Podbój Samos.
Pierwszym podbojem dokonanym przez Dariusza było podporządkowanie sobie Samos, na którym po zamordowaniu Polikratesa rządy trzymał jego dawny sekretarz Majandrios. Dariusz wprowadził na tron Sylosonta, brata Polikratesa, u którego wedle Herodota jeszcze przed objęciem panowania zaciągnął dług wdzięczności. Zdobyciem Samos dowodził Otanes, jeden z Siedmiu Mężów, który – wbrew rozkazom władcy – sprowokowany przez Majandriosa dokonał rzezi jego mieszkańców. Ostatecznie udało się Persom osadzić na tronie samijskim przychylnego sobie władcę.
Wyprawa przeciw Scytom.
Około roku 512 p.n.e. Dariusz przekroczył z armią Bosfor postępując na północ przez Bałkany i po przejściu Dunaju usiłował pokonać zamieszkujących dzisiejszą Ukrainę Scytów. Herodot podaje, że przyczyną tej wyprawy był rewanż za kilkudziesięcioletnią hegemonię Scytów w Azji, w rzeczywistości chodziło jednak zapewne o podporządkowanie sobie europejskich obszarów na północ od państwa perskiego i uniknięcie stałego zagrożenia ze strony zamieszkujących je plemion koczowniczych.
Scytowie jako pierwsi w historii zastosować mieli w obronie przed Dariuszem taktykę spalonej ziemi. Wykorzystując swą mobilność uchodzili oni przed wojskiem Dariusza opartym głównie na piechocie, pustosząc zostawianą za sobą ziemię tak, iż Persowie nie mieli co jeść i gdzie wypasać swych wierzchowców. Jednocześnie Scytowie, wspomagani przez sojusz okolicznych plemion, wśród których Herodot wymienia Geodonów, Budynów i Sauromatów, nękali Persów nieustannymi atakami podjazdowymi.
Po kilku miesiącach Scytowie mieli wysłać do Dariusza herolda, który zaniósł mu w darze ptaka, mysz, żabę i pięć strzał, nie objaśniając ani słowem, co te dary znaczą. Dariusz uznał je za znak poddania ziemi (mysz), wody (żaba) i wierzchowców (lotny ptak) potędze Persów symbolizowanej przez pięć strzał. Gobyras (jeden z Siedmiu Mężów) odczytał je przeciwnie – jako groźbę uśmiercenia Persów, jeśli nie zamienią się w ptaki i nie odlecą lub w żaby i nie odpłyną. Ten motyw tajemniczego posłania był później wykorzystywany w literaturze i sztukach plastycznych.
Herodot opisuje także, że Scytowie planowali wybić całkowicie armię Dariusza, odcinając jej drogę odwrotu. Dariusz przybył na teren Scytów dzięki mostowi przerzuconemu nad Dunajem (zwanym przez Greków Istrem), który wybudowali helleńscy lennicy Persji. Scytowie próbowali podburzyć ich przeciw suwerenom, jednak bezskutecznie. "Dzieje" podają, że decyzję o niezerwaniu mostu podjął Histiajos z Miletu – późniejszy przywódca powstania jońskiego.
Wyprawa przeciw Scytom zakończyła się niepowodzeniem i Dariusz zmuszony był na czele zdziesiątkowanej głodem i napaściami Scytów armii wycofać się z powrotem do Persji.
Wojna z Hellenami.
Powstanie jońskie.
W roku 499 p.n.e. wybuchło powstanie jońskie, w którym miasta Azji Mniejszej, podporządkowane za panowania Cyrusa, podjęły próbę zrzucenia perskiego jarzma.
Przyczyny powstania były różnorodne. Z pewnością nie bez znaczenia były tu wysokie daniny, jakie miasta jońskie płacić musiały na rzecz Persji. Ważnym czynnikiem był także brak swobody politycznej spowodowany podporządkowaniem miast jońskich satrapii lidyjskiej z siedzibą w Sardes. Ma to swoje historyczne uzasadnienie w przebiegu podbojów Cyrusa, podczas których odebrane Krezusowi Sardes stało się ważną twierdzą i punktem wypadowym Persów na cały obszar Azji Mniejszej.
Jednym z głównych inicjatorów powstania był ten sam Histiajos, który odmówił wystąpienia przeciw Persom podczas wycofywania się zza Dunaju. Wówczas bronił on – jak podaje Herodot – własnego interesu, gdyż po upadku hegemonii Perskiej Milet z pewnością wybrałby demokrację, obalając tyrana. Jednak w zamian za pomoc okazaną podczas wyprawy przeciw Scytom Histiajos otrzymał posiadłość w Myrkinos w Tracji, która zapewniała mu dochody większe, niż tyrania w Milecie. W ten sposób Persowie niechcący usunęli podstawową więź łączącą go z ich hegemonią. Megabazos, który był w owym czasie dowódcą wojsk perskich w Jonii, uprzedził Dariusza o niebezpieczeństwie, jakie stanowi Histiajos i król postanowił dla bezpieczeństwa trzymać go przy sobie, na dworze w Suzie. Histiajos jednak znalazł sposób, by wszcząć powstanie w miastach Jońskich. Dokonał tego przez swego zięcia – Aristagorasa, któremu przesłał wiadomość wytatuowaną na głowie ogolonego uprzednio niewolnika.
Aristagoras posłał po pomoc do Sparty i Aten. Lacedemończycy odmówili, Ateńczycy zaś udzielili powstaniu pomocy, przez co ściągnęli na siebie gniew Dariusza.
Powstanie jońskie miało ważny wymiar polityczny dla imperium Perskiego, utrwaliły bowiem jego związki z lokalnymi tyranami przeciw zwolennikom demokracji. Aristagoras jako przywódca powstania przekonywał do siebie mieszkańców różnych poleis obiecując im obalenie tyranów. W ten sposób wygnany został między innymi Ajakes syn Sylosonta tyran Samos.
Choć początkowo Grekom wiodło się dobrze i w pierwszym roku powstania zdobyli nawet Sardes, to losy walki szybko się odwróciły. Po klęsce Jończyków w bitwie morskiej pod Lade Powstanie zostało stłumione i Hellenowie ostatecznie zostali pokonani. Najsurowszą karę poniósł Milet, który został całkowicie zrównany z ziemią.
Powstanie trwało łącznie sześć lat.
Wyprawa na Helladę.
Po klęsce powstania jońskiego Dariusz zrozumiał, że dalsze utrzymanie hegemonii nad miastami jońskimi jest niemożliwe bez odcięcia ich od pomocy ze strony reszty Hellenów, zwłaszcza zaś Ateńczyków.
O nienawiści, jaką od czasu powstania Dariusz żywił wobec Ateńczyków, Herodot opowiada następującą historię. Władca Persów miał wystrzelić z łuku strzałę w powietrze ze słowami „Zeusie, użycz mi zemsty na Ateńczykach”, a następnie zlecić jednemu ze służących, by ilekroć król siądzie do stołu, ten trzykrotnie powtarzał mu „Panie, pamiętaj o Ateńczykach”.
Nie bez znaczenia był także fakt, że na dworze Dariusza przebywał Hippiasz, wygnany z Aten syn tyrana Pizystrata. On to podburzał władcę do ataku na Helladę, aby tym sposobem odzyskać panowanie nad Ateńczykami.
Dariusz zebrał więc armię i wysłał ją na Helladę. Bez większego kłopotu podbił Eretryjczyków i zbliżał się lądem do Aten. Przeciw prowadzonemu przez Hippiasza wojsku perskiemu wystąpiła piechota Ateńczyków i sprzymierzonych z nimi Platejczyków dowodzona przez Miltiadesa i w bitwie pod Maratonem odparła najeźdźców.
Przygotowania do drugiej wyprawy na Helladę.
Od czasu klęski pod Maratonem aż do swojej śmierci Dariusz przygotowywał się do kolejnej wyprawy na Helladę. Z dokonanych przez niego zbrojeń skorzystał już jednak nie on sam, lecz syn i następca tronu Kserkses I.
Polityka wewnętrzna.
Gospodarka.
Ocenia się, że Dariusz był zarówno wielkim prawodawcą, administratorem, ale również znakomitym finansistą na miarę wiedzy, jaką dysponował. Wprowadził daninę i inne opłaty, za co podlegli mu płatnicy nazywali go ‘kramarzem’. Ujednolicił system miar i wag ("miara królewska" ok. 36 litrów, oraz "łokieć królewski" dokładnie 46,1 centymetra). Wprowadził nową jednostkę wagi, karszę ("kersha").
Dariusz wprowadził własną monetę (darejki) i system podatkowy. Podjął działania w kierunku kodyfikacji prawa. W Egipcie nakazał odbudowę kanału łączącego Nil z Morzem Czerwonym, który stworzyli faraonowie saiccy.
Administracja.
Organizował sprawnie działający aparat państwowy zarządzający największą monarchią ówczesnego świata. Kontynuując politykę prowadzoną przez Cyrusa zapewnił poszczególnym plemionom i regionom znaczną autonomię przy konieczności uznania zwierzchnictwa króla perskiego i płacenia wynikających stąd danin.
Dariusz podzielił kraj na 23 satrapie (namiestnictwa) (Media, Elam, Armenia, Aria, Babilonia, Lidia, Drangiana, Aszria, Kapadocja, Egipt, Scytia, Jonia, Baktria, Gandara, Partia, Sagartia, Chorasmia-Sogdiana, Indus, Arabia, Karia, Libia, Nubia), na czele których stali wyznaczani przez niego satrapowie sprawujący władzę cywilną i wojskową. Niektóre satrapie wyodrębnione były wedle kryteriów geograficznych, inne obejmowały po prostu określone plemiona lub grupy ludnościowe.
Armia.
Zorganizował armię zawodową złożoną z 10 tys. tak zwanych nieśmiertelnych.
Dwór.
Żoną Dariusza była Atossa, córka Cyrusa Starszego. Następcą Dariusza był jego syn Kserkses I.
Najważniejszymi doradcami Dariusza byli wedle Herodota mężowie, którzy obalili wraz z nim poprzedniego władcę-uzurpatora w Sprzysiężeniu u Siedmiu. Wedle relacji Herodota nadwornym lekarzem Dariusza był Demokedes z Samos, największy medyk tamtych czasów, którego władca przejął jako niewolnika po śmierci Polikratesa.
Inne.
Około roku 510 p.n.e. Dariusz I Wielki po raz pierwszy w znanych źródłach wspomniał cukier, w kontekście trzciny cukrowej rosnącej nad rzeką Indus.

</doc>
<doc id="1273" url="https://pl.wikipedia.org/wiki?curid=1273" title="Deuter">
Deuter

Deuter (, D) – stabilny izotop wodoru występujący naturalnie. W wodzie morskiej (SMOW) występuje w ilości około 1 atomu na 6420 atomów protu (wodoru zwykłego, ) (około 0,02 grama w 1 litrze wody).
Jądro deuteru (deuteron) składa się z jednego protonu i jednego neutronu, podczas gdy jądrem protu jest jeden proton. Masa atomowa deuteru jest około dwukrotnie większa od izotopu i wynosi 2,0140 u.
Deuter został odkryty w 1931 roku przez Harolda Claytona Ureya, chemika z Columbia University, za co otrzymał on Nagrodę Nobla z chemii w 1934 roku.
Ze względu na małą masę i mały przekrój czynny (0,11 σ/fm²) deuter jest dobrym moderatorem szybkich neutronów. Związki deuteru (np. ciężka woda) wykorzystywane są w reaktorach jądrowych.
Deuter może zastępować zwykły wodór we wszystkich związkach, co skutkuje zwykle niewielkimi, lecz stosunkowo łatwymi do zmierzenia, zmianami ich właściwości fizycznych i chemicznych. Woda zawierająca atomy deuteru nosi nazwę ciężkiej wody. W zależności od składu izotopowego wodoru ciężka woda może mieć wzór:

</doc>
<doc id="1274" url="https://pl.wikipedia.org/wiki?curid=1274" title="Daniel Olbrychski">
Daniel Olbrychski

Daniel Marcel Olbrychski (ur. 27 lutego 1945 w Łowiczu) – polski aktor teatralny i filmowy.
Uznawany za jednego z najwybitniejszych aktorów filmowych i teatralnych swojego pokolenia. Zagrał w blisko 180 filmach kinowych i telewizyjnych. Debiutował w 1963 rolą w filmie Janusza Nasfetera "Ranny w lesie". Następnie występował w filmach najpopularniejszych polskich reżyserów, takich jak Andrzej Wajda, Janusz Morgenstern, Kazimierz Kutz, Julian Dziedzina, Krzysztof Zanussi, Jerzy Antczak, Jerzy Hoffman, Janusz Kijowski, Stanisław Bareja czy Krzysztof Kieślowski. W 1970 zaczął występować w produkcjach zagranicznych, zagrał m.in. u Volkera Schlöndorffa, Claude’a Leloucha czy Nikity Michałkowa.
Życiorys.
Urodził się 27 lutego 1945 w Łowiczu. Jest synem publicysty Franciszka Olbrychskiego (1905–1981) i Klementyny z Sołonowiczów (1909–1995), polonistki. Jego ciotką – siostrą matki – była Irena Śmiałowska (1908–2019), jedna z najdłużej żyjących Polek. Miał starszego brata, Krzysztofa (1939–2017), który był fizykiem. Dzieciństwo spędził w Czerniewie, Łodzi i Drohiczynie, gdzie debiutował jako aktor występami w przedstawieniach wystawianych w kościele. Uczęszczał do szkoły muzycznej, uczył się w klasie skrzypiec. Od młodości uprawia boks, trenował też szermierkę, badmintona i judo oraz bieg na 800 m w klubie Lotnik Warszawa.
Jednocześnie rozwijał się aktorsko – należał do kółka recytatorskiego Miłośników Starej Warszawy, prowadzonego przez Józefa Małgorzewskiego, a w czasie nauki w liceum im. Stefana Batorego w Warszawie zagrał Papkina w szkolnej inscenizacji "Zemsty" na scenie Teatru Buffo w reż. Jana Cichonia. Na początku lat 60. występował w Młodzieżowym Studiu Poetyckim, realizowanym w Telewizji Polskiej przez Andrzeja Konica, m.in. w tytułowej roli w "Kubie" na podstawie "Archipelagu ludzi odzyskanych" Igora Newerlego. Po ukończeniu liceum w 1963 rozpoczął studia w Państwowej Wyższej Szkole Teatralnej w Warszawie, które przerwał w związku z zaangażowaniem się w kolejne projekty filmowe. Aktorski egzamin eksternistyczny złożył dopiero w 1971.Już na początku studiów został dostrzeżony przez reżysera Janusza Nasfetera, który obsadził go w roli Korala w swoim filmie "Ranny w lesie" według powieści Witolda Zalewskiego. W 1965 Olbrychski zagrał swoją pierwszą dużą rolę – Rafała Olbromskiego w "Popiołach" Andrzeja Wajdy, ponadto wystąpił jako podporucznik Stefan „Żbik” Olewicz w dramacie wojennym Janusza Morgensterna "Potem nastąpi cisza". Do końca lat 60. zagrał jeszcze kilka głównych ról filmowych: w 1966 – postać Andrzeja w komedii muzycznej Stanisława Barei "Małżeństwo z rozsądku" (1967) i Tolka Szczepaniaka w "Bokserze" Juliana Dziedziny, w 1967 – Franka w "Skoku" Kazimierza Kutza i Marka Arensa w "Jowicie" Janusza Morgensterna, a w 1968 – studenta w filmie krótkometrażowym Krzysztofa Zanussiego "Zaliczenie", Karola XII w "Hrabinie Cosel" Jerzego Antczaka i Azję Tuhajbejowicza w ekranizacji "Pana Wołodyjowskiego" w reż. Jerzego Hoffmana. W 1969 został pierwszym laureatem Nagrody im. Zbyszka Cybulskiego, ponadto asystował Andrzejowi Wajdzie podczas kręcenia "Polowania na muchy", w którym zagrał drugoplanową rolę malarza. Pojawił się także w epizodycznej roli porucznika Stefana Sowińskiego w "Soli ziemi czarnej" Kazimierza Kutza, a także gościnnie wystąpił w debiutanckim filmie długometrażowym Krzysztofa Zanussiego "Struktura kryształu" oraz zagrał dwie role teatralne: Gustawa w "Ślubach panieńskich" w reż. Adama Hanuszkiewicza na scenie Teatru Powszechnego w Warszawie i Banka w "Makbecie" reżyserowanym przez Andrzeja Wajdę dla Teatru Telewizji.
W 1970 zagrał główne role w dramatach Wajdy: Bolesława w "Brzezinie" i Tadeusza w "Krajobrazie po bitwie". Dzięki występowi w tym drugim kandydował do nagrody za najlepszą rolę męską podczas 23. Międzynarodowego Festiwalu Filmowego w Cannes, jednak ostatecznie przegrał z Marcello Mastroiannim. Również w 1970 debiutował w zachodnim kinie epizodyczną rolą Siergieja Abramowa w międzynarodowej produkcji Miklósa Jancsó "Pacyfistka", a także wykreował na scenie Teatru Narodowego w Warszawie tytułowe role w reżyserowanych przez Adama Hanuszkiewicza: "Hamlecie" i "Beniowskim". W 1971 wystąpił u boku Jana Kreczmara w telewizyjnym filmie Krzysztofa Zanussiego "Die Rolle", a w 1972 zagrał w kolejnych dwóch filmach Wajdy: Mateusza Lewitę w niemieckim dramacie "Piłat i inni" i Pana Młodego w ekranizacji "Wesela". W 1974 premierę miał "Potop" Jerzego Hoffmana, w którym zagrał główną postać Andrzeja Kmicica. Mimo że jeszcze przed premierą był szeroko krytykowany w prasie za przyjęcie roli w filmie, występ w superprodukcji okazał się jednym z najważniejszych kroków w jego dorobku aktorskim, zapewnił mu najlepsze recenzje oraz największą popularność wśród widzów. Jak sam twierdzi, za występ w filmie zainkasował ok. 150 tys. zł. Następnie zagrał Borowieckiego w ekranizacji "Ziemi obiecanej" w reż. Andrzeja Wajdy.
W 1976 podpisał się pod „Listem 296”, będącym apelem przedstawicieli kultury o zbadanie represji wobec robotników i członków KOR. Tym samym wyraził publiczne wsparcie dla opozycji do ówczesnej władzy w Polsce, co skutkowało bojkotowaniem go i blokowaniem jego występów przez rządową telewizję. Jeszcze w 1977 wystąpił w roli Stanisława Przybyszewskiego w polsko-norweskiej produkcji Haakona Sandøya "Dagny", po czym zrobił sobie kilkumiesięczną przerwę od występów w filmach. Powrócił na wielki ekran w 1979 rolą Jana Brońskiego w międzynarodowej produkcji Volkera Schlöndorffa "Blaszany bębenek", a w czasie kręcenia filmu pracował również na planie psychologicznego melodramatu Andrzeja Wajdy "Panny z Wilka", w którym zagrał główną rolę – Wiktora Rubena.
Na początku lat 80. zaangażował się w działania „Solidarności”, m.in. wygłosił apel poległych podczas organizowanych 16 grudnia 1980 uroczystości odsłonięcia pomnika stoczniowców poległych w Grudniu 1970 w Gdańsku oraz wystąpił w koncertach okolicznościowych, na których zbierano fundusze na sfinansowanie budowy pomnika stoczniowców, a w 1981 podpisał się pod „listem ośmiu” (napisanym przez Józefa Rybickiego do Wojciecha Jaruzelskiego w proteście wobec wprowadzenia stanu wojennego w Polsce), czym naraził się SB. Wkrótce wyjechał do Francji, gdzie występował w roli Heralda von Wullnowa w sztuce "Szaleńcy są na wymarciu" na scenie Theatre des Amandiers w Nanterre oraz Retta Butlera w "Przeminęło z wiatrem" w paryskim Theatre Marigny. Pozostając na emigracji, wykreował także kolejne role kinowe: austriackiego dyrygenta Karla Kremera w filmie Claude’a Leloucha "Jedni i drudzy", Saint-Genisa w dramacie Josepha Loseya "Pstrąg", Saula Portera w filmie Jean-Pierre Igouxa "Derelitta" oraz jedną z głównych ról w debiutanckiej produkcji Monique Enckell "Gdybym miał 1000 lat", a także drugoplanową rolę Wiktorczyka w niemiecko-francuskim filmie wojennym Andrzeja Wajdy "Miłość w Niemczech". W 1984 wystąpił w niemiecko-fińskiej koprodukcji Vojtěcha Jasný’ego "Nieznośny samobójca", będącej ekranizacją "Samobójcy" Nikołaja Erdmana, a także zagrał podwójną rolę – braci-bliźniaków Vincenta i Thomasa Delaune – we "Flashbacku" Olivera Nolina oraz wcielił się w postać radzieckiego szachisty Tac-Taca w nagrodzonym Oscarem dla najlepszego filmu nieanglojęzycznego dramacie Richarda Dembo "Przekątna gońca".
W 1985 powrócił na polską scenę rolą Rodryka w "Cydzie" wystawianym w Teatrze Ateneum w Warszawie w reż. Adama Hanuszkiewicza, a także po latach przerwy pojawił się w polskim filmie, kreując postać Grzegorza, kierownika ośrodka Monaru w filmie Andrzeja Trzosa-Rastawieckiego "…jestem przeciw". Także w 1985 zagrał Daniela, kochanka Chiary we włoskiej komedii Francesco Nuttiego "Casablanca, Casablanca". W 1986 wcielił się w Leona Jogichesa w niemiecko-czeskosłowackim filmie biograficznym "Róża Luksemburg" w reż. Margarethe von Trotty, a także odegrał postać Scope’a, głównego bohatera filmu Piotra Szulkina "Ga, ga. Chwała bohaterom" i Franza von Schobera w filmie muzyczno-biograficznym Fritza Lehnera "Notturno" o życiu Franza Schuberta. Za rolę hokeisty Pita Hoefgesa w filmie telewizyjnym Dietera Wedela "Kampf der Tiger" (1987), reżyserowanym przez Dietera Wedela dla ZDF, zainkasował 120 tys. marek, wówczas najwyższą gażę w historii stacji. W 1988 zagrał Hareda we włoskim miniserialu "Tajemnice Sahary", terrorystę w greckim filmie Kostasa Zinirisa "To teleftaio stoichima" oraz Szpicla w melodramacie Philipa Kaufmana "Nieznośna lekkość bytu", a w 1989 zagrał księży w dwóch włoskich filmach: Adama w dramacie Michaela Andersona "Przed sklepem jubilera" na podstawie utworu Karola Wojtyły o tym samym tytule i Adriana w komedii telewizyjnej Franco Giraldiego "Izabella Kłamczucha". Ponadto zagrał epizodyczne role w serialach telewizyjnych Gillesa Béhata: Victora, dziennikarza-alkoholika w jednym z odcinków "Wysokiego napięcia" (1988) i Rolanda Korsky’ego w "Coplanie" (1989) oraz wcielił się w postać Karla Gieringa, hitlerowskiego policjanta we włosko-francuskim dramacie wojennym Jacquesa Rouffio "Czerwona orkiestra" o losach Leopolda Treppera.
W 1990 wystąpił na scenie stołecznego Teatru Rampy w przedstawieniu Andrzeja Strzeleckiego "Czerwony stoliczek" na podstawie wierszy Jana Brzechwy oraz wcielił się w rosyjskiego choreografa we włoskim miniserialu Rai 1 "Passi d’amore".
W 2010 zagrał rolę drugoplanową w filmie pt. "Salt" u boku Angeliny Jolie oraz uzyskał dyplom magistra w Akademii Teatralnej im. Aleksandra Zelwerowicza w Warszawie. Jesienią 2012 dołączył do obsady telenoweli TVP1 "Klan".
W 2015 zasiadał w jury sekcji „Cinéfondation” na 68. MFF w Cannes.
Życie prywatne.
W marcu 1967 poślubił aktorkę Monikę Dzienisiewicz, z którą ma syna, Rafała. W trakcie małżeństwa przez trzy lata był związany z piosenkarką Marylą Rodowicz, co uchodziło za jeden z najsłynniejszych romansów Polski lat 70. Po rozstaniu z Rodowicz rozwiódł się z żoną. 13 lutego 1978 poślubił dziennikarkę Zuzannę Łapicką, z którą ma córkę Weronikę (ur. 1981). Z pozamałżeńskiego związku z aktorką Barbarą Sukową ma syna, Wiktora (ur. 1988). W 1989 rozwiódł się z Łapicką, a 23 października 2003 poślubił teatrolożkę Krystynę Demską, która od 1993 jest jego menedżerką.
Przez wiele lat mieszkał we Francji, posługuje się biegle językiem francuskim. Ponadto komunikuje się w językach rosyjskim, włoskim i angielskim.
Został członkiem honorowego komitetu poparcia Bronisława Komorowskiego przed wyborami prezydenckimi w Polsce w 2015.
Inwigilacja ze strony służb specjalnych PRL.
Wydział III Komendy Stołecznej Milicji Obywatelskiej rozpracowywał Daniela Olbrychskiego w ramach Sprawy Operacyjnego Rozpracowania o kryptonimie „Kmicic”. Zbierano materiały mające wykazać jego wrogą wobec PRL działalność lub pozwolić na pozyskania go do współpracy w charakterze tajnego współpracownika na podstawie tzw. materiałów kompromitujących. Powodem zainteresowania służb specjalnych był fakt, że Daniel Olbrychski w 1977 podpisał apel Komitetu Obrony Robotników o powołanie komisji sejmowej do zbadania przypadków maltretowania uczestników protestów czerwcowych i łamania prawa przez MO, SB i wymiar sprawiedliwości. 6 lutego 1978 SOR „Kmicic” została zamknięta z powodu zaniechania wrogiej działalności „figuranta”, jednak jeszcze w 1983 Służba Bezpieczeństwa otrzymywała doniesienia tajnych współpracowników na jego temat. Dokumenty z jego obserwacji zachowały się w Archiwum Instytutu Pamięci Narodowej pod sygnaturami AIPN 00170/60, AIPN 00945/2185 oraz AIPN 01322/1022.

</doc>
<doc id="1275" url="https://pl.wikipedia.org/wiki?curid=1275" title="Depeche Mode">
Depeche Mode

Depeche Mode – brytyjska grupa muzyczna z kręgu muzyki elektronicznej i alternatywnego rocka, która powstała w 1980 w Basildon w Wielkiej Brytanii. Aktualnie członkami zespołu są Dave Gahan (wokal) i Martin Gore (klawisze, gitara elektryczna i wokal). Obaj należą do składu grupy od początku jej istnienia. Nazwa grupy powstała na podstawie inspiracji , zasugerował ją Gahan. Powstanie Depeche Mode poprzedzała grupa Composition of Sound. W 2006 zespół zdobył statuetkę MTV Europe Music Awards w kategorii „najlepszy zespół”. W 1990 grupa otrzymała nagrodę Rockbjörnen w kategorii „najlepszy zespół zagraniczny”. W 2020 roku Depeche Mode wprowadzono do Rock and Roll Hall of Fame.
Historia.
Wczesne lata (1977–1980).
W 1977 roku Vince Clarke (wokal, gitara) i Andrew Fletcher (bas) założyli zespół No Romance in China, w 1979 Clarke grał na gitarze w "Plan" razem z Robertem Marlow oraz Paulem Langwith. Martin Gore (gitara), który na początku skłaniał się ku punk rockowi, wraz z Philipem Burdettem (wokal) grał w "Norman and the Worms", w 1979 Gore, Clarke, Marlow i Paul Redmond utworzyli grupę "The French Look". W marcu 1980 powstał zespół "Composition of Sound" w składzie Clarke (wokal, gitara), Gore (instrumenty klawiszowe), Fletcher (bas).
Aby zarobić na instrumenty – syntezatory, Gore pracował jako urzędnik bankowy, a Fletcher jako agent ubezpieczeniowy. W 1980 Clarke trafił na występ Dave Gahana, po którym złożył mu propozycję dołączenia do zespołu. Równocześnie została zmieniona jego nazwa na Depeche Mode, zaczerpnięta z francuskiego magazynu. Martin Gore: „"Depeche Mode" oznacza to, jak szybko zmienia się moda. Lubię brzmienie tych słów”. Pierwszy utwór grupy, „Photographic” został umieszczony na kompilacji Some Bizzare Album, następnie został nagrany jeszcze raz, aby trafić na debiutancki album „Speak &amp; Spell”.
Speak &amp; Spell (1981).
Zespół zwrócił na siebie uwagę Daniela Millera, założyciela Mute Records, podczas występu w Bridge House w Canning Town. Pierwszym rezultatem był singel „Dreaming of Me” nagrany w grudniu 1980, a wydany w lutym 1981, który zdobył 57. miejsce na brytyjskiej liście przebojów. Następny – „New Life” – zajął miejsce 11. Trzy miesiące później „Just Can’t Get Enough” wspiął się na ósmą pozycję. W listopadzie 1981 został wydany "Speak &amp; Spell", który zebrał zróżnicowane recenzje w prasie: Melody Maker opisał go jako „wspaniały”, natomiast Rolling Stone nie szczędził słów krytyki. Na płycie znalazły się utwory błahe, naiwne, ocierające się o banał, oparte na tanecznych rytmach, na ich tle wyróżniały się kompozycje Gore’a. Depeche Mode zostało zakwalifikowane do nurtu new romantic, mimo że członkowie zespołu mieli przeciwne zdanie na ten temat.
Podczas trasy promującej album, Clarke zaczął wyrażać swoje niezadowolenie z kierunku w jakim podążał zespół: „Nigdy nie było czasu aby móc zrobić cokolwiek”, jednak wydaje się, że koledzy byli bardziej zainteresowani kompozycjami Martina i to było prawdziwym powodem odejścia. Clarke pod koniec 1981 ogłosił oficjalnie decyzję o opuszczeniu grupy. Zaproponował jeszcze wspólnie nagranie utworu „Only You”, ale oferta została odrzucona. Wraz z Alison Moyet założył Yazoo, a następnie Erasure z Andy Bellem. Po jego odejściu, głównym kompozytorem został Martin Gore, autor „Tora! Tora! Tora!” i „Big Muff” ze "Speak &amp; Spell". Martin Gore:
Zespół umieścił anonimowe ogłoszenie w "Melody Maker", na które odpowiedział Alan Wilder. Z perspektywy roku 2010 Wilder tak wspominał swoje pierwsze spotkanie z Depeche Mode: Po dwóch przesłuchaniach został przyjęty na początku 1982, najpierw jako muzyk koncertowy, stając się pełnoprawnym członkiem zespołu dopiero pod koniec następnego roku.
A Broken Frame (1982).
W styczniu 1982 ukazał się singel „See You”, który wspiął się na szóste miejsce brytyjskiej listy, osiągając tym samym lepszy wynik niż poprzednie nagranie. Zespół udał się na pierwsze światowe tournée, w następnych miesiącach ukazały się dwa następne single „The Meaning of Love” i „Leave in Silence”.
W lipcu 1982 rozpoczęły się prace nad kolejnym albumem. Alan Wilder został poinformowany przez Millera, że jego udział w studiu nie jest konieczny, jako że zespół chce udowodnić, że może odnieść sukces bez Clarka. „A Broken Frame” ukazał się we wrześniu, wszystkie utwory były autorstwa Martina Gore’a, charakteryzowały się nastrojowością oraz subtelnym brzmieniem. W „Further Excerpts from my Garden” został użyty riff z „V2 Schneider” Davida Bowie. W październiku odbyła się kolejna światowa trasa koncertowa.
Dave Gahan:
Andrew Fletcher:
Construction Time Again (1983).
W styczniu 1983 ukazał się singel „Get the Balance Right!” i był to pierwszy utwór, w którym udział miał Wilder. Pod wpływem koncertu Einstürzende Neubauten Gore zaczął nagrywać na magnetofonie wszystkie możliwe dźwięki, przetworzone następnie przez Synclavier. W ten sposób powstała baza sampli użyta podczas pracy nad następnym albumem. Przy nagrywaniu „Construction Time Again” zespół pracował z producentem Garethem Jonesem w John Foxx’s Garden Studios oraz w Hansa Studios w Berlinie Zachodnim. Płyta charakteryzowała się nowym brzmieniem, głównie dzięki zastosowaniu przez Wildera Synclaviera. Poprzez samplowanie zwykłych, codziennych odgłosów, Depeche Mode stworzyło eklektyczny, industrialny styl, podobny do tego jaki reprezentowały The Art of Noise i Einstürzende Neubauten.
Wraz z muzyką zmieniły się również teksty pisane przez Gore’a, skupiające się na sprawach społecznych i politycznych. Przykładem jest „Everything Counts” opowiadający o chciwości wielkich korporacji, a także napisane przez Wildera: „The Landscape is Changing” – ostrzeżenie przed dewastacją środowiska, „Two Minute Warning” refleksja nad wyścigiem zbrojeń. Także okładka symbolizuje zmiany i zerwanie z nurtem new romantic – przedstawiony robotnik ma „przebudować, a nie niszczyć”. „Everything Counts” zajął szóste miejsce w Wielkiej Brytanii, uplasował się w pierwszej trzydziestce list w Irlandii, RPA, Szwajcarii, Szwecji oraz Niemczech. Wilder był autorem piosenek „The Landscape is Changing” oraz „Two Minute Warning”.
Andrew Fletcher:
Some Great Reward (1984).
We wczesnych latach Depeche Mode zaistniało tylko w Europie i Australii. To się zmieniło za sprawą następnego singla „People are People” wydanego w marcu 1984, który zajął drugie miejsce w Irlandii, czwarte w Wielkiej Brytanii i pierwsze w Niemczech, a w połowie 1985 roku utwór został zauważony w USA, gdzie zajął trzynastą pozycję.
We wrześniu 1984 ukazała się płyta „Some Great Reward”. Pod względem literackim album poruszał takie tematy jak związek oparty na dominacji seksualnej („Master and Servant”), zdrada („Lie to Me”) czy rozliczenie z Bogiem („Blasphemous Rumours”). Ten ostatni został potępiony przez brytyjski kler. Natomiast traktujący o równości społecznej „People are People” stał się hymnem środowisk gejów i lesbijek. "Some Great Reward" zajął po raz pierwszy w historii miejsce na liście w USA.
W lipcu 1985 roku Depeche Mode po raz pierwszy wystąpiło w Polsce. W październiku ukazała się pierwsza składanka największych przebojów zespołu „The Singles 81→85” którą promowały single „Shake the Disease” i „It's Called a Heart”.
W tym czasie w niektórych kręgach zespół zaczął być kojarzony z subkulturą gotycką. W USA zespół zdobył takie uznanie za sprawą radia KROQ w Los Angeles czy WLIR z Nowego Jorku. Spostrzeganie w ten sposób Depeche Mode za oceanem pozostaje w dużej mierze w opozycji do Europy i Wielkiej Brytanii gdzie, mimo mrocznego i poważnego tonu w twórczości, grupa była rozpoznawana raczej jako idol nastolatków.
Black Celebration (1986).
Kolejne wydawnictwa to kolejne zmiany. Szesnasty singiel „Stripped” oraz album „Black Celebration” wypełniła muzyka mroczna i ponura. W trakcie jego powstawania, muzycy byli wyczerpani, pojawiła się także groźba rozwiązania formacji. Na płycie znalazła się nowa wersja „Fly on the Windscreen”, która pierwotnie ukazała się na drugiej stronie singla „It’s Called a Heart”. Drugi singiel „A Question of Lust” był pierwszym singlem zespołu wydanym również na kasecie magnetofonowej.
Teledysk do „A Question of Time” był pierwszym zrealizowanym przez reżysera Antona Corbijna, co zapoczątkowało współpracę trwającą po dzień dzisiejszy. Corbijn był odpowiedzialny także za niektóre okładki.
Music for the Masses (1987).
„Music for the Masses” przyniósł kolejne zmiany w sposobie pracy zespołu. Po raz pierwszy do współpracy zaproszono producenta Davida Bascombe’a, który nie był związany z Mute Records. Album nagrywany był w kwietniu i maju w studiu Konk w Londynie oraz Guillame Tell w Paryżu, a w czerwcu i lipcu dopracowywany był w PUK Studio w Danii.
Płyta była bardziej melodyjna i przebojowa w porównaniu do swojej poprzedniczki. Jej światowa sprzedaż wyniosła 2 miliony egzemplarzy. Single „Strangelove”, „Never Let Me Down Again” i „Behind the Wheel” znalazły się w pierwszej dziesiątce list przebojów w takich krajach jak: Kanada, Brazylia, Niemcy, RPA, Szwecja i Szwajcaria. „Strangelove” w Wielkiej Brytanii dotarł do miejsca 16. W utworze „I Want You Now” funkcję podkładu rytmicznego spełniają głosy, potraktowane jako instrumenty.
101 (1988).
Lata 1987–1988 zespół spędził na światowym tournée, obejmującym 101 koncertów, którego punktem kulminacyjnym był występ 18 czerwca 1988 na stadionie Rose Bowl w Pasadenie, gdzie publiczność liczyła 75 000 osób. Był to 101 koncert tego tournée. Trasa została udokumentowana filmem w reżyserii D.A. Pennebakera oraz albumem koncertowym "101".
Alan Wilder:
Violator (1990).
W połowie roku 1989 zespół rozpoczął kolejną sesję w Mediolanie z producentem Flood oraz inżynierem dźwięku François Kevorkianem. Pierwszym rezultatem był singel „Personal Jesus”. Przed jego wydaniem, w angielskiej prasie ukazało się ogłoszenie „Your own Personal Jesus”, a pod wskazanym numerem telefonu można było usłyszeć utwór. W rezultacie piosenka zajęła 13. miejsce w Wielkiej Brytanii, w USA – pierwsze od czasu „People are People”, a także wywołała oburzenie wśród organizacji chrześcijańskich. Singel osiągnął najlepszy wynik sprzedaży w historii Warner Bros. Records.
W lutym 1990 „Enjoy the Silence” zajął szóste miejsce w Wielkiej Brytanii oraz ósme w USA. Singel wygrał "Best British Single" podczas Brit Awards w 1991. Podczas promocji nowego albumu Violator zorganizowano spotkanie z fanami w Wherehouse Entertainment w Los Angeles. Przybyło wówczas około 20 000 osób zainteresowanych otrzymaniem autografu, wiele z nich doznało obrażeń na skutek napierającego tłumu oraz doszło niemalże do zamieszek. W ramach przeprosin ze strony zespołu ukazała się limitowana edycja nagrań dedykowana fanom w Los Angeles, wyemitowana także przez radio KROQ, które było sponsorem spotkania w Wherehouse Entertainment.
„Violator” uplasował się w pierwszej dziesiątce angielskiej listy, w USA pokrył się potrójną platyną za sprzedaż wynoszącą 3,5 miliona egzemplarzy. Ostatni na płycie „Clean” zawiera linię basu „One of These Days” zespołu Pink Floyd. Zespół udał się w trasę World Violation Tour – miarą popularności było 40 000 biletów sprzedanych w przeciągu ośmiu godzin na koncert w Nowym Jorku, 48 000 biletów w ciągu godziny w Los Angeles.
Songs of Faith and Devotion (1993).
W 1991 Gahan rozważał opuszczenie szeregów zespołu, do pozostania przekonały go nowe kompozycje Gore’a oraz wzbogacenie brzmienia o tradycyjne instrumenty. Dave Gahan:
Album „Songs of Faith and Devotion” przyniósł nowe aranżacje oparte na zniekształconym dźwięku gitary elektrycznej, dudach (gościnny udział Steaffana Hannigana) oraz wokalach w stylu gospel (Hilda Campbell, Bazil Meade, Samantha Smith). Kolejna zmiana to Alan Wilder grający na perkusji – w tej roli zadebiutował już w piosence "„Clean”" z poprzedniego albumu. Płyta dzięki tym zabiegom nabrała bardziej rockowego charakteru. "„Songs of Faith and Devotion”" zajął pierwsze miejsce na listach w Anglii i USA. Po jego wydaniu odbyła się czternastomiesięczna trasa Devotional, udokumentowana filmem oraz druga płytą koncertową „Songs of Faith and Devotion Live”.
W tym czasie Dave Gahan uzależnił się od heroiny, doznał ponadto ataku serca. Andy Fletcher odmówił wzięcia udziału w ostatniej części trasy z powodu załamania nerwowego i został zastąpiony na scenie przez Daryla Bamonte, który był wieloletnim współpracownikiem zespołu.
1 czerwca 1995 Alan Wilder ogłosił odejście z Depeche Mode, w swoim oficjalnym oświadczeniu napisał:
Andrew Fletcher:
Alan Wilder kontynuuje karierę w zespole Recoil.
W tym czasie duże obawy budził stan psychiczny Gahana – w 1995 próbował odebrać sobie życie, a rok później o mało nie przedawkował podczas pobytu w hotelu.
Ultra (1997).
Lata 1995 i 1996 to próby ze strony Martina Gore’a, aby zebrać zespół i rozpocząć pracę nad kolejnym wydawnictwem. Jednakże Gahan jeśli w ogóle zjawiał się na sesje to zajmowało mu tygodnie, aby nagrać cokolwiek. Gore rozważał nawet wydanie napisanych wówczas utworów na swojej solowej płycie, jednak ostatecznie do tego nie doszło. W połowie 1996 roku Gahan z dobrym skutkiem został poddany przymusowej terapii odwykowej. Wraz z producentem Timem Simenonem rozpoczęła się sesja albumu „Ultra”, wydanego rok później. Płyta zadebiutowała na miejscu pierwszym w Wielkiej Brytanii oraz piątym w USA. Ukazały się także single „Barrel of a Gun”, „It's No Good”, „Home” i „Useless”.
W 1998 ukazał się singel „Only When I Lose Myself”, pochodzący jeszcze z sesji "„Ultra”", promujący składankę „The Singles (86-98)”. Zespół udał się na czteromiesięczną trasę koncertową.
Exciter (2001).
W 2001 roku ukazał się „Exciter”, wyprodukowany przez Marka Bella. Albumowi nie udało się osiągnąć wyniku sprzedaży trzech swoich poprzedników, mimo że znalazł się w pierwszej dziesiątce w Wielkiej Brytanii i USA, otrzymał dość zróżnicowane recenzje w prasie. "„Exciter”" był pierwszą płyta zespołu która uplasowała się wyżej w USA niż w rodzimym kraju zespołu. Jako single zostały wydane „Dream On”, „I Feel Loved”, „Freelove” oraz „Goodnight Lovers”. Na późniejszych koncertach w ramach „Touring The Angel” grupa przedstawiała tylko „Goodnight Lovers” lub w ogóle cały album pomijała. Dave Gahan:
W 2004 ukazało się DVD Devotional, a także kompilacja „Remixes 81–04”, zawierająca nową wersję „Enjoy the Silence” autorstwa Mike’a Shinody, zatytułowana „Enjoy the Silence 04”.
Playing the Angel (2005).
Jedenasty album „Playing the Angel” ukazał się w październiku 2005, wyprodukowany przez Bena Hilliera. Była to pierwsza płyta Depeche Mode z tekstami Gahana oraz pierwsza od czasu "Some Great Reward", zawierająca piosenki które nie zostały napisane przez Gore’a. Dave Gahan:
Album zajął pierwsze miejsce na listach w siedemnastu krajach. Na singlach ukazały się „Precious”, „A Pain That I’m Used To”, „John the Revelator” oraz „Suffer Well” – pierwszy singel od czasów Clarke’a niebędący kompozycją Gore’a. W latach 2005–2006 zespół udał się w trasę Touring the Angel, obejmującą Amerykę Północną i Europę. Po raz pierwszy grupa odwiedziła Rumunię i Bułgarię. Na koncert w Meksyku 55 000 biletów zostało natychmiast sprzedane, co spowodowało zorganizowanie jeszcze jednego występu w tym mieście. Nagrania z 43 koncertów trasy ukazały się jako limitowane wersje na CD.
W 2006 i 2007 roku sukcesywnie ukazywały się nowe, zremasterowane wersje albumów. 3 kwietnia 2006: "Speak &amp; Spell", "Music for the Masses" i "Violator" w wersji SACD i DVD; "Broken Frame", "Some Great Reward", "Songs of Faith and Devotion" – 2 października 2006; "Construction Time Again", "Black Celebration": 26 marca 2007; "Ultra", "Exciter" – 1 października 2007. 25 września 2006 ukazało się DVD , będący zapisem koncertów z 18 i 19 lutego 2006, w reżyserii Blue Leach. W listopadzie 2006 ukazała się kompilacja „The Best Of, Volume 1”, zawierająca nowy utwór „Martyr”, pochodzący z sesji "Playing the Angel". 2 listopada zespół wygrał MTV Europe Music Awards w kategorii "Best Group".
W grudniu 2006 Depeche Mode otrzymało nominację nagrody Grammy w kategorii "Best Dance Recording" za utwór „Suffer Well”. W połowie grudnia iTunes wydał dyskografię The Complete Depeche Mode.
Sounds of the Universe (2009).
W lipcu 2007, podczas promocji drugiego solowego dzieła Gahana „Hourglass”, ogłoszono, że w 2008 Depeche Mode planuje nagranie kolejnego albumu. W marcu 2008 pojawiły się pogłoski jakoby Ben Hillier ma być jego producentem. W maju zespół pojawił się w studio, aby pracować nad utworami które przedstawił Gore. W sierpniu zespół pożegnał się z Warner Music, aby podpisać kontrakt z EMI. Podczas konferencji prasowej, która odbyła się 6 października 2008 roku w Berlinie, zespół ogłosił trasę koncertową Tour of the Universe. Na serwisie YouTube ukazała się seria filmów dokumentująca pracę w studiu. 15 stycznia 2009 na oficjalnej stronie zespołu pojawił się tytuł nowej płyty: „Sounds of the Universe”. Album ukazał się 20 kwietnia 2009, był promowany singlem „Wrong”, do którego teledysk wyreżyserował Patrick Daughters. Wydany został także box set „Sounds of the Universe Deluxe Edition Box Set” zawierający cały materiał z sesji nagraniowej.
Delta Machine (2013).
Premiera „Delta Machine” odbyła się 26 marca 2013 roku. 1 lutego w serwisie Vevo oraz YouTube pojawił się teledysk do najnowszego singla zespołu pt. „Heaven”. Miesiące marzec i kwiecień to promocja płyty w kilku stacjach TV w USA oraz Europie [min. 11 marca 2013 New York, Live on Letterman] oraz kameralne występy na żywo [min. 24 marca 2013 roku – Wiedeń, Museums Quartier podczas „Album Launch Event”]. Oficjalnie zespół rozpoczął swoją światową trasę koncertową "The Delta Machine Tour 2013/14" występem we francuskim Nice, Palais Nikaia 4 maja 2013 roku, a zakończył 4 marca 2014 w hali Olimpijskij w Moskwie. Koncert Depeche Mode w Polsce miał miejsce 25 lipca na Stadionie Narodowym w Warszawie, sprzedano ponad 53 tys. biletów. 24 lutego 2014 roku odbył się koncert grupy w Atlas Arenie w Łodzi, sprzedano ponad 15 tys. biletów.
Spirit (2017).
Premiera „Spirit” odbyła się 17 marca 2017 roku. 3 lutego w serwisie Vevo oraz YouTube pojawił się teledysk do najnowszego singla zespołu pt. „Where’s the Revolution”. Zespół rozpoczął swoją światową trasę koncertową The Global Spirit Tour występem w Sztokholmie 5 maja 2017 roku. Koncert Depeche Mode w Polsce miał miejsce 21 lipca 2017 r. na Stadionie Narodowym w Warszawie. Grupa wystąpiła 7, 9 i 11 lutego 2018 r. kolejno w Krakowie, Łodzi i Gdańsku. Kolejny występ odbył się w Polsce 5 lipca 2018 r. na festiwalu Open’er w Gdyni.
W 2020 roku Depeche Mode włączono do Rock and Roll Hall of Fame. Oprócz aktualnego składu, zaszczytu tego dostąpili też byli członkowie grupy, Vince Clarke i Alan Wilder.
Wewnątrz zespołu.
Od początku istnienia grupy nad jej karierą czuwał producent, Daniel Miller. Mimo że Miller formalnie nigdy nie należał do zespołu, jego rola w rozwoju Depeche Mode jest jednak bardzo duża. Jego twórczy i organizacyjny wkład w pracę był znaczący zwłaszcza w początkowych latach.
Po odejściu Clarke’a, lidera pierwotnego składu, grupa nie rozwiązała się i kontynuowała działanie. Prawdopodobnie wpłynęło na to niezdecydowanie muzyków i niechęć do podejmowania decyzji oraz właśnie zaangażowanie Daniela Millera, dla którego grupa była wcieleniem młodzieżowego elektronicznego popu, jaką sobie wymyślił, i której sukcesu się spodziewał. Grupa nie doczekała się kolejnego wyraźnego lidera i od tej pory istniała pod życzliwą opieką Millera jako zbitek indywidualności podejmujących wszelkie decyzje w sposób zbiorowy i demokratyczny.
Grupa działa na specyficznych zasadach artystycznych, organizacyjnych i towarzyskich. Trzon Depeche Mode tworzyły trzy osoby: Martin Gore, David Gahan i Andy Fletcher. Kompozytorem repertuaru grupy (i niekiedy wokalistą) jest Gore, jednak jako silny introwertyk nie stara się nią kierować. Z drugiej strony nawet jego solowe projekty i praca z innymi grupami nie odciągnęły go od pracy w zespole. Przeciwieństwem zamkniętego w sobie Gore’a jest wokalista Dave Gahan, ekstrawertyk i urodzony frontman. Tych dwóch członków grupy łączyła osoba Andy’ego Fletchera, który miał wprawdzie najmniejszy wkład w muzyczny dorobek grupy, ale przyjaźnił się ze skrytym Gorem i w naturalny sposób zapewniał jego komunikację z pozostałymi członkami ekipy. Dbał także o sprawy czysto organizacyjne. Andrew Fletcher:
Dave Gahan:
Na płaszczyźnie artystycznej podstawą działalności Depeche Mode jest szczególne porozumienie między Gorem i Gahanem, dwoma twórczymi biegunami grupy, jednak pod względem towarzyskim ci dwaj nie są mocno związani, głównie z powodu zamkniętego usposobienia Gore’a.
Grupa od początku prowadziła bujne życie rozrywkowe, któremu sprzyjała rosnąca popularność i częste trasy koncertowe, a także towarzystwo grup, które supportowały ich występy. Przez wiele lat udawało im się unikać zagrożeń płynących z nieustannego imprezowania, aż w końcu David Gahan popadł z tego powodu w poważne problemy życiowe, zdołał jednak wrócić do formy, a grupa pokonała kryzys wywołany jego uzależnieniami.
Depeche Mode jako grupa elektroniczna często współpracowała z różnymi inżynierami dźwięku. Podobnie jak Miller nie byli oni nigdy członkami grupy, ale na równi z nimi wpływali na kształt i styl kolejnych albumów. To także ważny element tej nietypowej grupy muzycznej.
Subkultura.
Grupa ma wielu fanów na całym świecie, w tym również w Polsce, gdzie tworzą oni dość charakterystyczną subkulturę. Nazywani są depeszowcami lub depeszami. Fani grupy spotykają się na organizowanych przez siebie zlotach fanów Depeche Mode oraz depotekach. Organizują się także w fanklubach.
Zloty fanów w Polsce.
Impreza organizowana przez fanów Depeche Mode dla fanów Depeche Mode. Zloty takie odbywają się w różnych miastach w Polsce i na świecie. Ideą tych spotkań jest wspólna zabawa przy dźwiękach zespołu. Przy okazji tych spotkań spotykają się depesze z różnych zakątków kraju. Na zlotach fanów Depeche Mode często organizowane są wszelakiego rodzaju konkursy jak: Dave dancing (konkurs tańca) czy konkurs śpiewu. Liczba i rodzaj konkursów jest zależna od organizatora. Organizatorami takich zlotów są przeważnie fankluby Depeche Mode. Na zlotach organizowane są także koncerty zespołów grających muzykę pokrewną lub inspirowaną Depeche Mode. Na zlotach o północy zgromadzonym ludziom przygrywa Pimpf – instrumentalny utwór, przy którym fani biorą się za ręce i tworzą okrąg falując ramionami. Organizatorzy zlotów starają się dbać pod każdym względem o uczestnika takiej imprezy przygotowując wystrój lokalu oparty na symbolice zespołu bądź wyświetlając przez telebim materiały związane z Depeche Mode tzw. wizualizacje. Największe zloty w Polsce odbyły i odbywają się w: Warszawie, Bytomiu, Bielsku-Białej, Bydgoszczy, Chorzowie, Inowrocławiu, Katowicach, Łodzi, Pabianicach, Poznaniu, Sopocie, Toruniu, Wrocławiu, Zielonej Górze oraz Nowym Tomyślu. Historycznie pierwszy zlot fanów Depeche Mode w Polsce miał miejsce w Szczecinie i był zorganizowany przez fanklub „Sattelite” (pierwsza połowa lat 80 XX wieku). Drugi zlot i kilka kolejnych było zorganizowanych w Pabianicach przez pabianicki fanklub „Muzyka dla mas”. Równie historycznym wydarzeniem był warszawski zlot, który odbył się pod patronatem Radia Wa-wa i Listy Przebojów Pr.3 Polskiego Radia, w 1992 roku w klubie Agon 501. Ci sami organizatorzy, aż do dziś prowadzą cykliczne imprezy z muzyką Depeche Mode w Warszawie pod nazwą "My Secret Garden Party".

</doc>
<doc id="1276" url="https://pl.wikipedia.org/wiki?curid=1276" title="Drawidowie">
Drawidowie

Drawidowie, Drawidzi – grupa ludów zamieszkująca południowe Indie i północną Sri Lankę, posługująca się językami drawidyjskimi. Największe ludy drawidyjskie to Tamilowie, Keralczycy, Telugowie i Tulu.
Istnieją hipotezy, że to Drawidowie zbudowali tzw. cywilizację doliny Indusu, istniejącą od 3 do 2 tysięcy lat p.n.e. w dorzeczu Indusu. Harappa i Mohendżo-Daro wyludniły się być może jeszcze przed najazdem Ariów. Według wielu przypuszczeń Drawidowie w północnych Indiach zostali zdegradowani w hierarchii społecznej dając początek niższym warnom.
Zgodnie z inną koncepcją Drawidowie są potomkami wzmiankowanych w Rygwedzie Dasów.

</doc>
<doc id="1279" url="https://pl.wikipedia.org/wiki?curid=1279" title="Deszcz">
Deszcz

Deszcz – opad atmosferyczny (hydrometeor), dosięgający powierzchni Ziemi w postaci kropel wody o średnicy większej od 0,5 mm. Gdy krople są mniejsze niż 0,5 mm, opad taki nazywa się mżawką. Opad niesięgający powierzchni Ziemi nazywa się virgą.
Duże krople wody (powyżej 8 mm) spadając ulegają rozpadowi. Deszcz może powstawać też z lodowych chmur wysokich, gdy opadające i ogrzane w pobliżu powierzchni Ziemi kryształy przekształcają się w krople wody, które mogą być wtedy duże lub małe w zależności od wilgotności względnej powietrza.
Intensywność deszczu klasyfikuje się jako: „lekki opad”, gdy spada nie więcej niż 2,5 mm wody na godzinę, „umiarkowany opad” – pomiędzy 2,5 a 7,5 mm wody na godzinę, „silny opad” – powyżej 7,5 mm wody na godzinę. 1 mm opadu to 1 litr wody na metr kwadratowy.
Powstawanie deszczu.
Deszcz powstaje w wyniku cyrkulacji atmosferycznej. Aby mógł powstać deszcz, najpierw muszą wytworzyć się odpowiednie ilości chmur. Proces rozpoczyna się od parowania wody z powierzchni Ziemi. Wraz z ciepłym powietrzem w atmosferze unosi się para wodna, która w wyniku spadku temperatury wraz z wysokością (około 0,6 °C na 100 m) ulega kondensacji, skraplając się lub krystalizując. Stałe formy opadu zmieniają się w ciekłe gdy znajdą się w temperaturze powyżej temperatury topnienia lodu. Aby opad mógł wystąpić, kropelki wody znajdujące się w chmurze muszą nabrać odpowiedniej masy (łącząc się ze sobą - Akrecja). Masa ta jest ważna z dwóch powodów. Po pierwsze w czasie opadania może wystąpić parowanie. Ponadto szybkość opadania kropli zależy od jej wielkości, a małe wolno opadające krople są niesione przez prądy powietrza i mogą unieść się wyniku działania prądów wstępujących.
Opady deszczu na świecie.
Zjawiska deszczu występują na większości obszarów Ziemi, wyjątek stanowią jedyne tereny gdzie panuje klimat polarny ze stałymi ujemnymi temperaturami. Opady deszczu są nierównomiernie rozłożone, czego przyczyną są głównie uwarunkowania cyrkulacji atmosferycznej (obieg wody) i cyrkulacja mas powietrza. Najmniejsze opady występują na pustyniach, stepach, w głębi lądu, gdzie dominują wyże baryczne, a obieg wody jest zaburzony. Największe opady występują w strefie równikowej, gdzie obieg wody jest ciągły, a obszar znajduje się w obrębie niżów.
Sztuczny deszcz.
Deszcz można wywołać sztucznie w następującym procesie: w okolicy wierzchołka chmury rozpyla się sztuczne jądra lodowe. Na ogół są to kryształki suchego lodu i jodku srebra. Pierwsza substancja wytwarza wokół siebie temperaturę do −78 °C, w której bardzo szybko powstaje duża ilość naturalnych kryształków lodowych. Z jodku srebra łatwo jest wywołać dym o bardzo drobnych cząsteczkach, które stają się jądrami krystalizacji. Tego typu opady należy wytwarzać najlepiej w temperaturze −10 °C. oraz przy stosunku jąder do kropli 1:1000. W innym wypadku deszcz może nie spaść w ogóle. Aby wytworzyć sztuczny opad, niezbędna jest wiedza na temat fizyki chmury (jej właściwości). Sztuczne opady nie są obfite i zwykle wynoszą do 10 mm i trwają do 15 minut.
Określenia potoczne.
Opad deszczu może mieć charakter przelotny, krótkotrwały o charakterze nawalnym (ulewa, oberwanie chmury).
Kapuśniaczek to deszcz o drobnych kroplach i niewielkiej intensywności i zazwyczaj przelotny.

</doc>
<doc id="1280" url="https://pl.wikipedia.org/wiki?curid=1280" title="Dolní Věstonice (stanowisko archeologiczne)">
Dolní Věstonice (stanowisko archeologiczne)

Dolní Věstonice – stanowisko archeologiczne koło wsi Dolní Věstonice na Morawach (Czechy). Jedno z najbardziej znanych stanowisk archeologicznych w Europie Środkowej. Wiek najstarszych odkrytych tam obozowisk łowców mamutów szacuje się na 28 tysięcy lat.
W 1937 roku odnaleziono tam kość promieniową młodego wilka z regularnymi nacięciami krzemieniem, co mogło świadczyć o wczesnych próbach mierzenia i liczenia. Kość ta zawiera 57 nacięć, z których pierwsze 25 zostało pogrupowane po 5 nacięć równej długości. Może to odnosić się do liczenia do pięciu palców u dłoni. Kość datowana jest na około 30-25 tysięcy lat p.n.e.
Trzech mieszkańców Dolních Věstonic żyło 31.115 lat temu (data kalibracji). Miało mitochondrialną haplogrupę U i jedną mieszańcową haplogrupę mitochondrialną U8.
W próbce Věstonice 13 oznaczono chromosomalną Y haplogrupę CT (notIJK), dla próbki Věstonice 15 - haplogrupę chromosomu Y BT, w próbce Věstonice 43 - haplogroupę Y chromosomu F, w próbce Věstonice 16 - chromosom Y haplogrupa C1a2.

</doc>
<doc id="1281" url="https://pl.wikipedia.org/wiki?curid=1281" title="Dzikowy skarb">
Dzikowy skarb

Dzikowy skarb – powieść Karola Bunscha z roku 1945, rozpoczynająca tzw. cykl piastowski. Na tło historycznych wydarzeń z czasów Mieszka I (chrzest Polski, zajęcie ujścia Odry, bitwa pod Cedynią) rzucono losy dwóch fikcyjnych bohaterów: mocarnego, choć prostodusznego Dzika oraz słabego, lecz chytrego Szmatki.
Treść powieści rozpoczyna się w 963 roku. Z podróży na Zachód wraca syn księcia Ziemomysła – Mieszko. Z podróży tej przywozi dziwnego człowieka niejedzącego raz na siedem dni mięsa, stroniącego od miodu i dziewek, wierzącego w Jedynego Boga. Tymczasem brat Mieszka – Ścibor, w czasie polowania, goniąc wielkiego odyńca, trafia w ostępach puszczy na zbójeckie gniazdo i do swej drużyny przyjmuje ogromnego Gniadego, którego nazywają od tej pory Dzikiem, gdyż zamiast ściganego odyńca to on stał się największą zdobyczą z polowania. Dobrym duchem i Dzika, i samego Mieszka jest niehistoryczny Zbrozło, pełnomocny dyplomata księcia i zapamiętały wróg nawały germańskiej, a wiernym aż do śmierci towarzyszem Dzika - młodszy od niego Tarło, syn władyki polańskiego. Dzik, wyrwawszy się z życia w głuszy, smakuje w winie i kobietach, co często sprowadza na niego kłopoty, podobnie jak jego buta i odwaga. Powieść oprócz opisów walk mówi o problemach ludzi, którzy nie mając korzeni, gubią się w świecie pełnym zdrady i samolubstwa.

</doc>
<doc id="1282" url="https://pl.wikipedia.org/wiki?curid=1282" title="Donald I">
Donald I

Donald I, Donald MacAlpin (ur. ok. 812, zm. 13 kwietnia 862) – król Alby (Szkocji) 858–862.
Życiorys.
Był młodszym synem króla Dalriady Alpina II. Objął władzę nad Piktami i Szkotami po swoim bracie Kennecie MacAlpinie. Ustanowił zbiór praw i zasad (tzw. prawa Aeda), które kodyfikowały m.in. tradycyjny zwyczaj wyboru następcy naczelnika czy króla spośród członków klanu ("tanistry") jeszcze za życia króla. W taki sposób został wybrany następca Donalda I, jego bratanek, Konstantyn I. Zwyczaj "tanistry" w szkockiej rodzinie panującej przetrwał aż do czasów króla Malcolma II w XI w.
Donald MacAlpin nie był żonaty i nie pozostawił potomków; zmarł w 862 r. lecz nie są znane okoliczności jego śmierci oraz miejsce pochówku.

</doc>
<doc id="1283" url="https://pl.wikipedia.org/wiki?curid=1283" title="Mired">
Mired

Mired [M] – jednostka temperatury barwowej światła. Jeden mired jest równy 106 K-1 = 1 MK-1. W użyciu jest również wielokrotność tej jednostki, dekamired: 1 daM = 10 M.
Są to wychodzące już z użycia jednostki, w jakich podaje się jeszcze czasami wartości filtrów korekcyjnych nakładanych na obiektywy aparatów fotograficznych.

</doc>
<doc id="1285" url="https://pl.wikipedia.org/wiki?curid=1285" title="Diadumemian">
Diadumemian



</doc>
<doc id="1286" url="https://pl.wikipedia.org/wiki?curid=1286" title="Delmatius">
Delmatius



</doc>
<doc id="1287" url="https://pl.wikipedia.org/wiki?curid=1287" title="Dialekt">
Dialekt

Dialekt, narzecze – wieloznaczny termin lingwistyczny. W najogólniejszym znaczeniu dialekt to odmiana języka, która odznacza się swoistymi cechami fonetycznymi, leksykalnymi czy gramatycznymi, odróżniającymi ją od innych form tego języka. Wszystkie dialekty w jednakowy sposób rządzą się zespołem zasad gramatycznych, choć ich systemy bywają silnie zróżnicowane.
Różnice dialektalne wykazują zasadniczo wszystkie języki świata, przy czym tylko niektóre z nich mają swoją odmianę ogólną, tzw. dialekt standardowy. Pewną formą dialektu (wariantem językowym o ustalonej strukturze) posługuje się każdy użytkownik języka. Czynniki społeczne prowadzą jednak do porzucania środków gwarowych na rzecz elementów języka standardowego, uważanych za neutralne geograficznie.
Zakres odrębności dialektalnych różni się w zależności od języka. Niektóre języki, jak np. rosyjski, przejawiają je w stosunkowo niewielkim stopniu, a istniejące dialekty mają dość szeroki zasięg geograficzny. W przypadku innych języków, takich jak niemiecki, można wyróżnić dużą liczbę wciąż żywych dialektów. Same dialekty mogą być zróżnicowane wewnętrznie i wykazywać drobne różnice na poziomie lokalnym (w języku polskim mówi się wówczas o gwarach). Granice między poszczególnymi dialektami bywają nieostre i trudne do wyznaczenia.
Badaniem dialektów (zwłaszcza regionalnych) zajmuje się dział językoznawstwa – dialektologia. W rozumieniu dialektologii tradycyjnej dialekt to byt przeciwstawiany językowi standardowemu.
Historia terminu.
Termin „dialekt” wywodzi się z greckiego słowa "diálektos" () oznaczającego "dyskurs, rozmowę, sposób mówienia", a które z kolei pochodzi od słów "diá" ( „poprzez”) i "legō" ( „mówię”). Określenie to pojawiło się w europejskim piśmiennictwie już w XVI wieku i pierwotnie oznaczało "sposób mówienia", "manierę" charakterystyczną dla danego mówiącego.
Współcześnie pod pojęciem tym rozumie się wariant języka wyodrębniony na podstawie pewnych odmienności, wynikających ze zróżnicowania geograficznego lub stratyfikacji społecznej jego użytkowników. Czyni się rozróżnienie między formami terytorialnymi a formami stratyfikacyjnymi, zwanymi precyzyjniej socjolektami. Rozgraniczenie to nie jest jednak ścisłe, gdyż formy o podłożu terytorialnym bywają zarazem ograniczone socjalnie.
Rodzaje dialektów.
Można wyróżnić dialekty regionalne, będące przedmiotem tradycyjnych badań dialektologicznych, oraz dialekty socjalne, których istnienie zostało stwierdzone przez późniejszą dialektologię miejską.
Brytyjski językoznawca Peter Trudgill proponuje następujący podział dialektów:
Podział języka na dialekty.
Z punktu widzenia lingwistyki język nie jest konkretnym tworem, lecz zespołem rozmaitych dialektów, na który mogą się składać zarówno odmiany o podłożu geograficznym i socjalnym, jak też ponadgwarowe standardy. Język zawsze się manifestuje w formie pewnej odmiany; z perspektywy lingwistycznej można zatem przyjąć, że każdy użytkownik języka posługuje się jakimś dialektem. Pośród dialektów wchodzących w skład języka nie można wyróżnić form wyższych ani niższych, choć obiegowe poglądy często przypisują rozmaitym dialektom różną wartość, a określony dialekt może być identyfikowany z konkretną funkcją komunikatywną. Praktykę używania dwóch odmian/dialektów języka (zwykle języka standardowego i dialektu miejscowego) przez jedną wspólnotę komunikatywną określa się mianem dyglosji.
Słowem „dialekt” często określa się formy języka bez postaci pisanej, w opozycji do form ustandaryzowanych lub literackich (grafolektów), o których mawia się „języki”. Mianem dialektów bywają określane także autonomiczne języki, które nie wypracowały tradycji piśmienniczej (niekiedy mowa np. o „dialektach afrykańskich”), niezgodnie z terminologią językoznawczą.
Charakterystyka pojęcia.
W rozumieniu językoznawstwa dialekt jest formą egzystencji języka charakterystyczną dla pewnej grupy jego użytkowników. Termin ten odnosi się w pierwszej kolejności do form wydzielonych geograficznie (geolektów/regiolektów), choć w szerszym ujęciu, charakterystycznym dla językoznawstwa angielskiego (gdzie jest w praktyce traktowany jako synonim ), może dotyczyć także mowy jakiejś grupy społecznej (socjolekt) lub etnicznej (etnolekt). Zgodnie ze współczesną definicją naukową jako swoiste dialekty można rozpatrywać wszystkie odmiany języka, także standardowe (literackie); w lingwistyce czyni się zatem rozróżnienie między dialektami standardowymi a niestandardowymi (wernakularnymi). W języku codziennym, a także w niektórych tradycjach językoznawczych występuje węższe ujęcie, zgodnie z którym dialekt to regionalny (lub socjalny) wariant języka, z definicji przeciwstawiany standardowi, czyli jego skodyfikowanej formie normatywnej. W skrajnej definicji pojęcie dialektu odnosi się również do idiolektów, tj. kodów właściwych dla poszczególnych jednostek.
Oba podejścia do definicji dialektu funkcjonują równolegle, choć w przypadku niektórych języków podejścia wartościującego nie da się zastosować z przyczyn obiektywnych. Przykładem może być język włoski, w którym za język standardowy służy dialekt florencki, równoważny i równorzędny innym dialektom tego języka.
Poszczególne dialekty można często dzielić na mniejsze formy, odzwierciedlające ich wewnętrzne zróżnicowanie: warianty lub poddialekty (subdialekty), w polskiej tradycji językoznawczej nazywane gwarami. Terminy „dialekt” i „gwara” są jednak często traktowane jako równoznaczne, zarówno w języku codziennym, jak i w terminologii naukowej. W kontekście badań literaturoznawczych pojęciem w praktyce tożsamym z szerzej ujmowanym dialektem jest rejestr stylistyczny.
W języku codziennym mianem "dialektów" określa się również języki pozbawione formy pisanej lub standaryzacji, używane w krajach rozwijających się lub odizolowanych częściach świata. Takie znaczenie terminu nie znajduje szerokiej akceptacji w literaturze językoznawczej, gdzie mówi się raczej o językach wernakularnych. Ponadto specjaliści czynią rozróżnienie między terminami „dialekt”, „slang” i „akcent”: akcent w socjolingwistyce dotyczy jedynie sposobu wymowy, tzn. cech fonetycznych lub fonologicznych właściwych dla pewnej grupy ludzi, slang stanowi zaś zbiór specyficznych środków leksykalnych, zwykle nietrwałych i kojarzonych ze środowiskami młodzieżowymi. Dialektem nazywa się natomiast odmianę języka, która jest odrębna na płaszczyźnie gramatyki, również w zakresie fonologii, a często także na poziomie słownictwa.
Język a dialekt.
Dialektami nazywane są różne odmiany jednego języka mówionego. O uznaniu jakiejś mowy za odrębny język, nie zaś za wariant danego języka decydują w znacznie większym stopniu rozstrzygnięcia pozajęzykoznawcze niż językoznawcze. W dyskusjach o różnicy pomiędzy językiem a dialektem często pojawia się aforyzm, przypisywany Maxowi Weinreichowi: „Język to dialekt z armią i flotą wojenną”. Jak głosi powiedzenie, rozróżnienie między terminami „język” a „dialekt” nie jest ścisłe: wydzielanie języków ma często charakter konwencjonalny i jest wyraźnie zależne od czynników socjopolitycznych.
Na gruncie językoznawstwa można uznać, że dwa kody komunikacyjne tworzą jeden język, jeśli są między sobą zrozumiałe. Kryterium to nie jest jednak stosowane w sposób ścisły, gdyż zjawisko wzajemnej zrozumiałości może przybierać różne stopnie nasilenia i występować w formie asymetrycznej. Rygorystyczne przestrzeganie tego kryterium uniemożliwiają również społeczne uwarunkowania językowe – wyodrębnianie języków bywa bowiem umotywowane powstawaniem organizmów państwowych oraz procesami standaryzacyjnymi zachodzącymi w obrębie kompleksów językowych (zob. Abstand- i Ausbausprachen). Istotną rolę odgrywa odgrywa także odległość geograficzna poszczególnych bytów językowych (por. przypadek języków polinezyjskich).
Przykładem mowy o spornym statusie jest kaszubszczyzna, uznawana przez niektórych specjalistów za dialekt języka polskiego, a przez innych za język zupełnie odrębny od polszczyzny ogólnej. Także wśród użytkowników mowy kaszubskiej nie ma jednomyślności na powyższy temat; Ministerstwo Edukacji RP uznało ostatecznie w 1996 roku kaszubszczyznę za język regionalny. Z drugiej strony język chiński oficjalnie (i przez większość użytkowników) uznawany jest za jeden język o dużej liczbie dialektów, pomimo że całkowicie wzajemnie niezrozumiałych, a specjaliści uznają go raczej za zespół języków. Poglądowi temu sprzyja fakt, iż wszystkie chińskie dialekty w piśmie są wzajemnie zrozumiałe.
W niektórych zakątkach świata, gdzie ludność posługuje się blisko spokrewnionymi i podobnymi językami, można mówić o istnieniu kontinuum, w którym trudno nakreślić granice między różnymi językami. Przykładowo pewne dialekty języka niderlandzkiego są zbliżone do gwar dolnoniemieckich, choć te używane w Holandii są uznawane za gwary niderlandzkie, a gwary spotykane w Niemczech – za gwary niemieckie. Rozróżnienie to wynika z czynników politycznych.

</doc>
<doc id="1289" url="https://pl.wikipedia.org/wiki?curid=1289" title="Dolby Surround Pro Logic">
Dolby Surround Pro Logic

Dolby Surround Pro Logic – format dekodowania dźwięku otaczającego, dookólnego ( – otaczać). Jest to ulepszona wersja systemu dźwięku przestrzennego Dolby Surround, tym razem z czterema kanałami: przednim lewym, przednim centralnym i przednim prawym oraz kanałem tylnym. System został opracowany przez Dolby Laboratories i wprowadzony na rynek elektroniki konsumpcyjnej w 1987 roku. Był to drugi (po Dolby Surround) system dźwięku dookólnego surround powszechnie przyjęty do użytku domowego. Zasada kodowania/dekodowania sygnału wywodzi się z opracowanego dla potrzeb kin profesjonalnego systemu Dolby Stereo.
Dolby Pro Logic wykorzystuje dekodowanie matrycowe 4-kanałowego sygnału zapisanego na dwóch ścieżkach, zgodnie z założeniami formatu Dolby Surround. Jak wiadomo, nagrania Dolby Surround można odtwarzać na sprzęcie bez dekodera Dolby Pro Logic otrzymując w takich warunkach stereo dwukanałowe. "Dolbyzowane" nagrania zapewniają też dobrą kompatybilność z odtwarzaniem monofonicznym. Sprzęt wyposażony w dekoder Dolby Pro Logic dekoduje matrycowo zakodowaną informację tak by stworzyć trzy kanały przednie oraz jeden kanał tylny odtwarzany przez dwa głośniki. W sumie do odtwarzania nagrań Dolby Surround (najlepiej) jak i Stereo (dodatkowa zaleta formatu) wykorzystuje się pięć zestawów głośnikowych. Tylny kanał surround ma pasmo ograniczone do zakresu 100Hz-7kHz i jest opóźniony zwykle o 20 ms. względem kanałów przednich.
Dzięki temu, że Dolby Surround nagrywa się na dwóch ścieżkach, każdy dwukanałowy system Hi-Fi nadaje się do zapisu dźwięku Pro Logic. Nagrania w Dolby Surround pojawiają się na różnych nośnikach jak VHS, CD czy Laserdisc.
Dolby Pro Logic II.
Po roku 2000 pomysł rozwinięto po raz kolejny – powstał Dolby Pro Logic II.
Pozwala on na zapis w sygnale stereo pełnej ścieżki 5.1: lewy, centralny, prawy, lewy surround, prawy surround i głośnik niskotonowy (subwoofer).
Dolby Pro Logic IIx.
Dostępny jest również system umożliwiający kodowanie i dekodowanie dźwięku w kanałach 5.1, 6.1, lub 7.1

</doc>
<doc id="1290" url="https://pl.wikipedia.org/wiki?curid=1290" title="DIMM">
DIMM

DIMM () – szereg standardów modułów pamięci RAM, w których styki złącza krawędziowego modułu znajdują się po obu stronach płytki drukowanej. Wcześniej stosowane moduły miały styki tylko z jednej strony i były oznaczane jako SIMM.
Miniaturowe moduły DIMM oznaczane są przez SO-DIMM.
Wraz ze zmianą stosowanych układów pamięci zmieniała się liczba styków modułu oraz miejsca wcięć (kluczy) zapobiegając włożeniu nieodpowiedniego modułu do gniazda.
Najpopularniejsze typy DIMM to:

</doc>
<doc id="1293" url="https://pl.wikipedia.org/wiki?curid=1293" title="Dydona i Eneasz">
Dydona i Eneasz

Dydona i Eneasz () – opera w trzech aktach do libretta Nahuma Tate'a skomponowana przez Henry’ego Purcella. Po raz pierwszy wystawiona w Londynie w roku 1689.
Treść.
Akt I.
Królowa Kartaginy, Dydona, kocha Eneasza – wodza drużyny trojańskiej, który ocalał z pogromu zdobytej przez Greków Troi. Pierwsza dama dworu, Belinda, zapewnia Dydonę o wzajemności Eneasza, ale królowa na wszelki wypadek decyduje się przywitać go obojętnie. Mieszkająca w lesie Czarownica pragnie zguby Dydony i całej Kartaginy. Wie, że na drodze do szczęścia królowej może stanąć jedynie misja Eneasza w kraju Latynów.
Akt II.
Na cześć gości z Troi w lesie odbywa się polowanie. Chór intonuje pieśń, wspominając legendę o bogini łowów Dianie i rozszarpanym przez własne psy młodzieńcu Akteonie. Pojawiają się Dydona i Eneasz, jednak z powodu nadciągającej burzy królowa wraca do pałacu. Przed Eneaszem zjawia się posłaniec bogów Merkury, który przynosi mu rozkaz Jowisza – wódz musi natychmiast wyruszać, aby wypełnić misję w kraju Latynów. Nie wie, że rzekomy Merkury to w rzeczywistości jeden z demonów, służących przebiegłej Czarownicy.
Akt III.
Czarownica cieszy się, widząc rozpacz królowej Dydony. Co prawda Eneasz wyraża gotowość sprzeciwienia się woli bogów i pozostania w Kartaginie, jednak dumna Dydona nie wyraża na to zgody. Woli umrzeć, niż poślubić człowieka, który śmiał pomyśleć o jej porzuceniu.
Historia utworu.
Opera powstała w 1680 r. w Londynie. Określenie gatunku nie jest możliwe – ani opera seria, ani tragedie lyrique; czasami określa się ją jako masque. Stylistyką nawiązuje do epoki późnego renesansu (bliżej szkoły florenckiej, niż weneckiej). Obecne są w niej dramatyczne recytatywy; krótkie arie; polifoniczne chóry; angielski kult śpiewu chóralnego; "malarstwo dźwiękowe", a także sceny komiczne. Jest w całości śpiewana i rozpoczyna się uwerturą francuską. Do znanych fragmentów należy "Lament Dydony" z 3 aktu: "When I am laid in earth", zgodnie z ówczesną tradycją oparty na basso continuo.

</doc>
<doc id="1294" url="https://pl.wikipedia.org/wiki?curid=1294" title="Długość geograficzna">
Długość geograficzna

Długość geograficzna (ang. "longitude"; symbol λ) – jedna ze współrzędnych geograficznych, kąt dwuścienny zawarty między półpłaszczyzną południka zerowego (południka przechodzącego przez park w Greenwich), a półpłaszczyzną południka przechodzącego przez dany punkt na powierzchni Ziemi.
Punkty położone na półkuli wschodniej, czyli na wschód od południka zerowego do 180°, mają długość geograficzną wschodnią (symbol E), czasem nazywaną też długością geograficzną dodatnią. Punkty położone na półkuli zachodniej, czyli na zachód od 0° do 180°, mają długość geograficzną zachodnią (symbol W), czyli ujemną. Wszystkie punkty położone na tym samym południku mają tę samą długość geograficzną.
W zależności od długości geograficznej, można obliczać matematycznie czas słoneczny miejscowy. Począwszy od południka zerowego, na którym czas nosi nazwę czasu uniwersalnego (GMT) to:
Do obliczeń czasu:
W przeszłości dla wyznaczania długości geograficznej istotne było od którego południka ją liczono. Wyznaczano ją m.in. od Ferro na Wyspach Kanaryjskich, Paryża, Rzymu i Pułkowa k. Petersburga. W 1911 Międzynarodowa Unia Geograficzna przyjęła za powszechnie obowiązujący południk przechodzący przez główny teleskop w Królewskim Obserwatorium Astronomicznym w Greenwich (dzielnica Londynu).
Historia.
Pomiar długości geograficznej jest istotny zarówno dla potrzeb kartografii, jak nawigacji morskiej. Marynarze i podróżnicy w przeszłości często stykali się z problemem jej precyzyjnego określenia. Szerokość geograficzna była obliczana z pomocą kwadrantu lub astrolabium, poprzez pomiar położenia Słońca lub wybranych gwiazd, ale długości geograficznej nie można było określić w podobny sposób. Amerigo Vespucci był prawdopodobnie pierwszym, który zaproponował rozwiązanie, poświęcając wiele czasu i sił na studiowanie problemu podczas swoich podróży po Nowym Świecie.
Poprzez porównanie względnych pozycji Księżyca i Marsa z ich oczekiwanymi pozycjami, Vespucci mógł z grubsza oszacować swoje położenie względem długości geograficznej. Jednak jego metoda miała kilka ograniczeń: po pierwsze, wymagała wystąpienia specyficznego zjawiska astronomicznego (w tym wypadku, przejścia Marsa w tej samej rektascensji co Księżyc) i obserwator musiał porównać obserwacje z danymi z almanachu. Trzeba było również znać dokładny czas, a to było trudne do ustalenia w dalekich krajach; dodatkowo metoda wymagała stabilnej platformy obserwacyjnej, o którą trudno na statku kołyszącym się na morzu.
W odróżnieniu od szerokości geograficznej, której naturalnym punktem zerowym, czyli punktem odniesienia, jest równik, dla długości geograficznej taki punkt nie istnieje. Zatem południk odniesienia, południk zerowy, musi być wybrany umownie. Częstą praktyką było uznawanie południka przechodzącego przez stolicę kraju, z którego wywodził się obserwator, za południk odniesienia. Brytyjscy kartografowie od dawna używali południka przechodzącego przez Greenwich w Londynie, ale w użyciu były jeszcze inne umowne "południki zerowe", przechodzące przez np. El Hierro, Rzym, Kopenhagę, Jerozolimę, Petersburg, Pizę, Paryż, Filadelfię czy Waszyngton. W 1884 w Waszyngtonie odbyła się międzynarodowa konferencja ("International Meridian Conference"), która zaakceptowała południk Greenwich jako uniwersalny południk zerowy.

</doc>
<doc id="1295" url="https://pl.wikipedia.org/wiki?curid=1295" title="Deflacja (ekonomia)">
Deflacja (ekonomia)

Deflacja (z łac. "deflo") – długotrwały spadek przeciętnego poziomu cen w gospodarce przekładający się na wzrost siły nabywczej pieniądza. 
W warunkach deflacji za tę samą ilość pieniędzy można kupować więcej towarów i usług. Przeciwieństwem deflacji jest inflacja.
Historia.
Przed 1930 rokiem w większości państw rozwiniętych deflacja była tak samo częstym zjawiskiem jak inflacja. Wraz ze spopularyzowaniem się teorii popytowych – głównie za sprawą Johna Maynarda Keynesa – zjawisko deflacji stało się rzadkie. 
Współcześnie deflacja występuje bardzo rzadko, gdyż w polityce ekonomicznej większości państw dominuje presja na utrzymywanie stałej, niewielkiej inflacji, uważanej obecnie przez sporą część ekonomistów za korzystną dla gospodarki (zwolennicy interwencyjnej polityki podaży pieniądza). Występowanie deflacji (jak na przykład w latach 90. XX wieku w Japonii) wiąże się zazwyczaj ze stagnacją gospodarczą przy jednoczesnym wysokim zadłużeniu wewnętrznym.
W sierpniu 2014 roku Główny Urząd Statystyczny i Narodowy Bank Polski zakomunikowały, że oznaki deflacji pojawiły się w Polsce (po raz pierwszy od 1972 roku).
W niektórych dziedzinach gospodarki obserwuje się częste spadki cen (np. telekomunikacja i informatyka, gdzie spadek cen urządzeń i usług nawet w skali jednego roku potrafi przekroczyć 50%), ale nie świadczy to bezpośrednio o deflacji – jest to efekt postępu technologicznego i wzrostu produkcji.

</doc>
<doc id="1298" url="https://pl.wikipedia.org/wiki?curid=1298" title="II Rzeczpospolita">
II Rzeczpospolita

II Rzeczpospolita (II RP; nazwa oficjalna: Rzeczpospolita Polska) – historyczne państwo polskie istniejące w latach 1918–1945, tj. od odzyskania suwerenności (1918) do wycofania uznania międzynarodowego dla rządu Rzeczypospolitej Polskiej na uchodźstwie (1945), które było konsekwencją wykonania porozumień zawartych na konferencji jałtańskiej (1945) między mocarstwami wielkiej trójki.Nazwa podkreśla ciągłość z I Rzecząpospolitą (1569–1795), zlikwidowaną traktatami rozbiorowymi zawartymi pomiędzy Austrią, Prusami i Rosją w drugiej połowie XVIII wieku (1772–1795). 
Podstawowy akt ustrojowy stanowiła Konstytucja marcowa, a następnie (od 1935) Konstytucja kwietniowa. Językiem urzędowym II Rzeczypospolitej był język polski, zaś walutą najpierw marka polska, a dopiero od 1924 złoty polski.
Ówczesna Polska była krajem niejednorodnym etnicznie (nieco ponad ⅔ ludności to Polacy), co stanowiło źródło problemów wewnętrznych. Największymi miastami (liczącymi ponad 200 tys. mieszkańców) były Warszawa (stolica Polski), Łódź, Lwów, Poznań, Kraków i Wilno, jednak zdecydowana większość ludności (70-75%) mieszkała na terenach wiejskich.
II RP powstała na fragmentach terytoriów Niemiec, Austro-Węgier i Rosji (zarówno „Kongresówki”, jak i „ziem zabranych”); pierwsze lata jej istnienia upłynęły pod znakiem sporów i walk o przyszłe granice oraz wojny polsko-bolszewickiej. Państwo to było republiką, początkowo rządzoną w sposób demokratyczny, od zamachu stanu w 1926 roku dążącą ku autorytaryzmowi.
W czasie II wojny światowej (1939–1945) terytorium państwowe II Rzeczypospolitej było okupowane przez Niemcy, ZSRR, Słowację i Litwę. II Rzeczpospolita zachowała suwerenność państwową, w stosunkach dyplomatycznych reprezentowana była przez rząd Rzeczypospolitej Polskiej na uchodźstwie, który uzyskał schronienie w Paryżu i Angers (na zasadzie eksterytorialnej do czerwca 1940), a następnie w Londynie, gdzie przeniósł swą siedzibę po klęsce Francji. Jako że państwo polskie wciąż posiadało konstytucyjne organy władzy państwowej (w tym tajną administrację cywilną i sądownictwo na terenie okupowanego kraju – Polskie Państwo Podziemne) i siły zbrojne, działające równolegle w podziemiu (Armia Krajowa) i na uchodźstwie, "de iure" i "de facto" II Rzeczpospolita istniała do 5 lipca 1945.
Większość terytorium państwowego II RP anektowanego przez ZSRR i Litwę w 1939 została w 1945 wcielona do Ukraińskiej SRR, Białoruskiej SRR i Litewskiej SRR. Obszary pozostałe przy Polsce stanowią większość terytorium współczesnego państwa polskiego, które w swojej Konstytucji wprost odwołuje się "do najlepszych tradycji Drugiej Rzeczypospolitej".
Daty graniczne.
Za symboliczny początek II Rzeczypospolitej przyjmuje się wydarzenia z 11 listopada 1918 roku, uznane za odzyskanie niepodległości przez Polskę, kiedy to Józef Piłsudski objął władzę wojskową z rąk Rady Regencyjnej w Warszawie. Tego samego dnia we francuskim Compiègne zostało podpisane zawieszenie broni pomiędzy państwami ententy a Niemcami, co formalnie zakończyło I wojnę światową, trwającą od 1914 roku. Trzy dni później (14 listopada) Piłsudski przejął również władzę cywilną, a zarówno Rada Regencyjna, jak i Tymczasowy Rząd Ludowy Republiki Polskiej rozwiązały się, przekazując władzę Piłsudskiemu, wkrótce Tymczasowemu Naczelnikowi Państwa.
Po agresji na Polskę III Rzeszy i ZSRR (kampanii wrześniowej) i okupacji wojennej terytoriów II RP przez obu agresorów (we wrześniu 1939) legalną kontynuacją władz II Rzeczypospolitej, uznawaną na arenie międzynarodowej przez cały okres II wojny światowej był Rząd RP na uchodźstwie, a jako podległa mu administracja w okupowanym kraju – Polskie Państwo Podziemne i jego struktury polityczne i wojskowe (Armia Krajowa).
Wycofanie uznania dyplomatycznego dla rządu RP na uchodźstwie przez Wielką Brytanię i USA 5 lipca 1945 roku (a następnie przez wszystkie pozostałe kraje świata zrzeszone w konstytuującej się wówczas Organizacji Narodów Zjednoczonych – jedynie Hiszpania, Kuba, Liban, Irlandia i Watykan jeszcze przez pewien czas po wojnie uznawały rząd RP na uchodźstwie) i w konsekwencji utratę podmiotowości prawnomiędzynarodowej należy uznać za formalny i faktyczny koniec II Rzeczypospolitej.
Ostatnim, symbolicznym aktem formalnego istnienia II Rzeczypospolitej było przekazanie 22 grudnia 1990 roku insygniów prezydenckich II Rzeczypospolitej i oryginału konstytucji kwietniowej przez Ryszarda Kaczorowskiego – ostatniego prezydenta II Rzeczypospolitej na uchodźstwie – pierwszemu wybranemu w wolnych wyborach prezydentowi RP – Lechowi Wałęsie.
Uznanie międzynarodowe.
Józef Piłsudski niezwłocznie po objęciu władzy cywilnej, tj. 16 listopada 1918 r., wystosował depesze do państw Ententy, informując je o powstaniu niepodległego państwa polskiego. Natomiast jako pierwsze istnienie niepodległego państwa polskiego uznały 20 listopada 1918 r. Niemcy, jednak już 15 grudnia 1918 roku Polska zerwała z tym państwem stosunki dyplomatyczne. Szersze uznanie niepodległości Polski na arenie międzynarodowej związane było z postawą Francji i Wielkiej Brytanii. Wkrótce po rozejmie w Trewirze i zawieszeniu broni na froncie polsko-ukraińskim, uznały rząd Polski: Rada Najwyższa Mocarstw Sprzymierzonych (21 lutego 1919 r.), Francja (24 lutego) oraz Wielka Brytania (25 lutego). Japonia 22 marca 1919 roku i 27 marca tego samego roku niepodległość Polski uznała Stolica Apostolska.
Terytorium i granice.
Długość granic.
Całkowita długość granic Polski – 5529 km
Granice z sąsiednimi państwami według długości
Ustalenie granic.
Granice II Rzeczypospolitej zostały ustalone traktatowo poprzez: traktat wersalski, traktat w Saint Germain, traktat ryski, traktat w Trianon i rozstrzygnięcia międzysojuszniczej Rady Ambasadorów. W 1921 w następstwie traktatu wersalskiego, wyników plebiscytu i trzech powstań śląskich do Polski przyłączono wschodnią część terytorium plebiscytowego na Górnym Śląsku.
Losy granic II Rzeczypospolitej.
Po zbrojnej agresji ZSRR na Polskę 17 września 1939, okupacji wojskowej wschodnich terenów II Rzeczypospolitej przez Armię Czerwoną i ustaleniu w dniu 28 września 1939 przez III Rzeszę i ZSRR w zawartym w Moskwie niemiecko-sowieckiej linii granicznej na okupowanych wojskowo przez Wehrmacht i Armię Czerwoną terenach Polski mieszkańcy obu okupowanych części państwa polskiego poddani zostali represjom przez okupantów.
Do Rzeszy bezpośrednio zostały wcielone: województwo pomorskie (Gdańsk-Prusy Zachodnie), śląskie, poznańskie (Kraj Warty), część łódzkiego z Łodzią, Suwalszczyzna, północna i zachodnia część Mazowsza oraz zachodnie części województw krakowskiego i kieleckiego.
Z terytorium Rzeczypospolitej pomiędzy linią granicy niemiecko-sowieckiej z 28 września 1939 a określoną w dekrecie wschodnią granicą ziem polskich wcielonych bezpośrednio do Niemiec (określoną jako nowa wschodnia granica Rzeszy) Adolf Hitler utworzył odrębny twór administracyjny podporządkowany Rzeszy – Generalne Gubernatorstwo.
W wyniku umowy między Niemcami i Słowacją, w listopadzie 1939 roku włączono do niej 52 przygraniczne gminy na Spiszu i Orawie.
Pozostałe terytorium Rzeczypospolitej Polskiej na wschód od linii granicznej ustalonej na terytorium Polski w układzie pomiędzy III Rzeszą a ZSRR zostało w październiku 1939 anektowane przez ZSRR. Formalną podstawą były pseudoplebiscyty w postaci wyborów w 1939, a następnie aneksja w trybie uchwały Rady Najwyższej ZSRR. Jednocześnie Związek Radziecki przekazał Wilno wraz z okręgiem Litwie, jednak w sierpniu 1940 r., po aneksji państw bałtyckich, również i ten obszar znalazł się w granicach ZSRR.
Były to akty prawne równoległe do dwóch dekretów Adolfa Hitlera (z 8 i 12 października 1939 r.), którymi jednostronnie wcielił zachodnie terytoria Polski do Rzeszy (zobacz: Tereny Rzeczypospolitej Polskiej anektowane przez III Rzeszę), tworząc jednocześnie z centralnych ziem II Rzeczypospolitej Generalne Gubernatorstwo.
Wszystkie powyższe akty prawne, rozporządzające jednostronnie suwerennym i określonym traktatami międzynarodowymi terytorium II Rzeczypospolitej były sprzeczne z ratyfikowaną przez Niemcy i Rosję . Były one w konsekwencji nieważne w świetle prawa międzynarodowego i nie były uznawane zarówno przez Rząd RP na uchodźstwie, jak i państwa sojusznicze wobec Polski, a także państwa trzecie (neutralne) przez cały czas trwania II wojny światowej. Wywodziły się z doktryny przyjętej wyłącznie przez III Rzeszę i ZSRR o zaprzestaniu istnienia państwa polskiego z dniem 28 września 1939, po kapitulacji Warszawy jako stolicy Polski.
W wyniku postanowień konferencji w Teheranie, konferencji jałtańskiej i konferencji poczdamskiej po zakończeniu II wojny światowej, Rzeczpospolita Polska (od 1952 pod nazwą Polska Rzeczpospolita Ludowa), objęła centralną i zachodnią część terytorium II Rzeczypospolitej, a także przyznane przez mocarstwa Ziemie Odzyskane i stała się prawnomiędzynarodowym sukcesorem II Rzeczypospolitej. Natomiast ziemie na wschód od Bugu, Kresy Wschodnie, czyli województwa wileńskie, nowogrodzkie, poleskie, wołyńskie, tarnopolskie i stanisławowskie, a także część województwa białostockiego i lwowskiego, zostały wcielone do ZSRR.
Ustrój polityczny.
System władzy w II Rzeczypospolitej określany był do 1926 jako republika demokratyczna z wielopartyjnym systemem parlamentarno-gabinetowym. Po zamachu stanu (przewrót majowy 1926) ustrój państwa uległ modyfikacji w trybie zmiany konstytucji (nowela sierpniowa) i faktycznego sposobu wykonywania władzy, w konsekwencji został przekształcony w system prezydencko-autokratyczny (od obozu politycznego sprawującego władzę zwany sanacją).
Władze.
Prezydenci.
Po przewrocie majowym w 1926 faktycznie najwyższą władzę w państwie sprawował Marszałek Polski Józef Piłsudski, który formalnie zajmował urząd Generalnego Inspektora Sił Zbrojnych i ministra spraw wojskowych w kolejnych rządach, a także – dwukrotnie (1926-1928, 1930) – premiera.
Rząd Rzeczypospolitej Polskiej na uchodźstwie.
Po agresji na Polskę III Rzeszy i ZSRR (kampania wrześniowa) i okupacji wojennej terytoriów II RP przez obu agresorów legalną kontynuacją władz II Rzeczypospolitej, uznawaną na arenie międzynarodowej przez cały okres II wojny światowej był Rząd RP na uchodźstwie, a jako podległa mu administracja w okupowanym kraju – Polskie Państwo Podziemne i jego struktury polityczne i wojskowe (Armia Krajowa).
Gospodarka.
Po zniszczeniach w czasie I wojny światowej Polska powstała z połączenia trzech zaborów, które przed wojną sprzedawały głównie do państw zaborczych. Nowe granice ograniczyły sprzedaż na stare rynki zbytu. Dodatkowo w 1925 wybuchła wojna celna z Niemcami, które były głównym partnerem handlowym.
Wielki kryzys w Polsce był znacznie głębszy i dłuższy wskutek zachowania wymienialności złotego na złoto (parytet złota), podczas gdy wiele krajów od niego odeszło i zdewaluowało swoje waluty, co uczyniło polskie towary za granicą droższymi. Według historycznych danych GUS w 1938 r. produkcja przemysłowa w Polsce była realnie o 19% większa niż w 1928 r., co było wzrostem nieco wyższym od średniego wzrostu w całej Europie (wzrost o 13% nie licząc ZSRR) i znacznie wyższym od wzrostu w St. Zjednoczonych (spadek o 23%) gdzie po stałym rozwoju w latach 1933–1937 produkcja przemysłowa w 1938 ponownie załamała się. W 1938 produkcja przemysłowa na głowę mieszkańca była wciąż prawie 10% niższa niż w 1913.
Gdyby nie rozwój gospodarki w kraju w latach 1936–1939, który był, obok lat 1926–1929, najszybszy w całym okresie istnienia II RP, to przed wrześniem 1939 roku nie udało by się osiągnąć globalnego poziomu produkcji przemysłu z 1913 roku, ale i tak produkcja przemysłowa przypadająca na jednego mieszkańca była w 1938 roku o kilkanaście procent niższa niż na terenach polskich w 1913 roku. Tymczasem wszędzie w Europie w okresie międzywojennym wskaźniki te były dużo wyższe. Zatem zacofanie, jeśli chodzi o uprzemysłowienie kraju, w latach 1918–1939 rosło.
Polski PKB na jednego mieszkańca przed 1939 rokiem nie przekroczył nigdy połowy średniego PKB na głowę w Europie Zachodniej.
Produkcja wytworzona w Polsce międzywojennej na mieszkańca wynosiła ok. 610 zł., gdy np. w Rumunii równowartość 600 zł., a w krajach Europy Zachodniej przeciętnie 1800 zł. (w USA 4500 zł.).
Przez całe lata trzydzieste państwo zwiększało swój udział w gospodarce. Przejmowało zagrożone upadkiem przedsiębiorstwa oraz zakładało własne. Pod koniec II RP przedsiębiorstwa państwowe wytwarzały ponad 25% produkcji przemysłowej, a wiele kluczowych działów gospodarki było pod całkowitą kontrolą rządu. System bankowy zdominowały cztery banki państwowe, które skupiły 42% ogółu wkładów klientów oraz opanowały 38% rynku kredytowego.
W 1929 roku zwolennik doktryny liberalizmu gospodarczego Adam Heydel pisał:
Energetyka: w 1914 roku na ziemiach polskich istniało 150 elektrowni produkujących 800 mln kWh. Według GUS w 1923 r. produkcja energii elektrycznej w II RP wyniosła 1511 mln kWh i do 1938 r. wzrosła do 3977 mln kWh. Zużycie energii na statystycznego Polaka wynosiło w 1937 roku 50kWh (mieszkaniec Paryża zużywał w tym czasie ponad 500 kWh, przeciętny Szwajcar – 700 kWh, a mieszkaniec amerykańskich miast nawet 1000 kWh na rok). Pod koniec 1938 roku prąd docierał do 3% wsi i 2% gospodarstw wiejskich.
Wydobycie ropy naftowej: w latach 1922–1938 produkcja ropy spadła z 705 tys. ton do 507 tys. ton ropy rocznie.
Motoryzacja: w latach 1926–1931 liczba samochodów w II RP wzrosła 4-krotnie. W okresie wielkiego kryzysu spadła o około 30%, a w następnych latach wróciła do poziomu z początku lat 30. Liczba samochodów przypadająca na 1000 mieszkańców w Polsce nie tylko pozostawała bardzo niska przez okres lat 30. na tle państw wysoko rozwiniętych, ale dystans do nich nawet się powiększył. Dla porównania w 1938 r. w Polsce przypadał 1 samochód na 1000 mieszkańców, w Japonii – 2,5, w Brazylii – 3,7, we Włoszech – 10, w Niemczech i Austrii – 25,1, w Wlk. Brytanii – 51,1, a w Stanach Zjednoczonych aż 228,8.
Rolnictwo: występując w Sejmie w 1935 roku wicepremier Eugeniusz Kwiatkowski stwierdzał: „Nasza struktura gospodarcza jest wyjątkowo niekorzystna (...). Wieś polska w XX w. powróciła prawie do gospodarki naturalnej. Szereg potrzeb wsi zaspakaja się w sposób anormalny i niezwykle prymitywny, zapałki dzieli się na części, wraca się do łuczywa, a transport pieszy i kołowy nawet na znaczne odległości przyszedł ponownie – po przerwie od końca XIX w. – do znaczenia”.
Kwestia chłopska.
W latach 30. ludność chłopska stanowiła ok. 71% ludności kraju.
Średnia długość życia na wsi wynosiła 47 lat i była o ponad 10 lat niższa niż w Europie Zachodniej.
W 1931 roku w Polsce 23,4% gospodarstw rolnych miało powierzchnię poniżej 2 ha, 35,5% powierzchnię od 2 do 5 ha. Z 2 ha nie można było wyżyć bez dodatkowych dochodów. Gospodarstwa od 2 do 5 ha zapewniały egzystencję na granicy głodu.
W wyniku „wielkiego kryzysu” głód stał się powszechnym, okresowym zjawiskiem na wsi. Ceny pszenicy w 1934 roku wynosiły zaledwie 34% ceny z 1928 roku. W 1937 roku koniunktura się poprawiła, ale chłopi tego nie odczuli, albowiem wzrosły jednocześnie podatki. Zadłużenie gospodarstw chłopskich pod koniec lat 30. wynosiło 4,3 mld złotych gdy wartość rocznej sprzedanej produkcji tylko 1,5 mld złotych.
Rezerwę użytków rolnych możliwych do rozparcelowania oceniano w 1938 roku na 4,6 mln ha, a liczbę ludności bezrolnej zamieszkującej na wsi na 5,5 mln ludzi. Ziemi było w Polsce zbyt mało by jedynie drogą reformy rolnej „rozładować” przeludnienie na wsi.
W 1939 roku zelektryfikowanych wsi w Polsce było 3%.
W dniach 16–25 sierpnia 1937 roku chłopi pod przewodnictwem Stronnictwa Ludowego zorganizowali w Polsce strajk. Był to największy w Polsce protest chłopski w którym wzięło udział kilka milionów chłopów. Strajk spotkał się z brutalną reakcją władz. Zginęły 44 osoby, ponad 5 tys. było aresztowanych a 617 skazano i osadzono w więzieniach.
Z odezwy Stronnictwa Ludowego proklamującej strajk chłopski, Warszawa 14 sierpnia 1937:
"Strajk (...) jest manifestem za koniecznością likwidacji systemu sanacyjnego w Polsce i przywróceniem obywatelowi praw mu przynależnych. (...) Żądamy ustroju demokratycznego dla Polski i nowych uczciwych wyborów"
W lutym 1938 roku Stronnictwo ludowe zapowiedziało kolejny protest chłopski. Rząd sanacyjny zareagował pacyfikacją zagrożonych powiatów województwa krakowskiego i lwowskiego. Pacyfikacja polegała na dewastacji gospodarstw działaczy ludowych – łamaniu mebli w ich domach i wysypywaniu ziarna. W niektórych przypadkach policja posuwała się do łamania nóg koniom i bydłu uderzeniami kolb i drągów.
"„Cukier na wsi nie istnieje. Większość dzieci nie widziała go nawet nigdy, chyba w formie cukierków na odpustach. Sól używa się obecnie szarą, nieraz nawet czerwoną bydlęcą. Na wiosnę w okresie przednówka z braku gotówki nawet na te najgorsze gatunki stosuje się, kilkakrotnie gotując ziemniaki w tej samej osolonej wodzie”"
Szkolnictwo oraz opieka przedszkolna.
W pierwszym roku akademickim niepodległej Polski (1918/19) działało na jej terenie 7 uczelni. Ich liczba rosła dzięki zakładaniu nowych placówek państwowych i prywatnych, osiągając poziom 24 w roku akademickim 1932/33 oraz 32 w roku 1937/38. Polscy studenci (w sumie 49.3 tys., z czego 28% to kobiety) koncentrowali się głównie w Warszawie (42%), drugim pod względem wielkości ośrodkiem akademickim był Lwów (19%), a następnie Kraków (15,6%) i Wilno (7,2%). Najpopularniejszym kierunkiem studiów było prawo (ponad 20% ogółu studentów).
W 1928 roku tekę ministra oświaty objął Kazimierz Świtalski, który rozpoczął działalność od dokonania w resorcie czystki personalnej. Naczelnym kryterium przy doborze kadry była lojalność wobec rządu. Po przewrocie majowym sanacja rzuciła hasło prowadzenia „wychowania państwowego”. Nowym ideałem wychowawczym miał być model obywatela – państwowca, opierający się na syntezie postawy bojownika i pracownika. Cechami tego wzorca miały być: dzielność życiowa, silna wola, potężna energia, zdolność do czynu i pracy, wytrwałość, honor oraz lojalność i ofiarność w stosunku do państwa. Czynniki oficjalne otwarcie wskazywały, że nauczyciel musi służyć nie tylko państwu, ale i grupie rządzącej.
Pod koniec lat 30. w związku z kryzysem światowym, nastąpiła gwałtowna zapaść szkolnictwa. W roku szkolnym 1931/32 brakowało miejsc w szkołach dla ok. 300 tys. dzieci. Przeciętna liczba uczniów na jednego nauczyciela wyniosła 58,3. 70% szkół w Polsce to były szkoły 1- i 2-klasowe, niedające możliwości kontynuowania nauki na poziomie średnim. Szkół 7-klasowych było ok. 10%. Najgorsza sytuacja była na wsi, gdzie tylko 14% szkół miało więcej niż 3 klasy. Do matury podchodziło niespełna połowa uczniów, którzy rozpoczęli naukę w gimnazjum. Pozostali porzucali szkołę, nie mogąc sprostać stawianym wymaganiom.
Mimo bezrobocia wśród nauczycieli z powodów budżetowych brakowało etatów dla zwiększenia liczby kadry nauczycielskiej. 25% dzieci uzyskiwało niezadowalające wyniki w nauce, co w zestawieniu z niezbyt wygórowanymi wymaganiami świadczyło raczej o niskim poziomie nauczania na tym poziomie szkolnictwa. Do VII klasy docierało tylko ok. 52% uczniów zaczynających od I klasy, a do VIII zaledwie 46%.
W drugiej połowie lat trzydziestych system szkolny wyglądał w ten sposób, że szkoła podstawowa liczyła 6 klas. Dodatkową siódmą klasę musieli skończyć ci, którzy nie chcieli dalej kontynuować nauki. Kontynuujący naukę mieli przed sobą 4 lata gimnazjum i dwa lata liceum. Przy czym wtedy rodzice musieli zapłacić 200 zł rocznie czesnego (pensja doświadczonego policjanta czy oficera w stopniu porucznika wynosiła ok. 300 zł miesięcznie). W efekcie do szkoły średniej trafiała młodzież z zamożnych domów. Maturę w 30-milionowym kraju zdawało ok. 30 tys. abitiurentów.
W latach 1937/38 - zaledwie ok. 84 tys. dzieci objętych było opieką w przedszkolach.
Mniejszości narodowe.
Polska w okresie międzywojennym była krajem wielonarodowościowym, w którym Polacy stanowili od 64 do 69,2% populacji. Na większości obszaru wiejskiego Kresów Wschodnich, Polacy stanowili mniejszość (na rzecz Ukraińców lub Białorusinów), natomiast większość w dużych miastach. Polacy przeważali m.in. na Wileńszczyźnie i w ówczesnym województwie lwowskim. Na zachodzie przeważali w niektórych okolicach Niemcy. W wielu miejscowościach dominowała ludność żydowska. Elitom politycznym młodego państwa polskiego, nieprzygotowanym do rządzenia wielonarodowym społeczeństwem, trudno było zaakceptować mniejszości narodowe jako pełnoprawnych obywateli państwa. Niejednokrotnie też przedstawiciele mniejszości narodowych stawali się obiektem ataków zmasowanej propagandy środowisk nacjonalistycznych. Wybrano zatem wariant wzmacniania polskości metodami administracyjnymi. Efekty okazały się jednak odwrotne od zamierzonych. Polityka narodowościowa realizowana w dwudziestoleciu międzywojennym przyniosła fatalne skutki dla państwa polskiego we wrześniu 1939 roku. Znaczna część obywateli polskich niepolskiej narodowości, oczekując jakichkolwiek zmian na lepsze, gotowa była przyjmować okupantów Polski jako wyzwolicieli spod polskiego panowania, z nadzieją na wywalczenie szerszego zakresu swobód narodowych i poprawę warunków ekonomicznych.
Narodowości według spisu z 1921 r. (samookreślenie według deklarowanej narodowości respondentów):
Narodowości według spisu z 1931 r. (samookreślenie według deklarowanego języka ojczystego respondentów):
Mniejszość ukraińska.
W lecie 1930 roku Organizacja Ukraińskich Nacjonalistów przeprowadziła na terenach zamieszkałych przez ludność ukrеaińską akcję terrorystyczną polegającą przede wszystkim na masowych podpaleniach. W odpowiedzi rząd polski we wrześniu tego roku rozpoczął akcję pacyfikacyjną na tych terenach. Objęła ona łącznie 493 wsie. Do wsi wkraczały oddziały policji wspieranej przez wojsko i przeprowadzały brutalne rewizje domostw w wyniku których dochodziło do niszczenia mienia i licznych pobić. W ich wyniku zginęło od siedmiu do 35 osób. Wobec tych metod polskiej władzy dotąd obojętni wobec kwestii politycznych ukraińscy chłopi zaczęli popierać OUN.
Mniejszość białoruska.
Na mocy pokoju ryskiego, tereny obecnej Białorusi podzielone zostały między Polskę a RFSRR. Bolszewicy utworzyli marionetkową Białoruską SRR. Ze strony polskiej większość negocjatorów była pod wpływem koncepcji endeckich, które przeczyły wizjom tworzenia federacji na obszarze byłego Wielkiego Księstwa Litewskiego. Rzeczpospolita objęła w przybliżeniu tereny na zachód od granicy II rozbioru (z niewielką korektą na korzyść Polski w postaci Pińska i Nieświeża), na których utworzono województwa białostockie, nowogródzkie, poleskie oraz wileńskie. Granicę polsko-sowiecką przeprowadzono 30–60 km na zachód i północny zachód o Mińska, zajętego w ostatnich dniach wojny polsko-bolszewickiej ponownie przez Wojsko Polskie, które po zawarciu rozejmu było zmuszone wycofać się z miasta. Do większych miast tego obszaru (skądinąd bardzo słabo zurbanizowanego) zalicza się Grodno i Brześć.
Według wyników spisu powszechnego z 1931 roku 990 tys. obywateli II RP podało język białoruski jako ojczysty, a na Polesiu 700 tys. – język „tutejszy”. Wśród ludności białoruskiej w II RP 77,6 procent stanowili analfabeci. Do inteligencji zaliczało się 0,17 procent ludności.
Powszechnie stosowaną przez włościan białoruskich formą walki z „polskim porządkiem” było wywoływanie pożarów. Ich pastwą padło wiele wsi, miasteczek, obiektów przemysłowych. Z raportów MSW jeszcze z przełomu 1925/1926 r. wynika, że władze polskie nie były w stanie skutecznie przeciwdziałać aktom dywersyjnym.
Białoruska Włościańsko–Robotnicza „Hromada” była pierwszą partią polityczną, której program rozpowszechnił się wśród białoruskich chłopów i robotników. Poza postulatem zjednoczenia wszystkich ziem białoruskich w jedną republikę nacisk programowy położono głównie na aspekty społeczne: konieczność reformy rolnej bez odszkodowań, zniesienie osadnictwa wojskowego, melioracji błot czy możność używania języka białoruskiego w urzędach. Liczyła sobie ona ok. 100 tys. członków. „Hromada” nie była przybudówką Komunistycznej Partii Zachodniej Białorusi, lecz istniały ścisłe kontakty między działaczami obu partii. W 1927 roku „Hromada” została zdelegalizowana przez władze sanacyjne. Po tym fakcie założona zostało ugrupowanie „Zmahańnie za Interesy Włościan i Robotników”, które skupiło w swych szeregach większość byłych członków „Hromady” i prezentujące podobny program. W 1928 roku wzięło udział w wyborach tworząc następnie w Sejmie klub poselski. Partię tę władze sanacyjne rozwiązały w 1930 roku. Wielu jej członków przeszło w szeregi nielegalnej Komunistycznej Partii Zachodniej Białorusi wchodzącej w skład ogólnopolskiej KPP. KPZB była organizacją odnoszącą na Białostocczyźnie największe sukcesy. W Polsce międzywojennej odbyło się wiele procesów politycznych w których oskarżonymi byli członkowie tej partii. Do tych, które znalazły największy oddźwięk społeczny, należał tzw. „proces 133” przeprowadzony w 1928 roku. KPZB próbowała brać udział w wyborach samorządowych, ale jej listy były unieważniane przez władze, a aktywni działacze aresztowani.
Władze polskie starały się nie dopuścić również do rozszerzenia białoruskiego ruchu spółdzielczego również dopatrując się w nim formy wpływów komunistycznych. W rezultacie obostrzeń stwarzanych przez władze w 1939 roku istniały tylko trzy spółdzielnie białoruskie. Władze sanacyjne zlikwidowały w 1937 roku Towarzystwo Szkoły Białoruskiej – największą organizację samorządową ludności białoruskiej, oskarżając ja o „infiltrację komunistyczną”. Stopniowo likwidowano w II RP szkolnictwo białoruskie. O ile w roku szkolnym 1918/1919 istniało 346 szkół białoruskich to w 1937 roku zostało ich tylko 5 szkół powszechnych białorusko–polskich, 44 szkoły w których wykładano białoruski jako jeden z przedmiotów i jedno gimnazjum białoruskie. W końcu lat trzydziestych władze sanacyjne rozwiązały bądź zawiesiły działalność wielu organizacji białoruskich w tym najważniejszych: Białoruskiego Instytutu Gospodarki i Kultury (styczeń 1937 r.), Białoruskiego Komitetu Narodowego (styczeń 1938 r.) i sparaliżowały działalność Białoruskiego Zjednoczenia Ludowego zamykając pismo „Biełaruskaja Krynica”. Powodem było zawarcie w statutach tych organizacji postulatu zjednoczenia narodu białoruskiego.
Dużym echem wśród prawosławnych w większości Białorusinów odbiła się akcja podjęta z inspiracji wojskowych władz sanacyjnych zakładająca zburzenie latem 1938 roku 127 „zbędnych” prawosławnych obiektów sakralnych (w szczególności na terenie Chełmszczyzny).
W 1939 roku wojewoda białostocki w następujący sposób oceniał wyniki polityki polonizacyjnej wobec Białorusinów: „Element polski nie potrafił dotychczas nie tylko porwać za sobą, ale nawet związać wsi białoruskiej przez wciągnięcie jej do wspólnych organizacji społecznych, politycznych czy gospodarczych. Żądaliśmy jedynie, aby mniejszość ta myślała po polsku nic w zamian nie dając (…). Chcąc ten proces przyspieszyć musimy wieś białoruską podbić kulturalnie.”, a dowódca Okręgu Korpusu nr IX gen. Jarnuszkiewicz stwierdzał: „Nie wystarczy to, że ktoś uważa się za Polaka, a pozostaje prawosławny. Na kresach synonim polskości to katolicyzm.”.
Przed wybuchem wojny nastawienie ludności białoruskiej tak opisywał o pismo „Biełaruskij Front”: „Ludność białoruska oczekuje jakichkolwiek zmian (…) filozofią mas chłopskich jest: nic nie mówić, nic nie wiedzieć, nic nie robić. Głodni, obdarci, niepiśmienni chłopi nie są zainteresowani żadnymi działaniami politycznymi ani społecznymi. Pójdą z entuzjazmem za każdym, kto obieca im chleb i więcej ziemi, by produkować chleb.”.
Akcja rewindykacyjno-polonizacyjna 1938 roku.
Po 1918 roku część ludności oficjalnie wyznania prawosławnego będąca wcześniej unitami, którym wiarę prawosławną narzuciły władze zaborcze siłą, z powrotem przeszła na katolicyzm. Wiązało się to z samorzutną akcją przejmowania cerkwi prawosławnych (wcześniej niekiedy będących świątyniami unickimi). Na tym tle dochodziło do konfliktów z pozostałościami ludności wyznania prawosławnego, głównie Ukraińcami, zamieszkującymi głównie południową część Chełmszczyzny. Akcję spontanicznego przejmowania cerkwi zakończył (z powodu obaw o narastające nastroje konfrontacyjne) rząd w 1924 roku uchwałą zakazującą przejmowania cerkwi do czasu uregulowania prawnego kwestii.
W 1929 roku wojewoda lubelski rozpoczął akcję wyburzania „zbędnych” cerkwi na terenach gdzie nie zamieszkiwali już prawosławni. Zniszczono 29 cerkwi. Akcję wstrzymano na skutek protestów ludności prawosławnej.
W 1937 roku rozpoczęto na szeroką skalę zakrojoną akcję polonizacji i katolicyzacji Chełmszczyzny gdzie w dużym procencie zamieszkiwała ludność ukraińska wyznania prawosławnego. Wydano m.in. zakaz nauczania języka ukraińskiego na Chełmszczyźnie i Podlasiu, nauka religii prawosławnej, a nawet kazania miały się odbywać w języku polskim. Masowo, pod przymusem wojskowym i policyjnym, nakazywano ludności prawosławnej deklarować przejście na katolicyzm. Dowództwo Korpusu Okręgu II Wojska Polskiego w Lublinie rozpoczęło jednocześnie w 1938 roku akcję wyburzania, często zabytkowych, cerkwi na obszarze Lubelszczyzny. Miejscowe władze inspirowały manifestacje miejscowych katolików, którzy podejmowali uchwały domagające się zamknięcia i wyburzenia cerkwi jako ośrodków dywersji ukraińskiej. Rozbiórkę cerkwi przeprowadzała administracja gminna na polecenie starostów za pomocą miejscowej młodzieży, głównie z oddziałów strażackich, więźniów lub wynajętych brygad. Często cerkwie były niszczone wraz z ich wyposażeniem liturgicznym. W rezultacie na Lubelszczyźnie zniszczono 91 cerkwi (pozostało 49), 10 kaplic i 26 domów modlitwy. Akcja spowodowała wzrost nastrojów antypolskich i antypaństwowych u ludności ukraińskiej.
Cat – Mackiewicz tak komentował tę akcję: „Burzenie świątyń prawosławnych to jeszcze jeden dowód, że rządzą nami ludzie nie dorośli do rządzenia(…).”. 30 marca 1938, rada miejska w Białymstoku podjęła uchwałę o zburzeniu niedokończonej cerkwi na placu Wolności- przeciwko głosowali radni „Bundu” i PPS.
Mniejszość żydowska.
Niepodległość w stosunkach polsko-żydowskich rozpoczęła się od pogromu antyżydowskiego w Kielcach, do którego doszło 11 listopada 1918 roku. W jego wyniku zginęły 4 osoby, a 250 zostało rannych. Rabowano żydowskie sklepy i mieszkania prywatne. Najwięcej ofiar było, gdy tłum wtargnął do Teatru Polskiego i zaczął linczować zgromadzonych tam członków organizacji syjonistycznej, którzy obradowali nad odezwą wyrażającą radość z odzyskania przez Polskę niepodległości. Porządek w mieście przywrócił dopiero oddział wojskowy gen. Wacława Iwaszkiewicza.
Podczas wojny polsko-bolszewickiej w armii polskiej szerzyły się nastroje antysemickie (Żydów oskarżano o popieranie Armii Czerwonej). Wojskowe władze polskie zarządziły utworzenie obozu w Jabłonnie, w którym internowano około tysiąca żołnierzy i oficerów żydowskiego pochodzenia (decyzja o jego utworzeniu została wydana 16 sierpnia 1920, obóz działał do 9 września 1920; jego powstanie wywołało skandal międzynarodowy, z którego minister spraw wojskowych gen. Sosnkowski musiał tłumaczyć się przed Sejmem i opinią publiczną). Wydano również rozkaz aresztowania we wszystkich wojskowych Okręgach Generalnych ok. 1000 wojskowych wśród których większość stanowili Żydzi. Wielu oficerów wyznania mojżeszowego, zasłużonych w walce o niepodległość zostało usuniętych z wojska. Żydowską młodzież akademicką z oddziałów ochotniczych skierowano do kompanii karnych.
Również po zakończeniu wojny polsko-bolszewickiej żołnierze pochodzenia żydowskiego traktowani byli jako żołnierze drugiej kategorii lub wręcz z góry byli podejrzewani o nielojalność wobec państwa polskiego. W odpowiedziach na interpelacje poselskie gen. Sosnkowski stwierdzał, że „Żydzi nie nadają się do poważniejszej pracy niż pisanie na maszynie”. W związku z uchwałą Sejmu z 17 czerwca 1919 r. według której oficerami mogli być tylko obywatele polscy narodowości polskiej degradowano oficerów pochodzenia żydowskiego nawet awansowanych już w Polsce niepodległej. W lipcu 1920 roku Wojsko Polskie zwolniło ze służby w wojskowych szpitalach lekarzy i pielęgniarki pochodzenia żydowskiego. 23 marca 1923 roku Sztab Generalny wydał tajny rozkaz usunięcia wszystkich Żydów z wojskowych zakładów graficznych. W drugiej połowie lat dwudziestych w Wojsku Polskim służyło 87 oficerów pochodzenia żydowskiego co stanowiło 0,5 procenta całego korpusu oficerskiego. Od końca lat dwudziestych natomiast osób pochodzenia żydowskiego nie rekrutowano do lotnictwa, marynarki, łączności i broni pancernej oraz Korpusu Ochrony Pogranicza.
Na początku lat dwudziestych dochodziło na kolei do licznych ekscesów antysemickich pod postacią bicia i rabowania żydowskich pasażerów. Żydzi obawiali się w szczególności dworca kolejowego w Bydgoszczy.
W 1922 roku na uczelniach odbyły się wiece poprzedzone memoriałem skierowane do senatów szkoł wyższych w celu wprowadzenia "numerus clausus." W 1923 roku nastąpiła próba wprowadzenia tych zmian w czym przeszkodził zamach majowy w 1926 roku i dążenia nowego rządu do zawarcia porozumienia z mniejszościami narodowymi. W 1931 Sejm uchwalił ustawę "O uchyleniu przepisów wyjątkowych związanych z pochodzeniem, narodowością, rasą lub religią obywateli Rzeczypospolitej". W latach 30. XX w. zdarzały się przypadki stosowania w praktyce "numerus clausus". Natomiast mimo postulatów "numerus nullus" nie zostało wprowadzone.
W listopadzie 1932 roku doszło we Lwowie do gwałtownych zamieszek antyżydowskich. Poszkodowanych zostało kilkaset osób. W grudniu 1935 roku, jako pierwsze w kraju, władze Politechniki Lwowskiej wprowadziły na wydziałach inżynierii i mechanicznym tzw. getto ławkowe, czyli oddzielne miejsce siedzenia dla studentów chrześcijan i Żydów.
W drugiej połowie lat 30. w Zamościu rozpoczęła się akcja antyżydowska. Kierował nią gen. Bruno Olbrycht – dowódca 3 Dywizji Piechoty Legionów i prezes Towarzystwa Rozwoju Ziem Wschodnich. Do akcji wciągnięto całe wojsko i znaczną część społeczności cywilnej miasta. Wojskowym rozkazem ogłoszono bojkot sklepów żydowskich. Młodzież gimnazjalna organizowała pikiety przed sklepami żydowskimi nie dopuszczając do nich klientów. Generał w związku ze swą walką z mniejszością żydowską oraz patronatem nad miejscowych harcerstwem zyskał dużą popularność w mieście i otrzymał honorowe obywatelstwo Zamościa.
W pierwszej połowie 1936 doszło do ekscesów, pogromu, o podłożu antysemickim w Mińsku Mazowieckim.
W maju 1937 roku w Brześciu nad Bugiem doszło do rozruchów antyżydowskich, w których zginęło trzech Żydów, a ponad pięćdziesięciu zostało rannych. Dzielnica żydowska została zdemolowana. Starosta i policja pozostali bierni. Również wojsko, mimo obecności w mieście, nie interweniowało. W rezultacie zamieszki trwały 16 godzin.
19 czerwca 1937 roku w Częstochowie Obóz Zjednoczenia Narodowego ogłosił deklarację antyżydowską w wyniku czego przez trzy dni polscy nacjonaliści atakowali ludność żydowską. Skutkiem tego było zniszczenie mienia 206 rodzin żydowskich od sklepów po mieszkania z własnością prywatną. 20 Żydów zostało rannych. Pogrom rozprzestrzenił się w następnych tygodniach na miejscowości znajdujące się w okolicach Częstochowy.
Religia.
Podział administracyjny:
Ludność największych miast w 1939.
W Polsce istniały wówczas: 1 miasto milionowe (Warszawa), 1 miasto o ludności powyżej 500 tys. (Łódź), 9 miast o ludności 100–500 tys., 12 miast o ludności 50–100 tys., 46 miast o ludności 20–50 tys. i 83 miasta o ludności 10–20 tys.

</doc>
<doc id="1299" url="https://pl.wikipedia.org/wiki?curid=1299" title="Didiusz Juliusz">
Didiusz Juliusz



</doc>
<doc id="1300" url="https://pl.wikipedia.org/wiki?curid=1300" title="Departament zamorski">
Departament zamorski

Departament zamorski (fr. "département d'outre-mer", "DOM") – nazwa francuskiego terytorium zależnego na prawach departamentu, wprowadzona w 1946 roku. Działają one na tych samych zasadach, co departamenty Francji metropolitalnej. Każdy z nich tworzy jednocześnie region administracyjny, składający się z jednego departamentu.
Obecnie jest to 5 departamentów o łącznej powierzchni ponad 89 tys. km² i ok. 2 mln ludności (2003/2007).
W wyniku referendum przeprowadzonego 29 marca 2009 Majotta została 31 marca 2011 piątym departamentem zamorskim. Historycznie departamentami zamorskimi było 15 departamentów byłej Algierii Francuskiej do uzyskania przez nią niepodległości w 1962 r. oraz Saint-Pierre i Miquelon w latach 1976-85.

</doc>
<doc id="1301" url="https://pl.wikipedia.org/wiki?curid=1301" title="Gwara śląska">
Gwara śląska



</doc>
<doc id="1302" url="https://pl.wikipedia.org/wiki?curid=1302" title="Dowód matematyczny">
Dowód matematyczny



</doc>
<doc id="1303" url="https://pl.wikipedia.org/wiki?curid=1303" title="Donatello">
Donatello

Donatello, właśc. Donato di Niccolò di Betto Bardi (ur. ok. 1386 we Florencji, zm. 13 grudnia 1466 tamże) – rzeźbiarz włoskiego renesansu.
Życiorys.
Działał we Florencji, Padwie i Sienie. Kształcił się i początkowo pracował u Lorenzo Ghibertiego, obok którego jest twórcą renesansowego stylu w rzeźbie. W okresie 1404-1407 pracował w warsztacie Ghibertiego we Florencji. W latach 1430–1433 w Rzymie studiował rzeźbę antyczną, 1443-1453 w Padwie. Wykonał rzeźby dla katedry florenckiej: posągi Dawida (1408/1409) i św. Jana Ewangelisty (1408-15), figury na fasadę kościoła Orsanmichele (słynny "św. Jerzy", ok. 1416). W Padwie stworzył pomnik kondotiera weneckiego, Erasmo da Narni, zw. Gattamelata (1447) – pierwszy pomnik konny od czasów antyku. Wyrzeźbił popiersie Contessiny de’ Bardi.
Donatello miał przełomowe znaczenie dla rozwoju rzeźby renesansowej i uwolnienia się jej od wpływów gotyku. Jako pierwszy nawiązał do antyku, stworzył typ renesansowego nagrobka, jako pierwszy wskrzesił akt (Dawid).
Jego dojrzałe prace cechuje swobodny układ postaci, portretowe traktowanie głów, opanowanie perspektywy, wyczucie ruchu i umiejętna kompozycja. Późne prace Donatella cechuje dynamizm, wnikliwość w oddaniu psychiki i naturalizm w przedstawianiu ekspresji. Wychodzi od detalu po ogólne opracowanie.
Był nauczycielem florenckiego malarza i rzeźbiarza Andrei del Verrocchio.

</doc>
<doc id="1305" url="https://pl.wikipedia.org/wiki?curid=1305" title="Rozumowanie dedukcyjne">
Rozumowanie dedukcyjne

Dedukcja – rodzaj rozumowania logicznego, mającego na celu dojście do określonego wniosku na podstawie wcześniej założonego zbioru przesłanek.
Rozumowanie dedukcyjne w odróżnieniu od rozumowania indukcyjnego jest w całości zawarte wewnątrz swoich założeń, to znaczy nie wymaga tworzenia nowych twierdzeń czy pojęć, lecz jest tylko prostym wyciąganiem wniosków. Jeśli jest przeprowadzone poprawnie, zaś zbiór przesłanek nie zawiera zdań fałszywych, to wnioski wyciągnięte w wyniku rozumowania dedukcyjnego są nieodparcie prawdziwe i nie można ich zasadnie zakwestionować; nie prowadzi nigdy od prawdy do fałszu.

</doc>
<doc id="1306" url="https://pl.wikipedia.org/wiki?curid=1306" title="Dominikana">
Dominikana

Dominikana, oficjalna nazwa: Republika Dominikańska – drugie co do wielkości (po Kubie) państwo na Morzu Karaibskim. Zajmuje około 2/3 powierzchni wyspy Haiti, dzieląc ją z położoną po zachodniej stronie Republiką Haiti.
Geografia.
Cyklony tropikalne sieją spustoszenie w kraju średnio co dwa lata.
Historia.
Prekolumbijskimi mieszkańcami kraju byli Karaibowie i Tainowie. W 1492 obszar został odkryty dla Europy przez Krzysztofa Kolumba. Dominikana pod nazwą Hispaniola weszła w skład hiszpańskiego imperium kolonialnego. W 1697 obszar dzisiejszej Dominikany stał się odrębną kolonią hiszpańską pod nazwą Santo Domingo. W tym samym roku zachodnia część wyspy trafiła pod władanie francuskie. W latach 1795–1808 cała wyspa znalazła się pod rządami Francji. W 1809 rządy nad Santo Domingo przywrócono Hiszpanom. W 1821 Dominikana ogłosiła niepodległość, jednak już w 1822 została zajęta przez wojska Haiti (niepodległego państwa powstałego na zachodzie). W 1844 proklamowana została niepodległa Republika Dominikany. Po kilku kolejnych próbach aneksji Dominikany przez Haiti rząd republiki zaproponował Hiszpanii ponowne włączenie w skład imperium. Hiszpanie zaakceptowali ofertę i w 1861 Dominikana znów stała się kolonią. W latach 1863–1865 trwało antyhiszpańskie powstanie zakończone ponownym ogłoszeniem niepodległości. W kolejnych latach nasilił się chaos i wewnętrzne walki. U progu XX wieku rosło zadłużenie i uzależnienie kraju od obcego, głównie amerykańskiego kapitału. Z powodu niewypłacalności i pod pretekstem konfliktów wewnętrznych w 1916 rozpoczęła się trwająca do 1924 amerykańska interwencja wojskowa.
Po okresie rządów prezydenta Horacio Vásqueza (1924-30), do władzy doszedł Rafael Leónidas Trujillo. Rządził on w dyktatorski sposób, utrzymując fasadę demokracji. Reżim opierał się na wojsku i jedynej legalnej partii politycznej, Partii Dominikańskiej. Trujillo odwoływał się do idei "hispanidad" (kultywowania tradycji hiszpańskich) i „wybielenia” społeczeństwa dominikańskiego. W 1937 armia przeprowadziła masakrę haitańskich imigrantów. W roku 1938 Dominikana była jedynym państwem na świecie deklarującym gotowość przyjęcia na wniosek Roosvelta żydowskich uchodźców z Niemiec i Austrii. Na okres rządów dyktatora przypadła korzystna koniunktura gospodarcza, która poskutkowała likwidacją zagranicznego zadłużenia (niemniej powszechna była korupcja, a rodzina Trujillo kontrolowała 75% majątku narodowego). W 1960 prezydenturę objął Joaquín Balaguer, który złagodził reżim. Do całkowitego upadku dyktatury doszło w 1961 po zabójstwie Trujillo.
Wybory w 1962 wygrał Juan Bosch z Dominikańskiej Partii Rewolucyjnej (PRD). Uchwalił on nową demokratyczną konstytucję, ale już w 1963 został obalony w wojskowym zamachu stanu. Władzę do 1965 sprawowała junta. W tym samym roku grupa młodych oficerów armii – zwolenników Boscha – podjęła zbrojną próbę przejęcia władzy (tzw. ruch konstytucjonalistyczny). Podczas walk stronę rządową wsparły interwencyjne oddziały USA. Po ich wycofaniu w 1966 do władzy powrócił Balaguer. W 1978 wybory wygrał Antonio Guzmán Fernández z PRD. W 1982 prezydentem został partyjny kolega Fernándeza, Salvador Jorge Blanco. Rządy Blanco zdominowały trudności ekonomiczne, wdrażanie dyskusyjnego programu liberalnych reform i konflikty wewnątrz rządzącej partii. W 1986 na urząd powrócił Balaguer, który wygrał wybory jako kandydat Chrześcijańsko-Społecznej Partii Reformistycznej. Zyskał on reelekcję w 1990 i 1994.
W 1996 władzę objął Leonel Fernández z Partii Wyzwolenia Dominikany (PLD). Dzięki aktywnej polityce międzynarodowej Fernández zdobył uznanie za granicą, jednak jego popularność w kraju topniała. W 2000 roku w wyborach prezydenckich zwyciężył Hipólito Mejía z PRD. W 2004 na stanowisko powrócił Leonel Fernández i rządził do 2012, kiedy zastąpił go Danilo Medina. W 2020 prezydentem został Luis Abinader.
Demografia.
73% Dominikańczyków to ludzie mieszanego pochodzenia rasowego, biali stanowią 16% mieszkańców a czarni 11%.
Około 1/4 ludności Republiki Dominikańskiej zamieszkuje stolicę kraju, Santo Domingo. Drugim pod względem ludności miastem jest Santiago de los Caballeros.
Podział administracyjny.
Dominikana podzielona jest na 31 prowincji oraz obszar wydzielony stolicy ("Distrito Nacional").
Język.
W Republice Dominikańskiej językiem urzędowym jest hiszpański. Język ten wprawdzie odbiega nieco od tego (lub tych – jako że w Hiszpanii występuje również wiele różnych dialektów), który używany jest na Półwyspie Iberyjskim, jednak nie na tyle, aby stwarzało to problemy z komunikowaniem się. Różnice te zaznaczają się zarówno na podłożu leksyki, jak i wymowy.
Religia.
Źródło: Prolades, 2010; Pew Forum, 2010; Operation World, 2010; LDS, 2012; jw.org, 2020.
Gospodarka.
Główne produkty przemysłu rolno-spożywczego to cukier, tytoń oraz kawa, które są obok złota i innych metali cennym towarem eksportowym.
Bardzo dużą rolę odgrywa przynosząca znaczne dochody turystyka. Dominikana posiada najlepiej rozwiniętą na Karaibach infrastrukturę pod kątem turystów. Dwoma najbardziej znanymi regionami wypoczynkowymi są Punta Cana i Puerto Plata. W obydwu dominują wielkie kompleksy hotelowe międzynarodowych sieci, usytuowane bezpośrednio przy plażach uważanych za jedne z najpiękniejszych na Karaibach.
Emisja gazów cieplarnianych.
Emisja równoważnika dwutlenku węgla z Dominikany wyniosła w 1990 roku 16,603 Mt, z czego mniej więcej połowę stanowił dwutlenek węgla, nieco mniej emisje metanu i znacząco mniej podtlenku azotu. W przeliczeniu na mieszkańca emisja wyniosła wówczas 1,116 t dwutlenku węgla, a w przeliczeniu na 1000 dolarów PKB 204 kg. Od tego czasu emisje dwutlenku węgla rosną nadal praktycznie jednostajnie (z większym skokiem w 2002, a po nim dwuletnim spadkiem), a pozostałych gazów cieplarnianych pozostają na podobnym poziomie. Głównym źródłem emisji przez cały czas była energetyka, a transport był na drugim miejscu. W 2018 emisja dwutlenku węgla pochodzenia kopalnego wyniosła 25,177 Mt, a w przeliczeniu na mieszkańca 2,313 t i w przeliczeniu na 1000 dolarów PKB 150 kg.

</doc>
<doc id="1307" url="https://pl.wikipedia.org/wiki?curid=1307" title="Dwutlenek węgla">
Dwutlenek węgla

Dwutlenek węgla, ditlenek węgla, , – nieorganiczny związek chemiczny z grupy tlenków, w którym węgiel występuje na IV stopniu utlenienia.
W temperaturze pokojowej jest to bezbarwny i niepalny gaz o kwaskowatym smaku, rozpuszczalny w wodzie (1,7 l /l ) i cięższy od powietrza (ok. 1,5 raza). Pod normalnym ciśnieniem przechodzi ze stanu stałego do gazowego (sublimuje) z pominięciem fazy ciekłej w temperaturze −78,5 °C. Można go jednak skroplić pod zwiększonym ciśnieniem, np. pod ciśnieniem 34 atm skrapla się w temperaturze 0 °C.
Występuje w organizmie człowieka i jest w nim wytwarzany, odgrywa ważną rolę w utrzymaniu równowagi kwasowo-zasadowej organizmu, jego zbyt małe, jak i zbyt duże stężenie jest szkodliwe dla organizmu. W większych stężeniach w powietrzu dwutlenek węgla uniemożliwia usuwanie dwutlenku węgla z organizmu, przez co jest szkodliwy dla zdrowia, a nawet zabójczy, a jego działanie powoduje powstawanie hiperkapni, a co za tym idzie kwasicy oddechowej i w następstwie obrzęku mózgu.
Występowanie.
Na Ziemi w naturze występuje w stanie gazowym w atmosferze, a także jako składnik gazów wulkanicznych i innych gazów podziemnych. Jest rozpuszczony i związany w wodzie oraz związany w skałach (np. jako składnik ). Jest częścią obiegu węgla w przyrodzie, jest produktem spalania i oddychania. Tworzy się przy utlenianiu i fermentacji substancji organicznych, powstając w dużych ilościach w: gorzelniach, wytwórniach win, silosach zbożowych, browarach, biogazowniach.
Jest wykorzystywany przez rośliny w procesie fotosyntezy.
W atmosferze Ziemi.
Dwutlenek węgla występuje w powietrzu w śladowych ilościach (około 0,04%), ale odgrywa ważną rolę w efekcie cieplarnianym i jako źródło węgla do fotosyntezy. Całkowita masa dwutlenku węgla w atmosferze wynosi około 3 kg, tj. 3 biliony ton. Stężenie zmienia się sezonowo i w zależności od szerokości geograficznej, a także lokalnie, szczególnie w pobliżu ziemi. Koncentracja jest na ogół większa nad lądami niż na oceanami, na półkuli północnej większa niż na południowej, na obszarach miejskich i w pobliżu miejsc spalania paliw kopalnych jest większa niż średnia. Koncentracja w pomieszczeniach może być nawet 10 razy większa niż średnia.
Dane z rdzeni lodowych ujawniły, że poziom w atmosferze w ciągu ostatnich 420 tys. lat do początku industrializacji w połowie XVIII wieku wahały się między 190 ppm podczas szczytów lodowcowych a 280 ppm w okresach ciepłych. Pierwsze systematyczne pomiary wykonywane od 1958 roku przez Charlesa Davida Keelinga, określiły stężenie objętościowe na 315 ppm. Kolejne pomiary wykazują wzrost ilości dwutlenku węgla w atmosferze. Średnioroczne stężenie dwutlenku węgla w 2018 r. osiągnęło 407,8 ppm, co stanowi nowy rekordowy poziom, który jest o 47 procent wyższy niż wartość sprzed okresu przemysłowego. Główną przyczyną wzrostu stężenia jest spalanie paliw kopalnych do produkcji energii oraz w sektorze przemysłowym.
Stężenie dwutlenku węgla w ciągu ostatnich 10 000 lat pozostawało względnie stałe około 300 ppm. Obieg węgla w atmosferze był w pobliżu warunków równowagi. Wraz z początkiem industrializacji w XIX wieku wzrosła zawartość dwutlenku węgla w atmosferze. Obecna koncentracja jest prawdopodobnie najwyższa od 15 do 20 milionów lat. W latach 1999–2018 zawartość dwutlenku węgla wzrosła średnio o 2,1 ppm rocznie z tendencją wzrostową o 0,05 ppm na rok
Człowiek w wyniku swej działalności wytwarza (w 2018 r.) około 0,0371 bilionów ton rocznie, co stanowi jedynie niewielką część dwutlenku węgla dostarczanego do atmosfery, głównym źródłem są procesy naturalne dostarczające około 0,55 biliona ton rocznie. Jednak naturalne pochłaniacze węgla pochłaniały, taką samą ilość , stężenie dwutlenku węgla pozostało względnie stałe przed industrializacją. Dodatkowy dwutlenek węgla nie pozostaje w całości w atmosferze, jest pochłaniany około w połowie przez biosferę i oceany, które pochłaniają teraz więcej dwutlenku węgla niż uwalniają, co powoduje ich zakwaszenie. Druga połowa wyemitowanego dwutlenku węgla pozostaje w atmosferze, co prowadzi do obserwowanego wzrostu koncentracji.
W wodzie.
Dwutlenek węgla jest rozpuszczalny w wodzie, reaguje także z nią tworząc kwas węglowy, który ulega dysocjacji elektrolitycznej częściowej lub całkowitej tworząc jon wodorowęglanowy () lub węglanowy ().
Dwutlenek węgla zawarty w atmosferze rozpuszcza się w kroplach deszczu i jest rozpuszczony w wodzie opadowej nadając jej lekko kwaśny odczyn. Woda przesiąkając do głębszych warstw gleby rozpuszcza zawarty w glebie dwutlenek węgla, jak i inne substancje, głównie związki wapnia. W wodzie zawierającej dwutlenek węgla i wapń, w zależności od pH dwutlenek węgla występuje jako wolny, wodorowęglanowy i węglanowy. Dwutlenek węgla rozpuszczony w wodzie jako wolny wywołuje korozję metali i betonu, jego działanie jest dwustronne, poprzez reakcję z metalem jako kwas oraz przez niszczenie warstw węglanów na powierzchni konstrukcji w wyniku reakcji tworzenia kwaśnych węglanów, które są lepiej rozpuszczalne w wodzie. Korozyjności dwutlenku węgla sprzyja tlen rozpuszczony w wodzie.
Jony te reagują z jonami dodatnimi tworząc elektrolity bądź związki chemiczne nierozpuszczalne lub słabo rozpuszczalne w wodzie. W wodach naturalnych reaguje głównie z jonami wapnia, magnezu. Stan równowagi, zależny od temperatury i ciśnienia parcjalnego dwutlenku węgla nad wodą oraz stężenia innych jonów w wodzie określa stężenie wszystkich możliwych związków tworzonych z dwutlenku węgla i innych rozpuszczonych związków. Rozpuszczalność dwutlenku węgla w wodzie spada wraz ze wzrostem temperatury.
Ponieważ zimna woda ma większą gęstość, woda bogata w dwutlenek węgla opada w głębsze warstwy. Tylko przy ciśnieniach powyżej 300 bar i temperaturach powyżej 120 °C (393 K) jest odwrotnie, co zachodzi blisko głębokich kominów hydrotermalnych.
Oceany zawierają około 50 razy więcej dwutlenku węgla niż atmosfera. Obecnie wody powierzchniowe oceanów zawierają mniejsze stężenie dwutlenku węgla niż wynikałoby to z równowagi dla 400 ppm w powietrzu. Ocean działa jak duży pochłaniacz dwutlenku węgla z atmosfery i pochłania około jednej trzeciej dwutlenku węgla uwalnianego w wyniku działalności człowieka. W górnych warstwach oceanów jest częściowo wiązany przez fotosyntezę. Wraz ze wzrostem stężenia dwutlenku węgla zmniejsza się alkaliczność wody, co nazywa się zakwaszeniem oceanów i może mieć negatywny wpływ na ekosystemy morskie. Wiele stworzeń morskich jest wrażliwych na zmiany kwasowości oceanów. Zdarzenia zakwaszenia w historii Ziemi doprowadziły do masowego wymierania i gwałtownego spadku proliferacji gatunków w oceanach. W szczególności wpływa to na organizmy, które budują struktury z węglanu wapnia, ponieważ rozpuszcza się on wraz ze wzrostem kwasowości wody. Szczególnie wrażliwe są korale, muszle i szkarłupnie, takie jak rozgwiazdy i jeżowce.
Wody podziemne zawierają dwutlenek węgla. Wody mineralne o dużej zawartości dwutlenku węgla zwane szczawami ( &gt; 1000 mg/dm³) lub wodami kwasowowęglowymi są butelkowane lub wykorzystywane jako źródło dwutlenku węgla. W wodzie przeznaczonej do konsumpcji i technologicznej dwutlenek węgla usuwa się z niej w procesie zwanym odkwaszaniem realizowanym poprzez kontakt wody z powietrzem. Woda w jeziorze może być nasycana od dołu pochodzącym z działalności wulkanicznej lub z rozkładu materiału organicznego, jeżeli w jeziorze nie zachodzi konwekcyjne mieszanie wody, to dolne warstwy wody mogą znacznie nasycić się dwutlenkiem węgla. Tak nagromadzony dwutlenek węgla może nagle wydostać się na powierzchnię, co jest zwane erupcją limniczną powodując drastyczny wzrost stężenia dwutlenku węgla w atmosferze aż do poziomu śmiertelnego dla ludzi i zwierząt. Zjawiskiem takim była katastrofa nad jeziorem Nyos.
Na innych planetach.
Dwutlenek węgla jest głównym składnikiem atmosfery Wenus i Marsa. Atmosfera Wenus składa się z 96,5% dwutlenku węgla, ma około 90 razy większą masę i ciśnienie niż atmosfera ziemska. Duża zawartość dwutlenku węgla oraz duża masa atmosfery jest przyczyną bardzo silnego efektu cieplarnianego, co w połączeniu z mniejszą odległością od Słońca niż Ziemia daje temperaturę powierzchni około 480 °C. Dwutlenek węgla stanowi również 96% masy marsjańskiej atmosfery, z powodu niskiego ciśnienia atmosferycznego wynoszącego około siedmiu milibarów, efekt cieplarniany, pomimo wysokiej zawartości dwutlenku węgla, prowadzi jedynie do wzrostu temperatury o około 5 K. W pobliżu biegunów Marsa atmosferyczny dwutlenek węgla zestala się w zimie tworząc czapy polarne (Planum Australe i Planum Boreum). Czapy częściowo sublimują latem, a resublimują zimą.
Atmosfery planet zewnętrznych i ich satelitów zawierają dwutlenek węgla.
Właściwości fizyczne.
Dwutlenek węgla pod ciśnieniem atmosferycznym poniżej −78,5 °C jest ciałem stałym, zwanym suchym lodem. Ogrzewany, nie topi się, ale ulega sublimacji, przechodząc bezpośrednio w stan gazowy. W tych warunkach nie ma zatem topnienia ani temperatury wrzenia.
Punkt potrójny dwutlenku węgla, w którym trzy fazy: stała, ciekła i gazowa są w równowadze termodynamicznej, jest w temperaturze −56,6 °C (216,58 K) i ciśnieniu 5,19 bar. Poniżej tego ciśnienia dwutlenek węgla nie występuje jako ciecz.
Temperatura krytyczna wynosi 31,0 °C, ciśnienie krytyczne wynosi 73,8 bar, a gęstość krytyczna wynosi 0,468 g/cm³. Poniżej temperatury krytycznej można skompresować dwutlenek węgla, zwiększając ciśnienie do bezbarwnej cieczy. W temperaturze pokojowej wymagane jest ciśnienie ok. 60 bar.
Stały dwutlenek węgla krystalizuje w układzie regularnym w grupie przestrzennej formula_1 (grupa nr 205), z parametrem sieci .
Rozpuszczalność w wodzie jest stosunkowo wysoka. W temperaturze 20 °C pod normalnym ciśnieniem nasycenie jest w równowadze z fazą czystego dwutlenku węgla przy 1688 mg/l.
W kowadle diamentowym pod ciśnieniem rzędu 40–48 GPa (ok. 400–480 tys. atm) uzyskano dwutlenek węgla w postaci amorficznej. Postać amorficzną mają tlenki pierwiastków tej samej grupy układu okresowego: (por. szkło kwarcowe) i , dla których faza taka może istnieć przy dowolnie niskim ciśnieniu, przeciwnie do dwutlenku węgla.
Budowa cząsteczki.
Cząsteczka dwutlenku węgla jest liniowa i centrosymetryczna, atom węgla znajduje się między atomami tlenu. Długość wiązania węgiel-tlen wynosi 116,3 pm, jest zauważalnie krótsza niż długość wiązania pojedynczego wiązania , a nawet krótsza niż w przypadku większości innych grup funkcyjnych z wiązaniem wielokrotnym. Ponieważ cząsteczka jest centrosymetryczna, nie ma elektrycznego momentu dipolowego. Cząsteczka ma 4 wewnętrzne stopnie swobody, odpowiadają im 4 drgania normalne cząsteczki. Wzbudzeniom pierwszego poziomu drgań odpowiadają liczby falowe i długości fali: drgania rozciągające symetryczne (1537 cm−1), drgania rozciągające asymetryczne (2349 cm−1, 4,25 μm), drgania zginające symetryczne i niesymetryczne (667 cm−1, 14,99 μm). Drgania rozciągające symetryczne nie mogą być wzbudzone przez foton, bo cząsteczka w obu stanach ma taki sam elektryczny moment dipolowy.
W konsekwencji tylko dwa pasma wibracyjne są obserwowane w widmie IR – tryb rozciągania antysymetrycznego przy 2349 cm−1 i para zdegenerowanych trybów zginania przy 667 cm−1. Wzbudzenie symetrycznego rozciągania cząsteczki przy 1388 cm−1 jest możliwe, jeżeli towarzyszy innemu przejściu zmieniającemu moment dipolowy cząsteczki, dlatego jest obserwowane w widmie Ramana.
Wytwarzanie.
W laboratorium najłatwiej wytworzyć dwutlenek węgla poprzez prażenie węglanu wapnia:
lub działając praktycznie dowolnym kwasem (np. octowym, solnym, cytrynowym) na węglany, np. węglan wapnia, węglan sodu () lub wodorowęglan sodu () i in.
Najdogodniej przeprowadza się takie reakcje chemiczne w aparacie Kippa.
W przemyśle dwutlenek węgla otrzymuje się jako produkt uboczny spalania węgla, węglowodorów oraz fermentacji alkoholowej. Reakcja utleniania węgla:
A także jako produkt uboczny wytwarzaniu wodoru z metanu, gazu syntezowego wykorzystywanego między innymi do produkcji amoniaku w metodzie Habera i Boscha. Przy produkcji wapna palonego i cementu.
Dwutlenek węgla pozyskuje się także poprzez odgazowanie wód mineralnych.
Znaczenie biologiczne.
Dwutlenek węgla jest końcowym produktem oddychania komórkowego w organizmach aerobowych, które uzyskują energię poprzez rozkład cukrów, tłuszczów i aminokwasów przez reakcję z tlenem w ich metabolizmie. Dotyczy to wszystkich roślin, glonów i zwierząt oraz grzybów i bakterii tlenowych. Usuwanie nadmiaru dwutlenku węgla z organizmu jest częścią oddychania zewnętrznego. U kręgowców dwutlenek węgla przemieszcza się we krwi z tkanek organizmu do skóry (np. płazy) lub skrzeli (np. ryby), skąd rozpuszcza się w wodzie albo do płuc u kręgowców oddychających powietrzem, z których jest wydychany. Podczas aktywnej fotosyntezy rośliny pochłaniają więcej dwutlenku węgla z atmosfery, niż uwalniają w procesie oddychania.
W organizmie człowieka.
Dwutlenek węgla w organizmie człowieka powstaje w tkankach wyniku utleniania cukrów, tłuszczów i białek, jest transportowany przez krew do płuc, gdzie w pęcherzykach płucnych przechodzi do powietrza i jest wydychany. Jego stężenie odgrywa ważną rolę w utrzymaniu równowagi kwasowo-zasadowej organizmu. Prawidłowe średnie ciśnienie parcjalne dwutlenku węgla w krwi tętniczej wynosi (40 ± 4) mmHg, w krwi żylnej – 46 mmHg. Przy prawidłowym funkcjonowaniu pęcherzyków płucnych ciśnienie parcjalne dwutlenku węgla w pęcherzyku płucnym jest równe ciśnieniu w krwi tętniczej (40 mmHg ≈ 5% powietrza obj.). Zwiększona zawartość dwutlenku węgla we krwi określana jest jako hiperkapnia a zmniejszona hipokapnia. Dwutlenek węgla z tkanek do płuc jest transportowany głównie w formie jonu wodorowęglanowego, w mniejszym w postaci rozpuszczonego w wodzie, a w niewielkim jako związany w hemoglobinie.
Dwutlenku węgla jest głównym czynnikiem chemicznej kontroli oddychania. Podniesione ciśnienie parcjalne we krwi i płynie mózgowo-rdzeniowym pobudza receptory centralne. Obniżone pH krwi, na które wpływa między innymi stężenie we krwi pobudza chemoreceptory obwodowe. Impulsy z receptorów docierają do centrum wdechowego. Celowa lub wywołana podenerwowaniem bądź stresem hiperwentylacja prowadząca do obniżenia stężenia dwutlenku węgla we krwi (hipokapnia) powoduje zaburzenia takie jak: oszołomienie, osłabienie, bóle głowy, zaburzenia wzrokowe, a nawet omdlenie.
Zwiększone stężenie we krwi może być wywołane różnymi czynnikami, takimi jak: niewystarczająca wentylacja płuc, upośledzenia funkcji układu oddechowego oraz zwiększone stężenie dwutlenku węgla we wdychanym powietrzu.
Zatrucie dwutlenkiem węgla.
Dwutlenek węgla zawarty w powietrzu w stężeniu do około 500 ppm nieszkodliwy dla ludzi, w wyższym stężeniu wywołuje duszności, wywołane utrudnionym wydaleniem dwutlenku węgla powstającego w organizmie. Stężenie powyżej 1000 ppm skutkuje znacznym upośledzeniem zdolności intelektualnych, z kolei stężenie 2500 ppm niemal całkowicie pozbawia człowieka wyższych zdolności umysłowych, a także znaczenie zmniejsza zdolności fizyczne, również w prostych czynnościach.
Dla zdrowego człowieka działanie toksyczne występuje przy stężeniach powyżej 5%, powodujące rozwój hiperkapnii i kwasicy oddechowej. Ciężka kwasica nasila działanie przywspółczulnej aktywności nerwowej, co powoduje osłabienie oddychania i krążenia. Stężenia ponad 10% dwutlenku węgla mogą powodować drgawki, śpiączkę i śmierć. w stężeniu przekraczającym 30% działa szybko, prowadząc do utraty przytomności w ciągu kilku sekund. To by tłumaczyło, dlaczego ofiary przypadkowego zatrucia często nie podejmują działań w celu rozwiązania sytuacji (otwierają drzwi itp.).
Badania wykazały dużą zmienność tolerancji na . Stężenia we krwi wahały się od co najmniej 0,055 do 0,085 atm (41,8–64,6 mmHg) wśród osób z objawami, bezpiecznego poziomu ekspozycji na nie można scharakteryzować pojedynczą wartością. Stężenia w powietrzu śmiertelnych przypadków zatrucia wahają się między 14,1 a 26% , tolerancja na spada wraz z wiekiem.
Do zatruć dwutlenkiem węgla dochodzi przede wszystkim w zakładach przemysłowych, głównie kopalniach, jednak zatrucia są także możliwe w zamkniętych pomieszczeniach, gdzie dochodzi do odparowania dużej ilości suchego lodu lub wydzielany jest w wyniku fermentacji.
 tworzy się przy utlenianiu i fermentacji substancji organicznych. Dzieje się tak w gorzelniach, wytwórniach win, silosach zbożowych, browarach, studzienkach kanalizacyjnych, szambach i innych podobnych. Odmienna sytuacja ma miejsce w kopalniach, gdzie na skutek prac górniczych lub ruchów górotworu zostają nagle uwolnione znaczne ilości gazów, w tym często dwutlenku węgla.
Mieszanka dwutlenku węgla i tlenu (tzw. „mikstura Meduny” lub „karbogen”) była stosowana przez węgierskiego lekarza Ladislasa Medunę jako jedna ze wstrząsowych terapii chorób psychicznych, podobnie jak ceniony przez Medunę pentetrazol. Stężenie dwutlenku było zawarte w przedziale od 1,5% do 50%.
Wykrywanie.
Obecność dwutlenku węgla w powietrzu, gazach obojętnych, rozpuszczonego w obojętnej wodzie można stwierdzić za pomocą wody wapiennej. W zetknięciu się wody wapiennej z dwutlenkiem węgla następuje reakcja:
Wytrącenie się węglanu wapnia powoduje zmętnienie wody wapiennej.

</doc>
<doc id="1308" url="https://pl.wikipedia.org/wiki?curid=1308" title="Drabina hakowa">
Drabina hakowa

Drabina hakowa – typ drabiny pożarniczej używany obecnie w Polsce jedynie w sporcie pożarniczym. W przeszłości drabiny tego typu były wykorzystywane również w akcjach ratowniczych.
Cechą charakterystyczną drabiny jest wieńczący ją hak, który umożliwia zaczepienie drabiny w otworze okiennym i dostanie się na wyższą kondygnację budynku.
Ze względu na swoją konstrukcję drabiny hakowe dzieliły się na:
Drabina hakowa jednobocznicowa.
Drabinki tego typu składały się z drewnianego drąga o przekroju prostokątnym, do którego montowane były szczeble. Całość zakończona była stalowym, uzębionym hakiem. Zaletą tego typu drabin był jej stosunkowo niewielki ciężar, wadą natomiast jej mała stabilność. Tego typu drabiny były używane przez straże w Stanach Zjednoczonych, Wielkiej Brytanii i Japonii.

</doc>
<doc id="1311" url="https://pl.wikipedia.org/wiki?curid=1311" title="Do ut des">
Do ut des

Do ut des () – pochodząca z prawa rzymskiego zasada wyrażająca ekwiwalentność świadczeń. Jest ona podstawą umów wzajemnych (synalagmatycznych). Każda ze stron zobowiązuje się dlatego i pod warunkiem, że druga strona spełni swe świadczenie. Na tej podstawie oparty jest art. 487 polskiego kodeksu cywilnego. 
Zasada ta wiąże osobę obdarowującą z obdarowaną. Rodzaj niepisanego kontraktu zobowiązującego osobę obdarowaną do odwzajemnienia się w ten sam sposób. Z kolei każdy odwzajemniony podarek jest pretekstem do kolejnego, itd. Tworzy się w ten sposób długotrwała więź między stronami, w której zwykle zaczynają odgrywać rolę także inne aspekty niż pierwotne motywy stron.
Na zasadzie wzajemności opierała się antropologiczna analiza prawa Bronisława Malinowskiego, w jego "Zwyczaju i zbrodni w społeczności dzikich". Kategoria ta odgrywa też ogromną rolę w teorii strukturalnej w antropologii.
Analiza gramatyczna.
"Do" ("indicativus praesentis activi") znaczy „daję” – pochodzi od "do, dare, dedi, datum", "des" to "coniunctivus preasentis activi" (żebyś dawał), użyty zgodnie z zasadami "consecutio temporum". "Ut des" to zdanie podrzędne celu (po co?).

</doc>
<doc id="1312" url="https://pl.wikipedia.org/wiki?curid=1312" title="Dialektyka">
Dialektyka

Dialektyka (, ) – nauka zajmująca się poprawnością argumentacji i refutacji podczas wypowiedzi. Kodyfikuje ona zasady poprawnego rozumowania służące do analizy argumentów potwierdzających lub kwestionujących udowadnianą w czasie dyskursu tezę, a także sposoby prowadzenia debaty, w czasie której jeden z uczestników stara się udowodnić tezę, a drugi ją obalić. Przez niektórych autorów niekiedy mylona z logiką.
Celem dialektyki nie jest osiągnięcie konsensusu, lecz przekształcanie niezgody w krytyczny instrument rozwoju wiedzy. Rozumowanie dialektyczne dotyczy twierdzeń, które budzą kontrowersje, a także opartych na niezweryfikowanych hipotezach. Dialektyka nie zajmuje się problemami, które można rozwiązać za pomocą wnioskowania logicznego, właściwego dla nauk dedukcyjnych. Jej zasady stosuje się do argumentacji w tych dziedzinach, które pozbawione są formalizacji – wówczas, gdy reguły logiki formalnej nie są oczywiste czy obowiązujące. Analizowane przez dialektykę argumenty nie są oparte na nieuniknionej relacji przyczynowo-skutkowej, ale na prawdopodobieństwie. Argumenty są w dialektyce prawdopodobne, gdy są uznawane przez wszystkich ludzi, bądź przez większość spośród nich, czyli są zgodne z opinią powszechną. Za argumenty prawdopodobne uznaje się także takie, które są głoszone przez osoby powszechnie uważane za autorytety. Systematyką oraz zastosowaniem tego typu argumentów i ich przesłanek zajmują się retoryka oraz topika.
Twórcą dialektyki jako nauki był w IV wieku p.n.e. Arystoteles. Jego twierdzenia rozwinęli w starożytności między innymi Cyceron, Kwintylian, czy Boecjusz. W średniowieczu dialektyka była jednym z podstawowych przedmiotów szkolnych, wykładanych w ramach sztuk wyzwolonych. Do XVIII wieku, w kulturze europejskiej, traktowano ją jako element niezbędnego wykształcenia, kształtujący poprawność rozumowania. Z dialektyki wywodzi się wiele stosowanych współcześnie pojęć naukowych, na przykład teza, system, doktryna, czy dogmat, jak również powszechnie używanych toposów – na przykład, że o faktach się nie dyskutuje.
W historii nauki używano niekiedy terminu "dialektyka" w innych znaczeniach. W starożytności i średniowieczu niektórzy uczeni stosowali go dla określenia , która w odróżnieniu od nie była logiką nazw, lecz logiką zdań. W czasach nowożytnych używano tego terminu w znaczeniu filozoficznym, przyjętym przez Hegla (teoria rzeczywistości jako walki i jedności przeciwieństw), Marksa (teoria rozwoju rzeczywistości jako walki i jedności przeciwieństw) lub Schopenhauera, który utożsamił dialektykę z erystyką. Te nowożytne znaczenia są zasadniczo odmienne od klasycznego ujęcia dialektyki i mają z nią niewiele wspólnego.
Znaczenie terminu.
Termin διαλεκτική występuje w pismach greckich od VI wieku przed Chrystusem. Używano go zawsze z domyślnym τέχνη – „sztuka”, „umiejętność”. Wywodzi się on z rzeczownika διάλεκτος, oznaczającego wygłaszaną mowę, dyskusję lub sposób wypowiadania się. Używano też czasownika διαλέγομαι – „dyskutuję”, „przemawiam”, „wypowiadam się” (powstałego wskutek złożenia słów δῐᾰ́ „przez” oraz λέγω – „mówię”). Termin ten oznaczał w starożytnej Grecji sztukę (umiejętność) właściwego rozumowania podczas wypowiadania się lub rozmowy. W I wieku przed Chrystusem, w pismach Cycerona, pojawił się łaciński odpowiednik tego terminu, którego źródłosłów był grecki, "dialectica". Z języka łacińskiego termin ten trafił w średniowieczu, poprzez szkoły, do języka polskiego.
Historia.
Starożytność.
Starożytna Grecja.
Za ojca dialektyki uważa się Heraklita z racji jego teorii wariabilizmu, która uznawała zmienność rzeczywistości i jedność przeciwieństw za zasadę istnienia świata. Arystoteles twierdził jednak, że twórcą dialektyki był Zenon z Elei, gdyż jako pierwszy przeanalizował "reductio ad absurdum". Sofiści (między innymi Protagoras), używali terminu dialektyka w rozumieniu narzędzia służącego do udowadniania tezy i wygrywania dysput, za pomocą zwodniczej argumentacji, a także wieloznaczności pojęć i sądów. Dialektyka była dla nich metodą tworzenia za pomocą środków językowych pozorów prawdy dla fałszywych sądów, czyli tego, co później nazwano argumentacją sofistyczną. Stanowisko sofistów skrytykował Sokrates, który zdefiniował dialektykę jako sztukę poszukiwania prawdy na drodze pytań i odpowiedzi. Wyróżnił na tej drodze dwa etapy – część elenktyczną (sztukę sprawdzanie poprawności argumentacji) oraz część majeutyczną (sztukę rodzenia argumentów). Uważał, że w pierwszym etapie należy sprowadzić tezę przeciwnika do absurdalnych konsekwencji, natomiast w drugim wydobyć z twierdzeń szczegółowych, na drodze opozycji i analogii, tezę ogólną.
Twierdzenia Sokratesa rozwinął Platon, dla którego dialektyka była przede wszystkim metodą dochodzenia do obiektywnej prawdy. W swoich dziełach podał on jej dwa znaczenia. Pierwsze akcentowało umiejętność zadawania pytań i udzielania odpowiedzi, drugie ukazywało dialektykę jako „najwyższą filozoficzną metodę”, polegającą na przechodzeniu od pojęć szczegółowych do pojęć bardziej ogólnych. Proces ten utożsamiał Platon z wznoszeniem się umysłu od danych zmysłowych do idei (obiektywnej prawdy). Wspólne obu znaczeniom było krytyczne rozróżnianie pojęć według zasady tożsamości i różnicy, mające na celu doprowadzenie do prawdy. Platon zdefiniował dialektykę jako sztukę odnalezienia i właściwego użycia odpowiedniego do danego problemu argumentu.
Twórcą dialektyki jako dyscypliny naukowej był w IV wieku przed Chrystusem Arystoteles. Jej zasady przedstawił w traktacie "Topiki", a potem rozszerzył i uszczegółowił w dwóch kolejnych traktatach – ' oraz '. Dla Arystotelesa celem dialektyki nie było ustalenie obiektywnej prawdy, ale realistyczne wyjaśnienie rzeczywistości. Zdefiniował on dialektykę jako naukę, która stosuje metodę uzasadniania twierdzeń prawdopodobnych za pomocą sylogizmów, zwłaszcza w odniesieniu do takich tez, które nie dają się udowodnić za pomocą rozumowania logicznego, czyli opartego na nieuniknionej relacji przyczynowo-skutkowej. W jego ujęciu zadaniem dialektyki było krytyczne badanie twierdzeń, poprzez analizę związków pojęciowych (rodzaj, gatunek, przypadłość itp.) istniejących między podmiotem a orzecznikiem sylogizmu. Analiza dialektyczna badając, czy przesłanki twierdzeń nie są używane w różnych znaczeniach lub zakresach, służy do uzasadniania ich podstaw przez przypisanie podmiotom i orzecznikom właściwych racjonalnych sensów, a także do wykluczenia występujących wśród nich błędów. Według Arystotelesa dialektyka była więc metodą służącą do wyprowadzania poprawnych wniosków z obszaru tego, co prawdopodobne, jak i sztuką poprawnej argumentacji.
"Topiki" oraz "O dowodach sofistycznych" zapoczątkowały długą i skomplikowaną historię dialektyki. Greccy uczeni pisali do nich komentarze, a także tworzyli własne traktaty, w których dokonywali reinterpretacji twierdzeń Arystotelesa. Do najwybitniejszych dialektów zaliczani są Teofrast z Eresos, Straton z Lampsaku, Eudemos z Rodos, a w późniejszym okresie Temistios, Aleksander z Afrodyzji czy Amoniusz. Za najstarszą szkołę dialektyczną, opierającą swoją naukę na twierdzeniach Arystotelesa, uważa się odgałęzienie szkoły megarejskiej. Jego przedstawicielami byli między innymi Diodor Kronos, Filon, Kleinomachos z Thurii, Pantoides. Opracowali oni dialektyczną teorię zdań i teorię negacji. Z czasem szkoła ta zaczęła uprawiać dialektykę w celach komercyjnych.
Starożytny Rzym.
Grecką dialektykę zaadaptował do nauki łacińskiej Cyceron. W traktacie "Topika" narzekał, że Rzymianie traktują retorykę jak poezję, nie studiując książek poświęconych dialektyce. Tymczasem dialektyka – jego zdaniem – jest niezbędnym elementem wykształcenia mówcy. Cyceron zdefiniował dialektykę jako "ratio disserendi", gdzie „ratio” odnosi się do poprawnego wnioskowania, a „disserendi” do dyskursu. Podzielił dialektykę na "ratio inveniendi" (odkrywanie argumentów uzasadniających tezę) i "ratio iudicandi" (ocenę argumentów). W przeciwieństwie do greckich teoretyków uważał, że ważniejsza od oceny poprawności argumentów jest umiejętność ich odpowiedniego dobierania.
Augustyn z Hippony uznał dialektykę za najważniejszą część wiedzy, "disciplina disciplinarum" wszelkich nauk. W jego ujęciu dialektyka znajduje szczególne zastosowanie w rozumowaniu odnoszącym się do przedmiotów wiecznych, koniecznych i niezmiennych.
Kluczowe dla dalszego rozwoju dialektyki były prace Boecjusza, który tradycyjnie uważany jest za pomost między dialektyką starożytną a średniowieczną. Boecjusz napisał komentarz do "Topik" Arystotelesa (współcześnie zaginiony) oraz komentarz do "Topiki" Cycerona. Przetłumaczył "Topiki" oraz "O dowodach sofistycznych" Arystotelesa na łacinę. Napisał też kilka traktatów, w których przedstawił własny pogląd na dialektykę – największy wpływ na dalszy rozwój nauki wywarły jego "De topicis differentiis".
Średniowiecze i nowożytność.
W średniowieczu dialektyka została jednym z podstawowych przedmiotów szkolnych, wykładanych w ramach sztuk wyzwolonych. Była składnikiem "trivium", obok gramatyki i retoryki. Nauczano jej na podstawie teorii Cycerona, Kwintyliana i Boecjusza. Jako podręcznika używano najczęściej "" Marcjana Kapelli. W podręczniku tym dialektyka została alegorycznie opisana jako surowa i chuda niewiasta, bowiem dla Kapelli dyscyplina ta była jedynie pomocniczą dla retoryki, reprezentowanej przez piękną i majestatyczną kobietę. Tak przedstawiano dialektykę w poezji i sztuce, jej postać utrwalona została na przykład na fasadach katedr w Paryżu, Chartres, Laon czy .
Odwrót od retoryki i położenie nacisku na znaczenie dialektyki, który dokonał się w XII wieku, najczęściej wiązany jest przez współczesnych badaczy z odnalezieniem w połowie tego stulecia łacińskich przekładów "Topik" oraz "" Arystotelesa, autorstwa Boecjusza. Tłumaczenia te były często kopiowane w całej Europie, zachowało się 250 rękopisów łacińskiego tekstu "Topik". Odkrycie przekładów Boecjusza, wraz ze wzrastającym zainteresowaniem myślą Arystotelesa, przygotowało grunt pod odrzucenie podręcznika Marcjana Kapelli i spowodowało powstanie wielu nowych prac na temat dialektyki oraz rozwój tej dyscypliny. Jan z Salisbury narzekał około 1180 roku, że uczniowie studiują z zapałem dialektykę, a czują pogardę dla opartych na autorytecie gramatyki, retoryki czy filozofii: "Czego naucza ten stary osioł? Po co nam prawi o tym, co powiedzieli i zrobili starożytni? My sami z siebie wydobywamy wiedzę!" Jan z Sulisbury krytykował jałowość debat dialektycznych. W jednych ze swoich dzieł zapisał relację z paryskiej dysputy, której był świadkiem. Gdy po dwunastu latach ponownie odwiedził Paryż, usłyszał tych samych mistrzów, którzy podczas dysput głosili te same tezy i używali takich samych argumentów. W opinii Jana, przez lata żaden z tych mistrzów niczego nowego nie wniósł do nauki.
W pierwszej połowie XIII wieku William z Sherwood zdefiniował dialektykę, opierając się na Arystotelesie, jako sztukę dochodzenia do prawdopodobnych opinii, znajdujących się w połowie drogi między pewnością wiedzy naukowej a fikcją sofistyki. sklasyfikował dialektykę jako część logiki i uznał za metodę, która daje dostęp do wszystkich innych metod. Około 1250 roku długi komentarz do "Topik" napisał Albert Wielki. Komentarz ten był najważniejszym dziełem tego, co później nazwano "dialektyką scholastyczną" – drukowano go jeszcze w XVI wieku. W XV wieku, wśród humanistów, narodził się ruch „nowej dialektyki”, który odwoływał się bezpośrednio do prac Arystotelesa. Rudolf Agricola sformułował teorię związku między dialektyką a retoryką. W pierwszej połowie XVI wieku zrekonstruował to, co uznał za „prawdziwą” dialektykę – w przeciwieństwie do średniowiecznych interpretacji – opierając się na komentarzach Aleksandra z Afrodyzji i Awerroesa. Dzięki tym wysiłkom, dialektyka stała się ogólnym i elastycznym narzędziem argumentacji dla uczonych XVI, XVII i XVIII wieku, czego przykładami są dzieła Galileusza i Leibnitza. Do początków XIX wieku traktowano dialektykę jako element podstawowego wykształcenia. Uważano ją za autonomiczną dziedziną wiedzy, niezbędną w kształceniu poprawności rozumowania.
W XX wieku dialektyka odrodziła się w pewnych koncepcjach poznawczych. Należą do nich teoria argumentacji Chaïma Perelmana czy teoria dialektyczna . Grupa uczonych, których poglądy nawiązują do "Topik" Arystotelesa, wydaje od 1947 roku pismo "". Pierwszym redaktorem naczelnym tego pisma był Gaston Bachelard.
Dialektyka w filozofii nowożytnej.
Klasyczne pojęcie dialektyki, jako sztuki argumentacji, uległo gruntownej reinterpretacji w filozofii nowożytnej. Od XIX w. zaczęło dominować ujęcie nowe, umiejscawiające dialektykę w obszarze teorii poznania. Nowe znaczenia dialektyki było na tyle odmienne, że można mówić o powstaniu nowej tradycji znaczeniowej, mającej niewiele wspólnego z ujęciami wcześniejszymi. Najogólniej ujmując, w nowożytnej filozofii dialektyka jest traktowana jako pewna własność rzeczywistości.
Filozofowie wczesnonowożytni, tacy jak Francis Bacon, Kartezjusz czy Pierre Gassendi, odrzucali dialektykę wraz z całą późną scholastyką, przeciwstawiając jej nową teorię wiedzy opartą na logice i wiedzy empirycznej. Właściwy początek nowożytnemu ujęciu dialektyki dał Immanuel Kant, który w "Krytyce czystego rozumu" (1781) przeprowadził krytykę klasycznej dialektyki, zajmującej się jego zdaniem "logiką pozoru". Na jej miejsce wprowadził „logikę transcendentalną”, składającą się z dwóch etapów: analityki i dialektyki transcendentalnej. Dialektyka transcendentalna zajmowała się krytyką sądów transcendentalnych (wykraczających poza doświadczenie).
Kantowskie przeformułowanie dialektyki zostało następnie rozwinięte przez idealizm niemiecki. Johann Gottlieb Fichte wprowadził w "Grundlage der gesamten Wissenschaftslehre" (1794) triadę teza-antyteza-synteza, która miała charakteryzować „dialektyczny” rozwój pojęć. Centralną rolę w tak rozumianej dialektyce grało zestawianie przeciwieństw.
Najpełniejszą formę takie ujęcie dialektyki znalazło w filozofii Hegla. W systemie Heglowskiej logiki, dialektyka ostatecznie przestała być dyscypliną zajmującą się argumentacją, a stała się pewną własnością procesów zachodzących w obiektywnej rzeczywistości. Triadyczny schemat opisuje rozwój Ducha, który przechodzi do coraz wyższych stadiów rozwoju. Dialektyka była też własnością bytu, podlegającemu ciągłemu ruchowi ścierających się przeciwieństw. Jednym z przykładów rozwoju dialektycznego była dialektyka pana i niewolnika opisana w "Fenomenologii Ducha" (1807).
Takie ujęcie dialektyki upowszechniło się w XIX-wiecznej filozofii, spychając klasyczne jej ujęcie na margines. W połowie XIX w. doszło do kolejnej zmiany, w której Heglowskie pojęcie dialektyki zostało zreinterpretowane przez Karola Marksa i Friedricha Engelsa w duchu materialistycznym. W marksistowskim ujęciu, Heglowska dialektyka krytykowana była jako idealizm („dialektyka pojęć”). Według marksizmu natomiast, rozwojowi dialektycznemu (teza-antyteza-synteza) podlegają formy organizacji materii w procesie historycznym. Dialektyka była zasadniczą metodą stosowaną do marksistowskiej interpretacji rzeczywistości, także przyrodniczej (dialektyka przyrody Friedricha Engelsa, która miała być podstawą do stworzenia nowych nauk przyrodniczych).
Pod koniec XIX w. doszło do powstania marksizmu ortodoksyjnego, który ze względu na wagę przypisywanej marksistowskiej dialektyki określany był jako materializm dialektyczny (pojęcie stworzone przez Gieorgija Walentynowicza Plechanowa). Tak rozumiana marksistowska dialektyka ("diamat") była podstawową metodą interpretacji rzeczywistości, a po zdobyciu władzy przez bolszewików, stała się oficjalną doktryną państwową państw socjalistycznych.
W krajach Zachodu rozwijano również odmienne koncepcje dialektyki. W ramach szeroko pojętego marksizmu, oryginalne koncepcje dialektyki rozwinęli Antonio Gramsci oraz Theodor Adorno ("Dialektyka oświecenia" napisana razem z Maxem Horkheimerem, oraz ").
Innymi filozofami współczesnymi, którzy rozwijali własne koncepcje dialektyki byli Søren Kierkegaard, Francis Herbert Bradley, Giovanni Gentile, Maurice Merleau-Ponty, Jean-Paul Sartre.
Nowożytne koncepcje dialektyki były przedmiotem licznych krytyk. Wskazywano, że mają one niewiele wspólnego z klasyczną dialektyką. Osobną grupę krytyk stanowią liczne krytyki dialektyki marksistowskiej, dokonywane z pozycji logiki, nauki, filozofii politycznej (m.in. za jej tendencje totalitarne), czy religii.
Dialektyka a logika.
Jedną z najtrwalszych spuścizn świata starożytnego jest system logiki formalnej. System ten – stworzony przez Arystotelesa a później rozwinięty przez stoików – ustanowił zasady analizy procesu wnioskowania. Dominował on w nauce do końca XIX wieku. Wówczas rozpoznano jego ograniczenia i opracowano inne systemy formalnej analizy logicznej, chociaż większość z tych nowożytnych systemów nadal miała swoje korzenie w myśli starożytnej, zwłaszcza w stoickim systemie logiki zdań.
Wyznaczenie ograniczeń logiki formalnej nie było odkryciem uczonych nowożytnych, na ograniczenia te wskazał już Arystoteles. U autorów starożytnych systemy logiki formalnej rzadko wpływały na tok rozumowania. Niewielu autorów – poza tymi, którzy pisali wyłącznie na temat logiki – wykazywało jakąkolwiek świadomość istnienia takich systemów. Dlatego Arystoteles zauważył, że chociaż logika jest niezbędnym narzędziem wykorzystywanym podczas analizy naukowej, to nie da jej się zastosować przy rozważaniu wielu różnych kwestii, zwłaszcza wykraczających poza empirię. Był zdania, że logika formalna – zwana przez niego analityką – obowiązuje jedynie podczas dyskursu dotyczącego wiedzy naukowej. Zasady obowiązujące podczas wnioskowania w innych przypadkach, uporządkował w system, który nazwał dialektyką. O ile bowiem wiedza obiektywna opiera się na przesłankach koniecznych i wynikających z nich nieuniknionych relacjach przyczynowo-skutkowych, czyli logicznych, to dialektyka wychodząc z przesłanek prawdziwych i rzeczywistych, ale niekoniecznych, opiera swoje wnioskowanie na prawdopodobieństwie. W " Arystoteles ujął to twierdzenie w następujący sposób: "Wiedza naukowa (ἐπιστήμη) i jej przedmiot różnią się od mniemania (δόξα) i przedmiotu mniemania tym, że wiedza naukowa jest ogólna i utworzona z przesłanek koniecznych, a to, co jest konieczne, nie może być inne. Istnieją fakty prawdziwe i rzeczywiste, które jednak mogą być inne. Wiedza naukowa oczywiście ich nie dotyczy – wtedy bowiem to, co może być inne, stałoby się tym, co nie może być inne".
U teoretyków retoryki umiejętność przekonywania poprzez mowę zawsze budziła obawy, że odbiorcy mogą zostać przekonani do niedopuszczalnych wniosków poprzez zastosowanie chwytów emocjonalnych. Arystoteles i Cyceron wykazali w teorii i praktyce, że właściwie zastosowany dobry argument jest bardziej przekonujący niż zły, ponieważ rozwój sztuki retoryki i zasady dialektyki pozwoliły na skuteczne zwalczanie błędnego rozumowania. Dobry argument rzadko będzie jednak zgodny z rygorystycznymi, formalnymi zasadami logiki, zbyt szczegółowymi i skomplikowanymi, aby przekonać odbiorcę.
Dialektyka przez wieki wypełniała w kulturze i nauce lukę między rygorami logiki formalnej a emocjonalnym potencjałem retoryki. Jest ona teorią wnioskowania, która, choć nie spełnia wymogów logiki, oferuje zestaw elastycznych schematów, które można stosować w wielu różnych kontekstach praktycznych. Systematyzuje argumenty, które nie zawsze są prawdziwe w znaczeniu formalnym, ale za pomocą których można wyciągać przekonujące wnioski – które i tak pojawiłyby się w większości przypadków – z rzeczywistych przesłanek. Przykładem, którym posługiwali się teoretycy dialektyki, było proste, często stosowane, rozumowanie dialektyczne a fortiori: "jeśli bronię człowieka przed oskarżeniem o kradzież niewielkiej ilości pieniędzy, zauważając iż nie skorzystał on z możliwości kradzieży większej kwoty, nie oznacza to, że taka osoba nie ukradła pieniędzy – ale stanowi ważny powód, by sądzić, że prawdopodobnie nie zrobiła tego".
Debata dialektyczna.
Debata akademicka.
Dialektyka, jako nauka, wywodzi się z teoretycznego opracowania schematu debat, które organizował Arystoteles w pierwszych latach swojej kariery jako filozof i nauczyciel, między rokiem 360 a 350 przed Chrystusem. Pomysł takich debat prawdopodobnie pochodził od Platona, ale jako stały element nauczania wprowadzono go w Akademii dopiero po śmierci założyciela. Dialektyczna debata była rodzajem pojedynku słownego między dwoma uczniami, z których jeden pełnił rolę pytającego, a drugi odpowiadającego. Nauczyciel wyznaczał problem, który był przedmiotem debaty. W "" Arystoteles wspominał, że w Akademii nauczał spierania się na argumenty nie za pomocą teorii, ale praktyki – dopiero wiele lat później opracował zasady i schematy prowadzenia takiego sporu, spisując je w traktacie "Topiki".
Problem, który rozstrzyga się za pomocą debaty dotyczy spraw, w których ludzie nie zgadzają się na podstawie argumentów po obu stronach, albo przeciwnie – gdy problem jest tak skomplikowany, że obie strony sporu nie mają żadnych argumentów. Nie są przedmiotem dialektyki problemy oczywiste, co do których panuje zgoda. Dlatego – jak przykładowo stwierdził Arystoteles – nie debatuje się nad problemami, które można rozwiązać za pomocą wnioskowania logicznego, właściwego dla nauk empirycznych ("Czy woda po podgrzaniu do odpowiedniej temperatury zagotuje się?"), ani fundamentalnymi, wspólnymi wszystkim ludziom kwestiami moralnymi ("Czy należy szanować rodziców?"). Problemy dialektyczne dzieli się tradycyjnie na trzy typy: moralne ("Czy powinno się być posłusznym rodzicom, gdy żądają czynu sprzecznego z prawem?)", teoretyczne ("Rodzajem dla człowieka jest zwierzę, nieprawdaż?") oraz fizyczne ("Czy świat jest wieczny?"). Problemy dialektyczne są tak sformułowane, aby można było na nie odpowiedzieć „tak” lub „nie”. Dlatego dialektyka nie zajmuje się kwestiami typu "Czym jest byt?" lub "Jak można osiągnąć szczęście?".
Debatę rozpoczyna pytający, który na podstawie problemu wyznaczonego przez nauczyciela, formułuje prostą kwestię. Odpowiadający wyraża swoje zdanie („tak” lub „nie“), stawiając tezę, a następnie ją uzasadniając. W zależności od tego, którą alternatywę wybierze odpowiadający, pytający przyjmuje zdanie przeciwne i stara się obalić tezę odpowiadającego. W tym celu, pod koniec swojej wypowiedzi, pytający zadaje odpowiadającemu kolejne pytanie, w formie wymagającej również odpowiedzi „tak” lub „nie”. Zależnie od odpowiedzi, pytający kończy, udowadniając sprzeczną naturę tezy odpowiadającego. Debata była ograniczona czasowo. Pytający przegrywał, gdy nie był w stanie obalić tezy w ustalonym czasie, natomiast wygrywał, gdy zdołał szybko wyprowadzić poprawne wnioski lub przesłanki z twierdzenia oponenta.
Zgodnie z zasadami dialektyki, jeżeli odpowiadający mówi „tak” na zadaną kwestię, przedstawiając uzasadnienie tezy formula_1 to pytający ma za zadania obalić formula_2 Aby to zrobić, musi znaleźć tezę formula_3 która z jednej strony jest wnioskiem wynikającym z formula_1 ale z drugiej strony jej treść jest nie do przyjęcia dla odpowiadającego. W tym przypadku odrzucenie formula_5 prowadzi do obalenia formula_2 Jeżeli natomiast odpowiadający mówi „nie” i uzasadnia tezę ¬formula_1 pytający musi uzasadnić formula_2 Aby to zrobić, musi znaleźć twierdzenie formula_3 które z jednej strony jest niezbędną przesłanką dla formula_1 a z drugiej którego treść odpowiadający powinien zaakceptować. W tym przypadku akceptacja formula_5 prowadzi do przyjęcia formula_12. Dlatego tradycyjnie dzieli się dialektykę na dialektykę negatywną – gdy jej zasady służą do obalenia dowolnej tezy poprzez analizę płynących z tezy wniosków – oraz dialektykę pozytywną – gdy jej zasady służą do obrony dowolnej tezy, poprzez wykazanie prawidłowości przesłanek, z których teza wynika.
Celem tej gry dialektycznej było ćwiczenie umiejętności wypowiadania się. Obaj mówcy mieli nauczyć się poprzez dyskusję, jak argumentować własną tezę i obalać tezę przeciwnika. Ćwiczenie to było regulowane kodeksem postępowania i nadzorowane przez nauczyciela, który pełnił funkcję sędziego. Debata akademicka była stałym elementem nauczania dialektyki w starożytności. Jej stosowanie zalecał Boecjusz, stąd stała się obowiązkowym ćwiczeniem w ramach średniowiecznego kursu sztuk wyzwolonych, gdzie zwano ją "obligatio", czyli obowiązkiem. Do XII wieku, gdy w dużej mierze funkcję edukacyjną debaty akademickiej zastąpiło na fakultetach uniwersyteckich "questio disputata", "obligatio" było niezbędnym elementem prowadzącym do uzyskania należytego wykształcenia. Między XIII a XVII wiekiem nadal ćwiczono "obligatio" w szkolnictwie, weszło ono do programu szkół jezuickich.
Questio disputata.
Wśród badaczy zajmujących się tą problematyką, nie ma zgody w sprawie przyczyn, dla których w dialektyce tradycyjną, wywodzącą się ze starożytności, debatę akademicką zastąpiła średniowieczna dysputa, zwana "questio disputata", niekiedy też debatą uniwersytecką, czy kwestią. Najstarsze wzmianki źródłowe o tego typu dysputach na uczelniach europejskich pochodzą z połowy XII wieku. Dysputa jako metoda nauczania uniwersyteckiego wywarła wielki wpływ na rozwój nauki, która w od XIII wieku stawała się coraz bardziej metodą formalną, podporządkowaną regułom dialektyki Arystotelesa. Zasadniczą formą pracy naukowej stała się kwestia ("aporia") – wydawano pojedyncze kwestie lub też zbiory kwestii, uporządkowane według pewnego planu. Do XVIII wieku ten gatunek literatury naukowej dominował wśród publikowanych dzieł.
Questio disputata było formalnym ćwiczeniem, które zajęło ważne miejsce w kształceniu uniwersyteckim. Obok wykładów ("lectio") stanowiło główną metodę nauczania w szkołach wyższych, w wielu krajach aż do XIX wieku. Dysputę uniwersytecką ("disputo publica") toczyło zazwyczaj dwóch bakałarzy pod kierunkiem mistrza, a przysłuchiwali jej się studenci. Mistrz wysuwał tezę ("questio"), której prawdziwość należało ustalić. Pierwszy z dyskutujących ("opponens") przedstawiał argumenty przeciwko tezie. Drugi z dyskutujących ("respondens") miał za zadanie obalić te argumenty lub wykazać ich słabość. Dyskusję zamykał mistrz w formie krótkiego podsumowania ("determinatio"). Mistrz lub bakałarz prowadzili także zamknięte dysputy ćwiczebne, w których spierali się studenci, zwane "disputo privata". Obok dysput szkolnych, na Uniwersytecie Paryskim wprowadzono zwyczaj dysput otwartych między mistrzami. Mogły się one odbywać wyłącznie w drugim tygodniu Adwentu oraz trzecim i czwartym tygodniu Wielkiego Postu. Pytania w takiej dyspucie między mistrzami zadawała publiczność, chociaż uczestnik debaty miał prawo odrzucić pytanie, jeżeli byłoby niezgodne z zasadami – stąd nazwa takich dysput: "questiones de quolibet".
Podczas dysputy, po wprowadzeniu tezy ("queritur utrum...") opponens negował ją za pomocą jednego lub kilku argumentów ("et videtur quod non..."), po czym respondens podawał jeden lub kilka argumentów ją podtrzymujących ("sed contra...)". W odpowiedzi opponens obalał argumenty przeciwnika poprzez wykazanie fałszywości ich przesłanek ("responsio..."), na co respondens wykazywał mu błędy w rozumowaniu i przywracał prawdziwość tezy początkowej ("unde patet..."). Opponens miał prawo do kolejnego responsio, na które mógł odpowiedzieć respondens. Podstawową zasadą questio disputata była możliwość użycia każdego argumentu tylko raz. Niekiedy ograniczano liczbę responsio, jednak w większości przypadków debata toczyła się do wyczerpania argumentów lub poddania się jednej ze stron. Prowadzący miał też prawo zakończyć debatę, gdy jej uczestnicy odeszli od zadanego tematu ("distinguo"). W przeciwieństwie do debaty akademickiej, w questio disputata nacisk kładziono na argumenty zarówno potwierdzające, jak i negujące tezę, a także na prawdziwość przesłanek i poprawność wnioskowania z tych przesłanek. O ile bowiem debata zalecana przez Arystotelesa miała za zadanie wskazanie wniosków z tezy, które służą jej obalaniu, to debata uniwersytecka służyła raczej do wykazania, że przesłanki tezy mogą wytrzymać krytykę.
Zasady dialektyki.
Podstawowe pojęcia.
Dialektyka jest metodą, dzięki której można – za pomocą sylogizmów – argumentować z prawdopodobnych przesłanek, unikając wewnętrznych sprzeczności. Poza zakres dialektyki wykraczają relacje między sylogizmami dialektycznymi a sylogizmami niedialektycznymi, na przykład sylogizmami opierającymi się na faktach empirycznych.
Dialektyka definiuje argumentację jako świat składający się z bytów. między którymi występuje wiele różnych relacji. Byty dialektyczne dzieli się na terminy, tezy i systemy. Podstawowe relacje między bytami określane są jako wynikanie, opozycja, sprzeczność, porządek systematyczny i porządek hierarchiczny. Akt w dialektyce polega na aktualizacji relacji między bytami, na przykład wynikanie urzeczywistnia się przez analizę, a opozycja przez definiowanie. Ludzki rozum jest zdolny rozpoznać tylko niewielką część z potencjalnych aktualizacji. Rozpoznana aktualizacja terminu przyjmuje formę tezy, która może występować jako definicja, postulat lub twierdzenie. Zestaw przesłanek i wniosków wynikających z tezy tworzy system, który jest zbiorem zdań powiązanych przez sylogizmy. Ten zbiór sylogizmów jest skończony.
Pierwsze przesłanki systemu, czyli byty, z których drogą stopniowej aktualizacji tworzy się tezę, określane są jako doktryna systemu. Byty tworzące doktrynę nazywane są toposami. Doktryna uznawana jest za prawdziwą, gdy toposy są prawdopodobne. Pierwsze przesłanki są prawdopodobne, gdy opierają się na opinii wspólnej wszystkim ludziom, opinii podzielanej przez większość lub na autorytecie. Szczególną odmianą argumentowania z autorytetu jest rozumowanie z hipotezy.
System dialektyczny.
Przedmiotem dialektyki są systemy, a nie pojedyncze terminy lub tezy. Dialektyka nie zajmuje się pojedynczymi systemami, ale systemami między którymi zaktualizowała się opozycja. Opozycja powstaje w akcie definiowania tezy poprzez zróżnicowanie, negację lub wykluczenie. Opozycja nie jest sprzecznością, ale odmiennością, w której dwa systemy negują się wzajemnie, ale nie odrzucają. Natomiast sprzeczność to odmowa uznania istnienia innego bytu. Jeżeli między dwoma systemami aktualizuje się sprzeczność, oznacza to, że jeden z tych systemów jest niepoprawny, bowiem sprzeczność może występować jedynie pomiędzy tezami, a nie systemami, lub też jeden z systemów jest dogmatyczny. Dogmat w dialektyce to pierwsza przesłanka, która wyklucza istnienie opozycyjnej pierwszej przesłanki. System dogmatyczny to taki system, którego doktryna nie dopuszcza alternatyw. Dialektyka nie zajmuje się poprawnością systemów dogmatycznych.
Poprawność (spójność) systemu wykazuje się na jeden z dwóch sposobów – intuicyjnie (dialektyka pozytywna) lub demonstracyjnie (dialektyka negatywna). Definicje i postulaty są tezami intuicyjnymi, to znaczy zakłada się ich prawdziwość, aby dokonać analizy systemu wstecz, od tezy aż do pierwszych przesłanek. Jeżeli sylogizmy są prawidłowe i doktryna systemu uznawana jest za prawdziwą, to tezę intuicyjną uznaje się za prawdziwą a system za poprawny. Twierdzenia są tezami demonstracyjnymi, to znaczy zakłada się ich fałszywość, aby dokonać analizy systemu od pierwszych wniosków. Jeżeli sylogizmy są prawidłowe, to tezę demonstracyjną uznaje się za prawdziwą a system za poprawny, niezależnie od statusu doktryny. Jeżeli analiza tez intuicyjnych lub demonstracyjnych wskazuje na brak doktryny, czyli łańcuch sylogizmów systemu jest potencjalnie nieskończony, tezę uznaje się za fałszywą a system za niepoprawny.
Dialektyka ustala prawdziwość tez tylko wewnątrz systemu, nie wypowiada się na temat statusu tez poza systemem. Natomiast poszczególne zdania systemu nie są ani prawdziwe, ani fałszywe. W dialektyce każda teza jest potencjalnie prawdziwa, to znaczy istnieje potencjalny system, wewnątrz którego zostanie uznana za prawdziwą.
Jeżeli zachodzi relacja opozycji dwóch poprawnych systemów, to w opozycji pozostają doktryny tych systemów. Opozycję taką rozwiązuje się w porządku hierarchicznym, poprzez intuicyjne zbudowanie systemu nadrzędnego, opartego na nowej doktrynie. System nadrzędny włącza z systemów podrzędnych byty należące do pewnych kategorii, a inne wyklucza. Wraz z ustanowieniem nowego systemu i rozwiązaniem opozycji, aktualizują się dwie nowe opozycje – między wykluczonymi bytami a nową tezą oraz między nowym systemem a istniejącymi wcześniej systemami. Dlatego niemożliwe jest ostateczne rozwiązanie opozycji dwóch poprawnych systemów. Każdy system znajduje się potencjalnie w opozycji do innego systemu. Nie istnieje żaden nadrzędny system, który obejmuje wszystkie podrzędne systemy, ponieważ zawsze aktualizuje się inny, opozycyjny system nadrzędny. Wszystkie dialektyczne rozwiązania są częściowe i nieostateczne.
W porządku hierarchicznym byty przynależą do kategorii. W dialektyce byty kategoryzuje się w trzech klasach: rodzaju, gatunku i przypadłości. Wszystkie byty spełniające określony zestaw warunków są zawarte w jednej kategorii, byty niespełniające warunków są wyłączone z kategorii. Kategorie są powiązane jako część i część, całość i część, część i całość. Relacje te są uogólnione jako wykluczanie, włączanie i wynikanie. Dialektyka aktualizuje byty poprzez ich kategoryzację, następnie na podstawie relacji między kategoriami buduje tezy, tworząc hierarchiczny system.
W dialektyce każdy system jest analizowany w swoich własnych kategoriach oraz w kategoriach systemu opozycyjnego. Dlatego celem dialektyki nie jest osiągnięcie konsensusu, lecz przekształcanie niezgody w krytyczny instrument rozwoju wiedzy. Rozumowanie dialektyczne dotyczy twierdzeń, które budzą kontrowersje i pozostają w opozycji do innych twierdzeń – na przykład w sytuacji, gdy dwie osoby mają sprzeczne opinie w jakiejś kwestii a starając się znaleźć podstawy do porozumienia, odkrywają, że jest ono niemożliwe. Dialektyka wyjaśnia taką sytuację, analizując w jaki sposób te dwie osoby różnią się między sobą pod względem założeń, ich interpretacji, sposobu wyciągnięcia wniosku, a także tego, co uznali za prawdopodobne oraz uważali za powszechne przekonanie. Dlatego można interpretować dialektykę jako naukę zajmującą się problemem niezgodności. Dialektyka rozpoczyna i kończy analizę od niezgody, wyjaśniając nie tylko podstawy tej niezgody, ale także jej konsekwencje.
Sylogizm dialektyczny.
Ponieważ system jest zbiorem zdań powiązanych przez sylogizmy, którego poprawność (spójność) należy ustalić poprzez dialektykę negatywną lub pozytywną, to obiektem analizy są w dialektyce sylogizmy. Sylogizm to rozumowanie, w którym wniosek wysnuwa się z dwóch przesłanek zawierających wspólny element. Oznacza to, że w sylogizmie, gdy się coś założy, to coś innego niż się założyło musi wynikać dlatego, że się założyło.
Sylogizm dialektyczny różni się od sylogizmu naukowego (logicznego) tym, że przesłanki, na których się opiera, nie są prawdziwe. Sylogizm dialektyczny jest uznawany za poprawny, gdy jego przesłanki są prawdopodobne a wnioskowanie prawidłowe. Poprawny sylogizm jest określany w dialektyce argumentem. Oznacza to, że gdy wnioskowanie oparte na sylogizmie jest poprawne, to argument dialektyczny jest zgodny z wiedzą ogólną oraz mentalnością uczestników i odbiorców debaty. W tym znaczeniu interpretuje się dialektykę jako udowadnianie za pomocą sylogizmów tezy niepewnej na podstawie tez pewnych.
Sylogizm dialektyczny może występować w formie entymematu dialektycznego. Entymemat to rozumowanie złożone z dwóch przesłanek i wniosku, w którym pomija się jedną z przesłanek lub wniosek, gdyż są oczywiste. Ukryta przesłanka lub wniosek pozostają „w głowie”. Entymemat stosowany jako topos może także przybrać formę sentencji. Jako przykład teoretycy dialektyki podawali – bardzo często używaną – pierwszą przesłankę: "nic nie dzieje się bez przyczyny". Opiera się ona na sylogizmie: "ponieważ każde wydarzenie jest skutkiem, który posiada swoją przyczynę, to przyczyna i skutek istnieją równocześnie". Sylogizm ten zostaje skrócony do entymematu ("ponieważ każde wydarzenie jest skutkiem czegoś, posiada więc zawsze przyczynę"), a następnie ujęty w powszechnie zrozumiałą, zgodną z opinią powszechną, formę toposu: "nic nie dzieje się bez przyczyny". Topos z entymematu ma zazwyczaj krótką, jednozdaniową formę. Dowodząc konieczności walki używa się miejsc wspólnych w rodzaju: „słodko jest umierać za ojczyznę”, „należy czcić bohaterów”, „dla tych, którzy bronią ojczyzny, otwarta jest droga do nieba”. Argumentując za pokojem stosuje się toposy: „trzeba bronić pokoju”, „lepiej jest rozmawiać z wrogiem niż walczyć”, „rzeczą niegodną jest zabijać”. Podczas analizy dialektycznej rozwija się toposy oraz entymematy do pełnych sylogizmów, a następnie sprawdza się ich poprawność.
Pierwsza przesłanka sylogizmu to podmiot ("subiectum", formula_13) – zawiera ona prawdę szczegółową. Druga przesłanka, zwierająca prawdę ogólną, to przesłanka pośrednia ("terminus medinus", formula_14). Orzecznik ("predicatum", formula_15), to wspólny element przesłanek, zawarty we wniosku. Pod względem budowy, zdanie w systemie ma formę podmiotowo–orzecznikową w jednym z czterech typów: każde formula_13 jest formula_17 żadne formula_13 nie jest formula_17 pewne formula_13 jest formula_15 lub pewne formula_13 nie jest formula_15. Pod względem rodzajów orzeczników (ich stosunków rzeczowych do podmiotu) zdania w systemie są jednego z pięciu typów: definicji, własności, rodzaju, gatunku lub przypadłości. Oznacza to, że sylogizmy dialektyczne dzielą się na takie, które dotyczą orzekania na temat definicji, własności, rodzaju, gatunku lub przypadłości. Pod względem struktury wnioskowania, do podstawowych sylogizmów dialektycznych należą: argument "a contrario", argument "a fortiori", "argument a completudine", argument "a coherentia", argument psychologiczny, argument historyczny, argument przez dowód nie wprost, argument teleologiczny (celowościowy), argument ekonomiczny, argument systematyczny i argument naturalistyczny.
Rodzaje sylogizmów dialektycznych.
Sylogizm a fortiori.
Sylogizm dialektyczny "a fortiori", czyli ze wzmocnienia, jest jednym z najczęściej stosowanych argumentów w dowodzeniu (również w formie entymematu). Opiera się on na formule „jeżeli formula_13 to tym bardziej formula_17 skoro formula_14”. Występuje w dwóch odmianach: "a minori ad maius" oraz "a maiori ad minus".
Pierwsza odmiana, "a minori ad maius", znajduje zastosowanie w dowodzeniu negatywnym, druga, "a maiori ad minus", w dowodzeniu pozytywnym. Dowodzenie negatywne zasadza się na argumentacji, że jeżeli nie wolno formula_27 to tym bardziej nie wolno formula_28 Dowodzenie pozytywne zakłada, że gdy wolno więcej, to tym bardziej nie wolno mniej. Nie zawsze dowody z tego typu sylogizmu sprowadzają się do nakazów lub zakazów, gdyż argument "a minori ad maius" polega na uzasadnieniu tego, co jest podrzędne tym, co jest nadrzędne, natomiast "a maiori ad minus" służy do uzasadnienia nadrzędnego przez podrzędne. Inaczej mówiąc, jakaś część zbioru udziela sensu całości zbioru (argument "pars pro toto"), albo całość udziela sensu części danego zbioru (argument "totum pro parte)".
Zbudowanym z tropów i figur retorycznych, często przytaczanym i naśladowanym sylogizmem dialektycznym "a fortiori", jest fragment "Kazania wtórego" Piotra Skargi: "jako najmilejszej matki swej miłować i onej czcić nie macie, która was urodziła i wychowała, nadała, wyniosła? Bóg matkę czcić rozkazał. Przeklęty, kto zasmuca matkę swoją. A która jest pierwsza i zasłużeńsza matka jako ojczyzna, od której imię macie i wszystko, co macie od niej jest?" Podmiotem rozumowania Skargi jest matka formula_29 przesłanką pośrednią nakaz czci matki formula_30 orzecznikiem – cześć i szacunek należny ojczyźnie formula_31 Metaforyczne nazywanie ojczyzny matką jest bardzo dawną tradycją. Ta, utrwalona u autora i odbiorców przenośnia, ułatwia przyjęcie wniosku o wrodzonym obowiązku miłości do ojczyzny. Sylogizm Skargi opiera się na identyfikacji słów bliskoznacznych w argumencie "a fortiori", w odmianie "a minori ad maius".
W innym miejscu "Kazania wtórego" Skarga dowodzi "a maiori ad minus": "poganie za Rzeczpospolitą umierali, nic się śmierci nie spodziewając, abo nic pewnego o zapłacie na onym świecie nie mając, na samej tylko poczciwej sławie u ludzi przestając. A my tak wielkie i tak pewne o zapłacie po śmierci Boga naszego obietnice mamy, jeśli to przykazanie o miłości wypełnim. I tu na ziemi nieśmiertelną sławę daje tym, którzy braciej i dobra pospolitego ucierpieli." Rozumowanie autora jest następujące: jeżeli wszyscy ludzie uznają obowiązek oddania życia za ojczyznę formula_32 to tym bardziej chrześcijanie powinni go wypełnić formula_33 skoro mają przykazanie miłości formula_34.
Zastosowanie.
Zasady dialektyki stosuje się do analizy ludzkich wypowiedzi, zwłaszcza podczas dyskursu. Dialektyka reguluje zasady dyskursu, w czasie którego ludzie nie zgadzają się ze sobą na podstawie argumentów. Dyskurs nie jest obiektem analizy dialektycznej, gdy odnosi się do już ustalonych faktów lub próby określenia faktów na sposób empiryczny. Z zasad dialektyki wywodzi się twierdzenie, że o faktach się nie dyskutuje.
Dialektyka, jako metanauka o poprawności rozumowania, ma zastosowanie do tych nauk szczegółowych, które nie przyjmują dogmatycznej doktryny – na przykład przez wieki była stosowana w filozofii i retoryce. Dialektyka nie ma zastosowania do nauk, które – z jej punktu widzenia – są systemami dogmatycznymi. Systemami dogmatycznymi są na przykład nauki empiryczne, gdyż w naukach tych przyjmuje się pierwsze przesłanki, które zakładają, że tylko z ich pomocą możliwe jest osiągnięcie jedynego prawdziwego i nadrzędnego systemu wiedzy. Dialektyka i nauki empiryczne, w ich historycznym aspekcie i tradycyjnie pojmowane, posługują się odrębnymi technikami, do których ostatecznie musi się odwoływać racjonalny, ludzki dyskurs. Uczeni posługujący się dialektyką są grupą ekspertów w budowie systemów opisujących zawiłe i subtelne kontrowersje; empirycy natomiast budują teorie na podstawie eksperymentów i obserwacji, zgodnych z procedurami naukowymi. Jednakże niektóre nauki empiryczne – na przykład fizyka, w zakresie, w jakim stosuje się w niej formuły matematyczne – są wysoce teoretyczne. Nieweryfikowalne teorie i wynikające z nich hipotezy, są artykułowane w dyskursie naukowym dialektycznie. Jeżeli jakakolwiek nauka empiryczna sięga po formę teoretyczną, jej świat argumentacji ma strukturę dialektyczną. Dlatego teoretyczne zasady przewidywania i weryfikacji oraz sposób budowania hipotez są często przypadkami zastosowania metody dialektycznej w naukach empirycznych.

</doc>
<doc id="1313" url="https://pl.wikipedia.org/wiki?curid=1313" title="Denis Papin">
Denis Papin

Denis Papin (ur. 22 sierpnia 1647, zm. ok. 1712 w Londynie) – francuski wynalazca.
Życiorys.
Urodził się w Chitenay koło Blois. Jako protestant musiał w 1675 emigrować do Anglii, gdzie spędził resztę życia. Jego współpracownikami byli Christiaan Huygens i Robert Boyle. W 1681 przedstawił kocioł będący pierwowzorem autoklawu i szybkowaru. Zastosował w nim po raz pierwszy zawór bezpieczeństwa. W 1698 skonstruował pierwszy tłokowy silnik parowy. Wynalazł także między innymi piec do topienia szkła i pompę wirową odśrodkową.

</doc>
<doc id="1320" url="https://pl.wikipedia.org/wiki?curid=1320" title="Kalendarium II wojny światowej">
Kalendarium II wojny światowej

Kalendarium II wojny światowej

</doc>
<doc id="1323" url="https://pl.wikipedia.org/wiki?curid=1323" title="Domena (biologia)">
Domena (biologia)

Domena ("dominium") – kategoria systematyczna wyższa od królestwa, stosowana w klasyfikacji biologicznej, zaproponowana w 1974 przez Royalla T. Moore’a, a wprowadzona w 1990 przez Carla Woese'a, Ottona Kandlera i Marka Wheelisa jako kategoria najwyższego poziomu (o najwyższej randze taksonomicznej). Domena jest kategorią równoważną proponowanym później przez innych systematyków nazwom: cesarstwo ("imperium") lub nadkrólestwo ("superregnum").
Uzasadnienie autorów.
Mikolog Royall T. Moore zaproponował w 1974 wprowadzenie dodatkowych „super” kategorii, w tym domeny, z łacińskim odpowiednikiem "Dominium". Domena miałaby być najwyższą kategorią systematyczną obejmującą, jako kategorie bezpośrednio podrzędne, dotychczasowe królestwa.
W 1990 Woese i inni stwierdzili, że dotychczasowy podział systematyczny organizmów na pięć królestw nie odzwierciedlał ówczesnego stanu wiedzy. Na podstawie badań molekularnych uznali, że życie na Ziemi powinno być systematyzowane w trzech grupach, którym nadali, zaproponowaną przez Moore’a, rangę domeny (ale z łacińskim odpowiednikiem "regio") i nazwali: Bacteria, Archaea i Eucarya. Zaproponowane przez nich domeny objęły królestwa dotychczasowe oraz nowe, które – ich zdaniem – powinny zostać jeszcze opisane. Wprowadzenie nowej kategorii wyższej rangi miało na celu uniknięcie burzenia tradycyjnie utrwalonego podziału na królestwa.
W pracy z 1990 autorzy nie określili królestw dla Bacteria i Eucarya, ograniczając się jedynie do stwierdzenia, że będzie ich wiele, a ich zdefiniowanie wymaga dalszych analiz. Natomiast dla domeny Archaea zaproponowali podział na Euryarchaeota i Crenarchaeota.
Podział organizmów na trzy domeny.
Podział ten został dokonany jedynie na podstawie porównania sekwencji rRNA, ale następnie znaleziono liczne fakty pasujące do niego. Z punktu widzenia biochemii i fizjologii komórek archeony są bardzo odmienne od bakterii właściwych, niektóre cechy zbliżają je do jądrowców.
Alternatywne podziały.
Istnieje też alternatywny podział na dwa cesarstwa (Prokaryota [Bacteria] i Eukaryota) z sześcioma królestwami, zaproponowany przez Thomasa Cavaliera-Smitha w 2004.
Nie jest on jednak zbyt popularny, głównie ze względu na brak pewności co do pokrewieństw między grupami eukariontów.
Amerykańska systematyk Lynn Margulis jest zdania, że rozdzielanie prokariontów na dwa taksony wysokiej rangi nie jest wystarczająco uzasadnione, bo mimo znaczących różnic biochemicznych są one jednak znacznie bardziej podobne do siebie niż do organizmów jądrowych. Wynika to z uznania planu budowy komórki za istotniejszą cechę systematyczną niż cechy biochemiczne – szczególnie że cechy biochemiczne mogą być „wymieniane” między nawet odlegle spokrewnionymi organizmami poprzez poziomy transfer genów.

</doc>
<doc id="1326" url="https://pl.wikipedia.org/wiki?curid=1326" title="BSD Daemon">
BSD Daemon

 
BSD Daemon (stgr. δαίμων "daimon" dosł. „ten, który coś rozdziela” lub „ten, który coś przydziela”, także: "nadprzyrodzona potęga", łac. "daemon") – maskotka systemów operacyjnych 4.2BSD, 4.3BSD i BSD4.4, od pierwszego wydania przyjęta przez wywodzący się od nich FreeBSD. 
Zwykle przedstawiany jako postać przypominająca diabełka w trampkach trzymającego w ręku trójząb (ang. "pitchfork")"," w nawiązaniu do uniksowej funkcji "fork()", czasami z aureolą nad głową (OpenBSD) lub w kasku inżyniera (NetBSD). "Daemon" nie ma oficjalnego imienia, nazwy. Popularnie określany jest jako "beastie" (przez inspirację amerykańską wymową skrótu B-S-D), czasem "Chuck".
Autorem pierwszych wersji graficznych był John Lasseter, pomysłodawcą i właścicielem praw autorskich jest Marshall Kirk McKusick, jeden z twórców BSD z laboratoriów CSRG Uniwersytetu Berkeley. Mianem "Daemon book" określano drukowane podręczniki systemów BSD (4.3 i 4.4), pełny tytuł "The Design and Implementation of the 4.3BSD UNIX Operating System" – noszące na okładce właśnie obraz "BSD daemona".
"Daemon" od strony technicznej jest w systemach Unix nazwą programów lub procesów działających niezauważalnie w tle i wykonujących czynności usługowe na rzecz systemu i klientów (np. "named" - skrót od "name daemon", serwer nazw DNS). Stał się przez to synonimem niewidzialnej, pożytecznej siły (vide slogan FreeBSD: "The power to serve" – Moc do usług) działającej w interesie użytkowników – w przeciwieństwie do zdiabolizowanego przez chrześcijaństwo "demona", interpretowanego jako zła siła. 
Także ze względu na wybuchające co jakiś czas wokół "daemona" religijne kontrowersje w środowiskach BSD można dostrzec oficjalny trend odchodzenia od wykorzystywania go jako graficznego identyfikatora tych projektów informatycznych. Od pewnego czasu OpenBSD posługuje się jako logo wizerunkiem "pancernej" rybki zwanej "Blowfish" w nawiązaniu do nazwy wydajnego algorytmu kryptograficznego. Od roku 2004 NetBSD używa nowego, oficjalnego logotypu a FreeBSD rok później. Wśród wielu sympatyków systemów spod znaku "daemona" kroki te spotkały się z nieprzychylnym przyjęciem jako wyznacznik myślenia w kategoriach czysto marketingowych i kapitulacja wobec ignorancji i nieporozumień.
 /( )` 
 \ \___ / | 
 /- _ `-/ ' 
 / / | ` \ 
 O O ) / | 
 (_.) _ ) / 
 `.___/` / 
 &lt;----. __ / __ \ 
 &lt;----|====O)))==) \) /==== 
 &lt;----' `--' `.__,' \ 
 \ / /\
 ______( (_ / \______/ 
 `--{__________) 
ASCII-Art.
"Beastie" przedstawione w ASCII-Art podobnie jak na ekranie startowym FreeBSD.

</doc>
<doc id="1327" url="https://pl.wikipedia.org/wiki?curid=1327" title="DRAM">
DRAM



</doc>
<doc id="1328" url="https://pl.wikipedia.org/wiki?curid=1328" title="Dane osobowe">
Dane osobowe

Dane osobowe – informacje o zidentyfikowanej lub możliwej do zidentyfikowania osobie fizycznej („osobie, której dane dotyczą”). Możliwa do zidentyfikowania osoba fizyczna to osoba, którą można bezpośrednio lub pośrednio zidentyfikować, w szczególności na podstawie identyfikatora takiego jak imię i nazwisko, numer identyfikacyjny, dane o lokalizacji, identyfikator internetowy lub jeden bądź kilka szczególnych czynników określających fizyczną, fizjologiczną, genetyczną, psychiczną, ekonomiczną, kulturową lub społeczną tożsamość osoby fizycznej.
Dane osobowe w Polsce.
W prawie polskim termin ten został zdefiniowany w ustawie o ochronie danych osobowych. W rozumieniu ustawy za dane osobowe uważano wszelkie informacje dotyczące zidentyfikowanej lub możliwej do zidentyfikowania osoby fizycznej. Osobą możliwą do zidentyfikowania była osoba, której tożsamość można było określić bezpośrednio lub pośrednio, w szczególności przez powołanie się na numer identyfikacyjny albo jeden lub kilka specyficznych czynników określających jej cechy fizyczne, fizjologiczne, umysłowe, ekonomiczne, kulturowe lub społeczne. Informacji nie uważano za umożliwiającą określenie tożsamości osoby, jeżeli wymagałoby to nadmiernych kosztów, czasu lub działań.
Danymi osobowymi nie były zatem pojedyncze informacje o dużym stopniu ogólności, np. sama nazwa ulicy, numer domu, w którym mieszka wiele osób, czy wysokość wynagrodzenia. Informacja ta stanowiła dane osobowe wówczas, gdy została zestawiona z innymi, dodatkowymi informacjami, np. imieniem i nazwiskiem, czy numerem PESEL, które w konsekwencji można odnieść do konkretnej osoby. Danymi osobowymi nie były również informacje o osobach zmarłych.
Nad kontrolą i ochroną prawną czuwał Generalny Inspektor Ochrony Danych Osobowych.
25 maja 2018 r. weszło w życie unijne Rozporządzenie o Ochronie Danych Osobowych (RODO), które zastąpiło polską ustawę o ochronie danych osobowych. 10 maja 2018 r. Sejm RP VIII kadencji uchwalił nową ustawę o ochronie danych osobowych, która zastąpiła ustawę o ochronie danych osobowych z 1997 r. i zapewnia stosowanie rozporządzenia Parlamentu Europejskiego i Rady (UE) 2016/679 oraz ustanawia nowy organ właściwy w sprawie ochrony danych osobowych – Prezesa Urzędu Ochrony Danych Osobowych w miejsce Generalnego Inspektora Ochrony Danych Osobowych.
Dane szczególnie chronione.
Według art. 27 ust. 1 ustawy z dnia 29 sierpnia 1997 r. o ochronie danych osobowych zabraniano przetwarzania danych ujawniających pochodzenie rasowe lub etniczne, poglądy polityczne, przekonania religijne lub filozoficzne, przynależność wyznaniową, partyjną lub związkową, jak również danych o stanie zdrowia, kodzie genetycznym, nałogach lub życiu seksualnym oraz danych dotyczących skazań, orzeczeń o ukaraniu i mandatów karnych, a także innych orzeczeń wydanych w postępowaniu sądowym lub administracyjnym. Są to dane zwane danymi wrażliwymi.
Przetwarzanie tych danych było jednak dopuszczalne w kilku przypadkach, m.in. jeżeli.
Generalny Inspektor Ochrony Danych Osobowych (GIODO).
Generalny Inspektor Ochrony Danych Osobowych (GIODO) kontrolował zgodność przetwarzania danych z przepisami ustawy, wydawał decyzje administracyjne i rozpatrywał skargi w sprawach wykonania przepisów o ochronie danych osobowych, prowadził rejestr zbiorów danych, opiniował akty prawne dotyczące ochrony danych osobowych, inicjował i podejmował przedsięwzięcia w zakresie doskonalenia ochrony danych osobowych, uczestniczył w pracach międzynarodowych organizacji i instytucji zajmujących się problematyką ochrony danych osobowych.
Od 22 kwietnia 2015 roku Generalnym Inspektorem Ochrony Danych Osobowych była Edyta Bielak-Jomaa, a zastępcą od 17 stycznia 2018 roku Mirosław Sanek.
Rozporządzenie o Ochronie Danych Osobowych (RODO).
Rozporządzenie o Ochronie Danych Osobowych (RODO) – rozporządzenie unijne, wchodzące w życie z dniem 25 maja 2018 roku, którego celem jest doprowadzenie do pełnej harmonizacji prawa materialnego w ramach UE i swobodnego przepływu danych osobowych. Stosowanie rozporządzenia na terytorium Polski ma zapewnić uchwalona przez Sejm VIII kadencji ustawa z dnia 10 maja 2018 r. o ochronie danych osobowych.
Urząd GIODO został zlikwidowany, a w jego miejsce powstał Urząd Ochrony Danych Osobowych (UODO), na czele którego stoi Prezes wybierany na 4 letnią kadencję. Prezesa Urzędu powołuje i odwołuje Sejm Rzeczypospolitej Polskiej za zgodą Senatu na wniosek Prezesa Rady Ministrów.
Nowe rozporządzenie wprowadza wiele zmian, które dotyczą wszystkich podmiotów gospodarczych mających do czynienia z przetwarzaniem danych osobowych. Najważniejsze z nich to:
Za naruszenie postanowień RODO organ nadzorczy jest uprawniony do nakładania na przedsiębiorstwo wysokich kar pieniężnych. W zależności od okoliczności naruszenia, do których należą m.in.: charakter, czas i waga naruszenia, umyślność lub nieumyślność podmiotu, wdrożone u administratora środki organizacyjne oraz techniczne, czy też sposób, w jaki organ nadzorczy dowiedział się o naruszeniu, a w szczególności, czy i w jakim zakresie przedsiębiorca zgłosił naruszenie, kara pieniężna może wynieść do 10 000 000 EUR, w przypadku przedsiębiorstwa – do 2% całkowitego rocznego światowego obrotu z poprzedniego roku obrotowego lub w przypadku większych naruszeń nawet do 20 000 000 EUR, w przypadku przedsiębiorstwa – do 4% całkowitego rocznego światowego obrotu z poprzedniego roku obrotowego.

</doc>
<doc id="1329" url="https://pl.wikipedia.org/wiki?curid=1329" title="Diecezja">
Diecezja

Diecezja (pot. biskupstwo) – jednostka administracyjna w kościołach chrześcijańskich podległa biskupowi.
W prawie Kościoła rzymskokatolickiego jest określana jako podstawowa forma kościoła partykularnego, w których istnieje i z których składa się jeden Kościół katolicki. Jest zarządzana przez biskupa diecezjalnego, którego w zarządzaniu wspierają: kuria, synod, kapituła katedralna, konsultorzy, rada kapłańska i rada duszpasterska.
W Kościołach wschodnich odpowiednikiem diecezji jest eparchia.
Etymologia.
Pierwotnie „dioecesis” (z grec. – „dioikesis”) oznaczał zarządzanie domem, jednostką administracyjną lub sprawowanie zarządu w ogóle. Rzymianie używali go początkowo na oznaczenie terytorium będącego pod zarządem miasta („civitas”). Teren taki znany był przede wszystkim pod nazwą „ager” lub „territorium”, jednak we wschodnich prowincjach imperium nazywano go właśnie „dioecesis”. Stąd też użycie słowa przyjęło się w słowniku chrześcijan, gdyż biskupi zwykle rezydowali w „civitas”, a obszar przez nich zarządzany pokrywał się z obszarem rzymskiej „dioecesis”. Diecezją od końca III wieku określano w Cesarstwie Rzymskim prowincje zarządzane przez legata, a później grupę prowincji, którą zarządzał wikariusz. Taką organizację administracji wprowadził Dioklecjan dzieląc imperium na 100 prowincji skupionych w 12 diecezjach: 
Africa, Asiana, Britania, Galia, Hispania, Italia, Moesia, Oriens, Pannonia, Pontica, Thracia, Viennensis.
Diecezje z kolei zostały zgrupowane (od pierwszej połowy IV w. n.e., za Konstantyna Wielkiego) w cztery prefektury.
Początki diecezji w chrześcijaństwie.
W I w. chrześcijanie nie używali terminu "diecezja". Kościół Powszechny podzielony był na autonomiczne kościoły partykularne, które były postrzegane przede wszystkim jako wspólnoty personalne, a nie terytorialne. Kościół partykularny skupiał chrześcijan danego miasta i jego okolic. Na jego czele stało prezbiterium, którego przewodniczący – od przełomu I i II w. – zaczął używać tytułu biskupa. W IV w. – po ogłoszeniu chrześcijaństwa religią panującą w imperium rzymskim – rozpoczęła się masowa chrystianizacja mieszkańców miast i osad rolniczych. Wielka liczba nowych wiernych wymagała reformy administracji kościelnej. Zaczęto akcentować funkcję terytorialną kościoła partykularnego. W ramach tegoż kościoła zaczęto tworzyć sieć parafii miejskich i wiejskich, a całe terytorium objęte organizacją parafialną i podległe władzy biskupa danego kościoła, zaczęto nazywać diecezją. Mimo pozornego porzucenia dawnego nazewnictwa, aż do dnia dzisiejszego prawo kanoniczne używa na oznaczenie diecezji także nazwy kościoła partykularnego. Nazwę "kościół" zamiast nazwy "diecezja" stosuje się w tytulaturze uroczystej. Np. archidiecezję rzymską nazywa się także Świętym Kościołem Rzymskim, a archidiecezję gnieźnieńską – Świętym Kościołem Gnieźnieńskim.
Miejsce diecezji w podziale administracyjnym Kościoła łacińskiego.
Diecezje zazwyczaj są zgrupowane w metropolie, rzadko zaś podlegają bezpośrednio Stolicy Apostolskiej (tzw. diecezje wyjęte).
Rodzaje diecezji rzymskokatolickich:
Jednostki równe diecezji to:
Ze szczególnych racji (np. obecność wiernych innego obrządku, żołnierzy) na terytorium należącym do wielu diecezji mogą istnieć specjalne ordynariaty personalne (np. ordynariat polowy).
Biskupstwa na ziemiach polskich.
Na ziemiach polskich najstarsze biskupstwo powstało w Poznaniu w 968, a na jego czele stanął Jordan z Dolnej Lotaryngii. Kolejno w 1000 w Gnieźnie, Krakowie, Wrocławiu i Kołobrzegu, w tym roku podporządkowano biskupstwo poznańskie arcybiskupstwu gnieźnieńskiemu (wbrew roszczeniom metropolii magdeburskiej). Do końca XII wieku wraz z umacnianiem się Kościoła utworzono biskupstwa w Kruszwicy (około 1034), Płocku (około 1075), Włocławku (1123), Lubuszu (1124) oraz Wolinie (1140). Zasadniczy zrąb podziału diecezjalnego w Polsce ukształtował się w czasach ostatnich Piastów. Większość stolic diecezjalnych zachowała swoje godności nawet do czasów zaborów. Obecnie (na 2013 rok) w Polsce jest 41 diecezji (archidiecezje – 14, diecezje – 27)
Czcionką pogrubioną oznaczono arcybiskupstwa

</doc>
<doc id="1330" url="https://pl.wikipedia.org/wiki?curid=1330" title="Endokrynologia">
Endokrynologia

Endokrynologia – nauka o wydzielaniu wewnętrznym, gruczołach, hormonach i ich działaniu. Jako dziedzina medycyny, zajmuje się zaburzeniami funkcji gruczołów wydzielania wewnętrznego (zaburzenia wydzielania hormonów), np. przysadki mózgowej, tarczycy, nadnerczy, jajników. W Polsce konsultantem krajowym endokrynologii od 7 czerwca 2019 jest prof. dr hab. Andrzej Lewiński. Diagnostyką i leczeniem zaburzeń endokrynologicznych u dzieci zajmuje się specjalizacja endokrynologia i diabetologia dziecięca, której konsultantem krajowym od 21 czerwca 2018 jest prof. dr hab. Mieczysław Walczak.

</doc>
<doc id="1331" url="https://pl.wikipedia.org/wiki?curid=1331" title="Ekonomia">
Ekonomia

Ekonomia – nauka społeczna analizująca oraz opisująca produkcję, dystrybucję oraz konsumpcję dóbr i usług. Nie jest nauką ścisłą, lecz posługuje się aparatem matematycznym (głównie metody ilościowe).
Słowo „ekonomia” wywodzi się z języka greckiego "οικονομία" i tłumaczy się jako "οἰκος" ("oikos"), co znaczy „dom” i "νόμος" ("nomos"), czyli „prawo, reguła”. Starożytni Grecy stosowali tę definicję do określania efektywnych zasad funkcjonowania gospodarstwa domowego.
Podstawowe zagadnienia ekonomii.
Ekonomia jest nauką o tym, jak jednostka i społeczeństwo decydują o wykorzystaniu zasobów (wszystkich, gdyż wszystkie zasoby mają alternatywne zastosowanie i z definicji są w niedoborze) – które mogą mieć także inne, alternatywne zastosowania – w celu wytwarzania różnych dóbr i rozdzielania ich na konsumpcję obecną lub przyszłą pomiędzy różne osoby i różne grupy w społeczeństwie.
Termin ekonomia pochodzi z greckiego οίκος ("oikos") – dom i νομος ("nomos") – prawo, reguła. Pierwszy raz pojawia się u Ksenofonta – taki tytuł nosi jedno z jego dzieł. Starożytni przez to słowo rozumieli zasady prowadzenia gospodarstwa domowego. Inna szkoła mówi, że słowo ekonomia jest połączeniem słów "oikos" – dom, gospodarstwo domowe i "nomeus" – człowiek, który zarządza, przydziela. Czasownik "oikonomeo" oznacza więc kierowanie domem. Ksenofont rozumiał "oikonomikos" jako kierowanie gospodarstwem domowym.
Jednym z podstawowych pojęć ekonomii jest rzadkość dóbr. Niemal wszystko jest rzadkie: żadna ilość dóbr nie jest w stanie całkowicie usatysfakcjonować społeczeństwa, bez względu na stopień zamożności każdy chce mieć więcej. Ekonomia nazywa ten stan nieograniczonością potrzeb ludzkich. Przedmiot zainteresowania ekonomii częściowo pokrywa się z zagadnieniami badanymi w ramach innych nauk społecznych, ale ekonomia zajmuje się głównie relacjami zachodzącymi między kupującym a sprzedającym oraz analizą rynku.
W ekonomii istnieje wiele nurtów badawczych (szkół), opartych na różnych założeniach co do funkcjonowania gospodarki i natury człowieka. Wyróżnia się między innymi:
Działy ekonomii.
Tradycyjnie ekonomię dzieli się na mikroekonomię, która zajmuje się tym, w jaki sposób gospodarstwa domowe i przedsiębiorstwa podejmują decyzje i jak współdziałają na konkretnych rynkach, oraz na makroekonomię, która skupia swoją uwagę na badaniu całej gospodarki.
Dzisiaj ekonomiści, uwzględniając oddziaływanie handlu zagranicznego i wzajemne powiązania gospodarcze na świecie, wyróżniają również dodatkowo, jako działy ekonomii, międzynarodowe stosunki gospodarcze – zajmujące się uwzględnieniem wpływu międzynarodowej wymiany handlowej na gospodarkę państwa oraz gospodarkę światową – dział ekonomii zajmujący się gospodarką całego świata jako jednego organizmu.
Pod pojęciem ekonomii pozytywnej rozumie się stwierdzenia będące naukowym i obiektywnym wyjaśnieniem funkcjonowania gospodarki (na przykład do ekonomii pozytywnej należy stwierdzenie „Dwukrotne zwiększenie opodatkowania wyrobów tytoniowych spowoduje spadek ich konsumpcji”), natomiast sądy ekonomiczne oparte na subiektywnym systemie wartościowania określane są mianem ekonomii normatywnej (przykładowo „Rząd polski powinien prowadzić politykę mającą na celu obniżenie poziomu konsumpcji wyrobów tytoniowych”).
Obok ekonomii pozytywnej i normatywnej wyróżniamy także pojęcie "sztuki ekonomii", które dotyczy zagadnień polityki. "Sztuka ekonomii" wiąże naukę ekonomii z ekonomią normatywną i stawia następujące pytania: Jeśli takie są czyjeś cele normatywne (ekonomia normatywna) i jeśli tak funkcjonuje gospodarka (ekonomia pozytywna), to jak można najlepiej osiągnąć te cele (sztuka ekonomii)?
Za dziedzinę ekonomii można też uważać historię gospodarczą oraz geografię ekonomiczną.

</doc>
<doc id="1332" url="https://pl.wikipedia.org/wiki?curid=1332" title="Etery">
Etery

Etery – organiczne związki chemiczne, w których występują wiązania C-O-C, przy czym żaden z atomów węgla nie jest związany z więcej niż jednym atomem tlenu.
Właściwości.
Wiązanie C-O-C jest dość trwałe. Rozkłada się dopiero pod wpływem działania silnych kwasów lub zasad w podwyższonej temperaturze, dzięki czemu etery są dość trwałymi i niezbyt reaktywnymi związkami. W najprostszym przypadku etery składają się z dwóch grup organicznych (R, R') połączonych atomem tlenu (R-O-R'), są jednak także znane polietery, w których występuje więcej niż jedno wiązanie C-O-C. Niektóre cykliczne polietery znane są pod nazwą eterów koronowych.
Proste etery zawierające tylko grupy alkilowe są bardzo słabo polarnymi związkami (nieco bardziej polarnymi niż alkeny, jednak mniej niż alkohole i estry). Rozpuszczalność eterów w wodzie jest podobna do rozpuszczalności alkoholi o tej samej masie cząsteczkowej (np. eter dietylowy i butan-1-ol ok. 8g na 100g wody).
Eter dimetylowy CH3OCH3 i etylometylowy CH3OC2H5 są gazami. Począwszy od eteru dietylowego CH3CH2OCH2CH3 etery alkilowe są cieczami. Część z nich ma działanie narkotyczne, np. niegdyś powszechnie stosowany w medycynie eter dietylowy.
Etery tworzą kompleksy ze związkami wykazującymi deficyt elektronów (kwasami Lewisa), np. z BF3 lub ze związkami Grignarda.
Synteza.
Najtańszą metodą otrzymywania eterów jest reakcja dehydratacji alkoholi, w praktyce jest ona ograniczona do syntezy eteru dietylowego:
lub reakcji alkoholi z chloro- i bromoalkanami
Metodę syntezy niesymetrycznych eterów z halogenków alkilowych i alkoholanów opracował A. Williamson. Metoda ta znana jest obecnie jako synteza Williamsona:
Zastosowanie.
Etery dialkilowe (najczęściej eter dietylowy) są stosowane jako mało polarne rozpuszczalniki, np. do otrzymywania związków Grignarda. Inne często stosowane etery to cykliczny tetrahydrofuran (THF), wykorzystywany jako rozpuszczalnik organiczny o umiarkowanej polarności oraz bardziej polarny cykliczny dieter, dioksan.
Eter dietylowy jest najstarszym środkiem do narkozy, używanym od roku 1846. Wtedy to amerykański dentysta William Morton w Charlton w Massachusetts wypróbował go do znieczulenia przed ekstrakcją zęba, a następnie podczas publicznego zabiegu chirurgicznego. W 4 miesiące później pierwszej takiej operacji na ziemiach polskich dokonano w Krakowie.
Nadtlenki eterów.
Etery podatne są na utlenianie tlenem. W wyniku reakcji tworzą się wodoronadtlenki eterów (następuje rodnikowa insercja cząsteczki tlenu, z rozerwaniem wiązania C-H przy węglu połączonym z tlenem). Nadtlenki są silnymi utleniaczami, odbarwiają wodę bromową, są inicjatorami reakcji wolnorodnikowych oraz są wybuchowe. Etery pozostawione w kontakcie z powietrzem mogą zawierać spore ilości nadtlenków. Są one wyżej wrzące od eterów i stanowią poważne zagrożenie przy ich destylacji (nigdy nie destyluje się eterów do końca).
Inne (zwyczajowe) użycie nazwy eter w chemii.
Pierwotnie terminem eter określano wszelkie substancje charakteryzujące się względną łatwością przeprowadzenia w stan gazowy. Cecha ta jest właściwa także dla substancji chemicznie nie będących eterami:

</doc>
<doc id="1333" url="https://pl.wikipedia.org/wiki?curid=1333" title="Elektrofil">
Elektrofil

Elektrofil (czynnik elektrofilowy) – cząsteczka lub grupa, w której występuje niedomiar elektronów i w odpowiednich warunkach jest w stanie je przyjąć, czyli być ich akceptorem.
Elektrofilami są wszystkie kwasy, zarówno zgodne z definicją Brønsteda, jak i Lewisa. Oprócz tego mogą to być także cząsteczki, które nie wykazują żadnych właściwości kwasowych, lecz tylko mają "zwykły" deficyt elektronów – pojęcie elektrofila jest więc szersze od pojęcia kwasu.
W odróżnieniu od kwasów, które można uszeregować według ich "mocy", elektrofile dzieli się raczej na "twarde" i "miękkie".
Twardy elektrofil to cząsteczka mała, zwarta i o bardzo skoncentrowanym "centrum elektrofilowości" – czyli jednym konkretnym miejscu w cząsteczce, które jest szczególnie skłonne przyjmować elektrony. Przykłady twardych elektrofili to: H+, K+, AlCl3.
Miękki elektrofil to na odwrót cząsteczka duża, z rozmytym "centrum elektrofilowości" – czyli brakiem jednego konkretnego miejsca, które jest szczególnie skłonne przyjmować elektrony. Przykłady miękkich elektrofili to: Br+, Ag+, BH3.

</doc>
<doc id="1334" url="https://pl.wikipedia.org/wiki?curid=1334" title="Ekson">
Ekson

Ekson, egzon, sekwencja kodująca – odcinek genu kodujący sekwencję aminokwasów w cząsteczce białka. Poszczególne eksony oddzielone są od siebie intronami (sekwencjami niekodującymi) i występują wyłącznie w komórkach eukariotycznych.
Pierwotny transkrypt zawiera wówczas na przemian ułożone odcinki intronowe i eksonowe. Po zsyntetyzowaniu czapeczki i poliadenylacji cząsteczki RNA, ale jeszcze przed jej eksportem z jądra do cytoplazmy następuje wycięcie wszystkich intronów oraz połączenie eksonów w jedną całość (splicing). Po zakończeniu tych procesów transkrypt staje się funkcjonalną cząsteczką informacyjnego RNA (mRNA), który w tej postaci może opuścić jądro komórkowe i zostać użytym w procesie translacji.

</doc>
<doc id="1340" url="https://pl.wikipedia.org/wiki?curid=1340" title="Era geologiczna">
Era geologiczna



</doc>
<doc id="1341" url="https://pl.wikipedia.org/wiki?curid=1341" title="Ekstrakcja">
Ekstrakcja

Ekstrakcja – wyodrębnianie składnika lub składników mieszanin metodą dyfuzji do cieczy lepiej rozpuszczających te związki chemiczne. Pojęcie ekstrakcji odnosi się najczęściej do procesów prowadzonych w układach ciecz – ciecz, w obszarze ograniczonej mieszalności. Ekstrakcją nazywa się również analogiczny proces, prowadzony w układach ciecz – ciało stałe (ługowanie, enfleurage).
W układach ciecz – ciecz substancje ekstrahowane ulegają podziałowi między rozpuszczalnik pierwotny (roztwór surowy), a rozpuszczalnik wtórny (ekstrahent), który powinien w miarę możliwości selektywnie absorbować odzyskiwane związki chemiczne. Uzyskuje się rafinat (rozpuszczalnik pierwotny, pozbawiony dużej części odzyskiwanego związku) i ekstrakt, który może być np. poddawany destylacji w celu odzyskania substancji ekstrahowanej i rozpuszczalnika
Efektywność procesu ekstrakcji zależy przede wszystkim od rodzaju rozpuszczalnika, ale duże znaczenie ma również temperatura i techniki postępowania (np. stopień rozwinięcia powierzchni wymiany masy, intensywność mieszania faz). Złożone mieszaniny związków chemicznych są rozdzielane metodami ekstrakcji frakcyjnej, z użyciem różnych ekstrahentów.
Po osiągnięciu stanu zbliżonego do równowagi obie ciecze – ekstrakt i rafinat – są rozdzielane, np. z użyciem rozdzielaczy laboratoryjnych, wirówek lub przemysłowych separatorów. Ekstrakty rozdziela się na frakcje lub pojedyncze związki np. metodą destylacji, odzyskując rozpuszczalnik.
Przykładem procesu ekstrakcji w układzie ciało stałe – ciecz jest proces parzenia kawy lub herbaty. Zawarte w kawie substancje smakowe dyfundują z ziarna (surowiec) do wody (ekstrahent). Analogicznie są otrzymywane leki galenowe (napary, odwary, wyciągi, nalewki). Różne tłuszcze roślinne, między innymi biopaliwa, są również produkowane z wykorzystaniem ekstrakcji. Ekstrakcję rozpuszczalnikami organicznymi stosuje się przede wszystkim do odzyskiwania oleju pozostającego w materiale po wytłaczaniu (wytłoki).
Podstawy fizykochemiczne.
Siłą napędową procesu ekstrakcji jest różnica między potencjałami termodynamicznymi układu przed i po procesie wymiany masy. Pod stałym ciśnieniem i w stałej temperaturze dyfuzja składników pomiędzy niemieszającymi się cieczami zachodzi samorzutnie tak długo, dopóki maleje entalpia swobodna układu, co zapisuje się matematycznie:
gdzie:
Równania wskazują, że w wielofazowych układach wieloskładnikowych o kierunku przemiany decydują zmiany potencjałów chemicznych wszystkich związków we wszystkich fazach (ewentualnie dodatkowo praca zewnętrzna, która jest wykonywana).
W uproszczeniu stan izotermiczno-izobarycznej równowagi termodynamicznej w procesie podziału związku chemicznego między dwie fazy ciekłe opisuje się korzystając z prawa podziału Nernsta:
gdzie:
Współczynnik podziału formula_11 ma wartość stałą dla roztworów doskonałych. W przypadku roztworów rzeczywistych wartości stałe mają współczynniki formula_12 obliczane z wykorzystaniem odpowiednich współczynników aktywności. Współczynniki formula_11 są zależne od stężenia związku w roztworach.
Wykresy fazowe dla układów trójskładnikowych ("p" = const).
Najprostsze przypadki równowag ekstrakcyjnych dotyczą układów trójskładnikowych, zawierających dwa rozpuszczalniki o ograniczonej wzajemnej rozpuszczalności i związek chemiczny, rozpuszczalny w obu cieczach.
Wzajemna rozpuszczalność dwóch cieczy zależy od:
Wprowadzany do układu dwuskładnikowego (A + B) trzeci składnik (C) może zwiększać lub zmniejszać obszar ograniczonej mieszalności A z B. Zależy to od wielkości oddziaływań cząsteczek związku C z cząsteczkami A i B. W przypadku ekstrakcji jest niezbędne, aby związek ekstrahowany (C) rozpuszczał się w obu rozpuszczalnikach, co występuje, gdy istnieją wystarczająco duże siły przyciągania A–C i B–C. W miarę zwiększania zawartości C w obu fazach zanika przyczyna wzajemnej niemieszalności A z B. Obecność C sprawia, że przestaje odgrywać znaczącą rolę różnica między siłami oddziaływania A – A, B – B i A – B, a wskutek tego wzrasta wzajemna mieszalność (do zaniku rozwarstwienia cieczy).
Zależność wzajemnej rozpuszczalności cieczy od składu układu A–B–C oraz temperatury przedstawia się w trójwymiarowym układzie współrzędnych skład – temperatura (graniastosłup, którego podstawą jest trójkąt Gibbsa). Na co najmniej jednej ze ścian graniastosłupa (np. A–B–T) musi się znajdować wykres fazowy układu dwuskładnikowego z obszarem ograniczonej mieszalności cieczy. Zakres tego obszaru oraz odpowiedniej trójwymiarowej przestrzeni współistnienia dwóch faz ciekłych zwykle zmniejsza się wraz ze wzrostem temperatury. W większości układów występuje górna graniczna temperatura mieszalności (na ścianie graniastosłupa lub w jego wnętrzu).
W niższej temperaturze przestrzeń współistnienia dwóch cieczy może się łączyć z przestrzenią współistnienia cieczy z fazą stałą. Mieści się ona pod powierzchniami roztworów nasyconych składnikami A, B i C. Kształt tych powierzchni zależy od rodzaju wykresów fazowych dla układów podwójnych A–B, B–C i C–A (ściany graniastosłupa). Na liniach wspólnych dla sąsiednich powierzchni nasyconych roztworów (np. nasyconych składnikami A i B) leżą punkty określające temperaturę i skład eutektyków podwójnych, zawierających trzeci składnik (np. równowaga A(BC)+B(AC)+ciecz). Układ ma jeden eutektyk potrójny, bez stopni swobody.
Na trójkątnych izotermicznych przekrojach graniastosłupa znajdują się linie przecięcia powierzchni roztworów nasyconych, które ograniczają obszary współistnienia faz (np. nasyconego roztworu z kryształami lub dwóch współistniejących cieczy). Obszary współistnienia są przecinane cięciwami równowagi. Cięciwy łączą punkty określające stężenia składników A, B i C we współistniejących fazach. Ilościowe udziały obu faz w dwufazowej mieszaninie określa się korzystając z reguły dźwigni.
Jednostopniowa ekstrakcja prosta polega na zmieszaniu (np. w rozdzielaczu) określonych ilości roztworu surowego (n. produkt syntezy chemicznej w wodnym roztworze) i czystego rozpuszczalnika wtórnego (np. eteru). Punkt opisujący chemiczny skład całej zawartości rozdzielacza leży na linii prostej łączącej wierzchołek trójkąta, w którym stężenia ekstrahenta jest równe 100% z punktem określającym skład roztworu surowego. Miejsce punktu na tej prostej zależy od proporcji cieczy wprowadzonych do rozdzielacza. Po doprowadzeniu do stanu równowagi warstwę wodną można przenieść do drugiego rozdzielacza i dodać do niej drugą porcję czystego rozpuszczalnika organicznego. Czynności wytrząsania cieczy, oddzielania warstwy wodnej i ekstrahowania czystym rozpuszczalnikiem mogą być powtarzane wielokrotnie, aż do osiągnięcia pożądanego stopnia odzyskania związku chemicznego z roztworu wodnego. Dysponując ograniczoną ilością czystego rozpuszczalnika można przeprowadzić ekstrakcję kilkoma dużymi porcjami, lecz zastosowanie większej liczby małych porcji umożliwia odzyskanie większej ilości preparatu.
Postępowanie bardziej efektywne polega na stosowaniu mało stężonych ekstraktów organicznych do ekstrakcji z ze stężonych roztworów wodnych. Jest to istotą ekstrakcji zwykłej wielokrotnej, wykonywanej w laboratoriach z użyciem rozdzielaczy, lub przeciwprądowej ekstrakcji ciągłej, stosowanej w przemyśle.
Urządzenia.
W warunkach laboratoryjnych jest stosowana ekstrakcja prosta lub wielokrotna z użyciem rozdzielaczy (wytrząsanie) lub ekstrakcja ciągła, z użyciem ekstraktorów lub perkolatorów o różnej konstrukcji, takich jak aparat Soxhleta lub Aparat Graefego (perkolacja).
Aparat Soxhleta działa podobnie do ekspresu do kawy. Rozpuszczalnik jest ogrzewany w kolbie okrągłodennej, a pary są skraplane w umieszczonej nad nią chłodnicy wodnej. Spływając do kolby przepłukuje materiał poddawany ekstrakcji, umieszczony w gilzie ekstrakcyjnej. Wzbogaca się w ekstrahowany składnik, o większym ciężarze właściwym od rozpuszczalnika. Ekstrakt spływa do kolby, gdy poziom kondensatu w nasadce z gilzą przekroczy pozom przelewu (kolanko bocznej rurki lewarowej).
Zasada działania laboratoryjnych perkolatorów do ciągłej ekstrakcji cieczy jest analogiczna. Aparaty umożliwiają ekstrakcję substancjii o współczynniku podziału k &lt; 1,5, z zastosowaniem bardzo małych ilości rozpuszczalnika.
W warunkach przemysłowych procesy ekstrakcji (mieszania cieczy), rozdzielania faz ciekłych i odzyskiwania rozpuszczalnika metodą destylacji są zwykle wykonywane w odrębnych aparatach. Stosuje się baterie połączonych bloków, złożonych z ekstaktora (zbiornik z mieszadłem), separatora faz ciekłych i destylatora (odzyskiwanie ekstrahenty), co umożliwia ekstrakcję wielostopniową. Rafinat z pierwszego bloku jest kierowany do kolejnego ekstraktora baterii, gdzie jest poddawany działaniu czystego rozpuszczalnika (wielokrotna ekstrakcja prosta) lub rozpuszczalnika opuszczającego ekstraktor następnego bloku. W drugim przypadku bateria ekstraktorów pracuje jak przeciwprądowa kolumna ekstrakcyjna. Elementarne ekstraktory odgrywają rolę półek, na których ustalają się kolejne stany równowagi.
Przemysłowe urządzenia do ekstrakcji z substancji stałych są zwykle cylindrycznymi zbiornikami, w których rozpuszczalnik przepływa przez materiał nieruchomy lub wsad w ruchu.
Złoże nieruchome jest umieszczane na ruszcie i okresowo usuwane po ekstrakcji. Ekstraktory są wyposażone w instalację doprowadzania i odprowadzania rozpuszczalnika oraz system ogrzewania parą (bezprzeponowo i przeponowo. Pracują okresowo w cyklach: załadowanie, ekstrakcja, parowanie i wyładowanie. Właściwa koordynacjia pracy czterech ekstraktorów pozwala uzyskać ciągłość pracy baterii.
W ekstraktorach pracujących w sposób ciągły materiał przesypuje się w dół lub jest transportowany w górę, np. transporterami kubełkowymi lub ślimakowymi, w przeciwprądzie do spływającego w dół rozpuszczalnika.
Zastosowania ekstrakcji w przemyśle (przykłady).
Ekstrakcja jest metodą rozdzielania wielu różnych naturalnych mieszanin związków chemicznych lub produktów syntez. Jest stosowana zwłaszcza w tych sytuacjach, gdy zawodzą techniki destylacyjne, np. ze względu na bardzo małe stężenia odzyskiwanych składników, tworzenie azeotropów), procesy termicznego rozkładu części związków itp.
Przykład 1 – ekstrakcja w produkcji olejów roślinnych
Ekstrakcja odgrywa znaczną rolę w przemyśle otrzymywania olejów roślinnych wykorzystywanych jako tłuszcze jadalne, składniki kosmetyków, paliwa i inne. Bywa bardziej korzystnym procesem rozdziału składników materiału roślinnego od destylacji. Rafinowane oleje roślinne podczas przeróbki tracą wiele swoich wartości, w tym zapachowych i smakowych (w pełni zachowywanych w procesie tłoczenia na zimno).
Ekstrakcja jest stosowana przede wszystkim w procesach odzyskiwania tłuszczów z materiałów ubogich w tłuszcz (np. kości, kiełków kukurydzy i zbóż) lub z wytłoków (pozostałości po tłoczeniu). Proces jest prowadzony „na zimno” (przepłukiwania surowca ciekłym rozpuszczalnikiem) lub na gorąco (wprowadzanie pary rozpuszczalnika, kondensujących w warstwie surowca). Spośród licznych stosowanych rozpuszczalników można wymienić takie jak czterochlorek węgla, trichloroetylen, benzol, benzyna ekstrakcyjna i inne.
W Polsce i większości innych krajów Europy podstawowym surowcem oleistym jest rzepak. Olej rzepakowy przeznaczony na biopaliwa jest otrzymywany z ziaren rzepaku w procesach tłoczenia na gorąco i ekstrakcji z użyciem heksanu. Ziarna, po mechanicznym oczyszczeniu, są wstępnie prażone i rozdrabniane, po czym kierowane do węzła wytłaczania. Z pras odbierany jest olej i wytłoki. Olej pozostały w wytłokach jest odzyskiwany metodą ekstrakcji, np. z użyciem heksanu jako rozpuszczalnika. Wytłoki przemieszczają się w ekstraktorze z góry w dół. na dolny poziom ekstraktora jest wprowadzany heksan, a na poziomy wyższe – tzw. miscella (rozpuszczalnik-olej), o coraz większym stężeniu oleju.
Śruta opuszczająca ekstraktor jest odciskana (odzyskanie części rozpuszczalnika), a następnie ogrzewana parą wodną – pośrednio i bezpośrednio (odparowanie reszty rozpuszczalnika). Odzyskiwany z mieszaniny par heksan zawraca się do ekstraktora.
Przykład 2 – ekstrakcja węgla brunatnego i torfu
Węgiel brunatny i torfy zawierają bituminy (10–20%), które są wyodrębniane z rozdrobnionego materiału metodą ekstrakcji na gorąco takimi rozpuszczalnikami, jak benzyna ekstrakcyjna lub mieszaniny benzenu z etanolem. Dodatek etanolu – rozpuszczalnika hydrofilowego – jest korzystny ze względu na zawartość wilgoci w surowcach (do 20%). Ekstrakcję prowadzi się w bateriach żelaznych ekstraktorów, wypełnianych rozdrobnionym surowcem, umieszczonym na rusztach. Do aparatów są wprowadzane pary rozpuszczalnika, które kondensują na złożu materiału i spływają w dół. Roztwór gromadzący się w dolnej części ekstraktora, zawierający bituminy, jest kierowany do wyparki, Po odparowaniu – rozpuszczalnika pozostaje bitumin, spływający do form, w których zastyga. Pary skraplają się z utworzeniem kondensatu dwufazowego (benzen – wodny roztwór alkoholu). Dwuskładnikowy rozpuszczalnik benzen-etanol jest odzyskiwany i zawracany do ekstraktora po rozdzieleniu fazy wodnej metodą rektyfikacji.
Poekstrakcyjny węgiel i torf są wykorzystywane jako paliwo. Otrzymane ekstrakty (bituminy) są stosowane do wyrobu materiałów izolacyjnych lub poddawane dalszej ekstrakcji rozpuszczalnikami selektywnymi (otrzymywanie wosków, żywic, substancji asfaltowych).
Olej, odprowadzany z ekstraktora w formie stężonej miscelli, jest uwalniany od rozpuszczalnika w aparatach wyparnych.

</doc>
<doc id="1342" url="https://pl.wikipedia.org/wiki?curid=1342" title="Elektryczność">
Elektryczność

Elektryczność (od gr. ήλεκτρον (elektron) – bursztyn) – zjawisko związane z oddziaływaniem ciał mających ładunek elektryczny (na przykład elektronów i protonów) oraz z przepływem tych ładunków (prądem elektrycznym). W fizyce elektryczność obejmuje elektrostatykę, elektrodynamikę i prąd elektryczny. Można wyróżnić elektryczność naturalną, np. atmosferyczną oraz elektryczność związaną z techniką.
Potocznie elektryczność jest kojarzona przede wszystkim z instalacją elektroenergetyczną.

</doc>
<doc id="1343" url="https://pl.wikipedia.org/wiki?curid=1343" title="Endoskopia">
Endoskopia

Endoskopia – ogólna nazwa zabiegów diagnostyczno-leczniczych w medycynie i w weterynarii, polegających na badaniu wnętrza ciała przy wykorzystaniu aparatów, zwanych endoskopami, umożliwiających doprowadzenie światła oraz optyki do wnętrza przewodu pokarmowego, oddechowego oraz jam ciała, np.: jamy otrzewnej, jamy opłucnej.
Badania endoskopowe polegają na wprowadzaniu do wnętrza ciała pacjenta części endoskopu, zwanej sondą, zawierającą światłowód do oświetlenia badanego pola, obrazowód – przekazujący obraz z wnętrza badanego narządu oraz kanał narzędziowy służący do wprowadzenia specjalnych narzędzi służących do pobierania materiału do badań i wykonywania zabiegów).
Historia.
Już w czasach starożytnych ówcześni lekarze starali się zaglądać do dostępnych wzrokowi ludzkiemu obszarów ciała. Należą do nich jama ustna i gardło, nos, ucho, pochwa i częściowo odbyt (w pismach Hipokratesa znajdują się opisy anoskopii – wziernikowania odbytu jak i operacji w tym rejonie wykonywanych pod kontrolą anoskopów). Źródłem światła było światło słoneczne odbite od lustra. Współczesną pochodną owych technik jest lusterko czołowe laryngologa.
Pierwsze urządzenia celowo wykonane w celu endoskopii powstały w początkach XIX w. Najczęściej używano je do badania pęcherza moczowego. Filip Bozzini (1773-1809) we Frankfurcie wykorzystał światło lampy gazowej w celu oświetlenia badanych endoskopem narządów. Badano najczęściej pochwę, odbytnicę i dolną część gardła. Rozwój optyki i mechaniki precyzyjnej pozwolił na konstruowanie coraz lepszych endoskopów. Pozwoliło to Adolfowi Kussmaulowi (1822-1902) z Fryburga w Niemczech na wykonanie w 1886 pierwszej gastroskopii. Pacjentem był zawodowy połykacz noży z cyrku. Wielkie zasługi dla rozwoju gastroskopii położył Jan Mikulicz-Radecki (1850-1905), który pracując wówczas w Wiedniu, konstruował wraz z inżynierami nowe typy endoskopów wykonując liczne badania górnego odcinka przewodu pokarmowego. W 1881 opisał on gastroskopię, w czasie której rozpoznał raka żołądka. W konkluzji artykułu stwierdził, iż spodziewa się, że dzięki gastroskopii będzie można tę chorobę rozpoznawać w mniej zaawansowanych stadiach. Istotnie w latach 60. XX wieku w Japonii powstało pojęcie „raka wczesnego” możliwego w praktyce do rozpoznania tylko endoskopowo. Urządzenie Mikulicza posiadało na końcu żarówkę elektryczną.
Pod koniec XIX wieku rozwój endoskopii został nieco wstrzymany przez wprowadzenie do medycyny odkrytych w 1895 przez Wilhelma Roentgena promieni X. Endoskopia powodowała wiele jatrogennych uszkodzeń przełyku i gardła, gdyż nie całe badanie (głównie wprowadzanie aparatu) odbywało się pod kontrolą wzroku badającego.
Mimo tego endoskopia rozwijała się i zaczęto wprowadzać niebędące już sztywnymi rurami, a posiadające pewną giętkość (dzięki przegubom). Pierwszy prawdziwie giętki endoskop wprowadzili w roku 1932 Rudolf Schindler (1888-1968) i Georg Wolf (1873-1938). W roku 1940 Bruce Kenamore wyprodukował endoskopowe kleszcze biopsyjne do pobierania materiału do badań histopatologicznych. Opisane endoskopy opierały się na systemie soczewek i źródle światła w końcówce aparatu. Ograniczało to w znacznym stopniu giętkość aparatu i zakres możliwych badań. W maju 1957 Basil Hirschowitz na spotkaniu Amerykańskiego Towarzystwa Gastroskopowego w Colorado Springs przedstawił endoskop zbudowany z włókien światłowodowych, kilka lat później ulepszony przez wprowadzenie tzw. zimnego światła czyli silną żarówkę położoną poza aparatem, której światło przewodzone było do obiektu badanego także poprzez światłowody. Otworzyła się nowa era endoskopii. Następnym krokiem było wprowadzenie w latach 90. XX w. videoendoskopów, gdzie rezygnuje się ze światłowodów na rzecz miniaturowej kamery CCD, umieszczanej na wprowadzanym do pacjenta końcu endoskopu.
Obecnie używane są również sztywne endoskopy (rigid endoscopes), które w kanale zawierają serię soczewek. Dają one obraz znacznie lepszej jakości niż endoskopy światłowodowe, ale stosuje się je głównie w laparoskopach i artroskopach.
Badania endoskopowe.
Badania układu oddechowego.
Bronchoskopia – badanie wnętrza tchawicy i oskrzeli, umożliwia wykrycie zmian chorobowych w obrębie tych narządów (zwężeń, guzów, nacieków nowotworowych lub zapalnych). Możliwe jest również pobieranie próbek wydzieliny z oskrzeli oraz przy użyciu specjalnych narzędzi pobranie wycinków błony śluzowej do badań histopatologicznych, cytologicznych i bakteriologicznych.
Aktualnie wykonuje się badanie bronchoskopowe przy użyciu giętkiego wziernika – fiberoskopu, a badanie takie nazywa się bronchofiberoskopią.
Pierwszy opis badania bronchoskopowego przy pomocy sztywnego brochoskopu podał w 1897 Gustav Killian, a badanie z użyciem giętkiego bronchofiberoskopu zostało po raz pierwszy wykonane w 1967 przez Ikedę w Japonii.
Badanie wykonuje się u chorego leżącego na plecach lub w pozycji siedzącej. Obowiązuje wykonanie znieczulenia miejscowego łuków podniebiennych, tylnej ściany gardła, krtani i dróg oddechowych poniżej krtani roztworem lidokainy. Dodatkowo stosuje się także tak zwaną "płytką sedację" podając badanemu dożylnie fentanyl lub midazolam.
W trakcie badania monitoruje się saturację (pulsoksymetria) i w przypadkach spadków saturacji dodatkowo podaje się tlen. W trakcie badania bronchoskopowego musi być zapewniony sprzęt do resuscytacji.
Do obejrzenia jamy nosowo-gardłowej używa się także fiberoskopu. Badanie zaś, pozwalające na obejrzenie migdałków, języczka, jamy nosowej i gardłowej, nazywane jest fiberoskopią. Do jego wykonania nie jest potrzebne znieczulenie, gdyż jest bezbolesne i proste. Sonda, kalibru minimalnie większego od wkładu do długopisu, wprowadzana jest przez gardło lub nos.
W trakcie i po bronchoskopii mogą wystąpić powikłania: uszkodzenie strun głosowych, uszkodzenie krtani, tchawicy, oskrzela, Odma opłucnowa, skurcz oskrzeli.
Laryngoskopia – badanie krtani.
Stroboskopia – umożliwia badanie tylnej ściany części krtaniowej gardła oraz obejrzenie z góry nagłośni. Stroboskop jest sztywną, metalową rurą, badanie nim może spowodować odruch wymiotny, ale nie wymaga znieczulenia.
Badania przewodu pokarmowego.
Gastroskopia (inaczej panendoskopia) – badanie górnego odcinka przewodu pokarmowego. Umożliwia diagnostykę schorzeń przełyku, żołądka i dwunastnicy, takich jak wrzody żołądka i dwunastnicy, nowotwory, a także pobieranie wycinków błony śluzowej do badań histopatologicznych i tamowanie niewielkich krwawień.
Kolonoskopia – badanie jelita grubego (okrężnicy).Dzieli się ona zależnie od zaawansowania badania na
Endoskopowa cholangiopankreatografia wsteczna – badanie umożliwiające diagnostykę schorzeń dróg żółciowych.
Endoskopia kapsułkowa – badanie umożliwiające diagnostykę całego jelita cienkiego. W odróżnieniu od innych badań endoskopowych, nie używa się do tego celu fiberoskopu w postaci giętkiej rury. Pacjent połyka metalową kapsułkę, zawierającą w sobie miniaturową kamerę, która, przechodząc przez przewód pokarmowy pacjenta, wykonuje ok. 50000 zdjęć. Zdjęcia te są przekazywane do urządzenia zamocowanego na brzuchu pacjenta. Po przejściu przez układ pokarmowy, kapsułka jest wydalana. Zaletą tego badania jest możliwość wglądu do całego jelita cienkiego trudno- lub niedostępnego dla klasycznych giętkich endoskopów, natomiast wadą jest niemożność pobierania wycinków do badań histopatologicznych.
Inne badania endoskopowe.
Artroskopia – wziernikowanie stawu, np. kolanowego.
Kolposkopia – wziernikowanie pochwy i szyjki macicy. Służy do oceny nieprawidłowości w obrębie pochwy i szyjki macicy.
Cystoskopia – wziernikowanie pęcherza, cewki moczowej, moczowodów oraz prostaty (u mężczyzn). Przez cewkę moczową wprowadza się cystoskop, umożliwiający oglądanie jej wnętrza. Celem tego badania może być rozpoznanie zakażeń, polipów, nowotworów złośliwych, kamicy nerkowej.
Laparoskopia – badanie wnętrza jamy otrzewnej, np. żołądka, wątroby, żeńskich organów płciowych, itp. Endoskop wprowadza się w tym przypadku przez niewielkie nacięcie brzucha.
Endoskopia igłowa, np. endoskopia oczna, angioendoskopia, korzystająca z ultracienkich włókien optycznych, umożliwiających oglądanie np. wewnętrznych struktur oka czy zastawek serca i naczyń wieńcowych.
Operacje endoskopowe.
Endoskopia, oprócz oglądania wnętrza narządów, umożliwia również wykonywanie niektórych operacji, takich jak polipektomia (usunięcie pojedynczego polipu np. z jelita grubego), papillotomia (nacięcie brodawki Vatera z przecięciem zwieracza Oddiego), appendektomia (wycięcie wyrostka), cholecystektomia (wycięcie pęcherzyka żółciowego), usunięcie kamieni z przewodów żółciowych, splenektomia (wycięcie śledziony), tamowanie niewielkich krwawień np. z wrzodów żołądka lub przełyku.

</doc>
<doc id="1344" url="https://pl.wikipedia.org/wiki?curid=1344" title="Euklides">
Euklides

Euklides z Aleksandrii (, "Eukleides", ur. ok. 365 p.n.e., zm. ok. 270 p.n.e.) – matematyk grecki przez większość życia działający w Aleksandrii, autor "Elementów" (, "Stoicheia"), jednego z najsłynniejszych dzieł matematycznych w historii.
Życie.
O życiu Euklidesa prawie nic nie wiadomo. Jego imię jest znane z tylko jednego źródła – z powstałego 7 stuleci później komentarza Proklosa do I księgi "Elementów"; inni określali go jako „autor "Stoicheia"”. Proklos stwierdził, że Euklides był trochę młodszy od uczniów Platona, a starszy od Eratostenesa i Archimedesa. Napisał też, że Euklides prawdopodobnie kształcił się w Atenach, bowiem ze szkoły Platona wyszła większość geometrów, od których jedynie mógł posiąść taką wiedzę.
"Elementy" Euklidesa.
Głównym dziełem Euklidesa są "Elementy". Było to aksjomatyczne ujęcie geometrii, które dotrwało w niezmienionej postaci jako kanon geometrii aż do XIX wieku (w niektórych krajach było używane jako podręcznik geometrii aż do XX wieku). Jak pisał Proklos, Euklides zebrał w całość i uporządkował (w księgach V i XII) wiele odkryć Eudoksosa z Knidos, uzupełnił wyniki Teajteta (w księgach X i XIII) oraz dostarczył niezbitych dowodów twierdzeń, które nie były przedtem ściśle uzasadnione przez jego poprzedników. Usystematyzował i nadał jednolitą postać podstawowej części ówczesnej wiedzy z geometrii płaskiej, przestrzennej i arytmetyki. To, że na początku każdej księgi podane są definicje, odpowiadało stanowisku Arystotelesa, że naukę dedukcyjną należy rozpoczynać od podania definicji i aksjomatów.
Proklos wyróżnił w "Elementach" konstrukcje i twierdzenia. Każda konstrukcja i każde twierdzenie przedstawione jest w sześciu krokach: (1) teza, (2) rysunek diagramu i ustalenie oznaczeń, (3) powtórzona teza z oznaczeniami, (4) zasadnicza część konstrukcji bądź dowodu, (5) uzasadnienie (tezy lub poprawności konstrukcji), (6) powtórzona teza (konstrukcje kończą się zwrotem: "co było do wykonania", a twierdzenia zwrotem: "co było do okazania").
Euklides starał się nadać swemu dziełu (zapewne pod wpływem Platona) charakter statyczny. W ukrytej formie pojawiają się tam jednak ruchy: przemieszczanie na płaszczyźnie, obroty przy kuli, walcu i stożku. W całym dziele widoczne jest też maksymalne dążenie do ścisłości. Jednakże zasady dedukcji określone zostały nie tylko przez podanie definicji i aksjomatów, ale też – w ukrytej formie – przez przykłady rozumowań, poczynając od pierwszej konstrukcji trójkąta równobocznego.
U Euklidesa nie było żadnej wersji aksjomatu ciągłości dla linii prostej, np. takiego jak u Dedekinda. Oryginalny system aksjomatyczny Euklidesa dopuszcza "model przeliczalny" w układzie kartezjańskim, gdy obie współrzędne formula_1 każdego punktu należą do "ciała pitagorejskiego", tj. najmniejszego zbioru formula_2 liczb rzeczywistych zawierającego liczby wymierne, zamkniętego ze względu na cztery działania arytmetyczne i takiego, że jest w nim rozwiązalne każde równanie postaci formula_3 przy formula_4 jest to zbiór przeliczalny i da się w nim rozwiązać każde równanie kwadratowe o współczynnikach z tego ciała, a więc w modelu tym wykonalne są wszystkie konstrukcje Euklidesa (dotyczące zawsze tylko prostych i okręgów).
W sposobie rozumowania Euklidesa prezentowanym w "Elementach" istotną rolę odgrywa specyficzne greckie użycie diagramów.
Inne dzieła Euklidesa.
Zachowało się dzieło Euklidesa z optyki, oparte na podzielanym przez pewnych greckich uczonych poglądzie, że widzenie polega na wysyłaniu promieni przez oko. Opisał on odbicia w zwierciadłach płaskich i sferycznych wklęsłych. Zajmował się też perspektywą, a mianowicie pozornym zmniejszaniem obrazu przy oddalaniu obiektu oraz obrazem stożków i walców przy patrzeniu z ukosa. Nie ocalało jednak jego dzieło o krzywych stożkowych.
Linki zewnętrzne.
Polskojęzyczne
Anglojęzyczne

</doc>
<doc id="1346" url="https://pl.wikipedia.org/wiki?curid=1346" title="Estonia">
Estonia

Estonia (), Republika Estońska (est. "Eesti Vabariik") – państwo unitarne w Europie Północnej, nad Morzem Bałtyckim, nad Zatoką Fińską, nad którą leży Tallinn, stolica i największe miasto kraju, i Zatoką Ryską. Powstało po I wojnie światowej. Członek Unii Europejskiej i NATO. Graniczy z Łotwą od południa i z Rosją od wschodu oraz z Finlandią przez Zatokę Fińską. Jedno z najbardziej zinformatyzowanych państw świata.
Nazwa.
Nazwa "Estonia" (we współczesnym języku estońskim "Eesti") może być wywodzona ze słowa "Aestii", zlatynizowanej nazwy nadanej przez starożytnych Germanów ludom zamieszkującym tereny na północny wschód od Wisły. Rzymski historyk Tacyt w 98 r. n.e. po raz pierwszy pisał o ludach "Aestii" i wczesnych Skandynawach.
Dawne skandynawskie sagi nazywają ziemie na południe od Zatoki Fińskiej "Eistland".
Tożsamość.
Estonia a Skandynawia.
Estonia ma silne wpływy skandynawskie, szczególnie szwedzkie i duńskie. Sama nazwa stolicy Estonii – Tallinn znaczy „Duńskie Miasto”.
Po uzyskaniu przez Estonię niepodległości w 1918 roku rząd estoński rozpoczął starania o przyjęcie do kręgu krajów nordyckich. Osobą szczególnie zainteresowaną włączeniem Estonii do tej grupy był Aleksander Kesküla. Próby te zostały zahamowane po drugiej wojnie światowej, po aneksji kraju przez ZSRR.
Po odzyskaniu niepodległości w 1991 r. powrócono do idei identyfikacji z kulturą nordycką. Kluczowym momentem była przemowa estońskiego ministra spraw zagranicznych Toomasa Hendrika Ilvesa w Szwedzkim Instytucie Spraw Zagranicznych w 1999 r.
Estonia a Finlandia.
Pod względem kulturowym, językowym, wyznaniowym i wieloma innymi Estonia jest podobna do Finlandii (Estończycy są najbliższymi krewnymi Finów). Różnicą między krajami mogą być silne wpływy niemieckie w Estonii, których w Finlandii nie było, a także inna historia najnowsza, duża mniejszość rosyjska oraz liberalny model gospodarczy.
Wpływy niemieckie.
Estonia (podobnie jak jej południowy sąsiad – Łotwa) od wczesnego średniowiecza, aż do początków XX wieku, a więc przez wieleset lat, znajdowała się pod bardzo silnym wpływem kultury niemieckiej. Było to spowodowane tym, że obecna Estonia i Łotwa to dawne Inflanty i inne krainy historyczne (np. Terra Mariana), które najdłużej w swej historii były pod niemieckim panowaniem. Kultura niemiecka oddziaływała tam jednak znacznie dłużej niż tylko w czasie oficjalnego panowania Niemców na tym terenie. Oddziaływała również w czasie panowania szwedzkiego, polskiego czy też rosyjskiego – wyższą klasę społeczeństwa stanowili tam wciąż Niemcy, obejmowali oni też często najważniejsze urzędy w administracji, a miasta w tych krajach wciąż miały niemiecki charakter. Jeden z polskich studentów, Bolesław Limanowski, w swych "Pamiętnikach" (1835–1870) opisuje, będące już pod rosyjskim panowaniem, miasto Tartu w Estonii: „Tartu miało charakter zupełnie niemieckiego miasta. Język niemiecki panował wszędzie: w urzędach, na katedrach uniwersyteckich, w sklepach, na ulicy. Właściwe miasto było z prawej strony Embachu. Miało ono piękny staroniemiecki wygląd, zwłaszcza główna ulica Ritterstrasse (Rycerska) przedstawiała się wspaniale. Lecz największą ozdobą było wzgórze piętrzące się nad miastem i porosłe bujnym lasem, tak zwane Domberg, od dawnej katedry katolickiej, w której ongiś kazał Piotr Skarga”. Kultura niemiecka silnie oddziaływała na, skupione głównie na wsiach, ludy fińskie, czyli przodków obecnych Estończyków oraz ludy bałtyckie – przodków obecnych Łotyszy. Kultura niemiecka wciąż obecna jest w wielu aspektach kulturowych dzisiejszych Estończyków i Łotyszy.
Geografia.
W skład Estonii wchodzi 2355 wysp i wysepek w Zatoce Ryskiej (największe Sarema i Hiuma) o łącznej powierzchni 4,2 tys. km² (9,2% powierzchni kraju). Zachodnie wybrzeże silnie rozczłonkowane, niskie, północne – wysokie i strome. Większość obszaru stanowią tereny nizinne (średnia wysokość 50 m) z najwyższym wzniesieniem Suur Munamägi, sięgającym 318 m n.p.m. Rzeźba polodowcowa (moreny, drumliny, ozy, jeziora). W północno-wschodniej części wysoczyzna Pandivere (wys. do 166 m), na południu i południowym wschodzie wzniesienia Sakala, Otepää i Haanja (do 318 m). Klimat umiarkowany, przejściowy między morskim i kontynentalnym. Średnia temperatura w najchłodniejszym miesiącu (w lutym) wynosi od –7 °C na wschodzie, do –3 °C na zachodnich wyspach, w lipcu 16–17 °C. Suma roczna opadów 500–700 mm, maksimum od lipca do września. Gęsta sieć rzeczna, zwłaszcza w południowej części, główne rzeki: Narwa, Ema, Parnawa; ponad 1000 jezior (ok. 5% powierzchni kraju), największe Pejpus (graniczne z Rosją). Estonia leży w strefie lasów mieszanych. Na ubogich glebach piaszczystych rosną bory sosnowe (z sosną zwyczajną), na glebach bardziej żyznych lasy świerkowe (ze świerkiem pospolitym), niekiedy ze znacznym udziałem dębu szypułkowego i innych drzew liściastych. Lasy zajmują ok. 38,5% powierzchni kraju, torfowiska (przeważnie wysokie) i tereny podmokłe – 20%. Na wschód od Tallinna (na wybrzeżu Zatoki Fińskiej) Park Narodowy Lahemaa. Zgodnie z ostatnimi badaniami powierzchnia Estonii wzrosła o 112 km². Najdłuższą rzeką Estonii jest Võhandu.
"Zobacz też: rzeki Estonii, Jeziora Estonii"
Ustrój polityczny.
Estonia jest republiką wielopartyjną. Ustrój polityczny kraju ukształtowała konstytucja z 1992 roku. Kładzie ona szczególny nacisk na dominację jednoizbowego parlamentu, który nazywa się Riigikogu. Jest on ciałem legislacyjnym, wybieranym w 5-przymiotnikowych wyborach (proporcjonalnych) na 4 lata z 5% progiem wyborczym dla partii. W parlamencie zasiada 101 deputowanych. Najważniejszymi zadaniami parlamentu, oprócz stanowienia prawa, są:
Mimo że prezydent posiada prawo weta wobec ustaw parlamentu, jego kompetencje ograniczają się do reprezentowania państwa i wskazania premiera po wyborach, których termin także on wyznacza.
Głównym organem wykonawczym polityki państwa jest rząd, odpowiedzialny przed parlamentem. Parlament kontroluje go nie tylko przez votum zaufania/nieufności, ale także przez interpelacje i zapytania (tzw. godzina pytań do premiera w każdą środę).
Siły zbrojne.
Estonia dysponuje trzema rodzajami sił zbrojnych: wojskami lądowymi, marynarką wojenną oraz siłami powietrznymi. Uzbrojenie sił lądowych Estonii składało się w 2014 roku m.in. z: 272 opancerzonych pojazdów bojowych oraz 144 zestawów artylerii holowanej. Marynarka wojenna Estonii ("Eesti Merevägi") dysponowała w 2014 roku jedną fregatą oraz siedmioma okrętami obrony przeciwminowej. Estońskie siły powietrzne z kolei posiadały w 2014 roku uzbrojenie w postaci m.in. dwóch samolotów szkolno-bojowych oraz czterech śmigłowców.
Wojska estońskie w 2014 roku liczyły 3,2 tys. żołnierzy zawodowych oraz 60 tys. rezerwistów. Według rankingu "Global Firepower" (2014) estońskie siły zbrojne stanowią 96. siłę militarną na świecie, z rocznym budżetem na cele obronne w wysokości 335 mln dolarów (USD).
Podział administracyjny.
Estonia jest podzielona na 15 prowincji (est. maakonnad; lp. – maakond; ‘powiat’). Prowincje z kolei dzielą się w sumie na 227 gmin dwóch rodzajów: 33 miejskie ("linn") i 194 wiejskie ("vald").
Demografia.
Liczba ludności Estonii na koniec 2018 roku wyniosła 1 323 820 osób, o 4690 osób więcej niż na koniec 2017. Zmiana ta wynika przede wszystkim z migracji. W 2018 roku do Estonii przyjechało 13030 osób, a wyjechało 6940. Wzrosła również liczba urodzeń dzieci do około 14 270, o około 500 więcej niż w poprzednim roku.
Estończycy stanowią 68,6% ludności (spis z 2006 r.), Rosjanie 25,6% (głównie w Tallinnie, Kohtla-Jarve i Narwie), Ukraińcy 2,1%, Białorusini 1,3%, Finowie 0,9%; pozostali to głównie Tatarzy, Łotysze, Żydzi, Polacy i Litwini. Od początków lat 90. spadek liczby ludności. Przyrost naturalny od 1991 ujemny (–5,3‰ w 1995 i –4,1‰ w 1997). Wskaźnik urodzeń 8,7‰ (1997); w wieku do 14 lat 19% populacji, 65 lat i więcej 14%. Ludność miejska 69% (1997). Gęstość zaludnienia 29,4 osób na km² (największa w północnej części, między Tallinnem a Narwą). Główne miasta poza stolicą: Tartu, Narwa, Kohtla-Järve, Parnawa.
Struktura etniczna.
Po zajęciu Estonii przez ZSRR, do tego kraju przesiedlono wielu Rosjan i innych Słowian stanowiących dziś ponad 28% mieszkańców kraju, ludzie ci w dużej części nie znają języka estońskiego, dlatego nie mogą zdać egzaminu przyznającego obywatelstwo estońskie. Po odzyskaniu niepodległości Estonii obywatelstwo estońskie nie zostało przyznane przywiezionym za ZSRR Rosjanom i ich potomkom, muszą oni ubiegać się o nie tak jak obcokrajowcy.
"Narodowości według spisu z 2000 roku:"
Polacy w Estonii.
Emigracja polska do Estonii w latach 30. XX w. liczyła ok. 1 tys. osób. Polacy skupieni byli głównie w Tallinnie, Narwie i Tartu. Byli to głównie rzemieślnicy i robotnicy. Pierwsze polskie organizacje w Estonii to: założony w 1929 roku Związek Narodowy Polski "Jutrzenka" w Tartu i założony w 1930 Związek Narodowy Polaków w Estonii w Tallinnie (1937 – 340 członków). Rozwijano działalność kulturalno-oświatową (chóry, biblioteki, teatry amatorskie i kółka samokształceniowe języka polskiego, historii i geografii).
W 1934 utworzono w Tallinnie pierwszą polską drużynę harcerską. W 1937–1939 w Estonii pracowało sezonowo około 4 tysięcy robotników rolnych, głównie z województwa wileńskiego i nowogrodzkiego. Część pozostała na stałe. W 1939 liczbę Polaków w Estonii szacowano na 1,5 tys. osób. W latach 1940–1941 i 1944–1945 miały miejsce prześladowania ludności polskiej przez NKWD (m.in. deportacje na Syberię). W 2016 roku Estonię zamieszkiwało 1747 Polaków.
Cyberpaństwo.
Estonia jest jednym z najbardziej zinformatyzowanych państw świata, w którym 99% usług publicznych administracji dokonywana jest on-line, zaś 67% społeczeństwa używa elektronicznych identyfikatorów. W 2019 roku 43,8% wyborców w wyborach do krajowego parlamentu oddało swój głos używając do tego celu internetu, w tym samym roku 46,7% wyborców oddało on-line swój głos w wyborach do Parlamentu Europejskiego.
Wysoki stopień informatyzacji państwa i społeczeństwa spowodował, że w roku 2007 – po usunięciu brązowego pomnika żołnierza radzieckiego w Tallinie – Estonia stała się celem pochodzącego z zagranicy największego w historii ataku cybernetycznego na infrastrukturę informatyczną rządu, większości krajowych mediów oraz banków, który spowodował paraliż państwa w znacznej jego części. Po tych atakach, w ramach NATO rozpoczęto prace nad włączeniem cyberprzestrzeni do domen operacyjnych Sojuszu Północnoatlantyckiego – obok domeny morskiej, lądowej i powietrznej. Będące ich następstwem zmiany prawa międzynarodowego doprowadziły do zmian doktryn obronnych sojuszu, który zrównał atak cybernetyczny na państwo członkowskie sojuszu z atakami na nie w którejkolwiek z pozostałych domen, zaś podczas szczytu NATO w Brukseli w 2018 roku, postanowiono o utworzeniu w Estonii Centrum Operacji w Cyberprzestrzeni NATO ("NATO Cyberspace Operations Centre"), wchodzącego w skład struktury dowodzenia NATO.
W wyniku podjętych przez władze kraju i społeczeństwo estońskie po atakach cybernetycznych z 2007 roku działań, Estonia uważana jest dziś za jedno z 5 najlepiej zabezpieczonych przed atakami cybernetycznymi państw świata.
Religia.
Estonia jest krajem silnie zlaicyzowanym, wyznaniem tradycyjnym jest luteranizm. Struktura religijna kraju w 2010 roku według "Pew Research Center":
Język.
Oficjalnym językiem kraju jest język estoński, należący do grupy języków ugrofińskich. Estoński jest bardzo blisko spokrewniony z językiem fińskim.
Język estoński posiada także bardzo silne wpływy germańskie (głównie z niemieckiego i szwedzkiego), około 30% wszystkich słów pochodzi z tych języków, w tym najwięcej z dolnosaksońskiej odmiany języka niemieckiego. Spowodowane jest to wielowiekową, niemiecką, szwedzką i duńską dominacją, osadnictwem i panowaniem na terenie Estonii.
Podczas ery radzieckiej język rosyjski był obowiązkowo nauczany w szkołach i stąd powszechna jego znajomość, nie tylko wśród etnicznych Rosjan, ale również wśród starszych, 30-70-letnich Estończyków. Historia Estonii sprawia jednak, że nawet znający język rosyjski Estończycy nie chcą go używać i w praktyce wolą porozumiewać się w dowolny inny sposób, przy pomocy kilku znanych słów angielskich lub na migi. Współcześnie w szkołach, jako pierwszy obcy język wykładany jest raczej angielski, który jest stosunkowo powszechnie znany wśród młodych ludzi.
"Języki, według spisu z 2000 roku:"
"Analfabetyzm, dane szacunkowe na rok 2003:"
Gospodarka.
Estonia jest jednym z najlepiej rozwiniętych gospodarczo państw dawnego bloku wschodniego oraz Estonia razem z Litwą jest jedną z najbogatszych republik dawnego Związku Radzieckiego.
W 2015 r. Estonia była 25. gospodarką Unii Europejskiej pod względem wielkości PKB w parytecie siły nabywczej i 108. gospodarką świata, a pod względem wielkości PKB nominalnego – 26. gospodarką UE i 102. gospodarką świata.
W 2015 r. PKB per capita w parytecie siły nabywczej Estonii wyniósł 21 400 PPS (74,6% średniej UE), a PKB per capita nominalny – 15 580 euro (54,2% średniej UE).
Estonia jest krajem przemysłowo-rolniczym. Do 1991 wchodziła w skład nadbałtyckiego regionu ekonomicznego ZSRR, silnie uzależniona od importu surowców i paliw. Reforma systemu gospodarczego została zapoczątkowana przed uzyskaniem niepodległości. Estonia jako pierwsze z państw powstałych po rozpadzie ZSRR opuściła w 1992 strefę rublową. Obecnie dynamicznie rozwijający się kraj (średniorocznie 9–12%), gospodarka oparta o usługi (69%). Przemysł to 28% PKB, a rolnictwo 4%.
Duża komputeryzacja państwa. Znaczne pozyskanie torfu. Silnie rozwinięty przemysł maszynowy, elektroniczny, drzewny i meblarski, chemiczny i spożywczy. Głównym ośrodkiem jest stolica Tallinn. Produkcja energii 8,8 TWh, piwa 95 mln litrów. Uprawa głównie jęczmienia, pszenicy, ziemniaków i żyta, w hodowli większe znaczenie ma trzoda i bydło mięsne. Pomyślnie rozwija się rybołówstwo – 104 tys. ton ryb.
Port morski w Tallinnie należy do większych na Bałtyku. Sieć drogowa liczy 28 tys. km, a jej uzupełnieniem jest 958 km kolei (2005 r.). Coraz większe znaczenie ma turystyka (dochody przekraczają pół miliarda dolarów). Eksport 9,65 mld dolarów (2006 rok), import 12,61 mld (2006)dolarów. Wartość PKB w 2004 roku wyniosła 7,2 mld euro, czyli 5,4 tys. na mieszkańca.
Bezrobocie: średnio 2% (2007 r.) (regiony zamieszkane przez Rosjan 10%).
Rolnictwo.
Użytki rolne zajmują 32% powierzchni kraju (2000). Zbiory zbóż (jęczmień, owies, pszenica) 643 tys. t (1996), rośliny pastewne (gł. wieloletnie trawy), ziemniaki (0,6 mln t), len, w strefach podmiejskich – warzywa. Intensywna hodowla bydła mleczno-mięsnego (758 tys. sztuk – 1990), trzody chlewnej typu mięsnego (1 mln), owiec, kóz, drobiu. Rybołówstwo morskie, głównie porty rybackie: Tallinn, Parnawa, Haapsalu i Kuressaare.
Turystyka.
W 2015 roku kraj ten odwiedziło 2,763 mln turystów (5,3% mniej niż w roku poprzednim), generując dla niego przychody na poziomie 1,5 mld dolarów. Głównym celem turystycznym jest Tallinn ze Starym Miastem, wpisanym na listę światowego dziedzictwa UNESCO.
Według danych za 2018 rok, najwięcej turystów pochodziło z Finlandii, Rosji, Łotwy, Niemiec i Szwecji.

</doc>
<doc id="1347" url="https://pl.wikipedia.org/wiki?curid=1347" title="Euro">
Euro

Euro (znak: €, kod ISO 4217: EUR; bułg. "евро", trb. "ewro"; gr. "ευρώ"; łot. "eiro"; lit. "euras"; malt. "ewro"; słoweń. "evro"; węg. "euró") – nazwa waluty wprowadzonej w większości państw Unii Europejskiej, a także innych, w miejsce walut krajowych. W formie gotówkowej walutę euro wprowadzono do obiegu dnia 1 stycznia 2002 roku.
Euro jest prawnym środkiem płatniczym w 20 państwach tworzących w Unii Europejskiej strefę euro a obejmującą swym obszarem około 341 mln Europejczyków.
Waluta euro używana jest także w 11 krajach i terytoriach nienależących do UE. W Watykanie, Monako, San Marino i Andorze przed wprowadzeniem euro do transakcji gotówkowych obowiązywały waluty krajów unijnych, z którymi sąsiadują. Pragmatyzm nakazywał, by i u nich obowiązywało euro. W częściowo uznawanym państwie Kosowo i w Czarnogórze, które uzyskały niepodległość dużo później niż wejście w życie euro i zdecydowały się nie tworzyć własnych walut, lecz wybrać jedną z najbardziej znaczących na świecie. Euro obowiązuje też w odległych od Europy francuskich posiadłościach na Oceanie Atlantyckim i Indyjskim oraz w brytyjskich bazach wojskowych na Cyprze.
Strefa euro (eurostrefa, euroland, obszar euro) jest tworzącą unię walutową wspólną przestrzenią unijnych państw, które wprowadziły euro jako swoją walutę, gdzie Europejski Bank Centralny prowadzi niezależną politykę pieniężną.
Przy kwocie w obiegu wynoszącej ponad 751 miliardów euro jest walutą o najwyższej wartości gotówkowej w świecie. Na euro przypada 27% światowych rezerw walutowych.
Wygląd.
Monety euro.
Wszystkie monety mają identyczne rewersy (strona wspólna) z nominałem i mapą Europy. Awersy (strona narodowa) zawierają symbole narodowe (przeważnie nieoficjalne) ustalone przez poszczególne kraje strefy euro. Wyjątkiem są Kosowo i Czarnogóra, które jednostronnie ogłosiły euro swoją walutą. Wszystkie monety są tak samo ważnym środkiem płatniczym bez względu na to, co przedstawiają i gdzie są wydawane.
Banknoty euro.
Wszystkie nominały, w przeciwieństwie do monet, są identyczne po obu stronach. Pod nazwą waluty zapisaną alfabetem łacińskim jest także nazwa zapisana alfabetem greckim oraz cyrylicą (monety: tylko łaciński). Banknoty wyróżniają się na tle prawie wszystkich innych walut świata tym, że nie zawierają twarzy ludzi uznanych przez państwo za wybitne. Awers zawiera bramę lub okna typowe dla danej epoki w architekturze, ujęte w taki sposób, aby nie było wiadomo, na których konkretnie budowlach są wzorowane. Każdy rewers zawiera most odpowiedni do czasów reprezentowanych przez awers oraz mapę Europy:
Utworzenie waluty.
Pierwsze plany utworzenia unii walutowej pojawiły się już w latach 60. XX wieku, lecz dopiero w latach 70. opracowano plan wprowadzenia wspólnej waluty, a w 1979 roku powstał europejski system walutowy. W 1986 ECU zostało trzecią walutą na świecie, w której emitowano obligacje międzynarodowe.
Genezy euro jako jednolitej waluty Unii Europejskiej należy szukać w historii Unii Europejskiej oraz w historii światowej gospodarki. Z jednej strony, w 1968 roku nastąpiła realna integracja gospodarcza w postaci unii celnej, z drugiej strony upadek systemu kursu walutowego doprowadził do zbyt mocno zmieniających się kursów walut, który w opinii polityków osłabiał handel.
W 1970 roku po raz pierwszy została skonkretyzowana idea europejskiej unii walutowej. W tak zwanym planie Wernera, luksemburski premier Pierre Werner wypracował wraz z ekspertami Unii Gospodarczej i Walutowej, ideę jednolitej waluty. Projekt ten poniósł fiasko z powodu upadku systemu z Bretton Woods.
Ostateczna decyzja o utworzeniu wspólnej waluty Unii Europejskiej zapadła w ramach traktatu z Maastricht, który powoływał do życia unię gospodarczą i walutową.
W grudniu 1995 w Madrycie wspólnej walucie nadano nazwę euro. Ustanowiono też system TARGET – system automatycznych przeliczeń walut narodowych na euro.
1 stycznia 1999 nastąpiła inauguracja euro w transakcjach bezgotówkowych w 11 krajach&lt;ref name="2866/98-1998"&gt;&lt;/ref&gt; (bez Grecji), a od 1 stycznia 2002 wprowadzono tę walutę w formie gotówkowej w dwunastu państwach UE (oprócz Wielkiej Brytanii, Szwecji i Danii). 1 lipca 2002 ostatecznie wycofano z obiegu waluty narodowe 12 państw, które przystąpiły do strefy euro.
Rozszerzenie strefy euro nastąpiło do tej pory siedmiokrotnie: 1 stycznia 2007 przez euro został zastąpiony tolar słoweński, 1 stycznia 2008 funt cypryjski i lira maltańska, 1 stycznia 2009 korona słowacka, 1 stycznia 2011 korona estońska, 1 stycznia 2014 łat łotewski, 1 stycznia 2015 lit litewski, a 1 stycznia 2023 kuna chorwacka. 
Sztywne kursy wymiany mają Bułgaria, Bośnia i Hercegowina, Komory i Republika Zielonego Przylądka. Waluta Danii należy do mechanizmu kursów walutowych ERM II.
Kryteria konwergencji.
Kryteria konwergencji czy też zbieżności można podzielić na dwie grupy: kryteria monetarne (inflacja, długookresowe stopy procentowe oraz kursy walutowe), oraz fiskalne (deficyt budżetowy, dług publiczny).
Aby wejść do strefy euro, należy spełnić kryteria konwergencji takie jak:
Strefa euro.
Obecnie członkami unii gospodarczej i walutowej jest 20 z 27 państw członkowskich Unii Europejskiej (Austria, Belgia, Chorwacja, Cypr, Estonia, Finlandia, Francja, Grecja, Hiszpania, Holandia, Irlandia, Litwa, Luksemburg, Łotwa, Malta, Niemcy, Portugalia, Słowacja, Słowenia, Włochy), a ponadto 4 inne państwa (Andora, Monako, San Marino, Watykan). Z kolei w Czarnogórze i na terytorium Kosowa – euro jest walutą bez członkostwa w unii gospodarczej i walutowej.
Wymiana walut narodowych na euro.
W roku 2002.
Początkowo waluta ta była tylko międzybankową walutą rozliczeniową i nie znajdowała się w normalnym obiegu. W dniu 1 stycznia 2002 roku nastąpiło zastąpienie walut państw członkowskich strefy euro monetami i banknotami euro, co było największą przeprowadzoną na świecie jednorazową operacją walutową. Cała akcja wymiany walut zakończyła się 1 lipca 2002 roku, kiedy to waluty narodowe państw strefy euro zostały całkowicie wycofane. Kursy między walutami narodowymi, które miało zastąpić euro, zostały zamrożone 1 stycznia 1999 roku.
1 stycznia 2002 roku ustanowiono strefę euro. Kurs wymiany za 1 €:
Wymianie uległo 4,5 biliona euro w gotówce oraz przeliczono waluty narodowe na ponad 10 bilionów euro na kontach bankowych na całym świecie.
Mechanizm ERM II.
Mechanizm kursów walutowych (ERM II) został wprowadzony przez Wspólnotę Europejską w 1979, jako część Europejskiego Systemu Walutowego, w celu redukcji wahań kursowych walut państw członkowskich Unii Europejskiej. Mechanizm ten oparty jest na powiązaniu i usztywnieniu kursów wymiany walut państw członkowskich. Do mechanizmu kursów walutowych (ERM II) od 1 stycznia 1999 r. należy Dania, a od 10 lipca 2020 r. Bułgaria
Emisja euro.
Banknoty euro są drukowane pod bezpośrednią kontrolą Europejskiego Banku Centralnego (w 14 różnych drukarniach) i mają jednolity wygląd we wszystkich państwach strefy euro.
Monety są produkowane przez mennice poszczególnych państw. Monety mają jednakowy kształt, jednakowy materiał i jednakowy wygląd rewersu (wspólna strona).
Awersy (strona narodowa) natomiast są inne w każdym z państw, które decydują, jakie symbole są tam zamieszczone (przy czym monety euro bez względu na stronę narodową są prawnym środkiem płatniczym na terenie całej strefy euro). Oznacza to, że sklepy czy banki na terenie danego kraju nie mają prawa do odmowy przyjęcia monet wybitych w innych krajach. Istnieją także srebrne monety 10 €, które są wprawdzie prawnym środkiem płatniczym, ale ze względu na ich wartość kolekcjonerską raczej nie są spotykane w sklepach.
Dystrybucją banknotów i monet zajmują się poszczególne banki centralne państw strefy euro pod ścisłą kontrolą Europejskiego Banku Centralnego.
Euro w Polsce.
Po wejściu do Unii Europejskiej w 2004 r., według pierwotnych planów Ministerstwa Finansów Polska miała być gotowa do wejścia do strefy euro w 2009 roku. Obecnie nieznana jest data planowanego wejścia złotego do mechanizmu kursów walutowych ERM II oraz wprowadzenia euro w Polsce.
W 2011 roku, a więc 2 lata po niespełnionym, planowanym terminie wycofania złotego, według sondaży większość Polaków była przeciwna zmianie waluty.
Na mocy § 11 rozporządzenia Ministra Finansów z dnia 4 września 2007 roku w sprawie ogólnych zezwoleń dewizowych również w Polsce można używać euro do rozliczeń, w których jedną stroną jest konsument i odbiorca usług (np. w sklepie, u fryzjera).
Po wygranych wyborach parlamentarnych w 2007 Platforma Obywatelska zapowiedziała, że Polska będzie starać się jak najszybciej spełnić kryteria spójności, aby wejść do strefy euro już w 2012 lub 2013 roku. W późniejszych wypowiedziach Prezes Rady Ministrów Donald Tusk zapowiedział, że Polska wejdzie do strefy euro już w 2011 roku. Wcześniej premier zapowiedział, że nie odbędzie się referendum w sprawie wejścia Polski do strefy euro. 16 września 2008 roku premier Tusk wspólnie z RPP i NBP potwierdzili zamiar spełnienia w 2011 roku przez Polskę kryteriów wejścia Polski do strefy euro. Pod koniec 2008 roku premier potwierdził, że referendum dotyczącego wprowadzenia euro w Polsce nie będzie. Warto jednak zauważyć, iż Rzeczpospolita Polska zobowiązała się w traktacie akcesyjnym do przyjęcia euro, nie określając jednakże, kiedy ma to nastąpić.
Do zamiany złotego na euro niezbędna jest zmiana uprawnień NBP określonych w Konstytucji Rzeczypospolitej Polskiej. Od strony produkcyjnej Polska jest przygotowana do decyzji o przyjęciu euro. Polska Wytwórnia Papierów Wartościowych od 2006 roku znajduje się wśród 15 akredytowanych przez Europejski Bank Centralny podmiotów, które mogą drukować euro.
W lutym 2009 NBP opublikował raport, w którym zaproponował opóźnienie przyjęcia euro ze względu na wahania kursu złotego podczas kryzysu finansowego. Rząd nie zmienił harmonogramu wstąpienia do strefy euro w 2012 roku.
W marcu 2009 pojawiły się ekspertyzy mówiące o braku konieczności zmiany Konstytucji RP (w tym artykułu 227) przy wprowadzaniu euro. Część konstytucjonalistów uważa, że zmiana ustawy zasadniczej jest tylko dostosowaniem polskich przepisów wewnętrznych do obowiązującego już prawa wspólnotowego. Powołują się na wyższość prawa unijnego nad polską konstytucją, co stoi jednak w sprzeczności z wykładnią Trybunału Konstytucyjnego, zawartą w sentencji wyroku o zgodności traktatu akcesyjnego z Konstytucją RP. Trybunał stanął wówczas na stanowisku, iż zasada pierwszeństwa prawa wspólnotowego dotyczy ustaw, nie zaś samej Konstytucji. Planom wprowadzenia euro bez zmiany Konstytucji sprzeciwia się PiS.
Rządzący w Polsce w latach 2015–2017 rząd Beaty Szydło podchodził do kwestii wejścia Polski do strefy euro bez entuzjazmu. Konrad Szymański, wiceminister spraw zagranicznych, pytany w 2017 o perspektywę wejścia Polski do strefy euro przed rokiem 2025, odpowiedział, że określenie polskiego stanowiska zależy od rozwiązania wewnętrznych problemów w eurolandzie.
Euro a inne kraje.
Pojawiające się natomiast na rynku numizmatycznym tak zwane próbne monety euro z Danii, Szwecji, Wielkiej Brytanii, Polski (istnieją nawet dwa warianty – bite na Słowacji na zlecenie polskich kupców numizmatycznych oraz w Wielkiej Brytanii na zlecenie firmy zagranicznej) i innych krajów wstępujących do Unii Europejskiej są produktem prywatnym, od których banki emisyjne (w tym Narodowy Bank Polski) zdecydowanie się odcinają; nie przeszkadza to jednak w handlu tymi monetami po dosyć wygórowanych cenach. Istnieją nawet „próbne monety euro” ze Szwajcarii, która do Unii nie należy, a nawet Szkocji i Padanii.
Euro jest też oficjalną walutą w Andorze, Czarnogórze i Kosowie. Zależny od euro jest także kurs marki transferowej, oficjalnej waluty Bośni i Hercegowiny (stały przelicznik 1 EUR = 1,95583 MK).
Począwszy od 2007 roku, euro stało się oficjalnym środkiem płatniczym w Słowenii, w 2008 na Cyprze i Malcie, w 2009 na Słowacji, w 2011 w Estonii, w 2014 na Łotwie, w 2015 na Litwie i w 2023 w Chorwacji.
Euro jest również środkiem płatniczym w większości terytoriów zamorskich Francji, między innymi na położonym przy kanadyjskim wybrzeżu St-Pierre-et-Miquelon w Ameryce Północnej oraz Gujanie Francuskiej w Ameryce Południowej. Natomiast francuskie terytoria zależne na Oceanie Spokojnym mają sztywno powiązany kurs waluty (franka CFP) z euro.
Bułgaria.
Po wejściu do Unii Europejskiej w 2007 r. Bułgaria miała problemy z inflacją. Z tego powodu szybkie przyjęcie nowej waluty było niemożliwe. Jednak od 2012 r. Bułgaria spełnia większość kryteriów konwergencji. Waluta Bułgarii jest sztywno powiązana z euro (kurs: 1 euro = 1,95583 BGN). W dniu 10 lipca 2020 r. bułgarska lewa została wprowadzona do mechanizmu ERM II. Przyjęcie waluty euro jest planowane na rok 2024.
Czechy.
Po wejściu do Unii Europejskiej w 2004 r. Czechy pierwotnie chciały wprowadzić euro w 2010 roku. Piętrzyły się głosy, by z powodu problemów gospodarczych wspólną walutę wprowadzić w późniejszym terminie. Prezes Krajowego Banku Republiki Czeskiej Zdeněk Tůma w jednym z wywiadów wspomniał rok 2019 jako możliwy termin wprowadzenia euro. Były premier Czech, Petr Nečas, powiedział, że nie planuje przystąpienia do strefy euro podczas jego rządów, które w związku ze skandalem korupcyjnym zakończyły się jego rezygnacją w 2013 roku.
Dania.
Dania jest unijnym państwem zwolnionym na mocy traktatu z Maastricht z obowiązku wprowadzenia u siebie waluty euro. W roku 2000 odbyło się dodatkowo referendum, w którym 53,2% społeczeństwa duńskiego odrzuciło pomysł wprowadzenia euro. W badaniu opiniotwórczego ekonomicznego pisma Børsen portalu z kwietnia 2010 roku wykazano, że 52% Duńczyków jest za wprowadzeniem europejskiej waluty, podczas gdy 41% przeciwko. Kolejne referendum było planowane na rok 2011, ale nie zostało przeprowadzone. Od początku istnienia strefy euro korona duńska funkcjonuje w ERM II w paśmie wahań ograniczonym do 2,25%.
Rumunia.
Rumunia jest państwem członkowskim UE od 2007 roku i podobnie jak Bułgaria ma problemy z dużą stopą inflacyjną. Narodowy Bank Rumunii (BNR) obrał 2015 jako rok docelowy dla wprowadzenia euro. Oficjalne założenia polityki pieniężnej (podpisane w 2010 roku przez ministra finansów publicznych i ministra sprawiedliwości) zakładały wejście Rumunii do strefy euro w dniu 1 stycznia 2015 roku. Jesienią 2011 roku władze kraju potwierdziły ten zamiar. W 2014 Rumunia oficjalnie ogłosiła, że dąży do wprowadzenia u siebie euro w 2019 roku. W roku 2018 rząd Rumunii ogłosił, iż akcesja do strefy Euro może nastąpić w roku 2024, jednak na początku roku 2021 w związku ze skutkami gospodarczymi spowodowanymi pandemią koronawirusa zostało ogłoszenie przeniesienie tego momentu na lata 2027–2028.
Szwecja.
Szwecja, która jest członkiem Unii Europejskiej od 1995 r., przeprowadziła 14 września 2003 roku referendum, w którym jej obywatele nie poparli wprowadzenia euro. Ponieważ Szwecja zadeklarowała w porozumieniu akcesyjnym, że warunkiem do wprowadzenia waluty jest spełnienie kryteriów konwergencji, przyjęcie nowej waluty zostało utrudnione przez nieprzystąpienie do mechanizmu zmiany kursu. Kolejne referendum miało się odbyć około 2013 roku. Minister finansów wyraził swoje poparcie dla wprowadzenia waluty euro w Szwecji.
Węgry.
Po wejściu do Unii Europejskiej w 2004 r. Węgry zamierzały wprowadzić euro już w 2010 roku, jednak z powodu ciągłego wysokiego deficytu krajowego cel ten okazał się nieosiągalny. Później Węgry w związku z nowym zadłużeniem w wysokości 10% PKB miały najwyższe zadłużenie wśród wszystkich krajów wspólnoty.
Negatywne konsekwencje wprowadzenia euro.
Euro jako unia walutowa oznacza pozbawienie się przez państwa członkowskie wpływu na gospodarkę poprzez zmiany kursu walutowego i stóp procentowych. Instrumenty te są stosowane, gdy państwa tracą konkurencyjność międzynarodową, gdy ceny, w tym płace, stają się zbyt wysokie w stosunku do produktywności firm produkujących dobra eksportowalne. Wtedy dobra te zostają wypychane z rynku krajowego i międzynarodowego. Powoduje to spadek produkcji i zatrudnienia w firmach produkujących te dobra oraz pogorszenie bilansu handlowego i deficytu na rachunku obrotów bieżących. Spadek produkcji i zatrudnienia w firmach produkujących dobra eksportowalne może być równoważony wzrostem w sektorach ich nieprodukujących szczególnie w budownictwie i w usługach. Zwiększone zakupy za granicą i deficyt na rachunku obrotów bieżących są finansowane bez problemu kredytem dopóki jest on tani.
Państwa odzyskują konkurencyjność międzynarodową przez obniżenie cen dóbr eksportowalnych poprzez obniżenie kursu waluty krajowej albo poprzez obniżenie cen, w tym płac, w kraju (deflacja). W przypadku płynnego kursu waluty zmiana bilansu płatniczego zmienia kurs walutowy, co zmienia wartość dóbr krajowych na rynku międzynarodowym z dnia na dzień, automatycznie i powszechnie. W przypadku sztywnego kursu waluty krajowej do waluty partnerów gospodarczych, jak w przypadku euro, pozostaje jedynie deflacja, która wymaga milionów decyzji, w tym zmiany umów. W przypadku spadku sprzedaży firmy raczej zwalniają część pracowników, a nie obniżają płace, także dlatego, że lepiej wykwalifikowani pracownicy mogą zmienić pracę. Raczej nie występują sytuację w których w firmach nie zagrożonych upadkiem pracownicy godzą się na obniżkę płac, aby zwiększyć zatrudnienie i sprzedaż. Odzyskiwanie konkurencyjności poprzez deflację jest procesem długotrwałym i powoduje wyższe bezrobocie i większy spadek PKB. I tak PKB w 2014 osiągnął 74% PKB z 2007 (ostatniego roku przed kryzysem) w Grecji, 91% we Włoszech, 93% w Portugalii i 94% w Hiszpanii, 105% w Niemczech, 107% w USA i 123% w Polsce.
, a za nim Stefan Kawalec i Ernest Pytlarczyk porównują kryzys w strefie euro do wielkiego kryzysu, a samo euro do wymienialności walut na złoto (standard złota), która pogłębiła i przedłużyła kryzys, a kraje, które przeprowadziły dewaluację waluty, poradziły sobie znacznie lepiej. W przypadku waluty wymienialnej na złoto i wystąpienia deficytu handlowego niezrównoważonego napływem kapitału z zagranicy następował odpływ złota z rezerw banku centralnego. Aby zapobiec utracie rezerw, bank centralny podnosił stopę procentową, co powodowało obniżenie podaży kredytu. W rezultacie po wybuchu wielkiego kryzysu państwa, które zdewaluowały swoje waluty w 1931, miały wyraźnie wyższą produkcję przemysłową w 1934 niż w 1929 – w ostatnim roku przed kryzysem. Państwa złotego bloku miały produkcję przemysłową niższą o 22% niż przed kryzysem. W 1936 różnica ta wynosiła 41 punktów procentowych: odpowiednio 127% poziomu z 1929 w krajach po dewaluacji w 1931 i 86% w krajach złotego bloku. Państwa, które porzuciły wymienialność na złoto, mogły prowadzić ekspansywną politykę monetarną i fiskalną, w sytuacji kryzysu bez niebezpieczeństwa inflacji, zwiększający popyt krajowy uruchamiający niewykorzystywane w kryzysie moce produkcyjne.
Także w przypadku prowadzenia właściwej polityki euro utrudnia odzyskanie konkurencyjności, jak w przypadku Finlandii, która w 2016 miała PKB o 3% niższy niż w 2007, mimo że według Kawalca mogła uchodzić za wzór: zadłużenie przed kryzysem na poziomie niewiele ponad 30% PKB, znakomity system edukacji i miejsce w czołówce rankingu konkurencyjności.
Według Kawalca i Pytlarczyka nie ma możliwości wprowadzenia instrumentów gospodarczych zastępujących osłabienie waluty narodowej, więc należy rozwiązać strefę euro poprzez wychodzenie krajów najbardziej konkurencyjnych. Występowanie krajów w kryzysie grozi wybuchem paniki bankowej. Według nich jeśli rozwiązania strefy euro nie dokonają prorynkowi i proeuropejscy przywódcy to mogą tego dokonać ich antyrynkowi i antyeuropejscy następcy razem ze zniszczeniem Unii Europejskiej.
Według Josepha Stiglitza strefa euro nie posiada, w 2016, nowych mechanizmów gwarantujących, że każde państwo będzie rozwijało się w odpowiednim tempie. Wymaga to pogłębienia integracji politycznej i gospodarczej albo rozwiązania strefy euro. W przeciwnym wypadku długotrwałe kryzysy, jak kryzys zadłużenia w strefie euro będą się powtarzać. Według Stigliza sztywny wymóg utrzymywania deficytu budżetowego poniżej 3% PKB działa jak automatyczny destabilizator, gdy w wyniku kryzysu spadają dochody. W tej sytuacji cięcia wydatków prowadzą do dalszego spadku PKB.
Nominały euro i centów.
Nominały okolicznościowe i kolekcjonerskie.
Każdy kraj ma prawo do emisji dwóch monet okolicznościowych w roku. Są to zawsze monety o nominale 2 euro, mające te same cechy i właściwości oraz identyczną stronę wspólną jak zwykłe monety 2 euro. Wyróżniają się natomiast motywem okolicznościowym, umieszczonym na stronie narodowej.
Monety okolicznościowe są prawnym środkiem płatniczym w całej strefie euro, co oznacza, że można się nimi posługiwać – i trzeba je akceptować – na równi ze zwykłymi monetami obiegowymi. Najczęściej monety okolicznościowe emituje się dla upamiętnienia rocznic historycznych lub doniosłych wydarzeń bieżących. Pierwszą taką monetę wyemitowała Grecja z okazji igrzysk olimpijskich w Atenach w 2004.
Oprócz tego emitowane są kolekcjonerskie monety euro o nietypowych nominałach: 0,25, ¼, 1 ½, 2 ½, 3, 4, 5, 6, 7, 8, 12, 12 ½, 14, 15, 25, 30, 50, 100, 150, 200, 250, 300, 400, 500, 1000, 2000, 2500, 5000, 10000, 100000 euro. Różne są także stopy w jakich te monety są wykonywane: srebro prób 500/100, 800/1000, 900/1000, 950/1000, złoto prób: 900/1000, 917/1000, 920/1000, 985/1000 oraz inne stopy: bimetal + złoto 750/1000, bimetal + srebro 900/1000 + Niob 998/1000, stopy Cu75 Zn20 Ni5, oraz Cu Ni, bimetal i Nordic gold.
Również banknoty wydawane są w nietypowych nominałach. W 2015 we Francji ukazał się po raz pierwszy banknot o nominale zero euro. Później takie nominały wydały m.in. Francja, Niemcy i Portugalia. Banknoty te są wydawane oficjalnie za zgodą Europejskiego Banku Centralnego i są wydawane zwykle w niskich nakładach, 5–30 tys.
Oficjalnym, trzyliterowym kodem euro (według ISO) jest EUR.
Znak graficzny euro.
Komisja Europejska zadecydowała o kształcie symbolu euro. Znak graficzny euro jest grecką literą ε (epsilon) przeciętą dwiema równoległymi liniami. Symbolizuje ona korzenie cywilizacji europejskiej, próby zintegrowania kontynentu i zapewnienia stabilizacji wewnętrznej. Niektórzy dopatrują się również w symbolu euro wyzwania dla dolara amerykańskiego, dla którego charakterystyczną cechą są dwie pionowe linie, czy analogii do jena, którego symbol również posiada taki element.
Znak € na klawiaturze.
W systemach operacyjnych rodziny Microsoft Windows, na większości klawiatur komputerowych (w tym polskiej i innych środkowoeuropejskich), znak € można wpisać przy wciśniętych klawiszach lub przy włączonej klawiaturze numerycznej (), wpisując przy wciśniętym kolejno cyfry 0, 1, 2, 8 ( = €). Ta sama metoda działa w przypadku prawie wszystkich innych europejskich ustawień regionalnych (bałtycki, grecki, turecki i zachodnioeuropejski) oraz w przypadku ustawień arabskich i hebrajskiego, wyjątkiem są ustawienia regionalne używające cyrylicy – w tym wypadku należy wprowadzić cyfry 0, 1, 3, 6 ( = €). W przypadku klawiatury polskiej programisty (najpowszechniej używanej w Polsce) i niektórych innych układów klawiatury również wciśnięcie lewego lub prawego klawisza Alt (zwanego inaczej AltGr) i litery U da taki wynik ( = €), w innych kombinacją taką może być , albo (w obu ostatnich przypadkach chodzi o klawisze standardowo oznaczone 4/$ i 5/% na głównej klawiaturze, nie cyframi 4 i 5 na numerycznej). Obsługa euro w systemach Windows 95 i NT 4 uzależniona jest od instalacji poprawki systemowej.
W przypadku niektórych programów można wpisać ciąg 20AC, a następnie wcisnąć klawisze . 20AC to szesnastkowy numer pozycji, na której znak € umieszczony jest w unikodzie. Inne programy pozwalają wstawić znak ten kombinacją lewy Alt i 8364 (wpisanych z klawiatury numerycznej): = €. 8364 to dziesiętny numer pozycji, na której znak € umieszczony jest w unikodzie.
W systemie Mac OS X, stosując układ klawiatury polski programisty, znak ten można uzyskać kombinacją klawiszy Alt i cyfry 3 ( = €). W układzie polskim maszynisty odpowiadającą kombinacją klawiszy jest .
W systemie Linux znak € zazwyczaj można wpisać przy użyciu . Niemniej jednak może zdarzyć się, w zależności od dystrybucji, że będzie wymagana modyfikacja układu klawiatury. Można to zrobić, korzystając z ustawień układu klawiatury (ang. "keyboard layout") dostępnych w centrum ustawień. W tym celu, po uruchomieniu układu klawiatury, należy wskazać używany układ (domyślnie wybrany aktualnie używany), a następnie posłużyć się przyciskiem „Opcje”. Na sam koniec należy z listy rozwijanej „Dodawanie znaków walut do pewnych klawiszy” zaznaczyć preferowany skrót, przy czym zaleca się ustawienie „Euro pod 5” aby móc korzystać z kombinacji w celu użycia znaku €.
Zważywszy na fakt, że znak € jest stosunkowo często stosowanym symbolem waluty, często zdarza się, że na nowych klawiaturach komputerów jest on nadrukowany na klawiszu 5/%. Sugeruje to użycie ww. kombinacji, niemniej jednak efekt zależy od użytego sterownika klawiatury.

</doc>
<doc id="1348" url="https://pl.wikipedia.org/wiki?curid=1348" title="Energia wewnętrzna">
Energia wewnętrzna

Energia wewnętrzna (formula_1 lub formula_2 formula_3) – w termodynamice jest to całkowita energia układu będąca sumą energii potencjalnej i kinetycznej makroskopowych części układu, energii kinetycznej cząsteczek, energii potencjalnej oddziaływań międzycząsteczkowych i wewnątrzcząsteczkowych itd.
Wartość energii wewnętrznej jest trudna do ustalenia ze względu na jej złożony charakter. W opisie procesów termodynamicznych istotniejsza i łatwiejsza do określenia jest zmiana energii wewnętrznej, dlatego określając energię wewnętrzną układu pomija się te rodzaje energii, które nie zmieniają się w rozpatrywanym układzie termodynamicznym. Na przykład dla gazu doskonałego jedyną składową energii wewnętrznej, która może się zmieniać, jest energia kinetyczna cząsteczek gazu. Stąd zmiana energii wewnętrznej równa jest zmianie energii kinetycznej cząsteczek.
Energia wewnętrzna jest jednym z potencjałów termodynamicznych. Według I zasady termodynamiki energia wewnętrzna stanowi jednoznaczną funkcję stanu, którą dla danej porcji gazu można wyrazić przez dowolne dwa parametry stanu, np. ciśnienie, temperaturę, objętość właściwą, entalpię, entropię i inne.
Związek z innymi wielkościami termodynamicznymi.
O ile energię wewnętrzną trudno opisać prostym wzorem, który uwzględniałby wszystkie jej części, to ze względu na fakt, że większość jej składników pozostaje stała w przemianach gazowych, zmiana energii wewnętrznej może być zapisana równaniem:
gdzie:
Ze wzorów tych wynika
Jednostką energii w układzie SI jest dżul [J].
W gazie doskonałym.
W przypadku gazu doskonałego zmiana energii wewnętrznej równa jest zmianie energii kinetycznej cząsteczek i wyraża ją wzór
gdzie:

</doc>
<doc id="1349" url="https://pl.wikipedia.org/wiki?curid=1349" title="Enhanced Chip Set">
Enhanced Chip Set

ECS ( – ulepszony chipset) – chipset nowocześniejszy niż OCS, montowany w komputerach klasy Amiga. Zaczął być stosowany w 1990, na początku w komputerze Amiga 3000. Produkowane później komputery Amiga wykorzystywały równolegle OCS i ECS lub wyłącznie ECS. W 1991 zaczęto go stosować w komputerach Amiga 500+. Ostatnią maszyną, w której ECS był wykorzystany, była Amiga 600.
W skład ECS wchodziły układy:
Cechy ECS.
Następcą ECS był chipset AGA.

</doc>
<doc id="1350" url="https://pl.wikipedia.org/wiki?curid=1350" title="Eukarioty">
Eukarioty



</doc>
<doc id="1351" url="https://pl.wikipedia.org/wiki?curid=1351" title="Eukariota">
Eukariota



</doc>
<doc id="1352" url="https://pl.wikipedia.org/wiki?curid=1352" title="Etnocentryzm">
Etnocentryzm

Etnocentryzm – postawa ujawniająca się przy zetknięciu z innymi kulturami, polegająca na uznawaniu własnego narodu lub grupy etnicznej za szczególnie wartościową oraz na wywyższaniu własnej kultury, którą traktuje się jako miernik w ocenianiu innych grup, co prowadzi często do postaw niechęci, a nawet wrogości.
Jest przeciwieństwem relatywizmu kulturowego, również w odniesieniu do oceny kultury „masowej” i „elitarnej”. Jako przeciwieństwo etnocentryzmu traktuje się też fascynację „egzotycznymi” kulturami, co dawniej nierzadko występowało u antropologów.
Częstym przejawem etnocentryzmu jest wyrażanie zdziwienia wobec zwyczajów w innych kulturach i uznawanie ich, w przeciwieństwie do własnych zwyczajów, jako nienaturalnych. Na jego występowanie może mieć wpływ stopień homogeniczności kultury, a z kolei on sam jest jedną z cech osobowości autorytarnej. Postawa etnocentryzmu występuje nie tylko w nowoczesnych społeczeństwach. Jest charakterystyczna obok ksenofobii dla sposobu myślenia ludzi w izolowanych społecznościach pierwotnych.
Grecy i Rzymianie ludy spoza własnej cywilizacji nazywali „barbarzyńcami”, a później Europejczycy w trakcie epoki odkryć geograficznych podejmowali działania na rzecz cywilizowania „dzikich”, niszcząc ich kultury.
Inne przykłady to ludy określające mianem „ludzi” tylko siebie samych, np. Kiowa, Lapończycy, Romowie czy Tunguzi. Żydzi dzielą całą ludzkość na potomków Abrahama i gojów, jaskrawym przykładem etnocentryzmu są Chiny, czyli dla Chińczyków „Państwo Środka” (por. sinocentryzm). Wiele religii afrykańskich jest etnocentrycznych, obcym często odmawiając człowieczeństwa i pełni praw.
W ZSRR powstaniu etnocentryzmu sprzyjało wprowadzenie w 1932 r. do dowodów osobistych obywateli informacji o narodowości.

</doc>
<doc id="1353" url="https://pl.wikipedia.org/wiki?curid=1353" title="Energia swobodna Helmholtza">
Energia swobodna Helmholtza

Energia swobodna Helmholtza ("a" lub "A" lub "F" ) – funkcja stanu i potencjał termodynamiczny odpowiadający tej części energii wewnętrznej, która może być w danym procesie uwolniona na zewnątrz układu w formie pracy lub ciepła przy stałej temperaturze i objętości.
Jest to przydatna funkcja, w odróżnieniu od energii wewnętrznej, można ją łatwo wyznaczyć, gdyż zależy w sposób naturalny od temperatury, objętości i liczby moli substancji, a parametry te można łatwo mierzyć. Funkcji tej używa się często przy złożonych procesach, w których przekazywanie energii odbywa się na kilka różnych sposobów (np:reakcja chemiczna połączona ze zmianą temperatury i ciśnienia).
Energia swobodna Helmholtza często jest oznaczana symbolem "F", ale przez IUPAC preferowane jest używanie "A" (zobacz: Alberty, 2001).
Definicja i związki.
Energię swobodną Helmholtza definiuje wzór:
Z definicji energii Helmholtza, energii wewnętrznej i entropii, dla procesu odwracalnego różniczkę energii Helmholtza określa wzór:
Wzór ten dla układu, w którym nie zmienia się liczba cząsteczek układu upraszcza się do:
Z powyższego wzoru wynikają zależności:
Entropia (S):
Ciśnienie (p):
Potencjał chemiczny (formula_6) i-tego składnika
gdzie:
Energia swobodna gazu doskonałego.
Energię swobodną Helmholtza jednoatomowego gazu doskonałego określa wzór:
gdzie:
Równanie to dla określonej temperatury, objętości, liczności materii oraz energii Helmholtza w określonych warunkach początkowych, jednoznacznie określa energię Helmholtza, co jest uzasadnieniem, że energia Helmholtza jest potencjałem termodynamicznym. Z równania tego poprzez różniczkowanie lub całkowanie można uzyskać inne zależności dla gazu doskonałego.

</doc>
<doc id="1355" url="https://pl.wikipedia.org/wiki?curid=1355" title="Entalpia">
Entalpia

Entalpia (zawartość ciepła) – w termodynamice wielkość fizyczna będąca funkcją stanu mająca wymiar energii, będąca też potencjałem termodynamicznym, oznaczana przez formula_1 formula_2,formula_3 lub formula_4 którą definiuje zależność:
gdzie:
Z powyższego wzoru wynika sens fizyczny entalpii. Entalpia jest równa sumie:
Wszystkie wielkości definiujące entalpię są parametrami stanu, dlatego entalpia też jest funkcją stanu.
Nieskończenie małą zmianę entalpii określa wzór:
Dla procesów, zachodzących dla ciał stałych i cieczy pod niezbyt dużym ciśnieniem składniki formula_12 i formula_13 są małe w porównaniu do formula_14 i mogą być pominięte, wówczas zmiana entalpii jest równa zmianie energii wewnętrznej:
Entalpia jako zawartość ciepła.
Z definicji entalpii i I zasady termodynamiki:
Gdy układ wykonuje wyłącznie pracę objętościową oraz gdy ciśnienie jest stałe, wówczas zmiana entalpii jest równa ciepłu dostarczonemu do układu:
Z tego, że entalpia jest funkcją stanu oraz powyższego wynika, że dla dowolnego procesu, w którym ciśnienie początkowe jest równe ciśnieniu końcowemu, ilość ciepła dostarczonego do układu jest równa zmianie entalpii:
Przemiany przebiegające przy stałym ciśnieniu są bardzo często spotykane w praktyce (np. kocioł parowy, przemiany fazowe, reakcje chemiczne), stąd entalpia jest bardzo często wykorzystywaną w obliczeniach funkcją stanu.
W termodynamice technicznej przydatne są wielkości termodynamiczne właściwe (odniesione do jednostki masy rozpatrywanego czynnika termodynamicznego). Wprowadza się więc entalpię właściwą:
Dla entalpii właściwej można zapisać wzór definicyjny w następującej postaci:
gdzie:
Zależność entalpii od temperatury.
Entalpia substancji zależy od jej temperatury. Przy stałym ciśnieniu formula_22 jest nazywana pojemnością cieplną
lub
gdzie: formula_25 – ciepło właściwe przy stałym ciśnieniu, formula_26 – masa substancji.
Entalpia standardowa.
Entalpia standardowa to entalpia danej substancji w jej czystej postaci w ciśnieniu standardowym (tj. 1 bar) w danej temperaturze. Zmianę entalpii standardowej oznacza się symbolem formula_27 Oznaczając entalpie, jak i entalpie standardowe, wprowadza się do symbolu entalpii oznaczenie przemiany formula_28 gdzie formula_29 oznacza przemianę. Stosowany jest też zapis formula_30
Entalpie standardowe tworzenia 1 mola (zobacz Standardowe molowe ciepło tworzenia) substancji są podawane w tabelach własności fizycznych substancji. Przyjmuje się, że pierwiastki w ich podstawowym stanie w warunkach standardowych mają entalpię równą 0.
Przykłady entalpii standardowych tworzenia:
Inne.
Z definicji oraz wyrażenia na energię wewnętrzną dla procesów odwracalnych:
wynika:
Z zależności tej wynika:
gdzie:
Entalpia gazów rzeczywistych i innych substancji zależy w sposób bardziej skomplikowany od temperatury, konieczne jest zastosowanie bardziej skomplikowanych zależności, uwzględniających m.in. ciśnienie. Szczególnie skomplikowane jest wyznaczenie entalpii stosowanej w technice pary wodnej (np. w kotłach i turbinach parowych, suszarniach, wymiennikach ciepła, sprężarkach i wentylatorach do gazów wilgotnych, silnikach cieplnych, zwłaszcza z wtryskiem wody bądź pary wodnej, sieci i węzłów ciepłowniczych i innych), gdyż jej parametry są oddalone w stosunkowo niewielkim stopniu od linii nasycenia i punktu krytycznego.
W termodynamice nie jest istotna wartość całkowitej entalpii, lecz jej przyrost lub zmniejszenie w danym procesie. Przyrost entalpii występuje w sprężarkach, natomiast zmniejszenie – w turbinach cieplnych.
Moc maszyny przepływowej (turbiny, sprężarki) obliczana jest jako iloczyn zmniejszenia (bądź przyrostu) wewnętrznego entalpii czynnika przepływowego i strumienia masy rozprężanego (lub sprężanego) czynnika.
Entalpia jako transformata Legendre’a.
Entalpia formula_40 jest transformatą Legendre’a energii wewnętrznej formula_41 po zmiennej formula_42
W równaniu:
formula_9 jest zmienną niezależną, a formula_8 zależną (funkcją objętości).
Dokonując transformacji Legendre’a, otrzymuje się nową funkcję formula_1 w której formula_8 jest zmienną niezależną, a formula_9 zależną (funkcją ciśnienia), czyli:

</doc>
<doc id="1356" url="https://pl.wikipedia.org/wiki?curid=1356" title="Ewolucja">
Ewolucja

Ewolucja – stopniowy proces zmian zachodzących w czasie. Pojęcie może odnosić się:

</doc>
<doc id="1357" url="https://pl.wikipedia.org/wiki?curid=1357" title="Edward Osborne Wilson">
Edward Osborne Wilson

Edward Osborne Wilson (ur. 10 czerwca 1929 w Birmingham w Alabamie, zm. 26 grudnia 2021 w Burlington) – amerykański biolog i zoolog, znany głównie ze swoich badań nad entomologią, ewolucją oraz socjobiologią.
Działalność.
Jest jednym z twórców współczesnej socjobiologii.
Otrzymał wiele wyróżnień za swoje prace, w szczególności National Medal of Science, Nagrodę Crafoorda oraz dwukrotnie Nagrodę Pulitzera (za "On Human Nature" i "The Ants"). Jest także laureatem Nagrody Lowella Thomasa.

</doc>
<doc id="1358" url="https://pl.wikipedia.org/wiki?curid=1358" title="Ewolucjonizm">
Ewolucjonizm



</doc>
<doc id="1359" url="https://pl.wikipedia.org/wiki?curid=1359" title="Ery i okresy geologiczne">
Ery i okresy geologiczne



</doc>
<doc id="1360" url="https://pl.wikipedia.org/wiki?curid=1360" title="Kenozoik">
Kenozoik

Era kenozoiczna, kenozoik – era, która rozpoczęła się ok. 66 mln lat temu (od wymierania kredowego) i wciąż trwa. Era kenozoiczna bywa czasem określana mianem ery ssaków, owadów lub ery roślin kwiatowych, bowiem te grupy przeszły w niej intensywny rozwój ewolucyjny.
Geologia.
Intensywna orogeneza alpejska doprowadziła w paleocenie do wyniesienia Gór Skalistych, a w następnych epokach gór Sierra Nevada i nowego pasma Gór Skalistych. Przez znaczną część eocenu Afryka i Ameryka Południowa były całkowicie odizolowane od lądów półkuli północnej.
Fauna.
W erze mezozoicznej doszło do wykształcenia najpierwotniejszych ssaków – jajorodnych stekowców. Już w kredzie istniały ssaki żyworodne – torbacze, a nawet łożyskowce. W kenozoiku ssaki nadal ewoluowały. Na początku paleogenu były to przede wszystkim pozostałości kredowe: wieloguzkowce, torbacze i prymitywne ssaki łożyskowe. Nie było dużych drapieżników. Na półkuli północnej pojawiły się pierwsze naczelne (Plesiadapiforma). Nastąpiła intensywna ewolucja łożyskowców i ich specjalizacja. Pojawiły się pradrapieżne i prakopytne (paleocen). Eocen („świt nowych czasów”) zawdzięcza nazwę pojawieniu się wielu występujących do dziś rzędów ssaków, a także niektórych istniejących nadal rodzin. Do najbardziej wyspecjalizowanych należą: nietoperze, walenie i brzegowce. Wtedy też pojawiły się lemurowate i wyrakowate. Parzystokopytne reprezentowane są m.in. przez maleńkiego „jelenia” "Diacodexis", a nieparzystokopytne przez pierwszego konia – "Hyracotherium".
Flora.
We wczesnym trzeciorzędzie wokół biegunów rozciągały się lasy wielkolistnych drzew zrzucających liście na zimę. Pozostałe obszary globu porastały lasy tropikalne.

</doc>
<doc id="1361" url="https://pl.wikipedia.org/wiki?curid=1361" title="Mezozoik">
Mezozoik

Era mezozoiczna, mezozoik – era, która rozpoczęła się od wielkiego wymierania pod koniec permu, a skończyła zagładą wielkich gadów, pod koniec kredy (patrz tabelka), znanego jako wymieranie kredowe. Era mezozoiczna trwała o jedną trzecią krócej niż paleozoiczna, bo tylko 186 milionów lat. Dzieli się ją na trzy okresy: trias, jurę i kredę.
Geologia.
W mezozoiku nastąpił rozpad superkontynentu Pangei, obejmującego wszystkie obszary lądowe Ziemi. Zgodnie z teorią tektoniki płyt, ruchy płyt tektonicznych rozdzieliły powstałą w permie Pangeę na istniejące obecnie kontynenty.
Na pograniczu triasu i jury rozpoczęło się formowanie Atlantyku i Oceanu Indyjskiego. Powstały także najstarsze zachowane do dziś fragmenty skorupy oceanicznej Pacyfiku (starsze dno, zaliczane do oceanu Panthalassa, zostało zsubdukowane do czasów współczesnych). Najstarszym z nich jest południowo-zachodni fragment dna Oceanu Spokojnego, na wschód od archipelagu Wysp Sundajskich. Na miejscu Atlantyku najpierw powstaje wąski basen oceaniczny typu Morza Czerwonego, oddzielający Amerykę od Europy i Afryki. Na miejscu obecnego Oceanu Indyjskiego początkowo nastąpiło odsunięcie Madagaskaru od Afryki, później nastąpiło pęknięcie na wschód od Madagaskaru i rozejście się Afryki, Azji, Australii i Antarktydy – powstanie Oceanu Indyjskiego. Starszy Ocean Tetydy, z którego do dziś zachowały się liczne osady morskie i ofiolity ulega zamknięciu na skutek subdukcji dna, na jego miejscu powstanie olbrzymi system górski: łańcuch alpejsko-himalajski. W triasie i jurze dochodzi do pierwszych, na razie słabych ruchów orogenezy alpejskiej. W kredzie nasila się aktywność tektoniczna – dochodzi do wypiętrzenia Tatr. W Sudetach i na Opolszczyźnie w płytkich morzach, rozdzielonych wyspą osadziły się grube seria piaszczyste i margliste.
Flora.
Trias jest okresem panowania roślin nagonasiennych iglastych. Rośliny kwiatowe (początkowo tylko magnoliowate) pojawiły się pod koniec ery mezozoicznej.
Fauna.
Mezozoik to era dominacji dinozaurów; już w triasie pojawiły się pierwsze prymitywne ssaki. Cała era charakteryzowała się wzrostem różnorodności gatunkowej gadów lądowych i morskich, której szczyt obserwujemy w jurze i kredzie. Poza znanymi już z wcześniejszego okresu gadami morskimi i lądowymi pojawiły się aktywnie latające gady, a także pierwsze prymitywne ptaki. Ewolucja bezkręgowców jest powolna, poza głowonogami (amonity i belemnity), które w związku z tym służą jako znakomite, pierwszorzędne skamieniałości przewodnie. Podobnie jak u schyłku paleozoiku, również i pod koniec mezozoiku dochodzi do masowego wymierania roślin i zwierząt. Jego przyczynami najprawdopodobniej są: upadek planetoidy w regionie półwyspu Jukatan, który tworzy krater Chicxulub oraz wulkanizm w Indiach, który stworzył trapy Dekanu. Wymieranie kredowe spowodowało zagładę dinozaurów (poza ptakami), pterozaurów i gadów morskich; wymarły także amonity, belemnity i liczne otwornice.
Mezozoik w Polsce.
Na obszarze Polski w dolomitach triasowych występują bogate złoża rud cynku i ołowiu, złoża wapieni i margli, wysady solne, a w skałach jurajskich – niewielkie ilości rud żelaza. W morzu kredowym osadziły się piaskowce tworzące obecnie Góry Stołowe oraz margle pokrywające znaczne obszary Opolszczyzny – tzw. kreda opolska.
Kredowe nasilenie aktywności tektonicznej spowodowało znaczne wypiętrzenie Tatr. Śladem geologicznych przeobrażeń w Polsce są surowce skalne: wapienie, margle, kreda i dolomity wydobywane w okolicach Opola, na Wyżynie Lubelskiej i w rejonie świętokrzyskim, a także skały fliszowe Karpat.

</doc>
<doc id="1362" url="https://pl.wikipedia.org/wiki?curid=1362" title="Era paleozoiczna">
Era paleozoiczna



</doc>
<doc id="1364" url="https://pl.wikipedia.org/wiki?curid=1364" title="Eugeniusz Kwiatkowski">
Eugeniusz Kwiatkowski

Eugeniusz Felicjan Kwiatkowski (ur. 30 grudnia 1888 w Krakowie, zm. 22 sierpnia 1974 tamże) – polski chemik, wicepremier, minister przemysłu i handlu (1926–1930), minister skarbu (1935–1939) II Rzeczypospolitej.
Kierował opracowaniem 4-letniego planu inwestycyjnego przewidującego rozbudowę infrastruktury, zwiększenie potencjału obronnego kraju, przygotowanie fundamentów dla przyszłej rozbudowy przemysłu, łącznie z aktywizacją Staropolskiego Okręgu Przemysłowego. Zainicjował budowę portu i miasta w Gdyni. Znacznie przyczynił się do powstania Stalowej Woli.
Wniósł znaczący wkład w rozwój polskiego przemysłu chemicznego: zakładów azotowych w Chorzowie i Tarnowie. Jak napisał Jan Nowak-Jeziorański, przyjaciel rodziny:
"Przeszedł Kwiatkowski do historii jako twórca Gdyni, ale określenie to znacznie zawęża jego rolę. Polegała ona na ocaleniu i umocnieniu niezależności gospodarczej, bez której Polska nie mogła się ostać jako niepodległe Państwo".
Dzieciństwo i młodość.
Syn Jana (1841–1902) i Wincentyny z Maszczyńskich (1864–1951). Ojciec – prawnik – był urzędnikiem kolei krakowskiej. Po odziedziczeniu majątku po bracie przeniósł się z rodziną do miejscowości Czernichowce pod Zbarażem, w której Eugeniusz spędził dzieciństwo wraz z rodzeństwem: Romanem (1885–1948), Janiną (1892–1994) i Zofią (1900–2000). W 1898 rozpoczął naukę w Gimnazjum Franciszka Józefa we Lwowie – nauka w tym czasie nie szła mu najlepiej. Od 1902 roku uczęszczał do Gimnazjum OO. Jezuitów w Bąkowicach pod Chyrowem. W 1907 otrzymał świadectwo dojrzałości. Po maturze, w latach 1907–1910, studiował na Wydziale Chemii Technicznej Politechniki Lwowskiej, gdzie nauka szła mu bardzo dobrze. Jednak w 1910 Eugeniusz na prośbę matki, która bała się aktywności politycznej i niepodległościowej syna, wyjechał na dalsze studia na uniwersytet do Monachium (1910–1912). W 1913 roku powrócił do Lwowa, w którym odbył praktykę w Gazowni Miejskiej. We wrześniu 1913 poślubił Leokadię z Glazerów (1890–1977), bratanicę bp Jakuba Glazera, z którą miał czworo dzieci: syna zmarłego w niemowlęcym wieku, Jana (1914–1939), Annę (1918–2007) i Ewę (1925–2018). W okresie studiów we Lwowie związał się z młodzieżowymi organizacjami niepodległościowymi "„Zet”" i "„Zarzewie”", a następnie był członkiem Polskich Drużyn Strzeleckich.
W czasie I wojny światowej walczył w Legionie Wschodnim, następnie w Legionach Polskich oraz zajmował się pracą konspiracyjną w Polskiej Organizacji Wojskowej. W okresie wojny polsko-bolszewickiej pracował w sekcji chemicznej Głównego Urzędu Zaopatrzenia Armii przy Ministerstwie Spraw Wojskowych. W 1921 wystąpił z wojska w stopniu porucznika.
Kwiatkowski: menadżer i polityk.
Jeszcze w trakcie I wojny światowej pełnił funkcję zastępcy dyrektora Gazowni Lubelskiej. Następnie, jako docent, wykładał chemię węgla kamiennego i gazu na Politechnice Warszawskiej. Jako inżynier chemik, podjął w 1921 pracę na stanowisku dyrektora technicznego w Państwowej Fabryce Związków Azotowych w (Starym) Chorzowie, której dyrektorem naczelnym był wówczas Ignacy Mościcki. W ciągu czterech lat doprowadził do rozkwitu fabryki, uprzednio pozbawionej przez Niemców dokumentacji i personelu technicznego. W latach 1924–1926 był prezesem Polskiego Stowarzyszenia Inżynierów i Techników Województwa Śląskiego, którego członkostwo honorowe otrzymał w roku 1928.
Po przewrocie majowym (1926) prezydent RP Ignacy Mościcki zarekomendował go na stanowisko ministra przemysłu i handlu w drugim rządzie Kazimierza Bartla, które to stanowisko piastował w latach 1926–1930.
Po 1930, kiedy nowy premier Walery Sławek nie zaproponował mu miejsca w rządzie, aż do 1935 roku pozostawał na marginesie życia politycznego. W 1931 roku zrezygnował z mandatu poselskiego w Sejmie Śląskim (który objął rok wcześniej z ramienia BBWR). W latach 1931–1935 był dyrektorem Państwowych Fabryk Związków Azotowych w Chorzowie i Mościcach.
Od października 1935 do 30 września 1939 pełnił funkcję wicepremiera i ministra skarbu w rządach: Mariana Zyndram-Kościałkowskiego i Felicjana Sławoja Składkowskiego. Jego politycznym protektorem był prezydent Mościcki.
Włączył się w działalność Obozu Zjednoczenia Narodowego. Stał się szeroko znany jako autor koncepcji rozwoju handlu morskiego i budowniczy portu w Gdyni.
Skalę problemów gospodarczych, z którymi miał się borykać, przedstawił w wystąpieniu sejmowym z 1935 roku, podczas którego stwierdzał: „Nasza struktura gospodarcza jest wyjątkowo niekorzystna (...). Wieś polska w XX w. powróciła prawie do gospodarki naturalnej. Szereg potrzeb wsi zaspakaja się w sposób anormalny i niezwykle prymitywny, zapałki dzieli się na części, wraca się do łuczywa, a transport pieszy i kołowy nawet na znaczne odległości przyszedł ponownie – po przerwie od końca XIX w. – do znaczenia”.
Od 1937 roku patronował Centralnemu Okręgowi Przemysłowemu, koncepcji autorstwa braci Kosieradzkich (Władysław Kosieradzki i Paweł Kosieradzki).
Opowiadał się za szybkim uprzemysłowieniem kraju i reformą rolną (zwolennik interwencjonizmu państwowego w dziedzinie cen płodów rolnych, oddłużania rolnictwa i inwestycji publicznych). Doceniał sukcesy radzieckiego planowania gospodarczego, jednocześnie podkreślając skalę prześladowań obywateli radzieckich. Był zwolennikiem równouprawnienia mniejszości narodowych w Polsce. W kręgach sanacyjnych był zwolennikiem dialogu z opozycją. Uważał, że bez porozumienia z silną w kraju opozycją nie można prowadzić aktywnej polityki gospodarczej. Pod pseudonimem umieszczał artykuły w opozycyjnym „Kurierze Warszawskim”. Działaczy opozycji zaprosił do udziału w tworzonym przez niego Obywatelskim Komitecie Pożyczki Obrony Narodowej. Udało mu się organizować spotkania przedstawicieli opozycji z prezydentem Mościckim. Jego starania o porozumienie i amnestię dla skazanych w procesie brzeskim nie przyniosły jednak rezultatów. Politycznie związany z tzw. „Zamkiem”, czyli obozem prezydenta Mościckiego pozostawał w konflikcie zarówno z Generalnym Inspektorem Sił Zbrojnych Rydzem-Śmigłym (na tle niechęci do dewaluacji złotego) i z ministrem spraw zagranicznych Beckiem (na tle stosunku do polityki wobec III Rzeszy, której Kwiatkowski był stanowczym krytykiem).
W obliczu klęski wrześniowej wraz z rządem opuścił Polskę 17 września 1939. W latach 1939–1945 internowany w Rumunii. Premier Władysław Sikorski odrzucił jego prośbę o przyjęcie w skład armii polskiej we Francji, motywując to jego osobistą odpowiedzialnością za klęskę 1939 roku jako członka władz przedwrześniowych.
8 lipca 1945 powrócił do kraju i w latach 1945–1948 był Delegatem Rządu dla Spraw Wybrzeża (jego zastępcą był Kazimierz Strzegocki). Krytykowany przez emigrację polityczną i opozycję w kraju. Zaangażował się w odbudowę gospodarki morskiej. W swoim przemówieniu z 1945 roku stwierdził: „Tu nad bałtyckim wybrzeżem ofiarowuje nam historia szanse, jakich nie mieliśmy od prawie pięciu wieków. Musimy więc skupić wszystkie siły i wszystkie uzdolnienia tkwiące w naszym narodzie, by te możliwości wyzyskać w całej pełni”. Utrzymywał poprawne stosunki z głównymi ówczesnymi politycznymi decydentami Bolesławem Bierutem i Władysławem Gomułką. Z sił politycznych popierał PPS, choć pozostał bezpartyjny. W latach 1947–1952 był posłem na Sejm Ustawodawczy. Krytykował m.in. zniesienie święta Konstytucji 3 Maja oraz późniejsze odebranie immunitetu poselskiego aresztowanemu Gomułce. Jednak na 98 posiedzeniu Sejmu Ustawodawczego – w trakcie którego odebrano Gomułce immunitet poselski – głosu nie zabierał.
W czasie pobytu na Wybrzeżu mieszkał w Sopocie, gdzie włączył się czynnie w działalność ZHP. Został przewodniczącym Zarządu Okręgu ZHP.
W 1948 roku został odsunięty od działalności publicznej i przeniesiony na przymusową emeryturę z administracyjnym zakazem pobytu na Wybrzeżu i w Warszawie. Zamieszkał w Krakowie. Po 1956 roku wrócił do aktywności i zajął się głównie pracą naukową z dziedziny chemii, ekonomii i historii. Zmarł 22 sierpnia 1974. Został pochowany na krakowskim Cmentarzu Rakowickim (kwatera XIV B-płn-5) obok swojego syna (zginął w 1939 roku postrzelony przez pomyłkę przez współtowarzyszy z wojska). Na miejsce spoczynku odprowadził Eugeniusza Kwiatkowskiego ówczesny arcybiskup krakowski Karol Wojtyła.
Twórca gospodarki morskiej.
Eugeniusz Kwiatkowski w Gdyni jest traktowany jako jedna z bardziej zasłużonych postaci dla rozwoju miasta. Dzięki niemu budowa gdyńskiego portu, która początkowo prowadzona była dość ospale, w 1926 roku ruszyła w błyskawicznym tempie, a Gdynia stała się dla międzywojennej Polski „oknem na świat”. Poza budową portu przyczynił się do powstania polskiej floty handlowej, uwalniając Polskę od opłacania obcych armatorów. Jednocześnie z jego inicjatywy powstała Dalekomorska Flota Rybacka.
Wybrane prace naukowe.
Jest autorem szeregu prac ekonomicznych:
W 2009 wydano „Archiwum Morskie Eugeniusza Kwiatkowskiego” (Wyższa Szkoła Administracji i Biznesu im. Eugeniusza Kwiatkowskiego w Gdyni, współpraca prof. Marian Marek Drozdowski).
Wyróżnienia.
Eugeniusz Kwiatkowski otrzymał tytuły honorowego obywatelstwa Gdyni (1928), honorowego obywatelstwa Łukowa (23 czerwca 1938) honorowego obywatelstwa Przeworska (21 grudnia 1938), Lubaczowa (1939), Jarosławia, Gminy Frysztak, Gminy Szczawne, Rymanowa (14 stycznia 1939), honorowego obywatelstwa Sanoka (styczeń 1939), Jasła (31 stycznia 1939), gminy Bircza (pocz. 1939), gminy powiatu brzozowskiego (pocz. 1939), honorowego obywatelstwa Szczecina (1946).
W lipcu 1939 zgłosił akces do Towarzystwa Popierania Budowy Publicznych Szkół Powszechnych i został wtedy członkiem dożywotnim tej organizacji.
19 sierpnia 1974 Uniwersytet Gdański przyznał Eugeniuszowi Kwiatkowskiemu tytuł "doktora honoris causa" za wkład w rozwój polskiej gospodarki morskiej oraz ogólnej teorii ekonomii.
Upamiętnienie.
Filmy biograficzne
Inne formy
Jego imię noszą:
W Polsce Ludowej jego imieniem nazwano statek handlowy. Ponadto w szeregu polskich miast znajdują się jego pomniki i tablice pamiątkowe.
Uchwałą z 24 stycznia 2002 Sejm RP zdecydował o ustanowieniu roku 2002 Rokiem Eugeniusza Kwiatkowskiego.

</doc>
<doc id="1365" url="https://pl.wikipedia.org/wiki?curid=1365" title="Enigma">
Enigma

 
Enigma (z „zagadka”) – niemiecka przenośna elektromechaniczna maszyna szyfrująca, oparta na mechanizmie obracających się wirników, skonstruowana przez Artura Scherbiusa. Była produkowana przez wytwórnię Scherbius &amp; Ritter, założoną w 1918 z inicjatywy Scherbiusa oraz innego niemieckiego inżyniera Richarda Rittera, zajmującą się konstrukcją i produkcją urządzeń elektrotechnicznych, między innymi silników asynchronicznych. Scherbius odkupił prawa patentowe do innej wirnikowej maszyny szyfrującej, opracowanej przez holenderskiego inżyniera Hugona Kocha.
Hugo Koch i Artur Scherbius nie byli pierwszymi, którzy skonstruowali maszyny szyfrujące oparte na wirnikach. Poza nimi prace nad podobnymi urządzeniami prowadzili także Edward Hebern (USA, 1917) i Arvid Gerhard Damm (Szwecja, 1919), ale tylko Enigma Scherbiusa, wprowadzona najpierw na rynek cywilny, a później do instytucji państwowych, osiągnęła sukces.
Enigma była używana komercyjnie od lat 20. XX wieku, a później została zaadaptowana przez instytucje państwowe wielu krajów. Podczas II wojny światowej maszyna ta była wykorzystywana głównie przez siły zbrojne oraz inne służby państwowe i wywiadowcze Niemiec, a także innych państw. W Rzeszy wprowadzono ją w 1926 do Kriegsmarine, od 15 lipca 1928 do Wehrmachtu, od 1 sierpnia 1935 do Luftwaffe, w 1937 do policji oraz SD. Należała do rodziny elektromechanicznych wirnikowych maszyn szyfrujących i była produkowana w wielu odmianach; dwie podstawowe wersje miały charakter handlowy i wojskowy.
Po raz pierwszy szyfrogramy zakodowane przy pomocy Enigmy udało się rozszyfrować polskim kryptologom w grudniu 1932 (lub styczniu 1933) w Pałacu Saskim w Warszawie, mieszczącym siedzibę Biura Szyfrów Oddziału II Sztabu Głównego Wojska Polskiego. Praca Polaków: mjr Franciszka Pokornego, kpt. Maksymiliana Ciężkiego, inż. Antoniego Pallutha oraz uzdolnionych młodych matematyków: Mariana Rejewskiego, Jerzego Różyckiego i Henryka Zygalskiego pozwoliły na dalsze wysiłki nad dekodowaniem szyfrów stale unowocześnianych maszyn Enigma najpierw w Polsce, a po wybuchu II wojny światowej we Francji i Wielkiej Brytanii. Do wybuchu wojny pracę kryptologów wydatnie wspierali inżynierowie z Wytwórni Radiotechnicznej „AVA” którzy konstruowali sobowtóry „Enigmy” oraz urządzenia i narzędzia pomocnicze do dekryptażu.
Najczęściej odszyfrowywanymi wiadomościami były przekazy zaszyfrowane Enigmą używaną przez Wehrmacht ("Wehrmacht Enigma"). Brytyjski wywiad wojskowy oznaczył Enigmę kryptonimem "ULTRA". Nazwa ta powstała ze względu na najwyższy stopień utajnienia faktu złamania szyfru Enigmy, wyższy niż "najtajniejszy" (), czyli "Ultratajny".
Opis działania.
Tak jak inne maszyny oparte na rotorach (wirnikach), Enigma jest połączeniem systemów elektrycznego i mechanicznego. Część mechaniczna składa się z alfabetycznej 26-znakowej klawiatury, zestawu osadzonych na wspólnej osi i obracających się bębenków nazywanych "rotorami" lub "wirnikami" (), obrotowych pierścieni na wirnikach oraz mechanizmu obracającego jeden lub kilka rotorów naraz za każdym naciśnięciem klawisza.
Część elektryczną tworzą stałe i ruchome połączenia i styki (w tym klawiatury i wirników), a także łącznica kablowa. Części mechaniczne służą także jako elementy obwodu elektrycznego – właściwe kodowanie liter odbywa się elektrycznie. Po naciśnięciu klawisza obwód elektryczny zamyka się, a prąd przepływa przez elementy składowe maszyny, powodując zapalenie się jednej z wielu lampek podświetlających literę wyjściową. Na przykład jeśli kodowana wiadomość zaczyna się od liter ALA..., operator maszyny naciska najpierw literę A, która może spowodować zapalenie się lampki z literą Z. W ten sposób pierwszą literą zakodowanej wiadomości będzie Z. Następnie operator naciska klawisz z literą L, która zostaje zakodowana w analogiczny sposób, i tak dalej.
Działanie Enigmy pokazano na diagramie po lewej. Dla uproszczenia pokazano tylko 4 zestawy kodujące, lampki, klawisze, kable łącznicy, gdy w rzeczywistości było ich 26. Prąd przepływa z baterii (1) przez obwód mającego dwa styki klawisza z literą (2) do łącznicy kablowej (3). Łącznica umożliwiała zamianę dwóch liter miejscami, a jednocześnie zapewniała połączenie klawiatury (2) z walcem wstępnym ("Eintrittswalze") (4). Prąd przepływa przez łącznicę kablową (3) do walca wstępnego (4), a następnie przez trzy (w przypadku zastosowania w wojskach lądowych) lub cztery (w przypadku marynarki) wirniki do bębenka odwracającego ("Umkehrwalze") (6). Bęben odwracający zawraca sygnał z powrotem przez wirniki (5), ale inną drogą, do walca wstępnego (4), następnie doprowadzając go do gniazda ‘S’ łącznicy, a stamtąd przewodem (8) ("Steckerverbindung") do gniazda ‘D’ i dwustykowego klawisza (9), powodując zaświecenie lampki.
Ciągłe obracanie się wirników powoduje bezustanne zmienianie drogi sygnału i kodowanie wiadomości szyfrem polialfabetycznym, zwanym też szyfrtem podstawieniowym, który na ówczesne czasy zapewniał wysokie bezpieczeństwo transmisji.
Wirniki.
Wirniki (nazywane także "bębenkami", "rotorami" lub "walcami" – po niemiecku "Walzen") stanowiły serce maszyny szyfrującej Enigma. Miały one postać koła o blisko 10 cm średnicy, wykonanego z twardej gumy lub bakelitu z ułożonymi w kształt okręgu mosiężnymi pinami na sprężynkach z jednej strony i płaskimi stykami elektrycznymi z drugiej. Ułożenie pinów i styków jest takie samo, jak opis literowy na pierścieniu alfabetycznym wirnika – typowo 26 liter od A do Z. Gdy wirniki są ułożone jeden za drugim na wspólnej osi, piny jednego z nich stykają się z płaskimi stykami elektrycznymi sąsiedniego, zamykając obwód elektryczny. Wewnątrz wirnika znajdowało się 26 przewodów łączących zgodnie z założoną kombinacją piny z jednej ze stykami po drugiej stronie. Sposób okablowania był inny dla każdego typu wirnika.
Pojedynczy wirnik zapewnia tylko proste szyfrowanie szyfrem podstawieniowym. Przykładowo pin odpowiadający literze E może być połączony ze stykiem od litery T po drugiej stronie. Złożoność systemu szyfrowania polega na zastosowaniu wielu równoległych współosiowych wirników – przeważnie trzech lub czterech – oraz regularnego obracania ich, co zwiększa stopień komplikacji.
Po włożeniu do maszyny szyfrującej, wirnik mógł być ustawiony w jednej z 26 pozycji. Przekręcenie bębenka umożliwiał przytwierdzony do niego karbowany pierścień wystający przez górną pokrywę maszyny po jej zamknięciu. Aby operator maszyny mógł ustawić wirnik w odpowiedniej pozycji, przymocowano do niego "pierścień alfabetyczny" z 26 literami lub cyframi, z których właściwa, odpowiadająca nastawieniu pozycji, była widoczna w specjalnym okienku pokrywy maszyny. We wczesnych modelach maszyny pierścień alfabetyczny był zamocowany do wirnika, ale później, w celu zwiększenia komplikacji szyfru, wprowadzono wirniki o zmiennym ustawieniu pierścienia alfabetycznego, którego pozycję określanego terminem "Ringstellung" (ustawieniem wirnika).
Enigmy Sił Lądowych (Heer) i Luftwaffe były wyposażone w kilka typów wirników, chociaż zaraz po jej wprowadzeniu były tylko trzy. 15 grudnia 1938 zwiększono zestaw wirników do pięciu, z których do zamontowania w maszynie wybierano trzy. Dla odróżnienia bębenki były oznaczane rzymskimi cyframi I, II, III, IV i V. Każdy z nich miał jedno zlokalizowane w różnych miejscach pierścienia alfabetycznego wcięcie, służące do obracania go, przez co złożoność szyfru znacznie wzrastała. Założenie konstruktorów maszyny, że zastosowanie wcięcia praktycznie uniemożliwi odkodowanie wiadomości, okazało się jednak błędne, ponieważ dzięki zastosowaniu opracowanej przez Jerzego Różyckiego metody zegarowej, a później brytyjskiej Banburismus, ostatecznie szyfr Enigmy został złamany.
Rozkład okablowania wirników I–V
 A B C D E F G H I J K L M N O P Q R S T U V W X Y Z
 I E K M F L G D Q V Z N T O W Y H X U S P A I B R C J
 II A J D K S I R U X B L H W T M C Q G Z N P Y F V O E
 III B D F H J L C P R T X V Z N Y E I W G A K M U S Q O
 IV E S O V P Z J A Y Q U I R H X L N F T G K D C M W B
 V V Z B R G I T Y U P S D N H L X A W M J Q O F E C K
W odróżnieniu od maszyn wojsk lądowych i lotniczych Enigmy Kriegsmarine były wyposażone w większy zestaw wirników, początkowo sześć, później siedem i ostatecznie osiem. Dodatkowe wirniki oznaczone jako VI, VII i VIII były okablowane w różny sposób i miały po dwa wcięcia na wysokości liter ‘N’ i ‘A’, które umożliwiały ich częstsze obracanie.
W używanej przez Kriegsmarine Enigma M4 zastosowano czwarty wirnik, którego dodanie nie wymagało przebudowy maszyny. Zastosowano cieńszy bębenek odwracający i specjalny czwarty wirnik, który się nie obracał, a był ustawiany ręcznie w jednej z 26 pozycji. Czwarty wirnik był produkowany w dwóch wersjach – "Beta" i "Gamma".
Rozkład okablowania wirników VI–VIII, Beta i Gamma
 A B C D E F G H I J K L M N O P Q R S T U V W X Y Z
 VI J P G V O U M F Y Q B E N H Z R D K A S X L I C T W
 VII N Z J H G R C X M Y S W B O U F A I V L P E K Q D T
 VIII F K Q H T L X O C B J S P D Z R A M E W N I U Y G V
 Beta L E Y J V C N I X W P B Q M D R T A K Z G F U H O S
 Gamma F S O K A N U E R H M B T I Y C W L Q P Z X V G J D
Ruch obrotowy wirników.
W celu zwiększenia komplikacji kodu niektóre wirniki poruszały się nie za każdym naciśnięciem klawisza. Takie działanie zapewnia odmienne kodowanie znaku w każdej pozycji bębenków i powstanie w efekcie bardzo skomplikowanego wieloalfabetycznego szyfru podstawieniowego.
Obracanie wirników zrealizowano za pomocą mechanizmu zębatkowo-zapadkowego. Na każdy z wirników maszyny nałożono koła zębate o 26 zębach współpracujących z zapadkami. Każde naciśnięcie klawisza maszyny powoduje jednoczesne popchnięcie zapadek, które, jeśli natrafią na występ zębatki bębenka, powodują jego obrót.
W Enigmie używanej przez siły lądowe i powietrzne na wirniki założono dodatkowe koło z wcięciem. Pięć podstawowych wirników (I–V) miało po jednym wcięciu, natomiast dodatkowe wirniki maszyn Kriegsmarine (VI–VIII) – po dwa. W pewnych pozycjach wcięcie to ustawiało się w takiej pozycji, że zapadka sąsiedniego wirnika umożliwiała przestawienie dwóch bębenków jednocześnie. W przeciwnym razie zapadka ślizga się po powierzchni koła z nacięciem, nie powodując dodatkowego obrotu. Dla wirników mających jedno wcięcie dodatkowy skok drugiego bębenka następuje co 26 obrotów pierwszego bębenka i podobnie – obrót trzeciego co 26 obrotów drugiego. Drugi wirnik obraca się w taki sam sposób jak trzeci, dlatego w pewnym momencie przeskoczy on o dwa ząbki za jednym naciśnięciem klawisza, skracając swój okres obrotu (podwójny krok).
Fakt występowania "podwójnego kroku" w Enigmie odróżnia sposób obracania się bębenków np. od samochodowego licznika kilometrów. "Podwójny krok" zachodzi, gdy pierwszy wirnik skokowo wykonuje obrót, a w momencie natrafienia zapadki na wcięcie w drugim wirniku następuje przestawienie go o jeden krok do przodu. Tak samo dzieje się z trzecim wirnikiem, ale w momencie natrafienia zapadki na wcięcie zostaje on obrócony o jeden krok wraz z drugim bębenkiem. W kolejnym cyklu zapadka popycha drugi wirnik po raz kolejny (drugi raz z rzędu).
W trójwirnikowej Enigmie mającej tylko po jednym wcięciu na pierwszym i drugim bębenku powtórzenie kombinacji kodu następuje co 16 900 cykli. 26×25×26 = 16 900 (Uwaga: nie jest to 26×26×26=17576 ze względu na "podwójny krok" drugiego z bębenków, chociaż wszystkie wirniki mają po 26 styków). Ze względu na ograniczoną do kilkuset znaków długość zazwyczaj nadawanych wiadomości, prawdopodobieństwo powtórzenia się sekwencji kodującej było praktycznie zerowe.
Aby zrobić miejsce na czwarty wirnik kodujący "Beta" lub "Gamma" w Enigmie Kriegsmarine, która weszła do użytku w 1942 roku, zastosowano cieńszy wirnik odwracający, a sam czwarty wirnik również miał mniejszą grubość. Pozostałe mechanizmy maszyny nie uległy zmianie, nie dodano również zapadki do dodatkowego wirnika, mógł być on ustawiany jedynie ręcznie w jednej z 26 pozycji.
Po naciśnięciu klawisza na klawiaturze, najpierw następuje obrót wirników, a dopiero później jest zestawiany obwód elektryczny.
Walec wstępny.
Walec wstępny (niem. "Eintrittswalze") lub stojan jest połączony z łącznicą kablową (jeśli jest ona obecna), albo bezpośrednio z klawiaturą i lampkami, a z drugiej strony z zestawem wirników. Chociaż sam sposób połączenia klawiatury z walcem nie ma większego znaczenia dla bezpieczeństwa kodowania, to początkowo przysporzył pewnych kłopotów Marianowi Rejewskiemu, który pracował nad odkryciem sposobu okablowania wirników. Komercyjna wersja maszyny miała klawisze połączone zgodnie z układem klawiatury: Q → A, W → B, E → C i tak dalej. Z kolei w wersji wojskowej połączona była alfabetycznie: A → A, B → B, C → C i tak dalej. Odkrycie tego faktu przez Rejewskiego umożliwiło mu opracowanie kolejnych równań, pozwalających ostatecznie na złamanie tajemnicy Enigmy.
Walec odwracający.
Z wyjątkiem pierwszych dwóch modeli Enigmy, oznaczonych literami A i B, wszystkie późniejsze maszyny miały walec odwracający, inaczej "reflektor" ("Umkehrwalze"). Było to opatentowane rozwiązanie, które odróżniało Enigmę od innych ówcześnie budowanych maszyn szyfrujących z wirnikami. Zadaniem walca odwracającego było połączenie styków elektrycznych ostatniego wirnika kodującego w pary i zawrócenie sygnału inną drogą przez zestaw wirników.
Połączenia par styków bębnów odwracających B i C (walec stały)
 UKW B AY BR CU DH EQ FS GL IP JX KN MO TZ VW
 UKW C AF BV CP DJ EI GO HY KR LZ MX NW QT SU
Bęben odwracający Enigmy jest symetryczny, co oznacza, że zaszyfrowana informacja jest rozkodowywana po przesłaniu jej tą sama drogą (jakby powtórnym zakodowaniu). Bęben ten nadaje Enigmie jeszcze jedną własność, mianowicie nigdy żadna litera przed zaszyfrowaniem nie może mieć tej samej wartości co zaszyfrowana (czyli nigdy A nie będzie po zaszyfrowaniu występować jako A). Wynika to z konstrukcji bębna, który zawsze zamienia znaki parami. Własność ta, choć miała być zaletą, jest w rzeczywistości błędem kryptologicznym i została wykorzystana do złamania kodu Enigmy.
W wersji komercyjnej typu C walec odwracający mógł być zainstalowany w jednej z dwóch pozycji, natomiast w nowszej wersji D w jednej z 26 pozycji, ale nie poruszał się on podczas szyfrowania. W wersji Enigmy przeznaczonej dla Abwehry walec odwracający obracał się tak samo, jak pozostałe wirniki.
Połączenia par styków bębnów odwracających B i C (obrotowy Enigmy M4)
 UKW B AE BN CK DQ FU GY HW IJ LO MP RX SZ TV
 UKW C AR BD CO EJ FN GT HK IV LM PW QZ SX UY
Enigmy wykorzystywane przez wojska lądowe i wojska lotnicze również miały nieruchome bębenki odwracające, które produkowano w czterech wersjach. Pierwsza z nich oznaczona jako "Umkehrwalze A" została zastąpiona 1 listopada 1937 przez "Umkehrwalze B". Trzecia wersja "Umkehrwalze C", wprowadzona w 1940, była używana bardzo krótko, prawdopodobnie na skutek błędu. Wersja Enigmy z tą wersją walca została rozkodowana przez sekcję Hut 6 ośrodka kryptologicznego w Bletchley Park. Czwartej wersji walca użyto po raz pierwszy około 2 grudnia 1944. W odróżnieniu od poprzednich "Umkehrwalze D", miał zmienne uzwojenie, które mogło być przestawiane przez operatora w jedno z predefiniowanych położeń.
Łącznica kablowa.
Łącznica kablowa ("Steckerbrett") umożliwia różnorodne okablowanie, które może być zmieniane przez operatora. Po raz pierwszy łącznicę kablową wprowadzono w 1930 do maszyn wojsk lądowych i Luftwaffe, a wkrótce zaadaptowano także w Kriegsmarine. Łącznica mimo swej prostoty pozwalała na znaczny wzrost komplikacji szyfru Enigmy, większy niż dodatkowy wirnik. Enigma bez łącznicy mogła być rozkodowana w relatywnie prosty sposób nawet metodami ręcznymi, natomiast zamiana liter przy pomocy łącznicy kablowej wymusiła zastosowanie do łamania kodów specjalnych maszyn.
Przewody łącznicy kablowej pozwalały zamienić niektóre pary liter miejscami, np. E i Q. Efektem była zamiana liter zarówno przed, jak i po przejściu sygnału przez wirniki kodujące. Przykładowo po naciśnięciu przez operatora klawisza E sygnał jest kierowany do Q, a następnie wprowadzany na wirniki. W tym samym czasie można zamienić do 13 par liter, czyli cały alfabet.
Sygnał elektryczny biegnie z klawiatury przez łącznicę kablową do walca wstępnego ("Eintrittswalze"). Każda litera na łącznicy ma dwa gniazda na wtyki bananowe, w które wkłada się wtyczkę. Po włożeniu wtyczek następuje odłączenie górnych wtyków od klawiatury i dolnych od walca wstępnego maszyny. Sygnał elektryczny przebiega kablem, zamieniając połączenia dwóch liter miejscami.
Akcesoria dodatkowe.
Bardzo przydatnym dodatkowym oprzyrządowaniem Enigmy M4 był Schreibmax, mała drukarka, która mogła drukować cały zestaw 26 znaków na wąskiej papierowej taśmie. Zastosowanie tego urządzenia umożliwiło rezygnację z drugiego operatora, którego zadaniem było odczytywanie z lampek i zapisywanie odkodowanej wiadomości. Schreibmax był instalowany na górnej pokrywie maszyny i podłączany zamiast panelu z lampkami, który na czas używania drukarki demontowano. Poza oczywistą wygodą użytkowania, zastosowanie Schreibmaxa zwiększyło również bezpieczeństwo transmisji, gdyż możliwe było zdalne zainstalowanie drukarki, choćby w drugim pomieszczeniu, co uniemożliwiało wprowadzającemu szyfrogram operatorowi odczytanie zdekodowanej wiadomości.
Innym przydatnym akcesorium był dodatkowy zdalny panel z lampkami, który tak jak w przypadku Schreibmaksa umożliwiał odczyt wiadomości w innym pomieszczeniu lub poza zasięgiem wzroku operatora. Wersje Enigmy wyposażone w dodatkowy panel miały większą skrzynię, pozwalającą na zmieszczenie go w odpowiedniej przegródce.
W 1944 Luftwaffe wprowadziła dodatkowy przełącznik łącznicy kablowej, nazywany Uhr (zegar). Miał on postać małego pudełka z 40-pozycyjnym przełącznikiem obrotowym, zastępującym dotychczasowe wtyczki. Po podłączeniu urządzenia do Enigmy zgodnie z aktualnym kluczem dziennym, operator mógł wybrać poprzez obrót gałki jedną z 40 pozycji, z której każda odpowiadała innej kombinacji okablowania.
Opis matematyczny.
Maszyna szyfrująca Enigma koduje litery w taki sposób, że każda z nich może być opisana matematycznie jako wynik permutacji. Na przykładzie trójwirnikowej Enigmy, używanej przez niemieckie siły lądowe i Luftwaffe, będzie to wyglądało następująco: niech formula_1 oznacza przekształcenie na łącznicy kablowej, formula_2 oznacza walec odwracający, a formula_3 formula_4 formula_5 oznaczają działania na trzech kolejnych wirnikach. Szyfrowanie formula_6 można wyrazić jako:
Po każdym naciśnięciu klawisza wirniki obracają się, zmieniając przekształcenie. Przykładowo, jeśli pierwszy z prawej wirnik formula_5 obróci się o formula_9 pozycji, przekształcenie będzie miało postać formula_10 gdzie formula_11 jest "permutacją cykliczną" odwzorowującą A na B, B na C... Z na A. Podobnie ruch wirników środkowego formula_12 i ostatniego z lewej formula_13 mogą być przedstawione jako obrót formula_12 o formula_15 pozycji i obrót formula_13 o formula_17 pozycji. Funkcja szyfrowania ma wtedy postać:
Procedury używania Enigmy.
Niemiecka komunikacja wojskowa została podzielona na wiele różnych sieci, z których każda używała innych ustawień dla używanych w niej maszyn szyfrujących Enigma. Sieci te w ośrodku kryptologicznym w Bletchley Park nosiły nazwę "kluczy" () i przypisano im dodatkowe kryptonimy kodowe, takie jak "Red", "Chaffinch" i "Shark". Każda z jednostek działających w danej sieci otrzymywała co pewien czas listy ustawień Enigmy. W celu pomyślnego przesłania wiadomości zarówno maszyna nadawcza, jak i odbiorcza musiały być identycznie ustawione, włączając w to ten sam zestaw wirników ustawionych w takich samych pozycjach startowych i z identycznie okablowaną łącznicą kablową. Wszystkie dane o ustawieniach maszyn ustalano z wyprzedzeniem i drukowano w postaci książek kodowych.
Początkowe ustawienie Enigmy, jej klucz zawierał następujące dane:
Enigma została zaprojektowana w taki sposób, że transmisja musiała być bezpieczna także w przypadku, gdy sposób okablowania wirników był znany dla podsłuchującego. W praktyce jednak dane na temat okablowania wirników były tajne. Z użyciem wirnika o nieznanym sposobie kablowania przybliżona liczba wszystkich ustawień wynosiła około 3.28 * 10114 (około 380 bitów), natomiast w przypadku wirników o jawnym sposobie kablowania oraz znajomości ustawień malała ona do około 1023 (76 bitów). Użytkownicy Enigmy byli pewni, że bezpieczeństwo przekazu jest całkowite ze względu na olbrzymią liczbę możliwych kombinacji ustawień maszyny, a jedyną metodą rozkodowania wiadomości jest atak metodą "brute force".
Procedury.
Większość kluczy obowiązywała przez określony czas, przeważnie jeden dzień, jednak do szyfrowania każdej wiadomości wirniki były ustawiane indywidualnie. Postępowano tak dlatego, że duża liczba przekazów zaszyfrowanych w ten sam lub podobny sposób stanowiła doskonały materiał dla kryptologów do analizy częstościowej i łatwiejszego złamania szyfru. Związane to było także z tym, że typowa depesza wojskowa na początku zawierała identyfikator (zwykle kryptonim) nadawcy. Powodowało to, że w przypadku nadawców przesyłających dużą liczbę depesz (np. sztabów wysokiego szczebla) otrzymywano dużą liczbę depesz o identycznym początku (zaszyfrowany identyfikator nadawcy, który wywiad przeciwnika zwykle znał), co mogło ułatwić atak kryptologiczny. Aby temu przeciwdziałać, dla każdej wiadomości wprowadzano indywidualne ustawienia, podobnie jak we współczesnej kryptografii stosuje się wektor startowy. Zaszyfrowana właściwa pozycja wirników była transmitowana tuż przed głównym szyfrogramem. Procedura ta, nazywana procedurą wstępną, choć miała podnieść bezpieczeństwo, to przez błędy szyfrantów niemieckich pozwoliła na złamanie pierwszych wersji Enigmy.
Jedna z pierwszych procedur wstępnych została wykorzystana przez polskich kryptologów do pierwszego złamania szyfru Enigmy. Polegała ona na ustawieniu wirników zgodnie z kluczem dziennym, odczytanym z książki kodowej. Początkowe ustawienie wirników ("Grundstellung") mogło mieć postać AOH i taką kombinację ustawiał operator. Następnie wybierano przypadkową kombinację ustawień wirników np. EIN, która stawała się indywidualnym kluczem wiadomości. Klucz wiadomości był wpisywany dwukrotnie (w celu uniknięcia błędów) jako EINEIN i po zaszyfrowaniu mógł mieć postać XHTLOA, którą nadawano na początku przekazu szyfrowanego. Po nadaniu klucza operator ustawiał wirniki maszyny w pozycji EIN i rozpoczynał wpisywanie wiadomości do zaszyfrowania.
Procedura odbiorcza była operacją odwrotną. Najpierw w maszynę ustawioną zgodnie z kluczem dziennym wpisywano pierwszą odebraną sekwencję znaków XHTLOA, która po rozkodowaniu dawała indywidualny klucz szyfrogramu EINEIN. Następnie operator ustawiał wirniki Enigmy w pozycję EIN i przystępował do dekodowania właściwego przekazu.
Pierwszym błędem procedury wstępnej było nadawanie w początkowym okresie używania Enigmy indywidualnego klucza wiadomości tekstem otwartym. Drugim – konstruowanie klucza wiadomości z trzech znaków nadawanych dwukrotnie, co pozwoliło na odkrycie relacji pomiędzy pierwszym i czwartym znakiem, drugim i piątym, oraz trzecim i szóstym. Oba te niedostateczne zabezpieczenia transmisji pozwoliły pracownikom polskiego Biura Szyfrów na odtworzenie działania Enigmy i dekodowanie wiadomości. W 1940 roku zmieniono procedurę wstępną, zwiększając bezpieczeństwo szyfrów. Inne błędy szyfrantów niemieckich związane z tą procedurą to:
Podczas II wojny światowej książki kodowe Enigmy zawierały tylko dane na temat zestawu wirników i ich wzajemnego ułożenia, bez kluczy dziennych. Dla każdej wiadomości operator wybierał przypadkowe ustawienie początkowe wirników, np. WZA i przypadkowy klucz wiadomości np. SXT. Po ustawieniu wirników Enigmy w położenie WZA wpisywał klucz wiadomości SXT, otrzymując przykładowo ciąg znaków UHL. Następnie ustawiał wirniki maszyny w położenie SXT i kodował resztę informacji. Transmitowany meldunek rozpoczynał się od ciągu znaków mówiącego o ustawieniu początkowym WZA, następnie zakodowanego klucza wiadomości UHL, wreszcie właściwej treści szyfrogramu. Odbierający wiadomość operator wykonywał operacje odwrotne: najpierw ustawiał wirniki w pozycję WZA i dekodował z ciągu UHL klucz wiadomości SXT. Następnie ustawiał maszynę zgodnie z kluczem SXT i deszyfrował przekaz. Ta procedura wstępna była znacznie bezpieczniejsza niż przedwojenne, ponieważ nie zawierała podwójnej sekwencji znaków.
Procedura ta była wykorzystywana tylko przez siły lądowe i Luftwaffe. Stosowane przez Kriegsmarine były znacznie bardziej złożone. Wiadomość przeznaczona do zakodowania Enigmą musiała być wstępnie zakodowana na podstawie "Kurzsignalheft", książki skrótów kodowych, zawierającej tabele zamieniające całe sentencje i zwroty na czteroliterowe grupy liter. Uwzględniono każde możliwe wyrażenie i każdy temat wiadomości i sytuacji na morzu. Oddzielne kody posiadały operacje tankowania i zaopatrzenia na morzu, nazwy zatok, państw, broni, pogody, pozycji wrogich jednostek, czasu, współrzędnych itd. Celem przyjęcia takiego rozwiązania było nie tylko utrudnienie złamania szyfru, ale także umożliwienie przekazania jak największej informacji w formie jak najkrótszej depeszy, w celu uniknięcia namierzenia. Druga książka kodowa zawierała "Kenngruppen" i "Spruchschlüssel", czyli klucze identyfikacyjne i klucze wiadomości.
Skróty i wytyczne.
Enigma wykorzystywana w wojsku używała 26-literowego alfabetu. Znaki przestankowe zastępowane były przez rzadko występujące sekwencje liter. Spacja była zwykle pomijana lub zastępowana literą X, która była też używana jako kropka (lub przecinek dziesiętny). Niektóre znaki były różnie wykorzystywane przez różne siły zbrojne. Heer i Luftwaffe zamiast przecinka wykorzystywały ZZ, a zamiast znaku zapytania – frazę FRAGE lub FRAQ. Kriegsmarine z kolei zamiast przecinka wykorzystywała literę Y, a zamiast znaku zapytania – UD. Litery CH, jak w wyrazie "Acht" (osiem) lub "Richtung" (kierunek), były zastępowane przez Q (AQT, RIQTUNG). Dwa, trzy lub cztery zera zastępowane były przez odpowiednio: CENTA, MILLE oraz MYRIA.
Heer i Luftwaffe przesyłały wiadomości w postaci pięcioliterowych grup. Kriegsmarine używała innych czterowirnikowych maszyn Enigma i inaczej przesyłano też meldunki, w postaci grup czteroliterowych. Najczęściej używane słowa w celu zamaskowania ich w kodzie wiadomości pisano na różne sposoby. Przykładowo słowo "Minensuchboot" (trałowiec) pisano jako MINENSUCHBOOT, MINBOOT, MMMBOOT lub MMM354. Aby dodatkowo utrudnić pracę kryptologom, wprowadzono ograniczenie długości meldunku do 250 znaków. Dłuższe przekazy dzielono na części z których każda miała swój własny klucz wiadomości.
Historia powstania Enigmy.
Zanim Enigma osiągnęła swą ostateczną formę, zbudowano wiele odmian i modeli tej maszyny. Najwcześniejsze Enigmy, które pojawiły się na początku lat 20. XX wieku, były maszynami przeznaczonymi na rynek cywilny. W połowie lat 20. zaczęły ich używać także niemieckie siły zbrojne, wprowadzając całą gamę różnego rodzaju usprawnień, zwiększających bezpieczeństwo przekazywanych meldunków. Dodatkowo wiele innych państw zaadaptowało Enigmę do swoich własnych potrzeb lub wykorzystało podobną zasadę działania we własnych maszynach szyfrujących (patrz niżej).
Wersja handlowa Enigmy.
23 lutego 1918 roku niemiecki inżynier Artur Scherbius złożył wniosek o przyznanie patentu na wirnikową maszynę szyfrującą oraz założył wraz z Richardem Ritterem firmę Scherbius &amp; Ritter, której celem była produkcja tego urządzenia. Obaj przedstawili projekt maszyny zarówno niemieckiej Kriegsmarine, jak i Ministerstwu Spraw Zagranicznych, ale nie uzyskali zainteresowania żadnej z tych instytucji. W tym wypadku przekazali prawa patentowe firmie Gewerkschaft Securitas, z której 9 lipca 1923 powstało Chiffriermaschinen Aktien-Gesellschaft (Maszyny Szyfrujące Spółka Akcyjna) w której Scherbius i Ritter zostali członkami zarządu.
W Chiffriermaschinen AG rozpoczęto produkcję i reklamowanie wirnikowej maszyny szyfrującej Enigma model A, wystawiając ją na kongresie Powszechnego Związku Pocztowego w roku 1923 i 1924. Pierwszy model był duży 65×45×35 cm i ciężki (ok. 50 kg), głównie ze względu na zintegrowaną maszynę do pisania. Druga wersja – model B – miała bardzo podobną konstrukcję. Chociaż noszące tę samą nazwę Enigma, oba modele A i B maszyny różniły się od późniejszych wersji nie tylko wymiarami i masą, ale także sposobem kodowania, ponieważ nie posiadały walca odwracającego.
Walec odwracający – wymyślony przez kolegę Scherbiusa Williego Korna – został wprowadzony po raz pierwszy w maszynie Enigma C w 1926 roku. Element ten stał się kluczowym w konstrukcji maszyn Enigma.
Wersja C była mniejsza i w odróżnieniu od poprzedników nadawała się do przenoszenia. Zrezygnowano w niej ze zintegrowanej maszyny do pisania, wprowadzając w zamian panel z literami podświetlanymi żarówkami. Dla odróżnienia od pierwszych odmian A i B, Enigmę C nazywano czasem "świecącą Enigmą". Enigma C była używana dość krótko, gdyż już w 1927 roku zastąpiono ją maszyną Enigma D, która poza Niemcami była wykorzystywana również w Szwecji, Holandii, Anglii, Japonii, Włoszech, Hiszpanii, Stanach Zjednoczonych i Polsce.
Wersja wojskowa Enigmy.
Kriegsmarine jako pierwsza w Niemczech przyjęła na wyposażenie maszyny Enigma, oznaczone jako Funkschlüssel C ("Koder radiowy C"), którą wprowadzono do produkcji w 1925, a do służby w 1926. Klawiatura maszyny i panel z lampkami zawierały 29 liter – A–Z, Ä, Ö i Ü – które były umieszczone alfabetycznie, a nie tak jak na standardowej klawiaturze niemieckiej QWERTZU. Wirniki posiadały 28 znaków, a styki litery X były połączone na wprost, bez zamiany. Do szyfrowania wybierano trzy z zestawu pięciu typów wirników, a walec odwracający mógł być zainstalowany w jednej z czterech pozycji oznaczonych jako α, β, γ i δ. Niedługo potem w lipcu 1933 konstrukcja maszyny została zmodyfikowana.
Od 15 lipca 1928 niemiecka Reichswehra wprowadziła do służby własną wersję Enigmy, oznaczoną jako Enigma G, która w lipcu 1930 została zmodyfikowana do wersji Enigma I. Jest ona również nazywana "Enigmą Wehrmachtu" lub "Enigmą Służb" i była intensywnie używana także przez inne niemieckie organizacje wojskowe i rządowe (takie jak kolej niemiecka), zarówno przed, jak i w czasie II wojny światowej. Główną różnicą między handlową wersją Enigmy i Enigmą I było dodanie łącznicy kablowej do zamiany liter parami, co zwiększało bezpieczeństwo szyfru maszyny. Inną różnicą było zastosowanie nieruchomego walca odwracającego i przeniesienie wcięć zębatki obracającej wirniki z obudowy wirnika na pierścień alfabetyczny.
W 1930 OKH zasugerował Kriegsmarine zaadaptowanie Enigmy do własnych potrzeb, prezentując zwiększone bezpieczeństwo wersji z łącznicą kablową oraz łatwiejszą łączność między rodzajami sił zbrojnych. Ostatecznie Kriegsmarine przyjęła Enigmę na wyposażenie w 1934, wybierając zmodyfikowaną wersję, używaną przez siły lądowe, oznaczoną jako Funkschlüssel M lub M3. Heer i Luftwaffe wykorzystywały w tym czasie zestaw trzech typów wirników, ale Kriegsmarine dla zwiększenia bezpieczeństwa zamówiła zestaw 5 typów wirników, z których do zainstalowania można było wybrać trzy z nich.
W grudniu 1938 także inne formacje Wehrmachtu zaczęły wykorzystywać rozszerzony do pięciu typów zestaw wirników. W 1938 Kriegsmarine wzbogaciła swój zestaw wirników o dodatkowe dwa typy i kolejny typ w 1939, co dało zestaw 8 typów wirników. W sierpniu 1935 również Luftwaffe zaczęła stosować do komunikacji maszyny Enigma w wersji używanej przez siły lądowe. Pierwsza czterowirnikowa Enigma została wprowadzona po raz pierwszy w Kriegsmarine 1 lutego 1942 z przeznaczeniem do łączności z niemieckimi okrętami podwodnymi. Oficjalnie maszyna nosiła oznaczenie M4, a sieć w której je wykorzystywano, została oznaczona przez aliantów kryptonimami "Triton" (Tryton) oraz "Shark" (rekin). Dodatkowy, znacznie cieńszy wirnik został umieszczony w maszynie wraz z nowym, również cieńszym walcem odwracającym.
Zbudowano również o wiele bardziej skomplikowaną maszynę szyfrującą, posiadającą 8 wirników, ze zintegrowaną maszyną do pisania, oznaczoną jako Enigma II. W 1933 polskie stacje nasłuchowe przechwyciły transmisje szyfrogramów między niemieckim dowództwem najwyższego szczebla, ale sama maszyna jako zbyt zawodna i podatna na częste zacięcia nie znalazła większego zastosowania i została wkrótce wycofana.
Służby wywiadu i kontrwywiadu wojskowego III Rzeszy Abwehra wykorzystywały maszynę w wersji Enigma G (nazywaną "Abwehr Enigma"). Ta wersja Enigmy posiadała 4 wirniki z wieloma wcięciami, które powodowały częstsze obroty podczas szyfrowania, ale nie posiadała przełącznicy kablowej. Dodatkowo maszyna posiadała licznik, którego stan zwiększał się po każdym naciśnięciu klawisza, przez co zyskała dodatkową nazwę "Zahlwerk Enigma" ("Enigma licznikowa"; niem. "zahlwerk" – "licznik").
Poza Niemcami Enigmę wykorzystywano także w innych krajach. Marynarka wojenna Włoch zaadaptowała do celów wojskowych handlową wersję maszyny, nazwaną „Koderem Marynarki D”. Hiszpania wykorzystywała Enigmy podczas wojny domowej. W Szwajcarskiej armii i dyplomacji korzystano z maszyn Enigma, oznaczonych jako model K lub Swiss K, które były bardzo podobne do handlowej wersji cywilnej Enigmy D. Ta wersja maszyny została rozszyfrowana przez wiele zespołów kryptologów z Polski, Francji, Wielkiej Brytanii i Stanów Zjednoczonych (ostatnia nazwa kodowa to INDIGO). Enigma T, oznaczona nazwą kodową Tirpitz, została wyprodukowana specjalnie dla Japonii.
Ocenia się, że powstało około 100 tysięcy maszyn Enigma; większość tych, które ocalały po II wojnie światowej, została sprzedana do państw rozwijających się jako urządzenia wciąż zapewniające wystarczający poziom bezpieczeństwa transmisji. Utrzymanie w tajemnicy umiejętności odszyfrowywania Enigmy umożliwiło wywiadowi brytyjskiemu i innym wywiadom państw zachodnich dostęp do kodowanych informacji, w tym poczty dyplomatycznej państw, które nadal używały Enigmę.
Polskie prace nad złamaniem szyfru Enigmy.
Pierwsze próby złamania szyfru Enigmy podejmowali Francuzi, Anglicy i Polacy już pod koniec lat dwudziestych, jednak bez rezultatu. Głównym problemem dekryptażu było zastosowanie przełomowego na owe czasy maszynowego szyfrowania szyfrem polialfabetycznym, w których każda litera tekstu jawnego szyfrowana jest za pomocą innej permutacji alfabetu, co pozwala ukryć własności językowe szyfrogramu oraz czynić go niewrażliwym na próby dekryptażu podejmowane przy użyciu dotychczas stosowanych metod lingwinistycznych.
W łamaniu szyfrów główną rolę odgrywali lingwiści, którzy w procesie kryptoanalizy wyłapywali charakterystyczne cechy języka, takie jak częstość powtarzania się liter, długość wyrazów itd. W przypadku zastosowania mechanicznych maszyn szyfrujących analiza lingwistyczna nie przynosiła żadnych rezultatów, co wymusiło na kierownictwie Biura Szyfrów Oddziału II Sztabu Głównego zatrudnienie do pracy profesjonalnych matematyków.
W styczniu 1929 na Uniwersytecie Poznańskim z inicjatywy Biura Szyfrów zorganizowano kurs kryptologii, przeznaczony dla najlepszych studentów matematyki, znających język niemiecki. Wybór uczelni poznańskiej nie był przypadkowy, gdyż ze względu na położenie miasta znajomość niemieckiego była tam powszechna. Na kurs, którego wykładowcami byli dojeżdżający z Warszawy mjr Franciszek Pokorny, kpt. Maksymilian Ciężki oraz inż. Antoni Palluth, zostało skierowanych dwudziestu kilku najzdolniejszych uczniów profesora Zdzisława Krygowskiego, w tym Marian Rejewski, Jerzy Różycki i Henryk Zygalski.
Jesienią 1930 utworzono w Poznaniu ekspozyturę Biura Szyfrów, w której zatrudniono ośmiu najzdolniejszych absolwentów kursu kryptologii, w tym Rejewskiego, Różyckiego i Zygalskiego. Dwa lata później filia została rozwiązana, a Marian Rejewski, Jerzy Różycki i Henryk Zygalski od 1 września 1932 rozpoczęli pracę w Referacie Szyfrów Niemieckich w Biurze Szyfrów Sztabu Głównego Wojska Polskiego, w Pałacu Saskim w Warszawie. Ich głównym zadaniem było złamanie Enigmy. Mocarstwa zachodnie mocno wątpiły w możliwość złamania algorytmu szyfrującego Enigmy, wszystkie nieliczne próby zrozumienia mechanizmu szyfrowania „Enigmą” okazywały się nieskuteczne.
W październiku 1931 francuski wywiad Deuxième Bureau zwerbował Hansa-Thilo Schmidta (ps. „Asché”), który podczas dziewiętnastu spotkań przekazał zdjęcia wojskowej wersji „Enigmy”, opis sposobu jej używania, instrukcję posługiwania się kluczami szyfrującymi oraz tablice miesięczne kluczy. Kpt. Gustave Bertrand z francuskiego wywiadu kopie uzyskanych informacji przekazał wywiadowi brytyjskiemu oraz 8 grudnia 1931 Stefanowi Mayerowi i Gwido Langerowi z polskiego wywiadu. Informacje te przyspieszyły złamanie „Enigmy”, ale potrafili je wykorzystać tylko Polacy.
W grudniu 1932 udało się Rejewskiemu rozwiązać szyfr Enigmy. Polacy opracowali efektywne metody deszyfrowania Enigmy, wykorzystując w tym celu w sposób nowatorski istniejące teorie kombinatoryczne tzw. cykli i transpozycji. Do określania permutacji cykli wirników Enigmy wykorzystywano zaprojektowany przez Rejewskiego cyklometr i wykonany przez wytwórnię „AVA” i "karty charakterystyk", które ze względu na zmianę kodowania wprowadzoną 15 września 1938 przestały być wykorzystywane. Do tego czasu ustalenie kodu dziennego przy pomocy powyższych narzędzi zajmowało około 15 do 20 minut.
Około października 1938 Rejewski opracował unikalne elektromechaniczne urządzenie, nazwane "bombą kryptologiczną", którego zadaniem było automatyczne łamanie szyfru Enigmy w oparciu o opracowaną teorię cykli. Bomba kryptologiczna składała się z sześciu sprzężonych polskich sobowtórów Enigmy, napędzanych silnikiem elektrycznym. W połowie listopada tego samego roku zbudowano sześć takich bomb, wykorzystywanych wyłącznie do rozszyfrowywania podwójnie szyfrowanych kluczy dziennych. Wszystkie sześć „bomb” zbudowała wytwórnia „AVA”, koszt jednej z nich szacowany jest na ok. sto tysięcy przedwojennych złotych (obecnie równowartość ponad miliona PLN). Szyfrogramy dekodowano przy pomocy perforowanych płacht Zygalskiego, opracowanych w celu znajdowania właściwych połłączeń Enigmy. Jedna bomba kryptologiczna pozwalała na odkodowanie klucza dziennego w ciągu około dwóch godzin i zastępowała pracę około 100 ludzi.
Używany do złamania „Enigmy” cyklometr, płachty Zygalskiego, później także 15 zrekonstruowanych „sobowtórów „Enigmy” wyprodukowała Wytwórnia Radiotechniczna AVA, spółka założona z niejawnym udziałem Sztabu Głównego WP przez inż. Antoniego Pallutha, oficera wywiadu Sztabu Głównego, uzdolnionych krótkofalowców: Ludomira Danilewicza i jego brata Leonarda, podoficera wojsk łączności Edwarda Fokczyńskiego. Jej kierownikiem technicznym oraz głównym konstruktorem był Tadeusz Heftman Od tego czasu Polacy mogli odczytywać korespondencję niemiecką, choć nie było to proste, bowiem Niemcy stale udoskonalali maszynę i procedury szyfrowania. W lutym 1933 w spółce zamówiono także wyprodukowanie polskiej maszyny szyfrującej nazwanej „Lacida”. Nazwa pochodzi od „La” – płk. Langera szefa całej operacji, „ci” – od nazwiska por. Ciężkiego i „da” – od Danilewicza. AVA produkowała także sprzęt łączności dla wojska, policji, straży granicznej, a także urządzenia łączności oraz radiopodsłuchu dla Biura Szyfrów.
W 1939 Niemcy kolejny raz zmienili sposób szyfrowania, co wymusiło konieczność zbudowania dalszych 54 bomb kryptologicznych (aby łączna ich liczba wynosiła 60) i opracowania 60 kompletów bardzo pracochłonnych w wykonaniu płacht Zygalskiego (jeden komplet liczył 26 płacht), które miały zawierać ok. 1,5 mln perforacji. Praca taka znacznie wykraczała poza możliwości finansowe polskiego wywiadu, było też oczywiste, że prace nie zakończą się przed wybuchem wojny.
Przekazanie metod rozwiązania Enigmy aliantom.
Pierwsze spotkanie polskich, francuskich oraz brytyjskich specjalistów kryptologii i radiowywiadu zorganizowano 9 i 10 stycznia 1939 w Paryżu, w siedzibie francuskiego wywiadu. W konferencji określonej jako „X-Y-Z” uczestniczyli ze strony gospodarzy: mjr Gustave Bertrand i kpt. Henri Braguenie; Anglicy: komandorzy Alastair Dennistor i Hugh Foss, a także Dillwyn Knox. Polski wywiad reprezentowany był przez płk Gwidona Langera i mjr Maksymiliana Ciężkiego; Polacy mieli ujawnić złamanie „Enigmy” jedynie w przypadku uzyskania wartościowych informacji na jej temat od pozostałych uczestników spotkania. Ponieważ Francuzi i Brytyjczycy nie mieli żadnych sukcesów, ustalono jedynie zasady współpracy w dekryptażu „Enigmy”.
W lipcu 1939, w związku ze spodziewanym wybuchem wojny oraz wspierającą Polskę postawie Francji, 25 i 26 lipcu 1939 odbyła się druga konferencja „X-Y-Z”, w ośrodku polskiego Biura Szyfrów w Pyrach pod Warszawą. Pracowały tam cztery radiostacje krótkofalowe dużej mocy (dalekiego zasięgu), konstrukcji inż. Tadeusza Heftmana, wyprodukowane przez wytwórnię „AVA”, służące do radiopodsłuchu oraz wychwytywania niemieckich depesz szyfrowanych „Enigmą”. Do wymienionych wcześniej oficerów wywiadu trzech państw dołączył płk Stewart Menzies z brytyjskiego wywiadu. Zdumionym Francuzom i Brytyjczykom Polacy przekazali po jednym egzemplarzu sobowtóra „Enigmy”, wyprodukowanego przez wytwórnię „AVA” oraz dokumentację dotyczącą metod rozwiązywania nastawień i kluczy „Enigmy”.
Dekryptaż „Enigmy” po wybuchu wojny.
Po wybuchu wojny kryptolodzy Biura Szyfrów ewakuowali się do Rumunii, następnie z pomocą francuskiego attaché wojskowego do Paryża. Pomimo nalegań Brytyjczyków, Francuzi nie zgodzili się na utworzenie polsko – francusko – brytyjskiego ośrodka dekryptażu „Enigmy”. Za zgodą polskich władz ustalono, że polscy kryptolodzy będą pracować we francuskim ośrodku dekryptażu, kierowanym przez mjr Gustave Bertranda; w pracach miał uczestniczyć brytyjski oficer łącznikowy kpt. Kenneth MacFarlan. Ośrodek zlokalizowano 35 km od Paryża, w willi Chateau de Vignolles w miejscowości Gretz-Armainvilliers. Ulokowano tam francuską jednostkę kryptologiczną (kryptonim „P.C.Bruno”, Poste de Commandement Bruno); ekipa piętnastu polskich kryptologów otrzymała kryptonim „Ekipa Z”. Prace związane z dekryptażem „Enigmy” podjęto 20 października 1939.
Ekipę tworzyli: ppłk dypl. Gwido Langer (kierownik); współpracował z mjr Bertrandem oraz kpt. MacFarlanem. Łamaniem szyfrów niemieckich zajmowali się: mjr Maksymilian Ciężki (kierownik); współpracował z mjr Renardem. Szyfry ręczne łamał kpt. Wiktor Michałowski, Larcher, por. Antonii Palluth. Szyfry maszynowe – Marian Rejewski, kpt. Braquenie oraz kryptolodzy: Jerzy Różycki, Henryk Zygalski; deszyfranci: ppor. Kazimierz Gaca, Ryszard Krajewski, Sylwester Palluth (bratanek Antoniego), por. Henryk Paszkowski. Szyfry sowieckie łamali: kpt. Jan Graliński, por. dr Stanisław Szachno, Piotr Smoleński. Za technikę odpowiedzialny był st. majster Edward Fokczyński.
Wielka Brytania zorganizowała własny ośrodek dekryptażu w Bletchley Park (kryptonim „Station X”) pod Londynem. Prace prowadzone były pod kierunkiem Alana Turinga, który wkrótce dostarczył Polakom 60 wykonanych przez Brytyjczyków „płacht Zygalskiego”, póxniej wielokrotnie przyjeżdżał na konsultacje. Wyniki prac polskiego zespołu przekazywane były na bieżaco Brytyjczykom, z Bletchley Park dostarczano zaszyfrowane „Enigmą” niemieckie depesze, przechwycone przez brytyjski radiowywiad. Prace nad dekryptażem Enigmy postępowały, 17 stycznia 1940 Polacy złamali pierwszy klucz dzienny „Enigmy” używanej przez Wehrmacht. Później liczba odnalezionych nastawień i kluczy wzrosła do 126. Do czerwca 1940 odczytano 8.335 zaszyfrowanych depesz. Brytyjczycy w Bletchley Park do dekryptażu „Enigmy” wykorzystywali maszynę Turinga, której zasada działania była odmienna od polskiej „bomby kryptologicznej”. Od 8 kwietnia 1940 Anglicy w miarę regularnie odczytywali już samodzielnie niemieckie depesze.
Polski zespół pracował w „P.C.Bruno” do 14 czerwca 1940; po upadku Francji 24 czerwca ekipę ewakuowano do Tuluzy, stamtąd samolotem 3 lipca do Oranu, potem do Algieru. Po kilku dniach zaakceptowano plan mjr Bertranda kontynuowania praca na nieokupowanym terenie Francji. Ekipa podjęła pracę na terenie administrowanym przez rząd Vichy w willi Chateau des Fouzes (kryptonim „Cadix”) w Uzès niedaleko Nîmes. Polską ekipę podporządkowano Oddziałowi II Sztabu Naczelnego Wodza, otrzymała kryptonim „Ekspozytura 300”.
W Algierze pozostała filia tego ośrodka, którą kierował major Maksymilian Ciężki. Co kilka miesięcy kryptolodzy z obu ośrodków wymieniali się, podróżując drogą morską z Francji do Algieru. Podczas jednej z takich wypraw w katastrofie statku "Lamoricière" płynącego z Algieru do Marsylii 9 stycznia 1942 w pobliżu Minorki (archipelag Balearów) zginęło trzech polskich pracowników ośrodka "Cadix", wśród nich Jerzy Różycki i oficer francuski.
Po wkroczeniu Niemców do południowej Francji 9 listopada 1942, zaistniała konieczność ewakuowania ośrodka "Cadix" z rejonu Uzès.
Rejewski i Zygalski 29 stycznia 1943 przedostali się przez granicę francusko-hiszpańską, ale w Hiszpanii prawie natychmiast zostali aresztowani przez tamtejszą policję. Najpierw osadzono ich w więzieniu w Séo de Urgel, a 24 marca przeniesiono do innego więzienia w Lérida. Ostatecznie dzięki wstawiennictwu Polskiego Czerwonego Krzyża obaj kryptolodzy zostali 4 maja uwolnieni i odesłani do Madrytu. Następnie Rejewski i Zygalski przedostali się do Portugalii, skąd na pokładzie HMS "Scottish" popłynęli do Gibraltaru, a stamtąd samolotem Douglas DC-3 do Wielkiej Brytanii, gdzie dotarli 3 sierpnia 1943. 16 sierpnia obaj rozpoczęli pracę w jednostce radiowej Sztabu Naczelnego Wodza Polskich Sił Zbrojnych w Stanmore-Boxmoor pod Londynem, gdzie pracowali do zakończenia wojny.
Pozostali członkowie przedwojennego Biura Szyfrów – płk Gwidon Langer i mjr Maksymilian Ciężki – zostali złapani przez Niemców i wysłani do oflagu Schloss-Eisenberg. Inż. Antoni Palluth i Edward Fokczyński trafili do obozu koncentracyjnego Sachsenhausen, gdzie obaj ponieśli śmierć; Palluth podczas alianckiego nalotu, a Fokczyński z wycieńczenia.
Dzięki pracy kryptologów polskich, a później także brytyjskich z Bletchley Park, oraz dzięki przechwyconym w międzyczasie egzemplarzom Enigmy, pod koniec wojny praktycznie cała korespondencja szyfrowana przy jej pomocy była odczytywana przez aliantów. Średnio na dekryptaż niemieckiego meldunku wystarczał jeden do dwóch dni.
Ocalałe Enigmy.
Informacje o rozszyfrowaniu Enigmy były utajnione do lat 70. XX wieku. Później maszyny wyszły z użycia i wiele egzemplarzy trafiło do zbiorów muzealnych w Europie i Stanach Zjednoczonych. W Polsce jedyny działający egzemplarz znajduje się w stołecznym Narodowym Muzeum Techniki. Urządzenie zostało uruchomione w 2015 roku, w standardowej wersji „typ I” dla wojsk lądowych i sił powietrznych, wariant do użytku w warunkach polowych z 1944 roku. Enigma wyposażona jest w wirniki szyfrujące II, III, V oraz bęben odwracający B. Ponadto enigmy znajdują się w Muzeum Wojska Polskiego (wersja wojskowa trójwirnikowa i handlowa) w Warszawie, Muzeum Wojska w Białymstoku i Muzeum Oręża Polskiego w Kołobrzegu, a także w izbie muzealnej Centralnego Ośrodka Szkolenia Agencji Bezpieczeństwa Wewnętrznego w Emowie.
W Deutsches Museum w Monachium znajdują się dwa egzemplarze, z 3 i 4 wirnikami, oraz kilka wcześniejszych wersji cywilnych. Jeden eksponat trzywirnikowy znajduje się w Muzeum Poczty w Berlinie. Działający egzemplarz Enigmy znajduje się w National Cryptologic Museum NSA w Fort Meade w stanie Maryland, gdzie udostępniono maszynę zwiedzającym, pozwalając własnoręcznie szyfrować i deszyfrować tekst. Inne egzemplarze znajdują się w muzeach Computer History Museum w Stanach Zjednoczonych, w Bletchley Park w Wielkiej Brytanii oraz w Instytucie Józefa Piłsudskiego w Londynie i Australian War Memorial w mieście Canberra w Australii. Wiele maszyn znajduje się także w rękach kolekcjonerów prywatnych. Egzemplarz Enigmy z Instytutu Józefa Piłsudskiego w Londynie został zbudowany przez Polaków w 1940 roku i był na wyposażeniu ośrodka Cadix w Uzes. Podczas likwidacji ośrodka maszynę, sprzęt i rzeczy osobiste zamurowano w piwnicy. W maju 1945 roku Marian Rejewski i Henryk Zygalski udali się z Londynu na południe Francji, by odzyskać pozostawione tam przed ewakuacją rzeczy i dostarczyć je do Anglii.
Pojawiające się sporadycznie na aukcjach Enigmy osiągają ceny rzędu 150-350 tysięcy dolarów. Można również zakupić działające repliki maszyn w wersji M4 Kriegsmarine, elektroniczne symulatory (tzw. Enigma-E) oraz oprogramowanie symulujące jej działanie. Jeden z nielicznych zachowanych egzemplarzy Enigmy I, wystawiony w 2020 roku na aukcji w Wiedniu, został sprzedany za 117,8 tys. euro.
Inne maszyny oparte na Enigmie.
Enigma wywarła znaczący wpływ na konstrukcje wielu maszyn szyfrujących, głównie opartych na wirnikach. Brytyjska maszyna szyfrująca Typex została zainspirowana patentami Enigmy, także tymi, które nie zostały wykorzystane w najsłynniejszej wojskowej wersji maszyny. Rząd brytyjski w trosce o zachowanie tajemnicy nie ujawnił informacji o wykorzystanych rozwiązaniach i w związku z tym nie płacił żadnych tantiem autorom projektu. Japończycy wykorzystywali własną maszynę szyfrującą, która przez kryptologów amerykańskich została określona kryptonimem GREEN. Miała cztery wirniki, ale zainstalowane współpłaszczyznowo obok siebie (tzn. nie na jednej osi). Japońska maszyna nie znalazła aż tak szerokiego zastosowania, jak niemiecka. Amerykański kryptolog William Friedman zbudował własną maszynę, oznaczoną M-325, odmienną konstrukcyjnie, ale kodującą w podobny do Enigmy sposób.
W 2002 roku zbudowano w Holandii unikalną maszynę, której konstrukcja opiera się na idei Enigmy, ale posiada 4 wirniki z zestawem 40 znaków każdy, co umożliwiło wykorzystanie również cyfr i znaków przestankowych. Każdy z wirników składa się z 509 części.
Zobacz też.
Inne maszyny szyfrujące z czasów II wojny światowej:

</doc>
<doc id="1366" url="https://pl.wikipedia.org/wiki?curid=1366" title="Erwin Rommel">
Erwin Rommel

Erwin Johannes Eugen Rommel (ur. 15 listopada 1891 w Heidenheim an der Brenz, zm. 14 października 1944 w Herrlingen) – niemiecki feldmarszałek.
Erwin Rommel był najmłodszym niemieckim feldmarszałkiem ("Generalfeldmarschall") podczas II wojny światowej. Dowodził Afrika Korps – niemieckim korpusem ekspedycyjnym w Afryce. Dzięki swoim znakomitym posunięciom i taktyce szybkiego przemieszczania wojsk stał się żywą legendą wśród żołnierzy niemieckich, ale przede wszystkim wśród aliantów. Ze względu na przebiegłość nazwany "Lisem Pustyni" (niem. "Wüstenfuchs"). Pod koniec wojny (1944) został skierowany do Francji jako dowódca Grupy Armii B, z zadaniem poprawienia umocnień w Normandii, w obliczu spodziewanej alianckiej inwazji. Miał syna.
Dzieciństwo i kariera przedwojenna.
Erwin Johannes Eugen Rommel urodził się 15 listopada 1891 w Heidenheim pod Ulm, małym mieście w Wirtembergii, jako syn dyrektora szkoły i trzecie z pięciorga dzieci. Mimo sporych zdolności uczył się nie najlepiej. Wolny czas najczęściej spędzał na powietrzu, jeżdżąc dużo na rowerze i na nartach. Zabawy te rozbudziły w nim miłość do otwartych przestrzeni. Lubił zabawki mechaniczne, w wieku 17 lat wraz z przyjaciółmi zbudował model samolotu i szybowiec naturalnych rozmiarów. Wahał się, czy zostać inżynierem, czy żołnierzem. W wieku 18 lat zdecydował i 19 lipca 1910 roku zaciągnął się jako fahnenjunker do 124 Wirtemberskiego Pułku Piechoty "König Wilhelm I" w Weingarten w Górnej Szwabii. Następnie naukę kontynuował w Szkole Wojennej Königliche Kriegsschule w Gdańsku.
Po trzech miesiącach od wstąpienia do akademii wojskowej, awansował do stopnia kaprala, a po kolejnych dwóch na sierżanta. Zapamiętano go jako bystrego młodzieńca, komunikatywnego, ale nieuległego, który mówi powoli i po namyśle. Był opanowany, powściągliwy w spożyciu alkoholu, niepalący. Szkołę ukończył bez większych sukcesów. Ze wszystkich przedmiotów otrzymał ocenę „dostateczny” i tylko w rubryce "Führung" (zdolności przywódcze) wpisano mu „dobry”.
W styczniu 1912 roku otrzymał szlify podporucznika i został odesłany do rodzimego pułku stacjonującego w budynkach poklasztornych w Weingarten, gdzie zajmował się szkoleniem rekrutów. 6 sierpnia 1914 roku jego jednostka otrzymała rozkaz wymarszu na front I wojny światowej.
I wojna światowa.
Podczas I wojny światowej Rommel służył we Francji, Rumunii i Włoszech. Pierwszy raz został ranny (w udo) 14 września 1914 roku w Lesie Argońskim. Do linii wrócił po 3-miesięcznym leczeniu i natychmiast wykazał się zdolnościami dowódczymi i inicjatywą. Na czele kompanii zdobył umocniony punkt oporu Francuzów, po czym wycofał się, tracąc zaledwie 5 ludzi.
Następnie skierowany został na przeszkolenie w "Württemberg Gebirgsbataillon" (wirtemberskim batalionie górskim) w Arlbergu w Alpach Austriackich. W czasie szkolenia wziął krótki urlop i ożenił się z Lucie-Marie Mollin, urodzoną w Gdańsku, pochodzącą z zachodniopruskiego ziemiaństwa. Z tego związku w 1928 roku przyszedł na świat syn Manfred, który po wojnie był burmistrzem Stuttgartu.
Najpierw w randze porucznika w 1915 w Wogezach, a następnie w Rumunii i Włoszech, zwrócił uwagę dowództwa, jako oficer umiejętnie prowadzący oddziały podczas licznych misji frontowych.
25 października 1917 roku jego oddział wielkości batalionu zaatakował i zdobył szczyt Matajur, biorąc do niewoli około 150 oficerów i 9000 żołnierzy armii włoskiej oraz 81 dział. Od tego momentu Erwin Rommel nie cenił żołnierzy włoskich zbyt wysoko. Jego oddział odegrał też znaczącą rolę podczas bitwy pod Caporetto. Był trzykrotnie ranny i otrzymał Krzyż Żelazny I i II klasy. Krótko po trzecim zranieniu i rekonwalescencji, mimo protestów, awansowano go na kapitana i przeniesiono go do pracy w sztabie. Za sukces wojenny z 25 października 1917 r. Cesarz Niemiecki i Król Prus Wilhelm II uhonorował oficera najwyższym odznaczeniem cesarskim – orderem Pour le Mérite w klasie wojskowej.
Lata międzywojenne.
Po wojnie Erwin Rommel założył Związek Starych Towarzyszy ("Kameradschaft"), składający się z ocalałych członków jego batalionu, z którymi do końca życia utrzymywał zażyłą przyjaźń.
W „stutysięcznej” armii, z czterema tysiącami oficerów, na którą pozwalał Niemcom traktat wersalski, Erwin Rommel przeszedł przez rozmaite przydziały. Dowodził m.in. kompanią karabinów maszynowych w Stuttgarcie, a po roku 1933 był w Ministerstwie Wojny oficerem łącznikowym z Hitlerjugend. Szkolił żołnierzy, poczynając od piechoty w Dreźnie. W 1935 roku był już podpułkownikiem i dowódcą batalionu, a następnie szefem kursów w akademii wojskowej w Poczdamie. W okresie poczdamskim napisał książkę „Piechota atakuje” ("Infanterie greift an"), w której zawarł swoje doświadczenia z czasów I wojny światowej i zilustrował własnymi rysunkami i mapami. Książka ta zwróciła uwagę Adolfa Hitlera, który w czasie wojny także był żołnierzem piechoty.
II wojna światowa.
Polska 1939.
Jesienią 1938 Adolf Hitler wyznaczył go dowódcą swej ochrony podczas wizyty w zajętej Czechosłowacji, gdzie dowodził batalionem eskorty wodza ("Führer-Begleit-Bataillon" – FBB). Od sierpnia 1939 do lutego 1940, m.in. w czasie pobytu Adolfa Hitlera w Polsce po rozpoczęciu II wojny światowej, Rommel pełnił funkcję komendanta Kwatery Głównej Hitlera ("Der Kommandant Führerhauptquartier"). Np. w tej roli przebywał w dniach 19–26 września 1939 z Adolfem Hitlerem w sopockim Kasino-Hotel.
Francja 1940.
W lutym 1940 Erwin Rommel, już jako generał major, pomimo braku doświadczenia w kierowaniu oddziałami pancernymi, objął dowództwo nad 7 Dywizją Pancerną. Trzy miesiące później, podczas inwazji na Francję, miał okazję sprawdzenia swoich teorii. W błyskawicznej kampanii jego żołnierze sforsowali Mozę, odparli brytyjski kontratak pod Arras i przedarli się przez francusko-belgijskie fortyfikacje, po czym jako pierwsza formacja dotarli do kanału La Manche. Kierując się następnie ku wybrzeżom Atlantyku, jego oddziały zniszczyły dwie francuskie dywizje. Akcje dywizji Erwina Rommla zdobyły podziw nawet u nieprzyjaciela. Błyskawicznie zdobył wiele alianckiego uzbrojenia, wziął do niewoli blisko 100 tysięcy jeńców. Jego nazwisko nie schodziło z nagłówków gazet, a Francuzi, ze względu na siłę, szybkość i zaskoczenie, nazwali jego dywizję "la Division Fantome", czyli Dywizją Duchów.
Po sukcesach Dywizji Duchów niemiecka prasa zasypywała generała pochwałami. Zarówno w Niemczech, jak i za granicą zaczęły się pojawiać plotki o jego rzekomej przeszłości: był murarzem i dawnym towarzyszem Adolfa Hitlera, jednym z jego pierwszych popleczników i bojówkarzem, dzielnym członkiem oddziału szturmowego, policjantem itd. Propaganda ta odniosła pewien skutek, bo np. jeszcze dziesięć lat po zakończeniu wojny amerykańskie encyklopedie pisały o „dowódcy oddziałów szturmowych”.
Afryka 1941–1943.
Generał Erwin Rommel przybył do Trypolisu 12 lutego 1941 roku. Jego przybycie do Afryki Północnej wiązało się ze znacznymi niepowodzeniami wojsk włoskich. Feldmarszałek Walther von Brauchitsch powierzył mu dowództwo nad 5 Dywizją Lekką i 15 Dywizją Pancerną, z zadaniem wsparcia włoskich wojsk zmotoryzowanych. Rommel miał podlegać włoskiemu marszałkowi Grazianiemu. 18 lutego, czyli w sześć dni po przybyciu do Afryki, rozkazem Hitlera powołano niezależny od dowództwa włoskiego korpus ekspedycyjny Afrika Korps. Dowodząc tymi oddziałami, Rommel zdobył największą sławę wojenną. Jego taktyczna maestria i zmysł dowódczy pozwoliły, mimo słabszego zaopatrzenia i mniejszej mobilności, odnieść wiele spektakularnych zwycięstw nad siłami aliantów.
Jego początkowe sukcesy w Libii, gdzie miał odeprzeć aliantów w stronę granicy z Egiptem, a następnie w samym Egipcie, przyniosły mu przydomek „Lisa Pustyni”. 30 stycznia 1942 roku został awansowany do stopnia generała pułkownika. Jego nominacja zbiegła się w czasie ze zdymisjonowaniem dowódcy sił brytyjskich Archibalda Wavella, którego zastąpił generał Claude Auchinleck. W tym okresie Afrika Korps, który od sierpnia 1941 roku był częścią Panzergruppe Afrika, zmagał się nie tylko z wrogiem, ale także z ogromnymi problemami logistyczno-zaopatrzeniowymi, gdyż po agresji III Rzeszy na Związek Sowiecki, afrykański teatr działań został zepchnięty przez Hitlera na dalszy plan.
"Lis Pustyni" zyskał sobie popularność wśród żołnierzy m.in. tym, że na froncie zawsze spożywał takie same posiłki jak oni, nawet gdy ograniczały się one do kilku kromek chleba. Jadał w towarzystwie zwykłych żołnierzy, rozmawiając z nimi i dowcipkując. Podczas bitwy zawsze znajdował się kilkaset metrów za czołgami pierwszego rzutu w swym wozie sztabowym, przez co często ryzykował życie. Gdy pewnego razu żołnierze Afrika Korps zatrzymali się na zbyt długi postój, Rommel wszedł między nich i krzyknął: „Jeśli natychmiast się nie ruszycie, to tak was kopnę w dupę, że od razu znajdziecie się w Kairze!”. Następnie wsiadł do samochodu i jechał za żołnierzami.
W listopadzie 1941 roku Sprzymierzeni przeszli do kontrofensywy, zadając oddziałom Rommla znaczne straty, zmusili go do wycofania się na linię Bengazi. Kontratak niemiecki nastąpił 26 maja 1942 po dostarczeniu zaopatrzenia, amunicji oraz nowych czołgów. Przy ich pomocy 21 czerwca 1942 roku oddziały niemieckie zdobyły opierający się wszystkim dotychczasowym szturmom Tobruk, a wraz z nim duże zapasy uzbrojenia, którego nie zdążyli zniszczyć wycofujący się Brytyjczycy. Następnego dnia Rommel został awansowany do stopnia feldmarszałka Rzeszy.
Armia brytyjska wycofała się na umocnione pozycje pod El Alamein. Właśnie tam generała Auchinlecka zastąpił generał Bernard Law Montgomery. Celem nowego dowódcy było pokonanie sił Osi za wszelką cenę i wyparcie ich z Afryki. Alianci mieli znaczną przewagę logistyczną. Dysponowali dużym wsparciem sił lotniczych. W czasie nieobecności Rommla, spowodowanej wyjazdem feldmarszałka do Europy celem przekonania Hitlera o konieczności wzmocnienia wojsk niemieckich w Afryce, Brytyjczycy przypuścili atak na pozycje niemieckie. Rommel wrócił do Afryki dwa dni po rozpoczęciu II bitwy pod El Alamein. Nie zdołał jednak powstrzymać wojsk brytyjskich. Montgomery został awansowany do rangi marszałka i wyniesiony do godności para, zaś prasa nadała mu tytuł „Lord Montgomery of Alamein”. W wyniku podjętych przezeń działań Afrika Korps znalazł się w pełnym odwrocie. Ponad 30 tysięcy żołnierzy państw Osi dostało się do niewoli. W krótkim czasie Afrika Korps został z Afryki wyparty.
Rommel został ewakuowany z Tunezji w marcu 1943 roku. Z rozkazu Hitlera objął dowództwo Grupy Armii B w północnych Włoszech. W kampanii tej Erwin Rommel, jako pierwszy oficer wojsk lądowych, został odznaczony Krzyżem Rycerskim z Liśćmi Dębowymi, Mieczami i Brylantami.
Francja 1943–1944.
Po opuszczeniu żołnierzy w Afryce stosunki między Rommlem a Hitlerem uległy pogorszeniu. Rommel, który dotychczas był zauroczony posunięciami führera – zarówno wojennymi, jak i ekonomicznymi, stracił wiarę w geniusz wodza i nie odzyskał jej już do końca życia. Kiedy 12 maja 1943 wojska Osi w Afryce kapitulowały, Rommla wezwano do Berlina. Rozgoryczony Hitler, blady i zmęczony, przyznał, że powinien posłuchać wcześniejszych próśb feldmarszałka.
Rommel, chcący ponownie znaleźć się w centrum działań wojennych, otrzymał rozkaz inspekcji nadbrzeżnych fortyfikacji, rozciągających się od Danii aż po Pireneje. Mimo zapewnień propagandy o solidnym przygotowaniu umocnień zaszokowany zameldował Naczelnemu Dowództwu o miernym stanie ich gotowości i słabym przygotowaniu do odparcia przypuszczanej inwazji wojsk sprzymierzonych w rejonie Wału Atlantyckiego.
Po kontroli nadbrzeżnych umocnień w Danii "Lis Pustyni" został oddelegowany do Francji. Stacjonujące tam oddziały niemieckie podlegały feldmarszałkowi Gerdowi von Rundstedtowi, naczelnemu dowódcy na froncie zachodnim. Hitler niezbyt jasno sprecyzował zadania Rommla. Szybko doszło do utarczek i sporów kompetencyjnych pomiędzy dowódcami. W trakcie gorącej dyskusji uzgodniono, że młodszemu Rommlowi przypadnie nadzór operacyjny nad odcinkiem przewidywanej inwazji pomiędzy ujściem Loary a granicą niemiecko-holenderską, a także, że 15 stycznia Rommel obejmie dowództwo wszystkich taktycznych oddziałów na wybrzeżach naprzeciw Anglii.
Rommel, zdając sobie sprawę, że w konfrontacji z przeciwnikiem kontrolującym przestrzeń powietrzną nie ma szans na zwycięstwo, zaproponował, by jednostki pancerne zostały rozmieszczone w małych ugrupowaniach jak najbliżej linii frontu. Uważał, że sukces zależeć będzie od wygranej na plażach, zanim jeszcze wojska aliantów zdołają utworzyć znaczniejszy przyczółek. Jego dowódca był jednak innego zdania i za cel obrał sformowanie dużej grupy pancernej nieopodal Paryża. Lądowanie wojsk sprzymierzonych 6 czerwca 1944 zaskoczyło Erwina Rommla na przyjęciu urodzinowym żony w Herrlingen, gdzie zatrzymał się w drodze na naradę z Hitlerem w Berchtesgaden.
17 lipca 1944 samochód Erwina Rommla został ostrzelany przez alianckie myśliwce. Feldmarszałek został poważnie ranny: doznał urazu lewej strony czaszki oraz kości policzkowej. Już nigdy nie miał zobaczyć pola bitwy. Jego kariera wojskowa dobiegła końca.
Zamach na Hitlera a Rommel.
Po nieudanym zamachu Heinrich Himmler i Martin Bormann poinformowali Hitlera, że Rommel solidaryzował się ze spiskowcami. Przedstawili mu raporty SD i informacje würzburskiego kreisleitera. Potwierdzeniem chwiejnej postawy feldmarszałka w oczach Hitlera był jego apel do führera, by zakończyć wojnę podpisaniem układu z aliantami. W kręgu najbliższych mu osób mówił też, że wojna jest przegrana. Ze względu na ogromną popularność Rommla Hitler zdecydował o zgładzeniu go po cichu i bez rozprawy sądowej. Rozkaz wykonał generał piechoty Wilhelm Burgdorf. Wraz z Ernstem Maiselem przybył do Rommla i postawił go przed wyborem: publiczny proces i kompromitacja oraz prawdopodobny lincz na rodzinie lub zażycie cyjanku i uniknięcie dalszych nieprzyjemności.
Przed śmiercią Rommel powiedział żonie i synowi tylko „umrę za piętnaście minut” i odjechał wraz z Burgdorfem i Maiselem. Zmarł w samochodzie. Opinię publiczną poinformowano, że Erwin Rommel zmarł w wyniku odniesionych ran. Wyprawiono mu pogrzeb państwowy ze wszystkimi honorami, na który jednak nie przybyli najwyżsi urzędnicy NSDAP.
Legenda Rommla.
Niemiecka propaganda świadomie pracowała nad wykreowaniem feldmarszałka na ideał niemieckiego żołnierza. Wybór właśnie na jego osobę padł z wielu powodów: z jednej strony przemawiały za tym niewątpliwe talenty wojskowe i przywódcze Rommla, jego ogromna ambicja i popularność wśród żołnierzy, ale także sposób bycia i atrakcyjny wygląd; z drugiej był on pupilkiem Hitlera, z którym niemal do końca łączyła go specyficzna więź – obaj mieli w sobie rodzaj uroku magnetyzującego otoczenie i bez oporów wykorzystywali to do swoich celów.
Rommel z ochotą współpracował nad tworzeniem owego wizerunku, obiecując sobie po tym przyśpieszenie kariery. Nie tylko był najczęściej fotografowanym niemieckim wojskowym, ale otrzymał nawet od Goebbelsa kamerę wraz z operatorem, by uwieczniać swe sukcesy podczas kampanii we Francji i w Afryce. W jego sztabie byli oficerowie odpowiedzialni za pracę nad wizerunkiem feldmarszałka. Jeszcze w 1940 nakręcono film fabularny „Sieg im Westen”, gloryfikujący zwycięstwo nad Francją, gdzie jedną z głównych postaci był Erwin Rommel. Charakteryzują go takie cnoty żołnierskie jak poczucie obowiązku i honoru, dyscyplina, pewność zwycięstwa, bezgraniczna lojalność. Posunięto się nawet do opublikowania fikcyjnego życiorysu Rommla, ufryzowanego na modłę narodowo-socjalistyczną, przeciw czemu zresztą bezskutecznie protestował.
Szczyt popularności osiągnął Rommel podczas kampanii w północnej Afryce. Prasa pełna była jego zdjęć na tle egzotycznych krajobrazów, kojarzonych przez czytelników z ciągłym powiększaniem terytorium Trzeciej Rzeszy, zdobywaniem kolonii i zaspokajających tęsknotę przeciętnego Niemca za dalekimi podróżami. Zwłaszcza od czasu nasilających się klęsk na froncie wschodnim, bardzo wiele uwagi poświęcano sukcesom Afrika Korps i jego dowódcy. Także alianci (np. Churchill) publicznie wypowiadali się z uznaniem o feldmarszałku. Przyczyny tego nie są jednak całkiem jednoznaczne – był on faktycznie bardzo zdolnym oficerem, z drugiej jednak strony istniała pilna potrzeba wyjaśnienia własnym społeczeństwom przyczyn ponoszonych klęsk, mimo przewagi militarnej. Ponadto alianci poszukiwali przyszłego przywódcy Niemiec ponazistowskich. Musiał to być człowiek popularny we własnym kraju, a jednocześnie niekontrowersyjny dla partnerów zagranicznych.
Także kino – w tym Hollywood – podchwyciło legendę Rommla. Do dziś, jako rycerski wojownik, walczący za swój kraj, skutecznie, ale bez barbarzyństwa, uosabia on w Niemczech mit „niepokalanego Wehrmachtu” – armii, która, w przeciwieństwie do SS, walczyła honorowo i jedynie na froncie. Powojenna armia niemiecka – Bundeswehra – długo uważała Rommla za jedną ze świetlanych postaci w swej historii, jego imieniem nazwano koszary w Goslarze i okręt wojenny. Fakt, że sympatyzował z zamachowcami na Hitlera, czynił go atrakcyjnym także dla społeczeństwa niemieckiego. Zapomniano przy tym, że karierę zrobił w czasach nazistowskich i aktywnie wspierał goebbelsowską propagandę wielkich Niemiec. Dopiero w roku 2001 usunięto tablicę z jego nazwiskiem w kasynie oficerskim w Goslarze, twierdząc, że feldmarszałek był żołnierzem zbrodniczego reżimu, więc honorowanie go byłoby honorowaniem hitlerowskiej III Rzeszy.

</doc>
<doc id="1367" url="https://pl.wikipedia.org/wiki?curid=1367" title="Entropia">
Entropia

Entropia ("s" lub "S") – termodynamiczna funkcja stanu, określająca kierunek przebiegu procesów spontanicznych (samorzutnych) w odosobnionym układzie termodynamicznym. Entropia jest miarą stopnia nieuporządkowania układu i rozproszenia energii. Jest wielkością ekstensywną. Zgodnie z drugą zasadą termodynamiki, jeżeli układ termodynamiczny przechodzi od jednego stanu równowagi do drugiego, bez udziału czynników zewnętrznych (a więc spontanicznie), to jego entropia zawsze rośnie. Pojęcie entropii wprowadził niemiecki uczony Rudolf Clausius.
W termodynamice klasycznej.
W ramach II zasady termodynamiki zmiana entropii (w procesach kwazistatycznych) jest zdefiniowana przez swoją różniczkę zupełną jako:
gdzie:
Entropię pewnego stanu termodynamicznego formula_4 można wyznaczyć ze wzoru:
gdzie:
Podstawowe równanie termodynamiki fenomenologicznej, w którym występuje entropia, ma postać
gdzie:
W termodynamice statystycznej.
Całkowita entropia układu makroskopowego jest równa:
równoważnie:
gdzie:
Zatem
jest liczbą bitów potrzebnych do pełnego określenia, którą realizację przyjął dany układ.
Praktyczne obliczenie "W" jest w większości przypadków technicznie niemożliwe, można jednak oszacowywać całkowitą entropię układów poprzez wyznaczenie ich całkowitej pojemności cieplnej poczynając od temperatury 0 K do aktualnej temperatury układu i podzielenie jej przez temperaturę układu.
Ciało pozbawione niedoskonałości, zwane kryształem doskonałym, ma w temperaturze 0 bezwzględnego (0 K) entropię równą 0, gdyż jego stan może być zrealizowany tylko na jeden sposób (każda cząsteczka wykonuje drgania zerowe i zajmuje miejsce o najmniejszej energii). Jest to jedno ze sformułowań trzeciej zasady termodynamiki. Oznacza to, że każde rzeczywiste ciało ma w temperaturze większej od zera bezwzględnego entropię większą od zera.
Entropia czarnej dziury.
W ogólnej teorii względności, aby opisać czarną dziurę, wystarczy podać jej masę, moment pędu i ładunek elektryczny. Zgodnie z tą teorią czarna dziura nie zawiera żadnej informacji ponad te parametry. Potocznym językiem fizycznym „brak włosów” w pojęciu czarnej dziury oznacza, że jej entropia jest równa 0. Do czarnej dziury wpada materia o niezerowej entropii, zatem przy wpadaniu entropia całego układu się zmniejsza. Wynika z tego, że ogólna teoria względności łamie drugą zasadę termodynamiki. Fizycy zaczęli więc poszukiwać uogólnienia teorii czarnych dziur, tak żeby pozostawała w zgodzie z termodynamiką. Owocne okazało się rozważenie efektów kwantowych.
Wzór na entropię czarnej dziury powstał przy założeniu, że podczas spadania ciała do czarnej dziury jej masa rośnie wraz z jej entropią; proporcjonalny do masy jest horyzont zdarzeń, czyli promień Schwarzschilda.
Ścisły wzór wg Stephena Hawkinga ma postać:
gdzie:
Kosmologia.
Według II zasady termodynamiki każdy układ izolowany dąży do stanu równowagi, w którym entropia osiąga maksimum. Zakładając, że Wszechświat jako całość jest układem izolowanym, powinien on również dążyć do równowagi. Wychodząc z tych założeń, Hermann von Helmholtz wysunął hipotezę śmierci cieplnej Wszechświata, według której Wszechświat w końcu dojdzie do równowagi termodynamicznej, w której niemożliwa będzie zamiana energii cieplnej na pracę, przez co niemożliwy będzie rozwój Wszechświata. Stwierdzenie tego faktu jest jednak stosunkowo trudne do zaobserwowania i dlatego prowadzi się liczne dyskusje, czy Wszechświat jest, czy nie jest układem izolowanym, czy też tylko zamkniętym, oraz czy rzeczywiście dąży jako całość do równowagi. Przeciwnicy tej koncepcji są zdania, że rozszerzającego się Wszechświata nie można traktować jako układu izolowanego, gdyż nie można wyznaczyć obszaru, z którego nie wychodziłoby promieniowanie. Wiadomo jedynie, że entropia olbrzymiej większości znanych układów izolowanych rośnie w kierunku, który nazywamy przyszłością. Tak więc, z tego punktu widzenia, termodynamika określa kierunek upływu czasu (tzw. termodynamiczna strzałka czasu).
Według Boltzmanna aktualna entropia Wszechświata jest jeszcze bardzo niska, w porównaniu z wartością „docelową”, na co dowodem miały być wysokie wartości fluktuacji statystycznych zjawisk obserwowanych w skali kosmosu – np. bardzo nierównomierne rozmieszczenie gwiazd w przestrzeni. Współcześnie taka interpretacja entropii jest jednak uważana za całkowicie nieuprawnioną z kosmologicznego punktu widzenia.
Powiązania z innymi naukami.
Z punktu widzenia fizycznego każdy proces ekonomiczny również ma charakter jednokierunkowego wzrostu entropii, sporadycznie formułowano teorie o ekwiwalentności pieniądza i niskiej entropii (G. Helm, J. Lotka).

</doc>
<doc id="1369" url="https://pl.wikipedia.org/wiki?curid=1369" title="Electronic Frontier Foundation">
Electronic Frontier Foundation

Electronic Frontier Foundation – założona w lipcu 1990 roku w Stanach Zjednoczonych organizacja pozarządowa mająca na celu walkę o wolności obywatelskie (takie jak prawo do anonimowości, prywatności i wolności słowa) w "elektronicznym świecie" (prawa cyfrowe). Jej twórcami są Mitch Kapor, John Gilmore i John Perry Barlow.
Organizacja EFF patronuje między innymi systemowi Tor, programowi zapewniającemu anonimowość w sieci. Prowadzi bazę danych drukarek wykorzystujących steganografię drukarkową. Ważniejsze sprawy, w które fundacja się zaangażowała:

</doc>
<doc id="1370" url="https://pl.wikipedia.org/wiki?curid=1370" title="Etnogeneza">
Etnogeneza

Etnogeneza – proces kształtowania się etnosu grup etnicznych, a według niektórych badaczy także samej grupy etnicznej. Badaniem etnogenezy zajmuje się historia, etnologia, archeologia, antropologia kulturowa, socjologia i językoznawstwo. Termin wywodzi się od neologizmu "ethnogenesis" użytego pierwszy raz w połowie XIX wieku przez Henry`ego Timroda. Następnie pojęcie przejął świat XX-wiecznych antropologów - akademików.
Podstawowe formy etnogenezy to:

</doc>
<doc id="1372" url="https://pl.wikipedia.org/wiki?curid=1372" title="Elektroujemność">
Elektroujemność

Elektroujemność, skala elektroujemności – miara tendencji do przyciągania elektronów przez atomy danego pierwiastka, gdy tworzy on związek chemiczny z atomami innego pierwiastka. Bardziej elektroujemny pierwiastek „przyciąga” do siebie elektrony tworzące wiązanie z atomem mniej elektroujemnym, co prowadzi do polaryzacji wiązania. W skrajnym przypadku, gdy elektroujemności obu pierwiastków bardzo się różnią (np. sód i chlor), dochodzi do pełnego przeskoku elektronów na bardziej elektroujemny atom, co prowadzi do powstania wiązania jonowego.
Elektroujemność pierwiastków jest często zależna od układu atomów w danym związku, ich stopnia utlenienia, przyjętej w danym momencie hybrydyzacji i dość często zdarza się, że wiązania polaryzują się odwrotnie niżby to wynikało z formalnej elektroujemności związanych pierwiastków. Mimo to zaproponowano wiele sposobów, aby ilościowo zdefiniować ogólną elektroujemność pierwiastków.
Skala Paulinga.
Pierwszą taką propozycją była skala Paulinga, oparta na pomiarach energii i polaryzacji wiązań prostych dwuatomowych związków chemicznych, opracowana przez Linusa Carla Paulinga w 1932. Jest to skala empiryczna oparta na doświadczalnych wielkościach termodynamicznych. Miarą różnicy elektroujemności pierwiastków A i B na skali Paulinga jest różnica energii wiązania heterojądrowego A-B i średniej energii homojądrowych wiązań A-A i B-B.
Zgodnie z tą skalą największą elektroujemność ma fluor (E = 4), najmniejszą – cez i frans (E = 0,7), pozostałe pierwiastki są umieszczone pomiędzy (np.: Li : 1,0, Be : 1,5, B : 2,0, C : 2,5, N : 3,0, O : 3,5, F : 4,0). Elektroujemność rośnie ze wzrostem liczby atomowej w okresach i maleje w grupach układu okresowego. Wartość na skali Paulinga jest wielkością uśrednioną lub ograniczoną i dotyczącą tylko pewnej grupy połączeń pierwiastka.
Skala ta jest wciąż najczęściej używana, jednak bardzo mało precyzyjna i często prowadzi do błędnych wniosków.
Mimo że skala Paulinga została stworzona metodami eksperymentalnymi, Allred i Rochow wykazali, że jest ona w gruncie rzeczy zależna od liczby elektronów występujących w atomach danego pierwiastka i kwadratu jego promienia walencyjnego.
Skala Allreda-Rochowa.
Inną skalę zaproponowali Allred i Rochow, którzy obliczyli elektroujemność na podstawie liczby atomowej i efektywnego promienia walencyjnego atomów.
Skala Allreda oparta jest na pojęciu „siły przyciągania” elektronów przez jądra atomów. Siła ta została zdefiniowana wzorem:
gdzie:
Wartość elektroujemności w skali Allreda-Rochowa można obliczyć ze wzoru:
gdzie: formula_2 wyrażone jest angstremach.
Różnice między skalą Allreda i Paulinga dochodzą do 1. Skala Allreda daje często lepsze wyniki praktyczne od skali Paulinga, gdyż bierze pod uwagę nie tylko ogólny stosunek ładunku elektronów do promienia walencyjnego, lecz także bezpośrednie oddziaływanie poszczególnych elektronów z jądrem.
Skala Mullikena.
Skalą biorącą pod uwagę rzeczywisty stan atomu w danej cząsteczce, a więc liczbę i rodzaj wiązań w jakich uczestniczy atom w danym momencie, jest skala Mullikena. W skali Mullikena jednak pierwiastki mają zmienną elektroujemność, zależną od tego w jakim związku występują, więc jest ona trudna do stosowania w praktyce.

</doc>
<doc id="1373" url="https://pl.wikipedia.org/wiki?curid=1373" title="Erik Karlfeldt">
Erik Karlfeldt



</doc>
<doc id="1374" url="https://pl.wikipedia.org/wiki?curid=1374" title="Eugene O’Neill">
Eugene O’Neill

Eugene Gladstone O’Neill (ur. 16 października 1888 w Nowym Jorku, zm. 27 listopada 1953 w Bostonie) – amerykański dramaturg, laureat Nagrody Nobla w dziedzinie literatury za rok 1936.
Jego córka Oona była żoną Charlie Chaplina.
Lata młodzieńcze.
Urodził się w hotelu Barrett na Broadwayu na Times Square, w Nowym Jorku. Dzisiaj w tym miejscu znajduje się kawiarnia Starbucks (ulica Broadway numer 1500, północno-wschodni róg 43. ulicy i Broadwayu). Na zewnętrznej ścianie kawiarni widnieje tablica upamiętniająca narodziny O’Neilla: "Eugene O’Neill, 16 października 1888 – 27 listopada 1953.
Był synem irlandzkiego aktora Jamesa O’Neilla i Elli O’Neill. Jak większość Irlandczyków O’Neill rozpoczął naukę w szkole rzymskokatolickiej z internatem. Wakacje letnie spędzał w stanie Connecticut w miejscowości Nowy Londyn.
Studiował na Uniwersytecie w Princeton, spędził kilka kolejnych lat na morzu. W tym czasie chorował na depresję i popadał w alkoholizm po śmierci członków najbliższej rodziny. Rodzice O’Neilla oraz jego starszy brat Jamie zmarli w ciągu trzech kolejnych lat. Życie rodzinne O’Neilla przedstawia jego autobiograficzna sztuka "Zmierzch długiego dnia".
Pisarstwo było dla O’Neilla formą ucieczki od smutnej rzeczywistości. Pomimo depresji uwielbiał morze, na którym pracował przez kilka lat i które wkrótce stało się wiodącym tematem jego sztuk. Miejscem akcji wielu z nich jest właśnie pokład statku.
Podczas pobytu w sanatorium w latach 1912-1913, gdzie wracał do zdrowia po przebytej gruźlicy, zdecydował, iż zostanie zawodowym dramaturgiem. Wcześniej pracował dla "New London Telegraph", publikując tam swoją poezję oraz pisząc reportaże.
W drugiej dekadzie dwudziestego wieku był częstym gościem w Greenwich Village. Poznał wtedy założyciela Komunistycznej Partii Pracy, dziennikarza Johna Reeda i jego żonę, pisarkę Louise Bryant. W filmie "Czerwoni" (z 1981), o życiu Johna Reeda, postać O’Neilla zagrał Jack Nicholson.

</doc>
<doc id="1375" url="https://pl.wikipedia.org/wiki?curid=1375" title="Ekologia">
Ekologia

Ekologia (gr. "οἶκος" ("oíkos") ‘dom’ + "λόγος" ("logos") ‘słowo, nauka’) – nauka o strukturze i funkcjonowaniu przyrody, zajmująca się badaniem oddziaływań pomiędzy organizmami a ich środowiskiem oraz wzajemnie między tymi organizmami (czyli strukturą ekosystemów).
Przedmiot ekologii.
Ekologia zajmuje się badaniem powiązań między organizmami żywymi a środowiskiem abiotycznym (układy biologiczne istnieją w sieci powiązań między sobą i otaczającym je środowiskiem), opartych na różnego rodzaju interakcjach. Odkrywanie tych zjawisk dokonywało się od starożytności, ale ekologia jako samodzielna nauka rozwinęła się w zasadzie w XIX w. Ekologia nie jest nauką obojętną wobec egzystencji przyrody i człowieka, dlatego często w potocznych dyskusjach utożsamiana jest z sozologią i filozofią. Ekologia najogólniej jest nauką o porządku i nieporządku w przyrodzie oraz o konsekwencjach wynikających z tego porządku i nieporządku dla istnienia biosfery i człowieka.
Ze względów zarówno filozoficznych, jak i utylitarnych pojęcie „ekologia” używane bywa w szerokim kontekście znaczeniowym. Określenia "ekologia, ekologiczny" są często używane w języku potocznym w szerokim i czasem nieprecyzyjnym sensie znaczeniowym, nie zawsze związanym z ekologią jako nauką. Często odnoszą się do sozologii, tj. nauki o ochronie środowiska lub do ochrony środowiska jako takiej, a nawet do filozofii ekologicznej (ekozofia), działalności społecznej czy artystycznej.
Termin ten, od słowa "oecologia", wprowadził w 1866 r. niemiecki biolog i ewolucjonista Ernst Haeckel, by określić badania nad zwierzętami i ich relacjami z otaczającym światem nieorganicznym i organicznym, ze szczególnym uwzględnieniem interakcji, przyjaznych lub wrogich, z organizmami roślinnymi i zwierzęcymi, z którymi wchodzą w kontakt. Na organizmy w środowisku oddziałują czynniki abiotyczne i biotyczne.
Jedni autorzy sądzą, że przedmiotem ekologii powinny być relacje między rzeczywistością biotyczną a abiotyczną, inni natomiast rozszerzają jej zakres na tak zwany wymiar aplikacyjny (tzw. ekologia stosowana). W konsekwencji dla jednych jest to nauka biologiczna, dla innych geograficzna, a jeszcze inni poszerzają ją o problematykę ochrony środowiska (zob. np. ekologizm). Jedni bronią jej wymiaru ilościowego (strategia redukcjonistyczna), inni skupiają się na wymiarze jakościowym (strategia holistyczna). Z powodu tak różnorodnych podejść i poglądów na zakres ekologii w podręcznikach spotyka się różne jej definicje i różne modele teoretyczne.
Zazwyczaj za najważniejsze pojęcia w ekologii uważa się następujące: populacja, biocenoza, ekosystem, krajobraz, biosfera, sukcesja ekologiczna.
Działy ekologii.
Współcześnie wyodrębniane są dwa główne działy ekologii – ekologia gatunku i ekologia zespołów wielogatunkowych (synekologia, biocenologia, badania tworzenia się i struktury ekosystemów). W zakres ekologii gatunku wchodzi:
Wśród działów ekologii wyodrębnionych ze względu na metodologię badań wymieniane są m.in.:
Działem ekologii silnie zakorzenionym w biochemii jest ekologia biochemiczna.

</doc>
<doc id="1376" url="https://pl.wikipedia.org/wiki?curid=1376" title="Etologia">
Etologia

Etologia (gr. ήθος – obyczaj) – dział zoologii badający zachowania zwierząt, zarówno dziedziczonych, jak i nabytych, ich aspektem przystosowawczym, rozwojem osobniczym, orientacją przestrzenną, zachowaniami społecznymi.
Twórcą nowoczesnej etologii jest Konrad Lorenz. Porównując zachowania (np. drapanie się) różnych gatunków, stwierdził on, że mogą one pomóc w poznaniu ewolucji, a na podstawie badań kaczek doszedł do wniosku, że zachowania zależą w prosty sposób od genów.

</doc>
<doc id="1377" url="https://pl.wikipedia.org/wiki?curid=1377" title="Esperanto">
Esperanto

Esperanto (esperanto: "osoba mająca nadzieję", pierwotnie Lingvo Internacia, w tłum. "język międzynarodowy") – najbardziej rozpowszechniony na świecie międzynarodowy język pomocniczy. Jego nazwa pochodzi od pseudonimu „Dr. Esperanto” ("doktor mający nadzieję"), pod którym Ludwik Zamenhof opublikował w 1887 podstawy języka w książce "Język międzynarodowy. Przedmowa i podręcznik kompletny". Jego celem było stworzenie neutralnego i łatwego do nauki języka, przydatnego do międzynarodowej komunikacji, nie zastępującego jednak innych języków narodowych.
Pomimo że żadne państwo nie uznaje esperanto za swój język urzędowy, jest ono używane przez międzynarodową wspólnotę, której wielkość, według różnych źródeł, szacowana jest na od stu tysięcy do dwóch milionów użytkowników (zależnie od poziomu opanowania języka); dla około tysiąca z nich esperanto jest pierwszym językiem.
Esperanto doczekało się także międzynarodowego uznania, w postaci dwóch rezolucji UNESCO, a także wsparcia ze strony znanych osobistości życia publicznego. W setną rocznicę powstania Światowego Związku Esperantystów Sejm Rzeczypospolitej Polskiej podjął uchwałę, w której złożył wyrazy uznania dla kontynuatorów dzieła dr. Ludwika Zamenhofa. W 2014 roku z inicjatywy polskich esperantystów język esperanto został wpisany na krajową listę niematerialnego dziedzictwa kulturowego. Współcześnie używa się tego języka w podróży, korespondencji, podczas międzynarodowych spotkań, kongresów, dyskusji naukowych (np. w działalności Międzynarodowej Akademii Nauk San Marino), tworzenia oryginalnej literatury oraz jej tłumaczenia, w muzyce, teatrze, kinie, reportażu internetowym i mediach prasowych oraz do tworzenia audycji radiowych i telewizyjnych. Przesłanką wskazującą na popularność języka esperanto jest liczba krajowych organizacji esperantystów (np. Czeski Związek Esperantystów, Polski Związek Esperantystów), jak również duża liczba i różnorodność organizacji tematycznych grupujących esperantystów – zwolenników jakiegoś światopoglądu, ideologii, religii, zawodów, hobby itd. (np. Esperancki Związek Prawniczy, Międzynarodowa Liga Nauczycieli Esperantystów). O popularności esperanto świadczą też liczne i bardzo różnorodne ZEOj (obiekty upamiętniające esperanto i postać Ludwika Zamenhofa) na całym świecie.
Zdecydowana większość słownictwa w esperanto pochodzi z języków zachodnioeuropejskich, jednocześnie ukazując wpływy języków słowiańskich poprzez swoją syntaktykę i morfologię. Morfemy nie podlegają zmianom i można tworzyć z nich ogromną liczbę kombinacji, tworząc zróżnicowane znaczeniowo wyrazy; esperanto ma więc wiele wspólnego z językami analitycznymi, do których zalicza się między innymi chiński. Z drugiej jednak strony, struktura wewnętrzna esperanto w pewnym stopniu odzwierciedla języki aglutynacyjne, takie jak japoński, suahili czy turecki.
Historia.
Młodość Zamenhofa.
Powstanie esperanta jest dziełem Ludwika Zamenhofa, lekarza okulisty żydowskiego pochodzenia, zamieszkującego zajęte przez Rosję ziemie polskie, urodzonego w Białymstoku. Dzieciństwo spędzone w tym wielokulturowym mieście było dla niego okazją do obserwowania nieprzyjaznych stosunków pomiędzy przedstawicielami zamieszkujących je narodów: Rosjanami, Polakami, Niemcami i Żydami. Za główną przyczynę konfliktów Zamenhof uznał brak wspólnego języka, dlatego też już jako uczeń rozpoczął prace nad projektem nowego języka wspólnego dla wszystkich ludzi. W przeciwieństwie do języków narodowych miał to być w jego zamyśle język neutralny i łatwy do nauczenia, tak aby mógł być przyjęty przez wszystkich jako drugi język, nauczany równolegle do języka narodowego i używany w sytuacjach wymagających międzynarodowego porozumienia.
Pierwsze pomysły.
Zamenhof początkowo brał pod uwagę wskrzeszenie łaciny, której uczył się w szkole, jednak uznał, że jest ona zbyt skomplikowana do codziennej komunikacji. Ucząc się języka angielskiego zauważył, że odmiana czasownika przez rodzaj i liczbę nie jest koniecznością, a system gramatyczny języka może być o wiele prostszy niż mu się wcześniej wydawało. Wciąż nie udało mu się za to rozwiązać problemu zbyt dużego zasobu słownictwa do nauczenia, aż pewnego razu zauważył dwa szyldy po rosyjsku: швейцарская (‘portiernia’, od швейцар, ‘portier’) i кондитерская (‘cukiernia’, od кондитер, ‘cukiernik’). Te słowa z identycznym przyrostkiem podsunęły mu pomysł, by poprzez regularny system derywacji zmniejszyć liczbę morfemów należących do języka. Aby uzyskać jak najbardziej międzynarodowe słownictwo, Zamenhof zdecydował się zapożyczyć je głównie z języków romańskich i germańskich, nauczanych wówczas powszechnie na całym świecie.
Wersja ostateczna.
Pierwszy projekt Zamenhofa nazwany "Lingwe uniwersala" był już niemal gotowy w 1878, gdy ojciec Ludwika, uznawszy pomysł syna za daremny i nierealny, zniszczył jego notatki. W latach 1879–1885 Zamenhof studiował medycynę w Moskwie i Warszawie i wtedy również rozpoczął ponowne prace nad językiem międzynarodowym. W 1879 roku nauczył swoich przyjaciół pierwszej odnowionej wersji języka. Po kilku latach tłumaczył już poezję, chcąc w ten sposób ulepszyć projekt. W 1895 wspominał: „Przez sześć lat pracowałem nad ulepszaniem i testowaniem języka, choć w roku 1878 wydało mi się, że był już całkowicie gotowy”.
Gdy publikacja projektu była już przygotowana, została wstrzymana przez carską cenzurę. Zamenhof, rozczarowany tym faktem, wykorzystał wolny czas na tłumaczenie m.in. Starego Testamentu i kilku sztuk Szekspira. Wreszcie w 1887 udało mu się wydać pierwszy podręcznik zatytułowany "Международный языкъ" ("Język międzynarodowy"), który będzie znany później wśród esperantystów jako Unua Libro ("Pierwsza Książka"). Zaprezentowany w nim język jest tym samym, którego używa się do dziś. Pseudonim Zamenhofa "Doktoro Esperanto", pod którym książka została wydana, wkrótce stał się określeniem języka – początkowo jako "Język doktora Esperanto", a następnie w skrócie jako "Esperanto".
Pierwsze próby reform.
Zamenhof otrzymał wiele pełnych entuzjazmu listów, często zawierających propozycje różnych zmian w języku. Wszystkie sugestie zapisywał, a następnie zaczął publikować w gazecie „La Esperantisto” wydawanej wówczas w Norymberdze. Wśród czytelników gazety dwukrotnie przeprowadzono głosowanie na temat reform, jednak większość była im przeciwna. Po tych głosowaniach na pewien czas ucichły głosy postulujące zmiany, a język zaczął się rozpowszechniać. Najwięcej abonentów „La Esperantisto” miała w Rosji, toteż wielkim ciosem był zakaz rozpowszechniania czasopisma wydany w 1895 przez carską cenzurę z powodu tłumaczenia tekstu Lwa Tołstoja. Gazeta niebawem została zamknięta, lecz niedługo potem zastąpiła ją nowa pod tytułem „Lingvo Internacia”. Była ona początkowo wydawana w Uppsali, następnie na Węgrzech i wreszcie w Paryżu, gdzie publikację przerwała dopiero I wojna światowa.
Rozrost społeczności.
Nowego języka międzynarodowego zaczęto również używać do organizowania współpracy zawodowej i hobbystycznej na poziomie międzynarodowym. W pierwszych dziesięcioleciach komunikacja w esperanto odbywała się niemal wyłącznie na piśmie, lecz po niespodziewanie popularnym Światowym Kongresie w 1905 w Boulogne-sur-Mer, który udowodnił możliwość używania języka także w mowie, szybko zaczęły się rozwijać również kontakty osobiste i spotkania między esperantystami. W Boulogne-sur-Mer uchwalono także oficjalny i nienaruszalny zbiór zasad języka pod nazwą Fundamento de Esperanto.
Już podczas Światowego Kongresu w Barcelonie w 1909 miało miejsce kilka spotkań wśród biorących udział katolików, którzy w końcu postanowili zorganizować w następnym roku, 1910, osobny kongres katolickich esperantystów. Podczas niego założono Międzynarodowy Katolicki Związek Esperantystów (Internacia Katolika Unuiĝo Esperantista), którego główny organ, gazeta „Espero Katolika”, był wydawany już w 1903 i jest najstarszym do dziś ukazującym się czasopismem esperanckim.
W roku 1912, w czasie uroczystej przysięgi podczas ósmego Światowego Kongresu w Krakowie, Zamenhof zrzekł się swojej oficjalnej roli w ruchu esperanckim. Na dziesiąty Światowy Kongres mający odbyć się w Paryżu w 1914 zapisało się ponad 4000 osób, jednak przez I wojnę światową nie doszedł on do skutku, a Zamenhof był zmuszony wracać do domu przez Skandynawię.
Dążenie do pokoju i harmonii po I wojnie światowej obudziło nowe nadzieje, dzięki czemu esperanto szybko się rozpowszechniało. Pierwszy Światowy Kongres po wojnie miał miejsce w 1920 w Hadze, kolejny w 1921 w Pradze. W 1927 w Wiedniu, w pałacu Hofburg założono muzeum esperanta, Internacia Esperanto-Muzeo, które w 1929 związało się z Austriacką Biblioteką Narodową i dziś mieści się w osobnym budynku.
W okresie międzywojennym i podczas II wojny światowej miały miejsce prześladowania esperantystów, między innymi w nazistowskich Niemczech i stalinowskim Związku Radzieckim.
Po drugiej wojnie światowej.
Starania o uznanie esperanta za język światowy spotykały się z pozytywnymi reakcjami: petycje na jego rzecz skierowane do ONZ podpisało ponad 80 mln osób, w Czechosłowacji na przykład m.in. noblista prof. Jaroslav Heyrovský.
Zgromadzenie Ogólne UNESCO przyjęło rezolucje odnośnie do esperanta w Montevideo 10 grudnia 1954 i w Sofii 8 listopada 1985. Wyraziło w nich uznanie dla "osiągnięć esperanta na polu międzynarodowej wymiany intelektualnej i na rzecz zbliżania do siebie narodów świata", wezwało państwa członkowskie do "zachęcania do włączenia w programy nauczania szkół i uczelni zagadnienia problemów językowych i esperanta" oraz zarekomendowało międzynarodowym organizacjom pozarządowym "włączyć się do świętowania 100-lecia esperanta i przeanalizować możliwość używania języka do przekazywania wszelkiego rodzaju informacji między swoimi członkami, także tych dotyczących działalności UNESCO".
Poparcie dla esperanta wyrażały również władze Polskiej Akademii Nauk. Jubileuszowy, 72. Światowy Kongres w 1987 w Warszawie (stulecie publikacji języka) skupił prawie sześć tysięcy osób 60 narodowości.
Również Międzynarodowy Katolicki Związek Esperantystów osiągnął ważny postęp, gdy w roku 1990 wydany został dokument "Norme per la celebrazione della Messa in esperanto", w którym Stolica Apostolska zezwala na odprawianie mszy w esperanto bez specjalnych zezwoleń. Tym sposobem esperanto stało się jedynym uznanym sztucznym językiem liturgicznym Kościoła katolickiego.
Początkiem obchodów 150. rocznicy urodzin Ludwika Zamenhofa było sympozjum w siedzibie UNESCO w grudniu 2008, ich kulminacją był Światowy Kongres Esperanto w lipcu 2009, w rodzinnym mieście Zamenhofa, Białymstoku, a zakończeniem – sympozjum z udziałem dyplomatów ONZ w Nowym Jorku.
Fakt, że wiele celów ruchu esperanckiego nie zostało osiągniętych, jest przypisywany między innymi technologicznej i kulturowej hegemonii Wielkiej Brytanii i Stanów Zjednoczonych, zwłaszcza w okresie po drugiej wojnie światowej, co poskutkowało dzisiejszą rolą języka angielskiego jako narzędzia komunikacji w większości międzynarodowych działań.
Współczesność.
Esperanto jest dziś w pełni rozwiniętym językiem z tysiącami użytkowników na całym świecie i dużą liczbą wydawnictw. Do znanych na świecie esperantystów należą noblista w dziedzinie ekonomii Reinhard Selten, mistrzyni świata w szachach Zsuzsa Polgár czy Tivadar Soros, ojciec finansisty George’a Sorosa.
Użytkownicy.
Język esperanto jest jak na razie najbardziej znanym i rozpowszechnionym projektem języka międzynarodowego. Względem liczby użytkowników esperanta istnieje znaczna rozbieżność szacunków. Szacunku na poziomie 1,5 miliona dokonał w latach osiemdziesiątych XX wieku prof. Sidney Culbert z uniwersytetu w Waszyngtonie w swoim opracowaniu dotyczącym najczęściej używanych języków.
Esperantyści zrzeszają się w stowarzyszeniach krajowych, na wszystkich zamieszkanych kontynentach i w większości państw świata. Zrzeszają się również w stowarzyszeniach tematycznych grupujący zwolenników danego światopoglądu, ideologii, religii, zawodów, hobby itd. Informacje o stowarzyszeniach esperanckich udostępnia Światowy Związek Esperantystów. Ze względu na rozpowszechnienie esperanta Światowe Kongresy Esperanta odbywają się corocznie (począwszy od roku 1905), w różnych krajach świata, na wszystkich kontynentach (dotychczas z wyjątkiem Afryki).
W roku 1908 główny lekarz kopalni rudy cynku w kondominium Moresnet, Wilhelm Molly, próbował na terytorium tego kraju ustanowić pierwsze państwo esperantystów „Amikejo” (amikejo = miejsce wielkiej przyjaźni), co jednak nie zakończyło się sukcesem.
Dla pewnej grupy ludzi, szacowanej na około tysiąc osób, esperanto jest językiem rodzimym. Społeczność tę interlingwiści dzielą na podgrupy i typy, by zbadać przemiany znaczeniowo-fonetyczne wśród poszczególnych grup i ludzi. Wśród niektórych dzieci poznających esperanto jako pierwszy język, a które przez długi czas nie poznają innego języka, zauważa się innowacje znaczeniowe – potwierdzenie koncepcji gier językowych Wittgensteina. Objawia się to tworzeniem wieloczłonowych słów i zniekształceń członów najczęściej będących skrótami, co prowadzi do naturalnego wytwarzania się skomplikowanej znaczeniowo mowy esperanckiej. Skomplikowanie mowy dzieci mówiących esperantem jako swoim pierwszym językiem przekraczało wyobrażenia jego znawców, a pozostawienie takich dzieci dla dalszego rozwijania się ich języka może grozić ich niekomunikatywnością.
Język taki chciał już utworzyć esperancki poeta Kálmán Kalocsay, wprowadzając człony łacińskie. Esperantem eksperymentował także Julian Tuwim, który przetłumaczył na esperanto wiersze Leopolda Staffa, a także np. swój debiutancki wiersz „Prośbę”, „Kwiaty polskie” czy „Bal w operze”.
Oficjalny status i uznanie.
Universala Esperanto-Asocio (Światowy Związek Esperantystów, UEA) utrzymuje oficjalne stosunki z UNESCO, ONZ, UNICEF, Radą Europy, Organizacją Państw Amerykańskich oraz Międzynarodową Organizacją Normalizacyjną (ISO). Podejmowano starania o przyznanie jej nagrody Nobla w 2009, poparte m.in. ustawą przez Sejm Rzeczypospolitej Polskiej. W 2009 Mongola Esperanto-Societo (Mongolskie Stowarzyszenie Esperantystów) stało się 70. krajową organizacją esperancką zrzeszoną z UEA. Krajowe związki esperantystów działają w 19 państwach afrykańskich i 21 azjatyckich.
Nauczanie.
Niektóre szkoły wyższe włączają esperanto do programów studiów lingwistycznych, inne oferują naukę esperanta jako osobny przedmiot. Na Uniwersytecie Adama Mickiewicza w Poznaniu prowadzone są 3-letnie studia na kierunku interlingwistyka skupiające się na esperancie i używające go jako języka wykładowego.
Podobnie jak z językami naturalnymi również w odniesieniu do esperanta można otrzymać certyfikat językowy. Certyfikat językowy dla znajomości esperanto wydaje Państwowe Centrum Egzaminów Językowych działające pod auspicjami Uniwersytetu im. Loránda Eötvösa. Certyfikaty wydawane są zgodnie z systemem poziomów biegłości językowej przyjętej przez Radę Europy. Certyfikaty językowe wydaje również Uniwersytet Jagielloński oraz Francuski Instytut Esperanto.
Pionierem nauczania esperanto w Polsce był Mieczysław Sygnarski, autor łącznie 16 opracowań i podręczników do nauki esperanto, w tym pierwszego podręcznika do nauki języka esperanto dla szkół średnich.
Esperanto w praktyce.
Spotkania i podróże.
Co roku esperantyści organizują setki międzynarodowych konferencji i spotkań – bez tłumaczy. Do największych należy Światowy Kongres Esperanto ("Universala Kongreso de Esperanto"), którego 104 edycja gościła w 2019 roku w Lahti. Z powodu pandemii COVID-19 Kongresy w latach 2020–2021 odbyły się w Internecie. Od 1938 organizowane są Międzynarodowe Kongresy Młodzieży ("Internacia Junulara Kongreso") – ostatnio w Liptowskim Gródku w 2019 roku oraz w Internecie w 2020 roku. W 2017 roku powstał serwis zbierający informacje o wydarzeniach związanych ze społecznością esperanto Eventa Servo.
Celem ułatwienia podróży za pośrednictwem esperanta powstała sieć Pasporta Servo, którą opiekuje się Światowa Esperancka Organizacja Młodzieżowa. Od założenia w 1974 aż do 2008 roku podstawą jej działania była wydawana rokrocznie książeczka z adresami ok. 1100 osób z 90 krajów (2011) gotowych bezpłatnie gościć podróżujących esperantystów. Od 2009 roku sieć działa przede wszystkim w oparciu o Internet.
Biblioteki i badania naukowe.
Biblioteka Internacia Esperanto-Muzeo (Międzynarodowego Muzeum Esperanta) w Wiedniu w swojej kolekcji posiada ponad 35 000 woluminów w 500 językach sztucznych, z czego najwięcej w esperanto. Jest tym samym największą biblioteką esperancką na świecie. Do innych dużych bibliotek (z ponad 20 000 woluminów) zaliczają się Biblioteka Hectora Hodlera w biurze UEA w Rotterdamie, Biblioteka Bultera przy Esperanto-Asocio de Britio (Brytyjskim Związku Esperantystów) w Stoke-on-Trent, Germana Esperanto-Biblioteko (Niemiecka Biblioteka Esperancka) w Aalen oraz biblioteka Japana Esperanto-Instituto (Japońskiego Instytutu Esperanta) w Tokio.
Język esperanto jest przedmiotem badań w szkołach wyższych. W Polsce studia nad językami międzynarodowymi (m.in. nad esperanto) prowadzone są w Instytucie Językoznawstwa Uniwersytetu im. Adama Mickiewicza. Studia skupiają się na esperancie, jako obecnie jedynym języku planowym, upowszechnionym na świecie oraz zajmują się jego lingwistyczną analizą, literaturą i historią. Ważnym elementem studiów jest komunikacja międzykulturowa. Celem studiów jest również kształcenie nauczycieli języka esperanto w ramach specjalizacji: dydaktyka esperanta.
Literatura.
W esperancie istnieje zarówno oryginalna literatura, jak i przekłady. O uznaniu dla tradycji literackiej esperanta świadczy przyjęcie Esperanta PEN-Centro do międzynarodowego PEN Clubu w 1993 Do istotnych współczesnych pisarzy esperanckich należą powieściopisarze Trevor Steele (Australia), István Nemere (Węgry), Spomenka Štimec (Chorwacja) i Manuel de Seabra (Katalonia); poeci Mauro Nervi (Włochy), Mao Zifu (Chiny), Michaił Giszpling (Izrael) i Abel Montagut (Katalonia); eseiści i tłumacze Probal Dasgupta (Indie, USA), Humphrey Tonkin (USA), Kurisu Kei (Japonia). Szkocki poeta William Auld za swoją twórczość w esperanto był kilkukrotnie nominowany do literackiej Nagrody Nobla, m.in. w 2004 i 2006 roku. Podobne nominacje otrzymali również Marjorie Boulton i Baldur Ragnarsson. W katologu internetowej księgarni Universala Esperanto-Asocio widnieje ok. 6700 książek.
Do wydanych ostatnio przekładów znanych dzieł na esperanto należą na przykład "Stary człowiek i morze" Hemingwaya, "Władca Pierścieni" Tolkiena, "Sto lat samotności" Garcíi Márqueza, rubajjaty Omara Chajjama, "Blaszany bębenek" Güntera Grassa, "Opisanie świata" Marco Polo, "Lalka" Bolesława Prusa czy wielka rodzinna saga "Sen czerwonego pawilonu" Cao Xueqina. Spośród książek dla dzieci, oprócz Asteriksa, Kubusia Puchatka i Tintina, przełożono również na przykład "Pippi Pończoszankę" i wszystkie książki z serii o Muminkach fińskiej pisarki Tove Jansson. Teksty niektórych przekładów można znaleźć w Internecie.
Muzyka.
Muzyka wykonywana w esperanto obejmuje różne gatunki takie jak pieśni ludowe, rock, reggae, piosenki kabaretowe, utwory solowe i chóralne, a także operę. Do aktywnych wykonawców należą np. szwedzki zespół La Perdita Generacio, oksytański piosenkarz JoMo, fiński zespół Dolchamar, kazachski duet Ĵomart kaj Nataŝa, fryzyjska grupa Kajto czy polski bard Georgo Handzlik. Również niektórzy sławni kompozytorzy i artyści, tacy jak Elvis Costello czy Michael Jackson, nagrywali w esperanto, komponowali utwory inspirowane tym językiem lub używali go w swoich materiałach promocyjnych. Popularny w latach 80. w Czechosłowacji zespół Team po wielkim sukcesie swojego pierwszego albumu (250 tys. sprzedanych egzemplarzy) nagrał również jego esperancką wersję. Do klasycznych dzieł na orkiestrę i chór z esperanckimi tekstami należą "La Koro Sutro" Lou Harrisona czy też pierwsza symfonia w esperanto autorstwa Davida Gainesa. We francuskiej Tuluzie działa wytwórnia muzyczna Vinilkosmo, która specjalizuje się w produkcji esperanckiej muzyki. Główny internetowy zbiór tekstów piosenek w esperanto KantarViki przekroczył w kwietniu 2013 liczbę 3000 utworów, w tym zarówno oryginalnych, jak i zaadaptowanych z innych języków.
Teatr i kino.
Sztuki teatralne tak różnorodnych autorów jak Goldoni, Ionesco, Szekspir czy Alan Ayckbourn są w ostatnich latach wystawiane również w esperanto. W filmach esperanto pojawia się niekiedy jako tło – np. w "Dyktatorze" Charliego Chaplina pojawiają się napisy i plakaty w tym języku – lub jako przedstawienie przyszłości, np. w filmie akcji "" czy w serialu komediowym science-fiction "Czerwony karzeł". Esperanckie dialogi pojawiają się np. w "Idiot’s Delight" z Clarkiem Gable czy w japońskim filmie "Jan Arima no shūgeki". Filmy pełnometrażowe są jednak rzadkością. Mimo to istnieje ok. 25 filmów pełnometrażowych, w których pojawia się esperanto. Istotnymi wyjątkami są tu "Angoroj", pierwszy całkowicie esperancki film pełnometrażowy, czy kultowy "Incubus" (w głównej roli William Shatner). Na esperanto przekładane są również napisy do filmów; organizacją i gromadzeniem przekładów zajmuje się strona internetowa Verda Filmejo. Z Verda Filmejo wyłoniła się grupa Filmoj sen Limoj ("Filmy bez granic"). Ostatnio pojawiły się również amatorskie esperanckie projekty i społeczności tworzące krótkie filmy całkowicie w esperanto. Ich długość zazwyczaj nie przekracza kilkudziesięciu minut. Przykładem jest tu brazylijska spółka Imagu Filmoj, która wyprodukowała m.in. pełnometrażowy film "Gerda Malaperis" oparty na powieści Claude Pirona.
Czasopisma.
Ponad 100 gazet i czasopism ukazuje się regularnie w esperanto, wśród nich poświęcone aktualnościom "Monato", czasopismo literackie "Beletra Almanako" czy też oficjalne organy TEJO i UEA – odp. "Kontakto" i "Esperanto". Prenumeratorzy uzyskują również elektroniczny dostęp do wielu innych ważnych czasopism, w tym do numerów archiwalnych. Istnieją periodyki poświęcone medycynie, nauce, młodzieży, religii, czasopisma edukacyjne i pedagogiczne, literackie i tematyczne. Gazeta Heroldo de Esperanto jest wydawana od niemal stu lat (od 1920), a nowy właściciel, Sociala Grupo Lexus, planuje w 2017 sześciokrotnie zwiększyć liczbę prenumeratorów i już w 2018 wydawać "Heroldo" dwa razy w miesiącu, na 24 stronach.
Niezależnym komentowaniem wydarzeń w ruchu esperanckim zajmuje się internetowy magazyn Libera folio.
Radio i telewizja.
Rozgłośnie radiowe w Brazylii (Radio Boa Nova), Chinach (Chińskie Radio Międzynarodowe), Australii (Melbourne Ethnic Community Radio), na Kubie (Radio Habana Cuba), i w Watykanie (Radio Watykańskie) nadają aktualnie (wrzesień 2016) regularne audycje w esperanto. Rośnie również liczba programów dostępnych przez Internet, kolejne stacje (profesjonalne i amatorskie) działają głównie lub wyłącznie w sieci. Do popularnych esperanckich podkastów należą np. Varsovia Vento, Kern.punkto, Esperanta Retradio czy Radio Verda (do 2013). Podkast Pola Retradio stanowi kontynuację dla zlikwidowanych w 2011 roku esperanckich audycji Polskiego Radia. W 2011 powstało internetowe radio Muzaiko, pierwsze nadające programy w esperanto przez 24 godziny na dobę. Aplikacja Muzaiko na smartfony umożliwia również odsłuchiwanie podkastów z innych stacji radiowych, m.in. wymienionych wyżej krajowych rozgłośni. Regularne programy w esperanto nadawała Telewizja Białystok.
Internet.
Rozwój i upowszechnienie nowych technologii stało się motorem napędowym dla esperanta, dzięki czemu można mówić o swoistym odrodzeniu języka. W Internecie dostępne są w esperanto strony, kursy, fora, czaty, blogi, grupy dyskusyjne, filmy, prasa, podkasty i kanały radiowe (np. Muzaiko). Sytuację języka w internecie obrazuje również objętość esperanckiej Wikipedii, która we wrześniu 2016 liczyła ponad 230 000 haseł i prawie 400 aktywnych użytkowników.
W Internecie dostępne są esperanckie słowniki, m.in. elektroniczna wersja najobszerniejszego słownika definicyjnego Plena Ilustrita Vortaro de Esperanto, Reta Vortaro, Wikisłownik. Od 2002 roku działa poświęcony nauce esperanta portal Lernu!, dostępny w 37 językach. W 2015 roku ruszył anglojęzyczny kurs esperanta w popularnej aplikacji Duolingo, który znacznie przyczynił się do popularyzacji esperanta w sieci. Po roku od uruchomienia przekroczył on próg 400 tysięcy zarejestrowanych użytkowników, z których kończyło kurs codziennie 30 osób. Wkrótce (lato 2016) zostanie uruchomiony kolejny kurs w języku hiszpańskim.
W serwisie YouTube dostępne są liczne nagrania wideo w esperanto i na temat esperanta: muzyka, filmy, wideoblogi, wywiady, relacje z esperanckich imprez, wykłady, kursy, sztuki teatralne, przewodniki turystyczne, audiobooki itd. Najpopularniejszym youtuberem esperanckim jest Richard Delamore z Australii, tworzący pod pseudonimem Evildea. W trakcie pandemii popularność zdobyła również Chelsea Rae Moses z USA.
Esperanto jest szeroko używane w komunikatorach internetowych ICQ, IRC, MSN i Skype. Wśród użytkowników kursu esperanta w Duolingo popularność zdobywa komunikator Telegram. Programy komputerowe takie jak LibreOffice, Firefox, IrfanView, środowisko graficzne KDE i systemy operacyjne Ubuntu i Mandriva są dostępne w esperanto. Popularne strony internetowe takie jak Google, Wikipedia, Facebook czy Ipernity posiadają również esperanckie wersje. W 2017 roku została uruchomiona aplikacja społecznościowa Amikumu umożliwiająca użytkownikom smartfonów wyszukanie esperantystów znajdujących się w pobliżu w oparciu o GPS. Pod koniec 2018 roku Johannes Genberg ze Szwecji stworzył serwis społecznościowy dla esperantystów Nubo.re, strona nie działała jednak poprawnie i została w 2020 zamknięta, a jej twórca otworzył nowy serwis o nazwie MiaVivo.net, który bazuje na programie PeepSo.
Religia.
Podczas I Światowego Kongresu Esperanta (1905) ks. Peltier przygotował mszę świętą w języku esperanto, a podczas II Światowego Kongresu Esperanta w Genewie w roku 1906 wygłosił pierwsze w historii kazanie w języku esperanto. Od roku 1990 esperanto jest oficjalnie zaliczone do liturgicznych języków Kościoła katolickiego. Na esperanto jest przetłumaczona także Biblia, a Stary Testament jest pierwszym dziełem literackim wydanym w esperanto z tłumaczeniem dokonanym przez samego Ludwika Zamenhofa. W Polsce pierwszą mszę w języku esperanto odprawił biskup Jan Maria Michał Sitek zwierzchnik Kościoła Starokatolickiego Mariawitów. Było to 2 sierpnia 1959 roku w kościele ewangelicko-augsburskim pw. Świętej Trójcy w Warszawie. Śpiewy liturgiczne przygotował chór parafii mariawickiej z Leszna. Okazją do dokonania przekładu tekstów liturgii był XLIV Światowy Kongres Esperanto, który obradował wówczas w Warszawie. Inicjatywa nabożeństwa ekumenicznego w języku esperanto wyszła od Polskiej Rady Ekumenicznej. Zdecydowano również, że nabożeństwo zostanie odprawione w obrządku mariawickim, najbliższym rzymskokatolickiemu, a tym samym większości uczestników Kongresu. Przekład liturgii powierzono bp. Janowi Marii Michałowi Sitkowi, zaś opiekę merytoryczną kapłanom mariawitom. Mariawici aktywnie uczestniczyli w międzynarodowym ruchu esperanckim od 1906 roku. Papież Jan Paweł II znał esperanto i również w tym języku udzielał błogosławieństwa „Urbi et Orbi”.
Audycje religijne w języku esperanto nadaje Radio Watykańskie.
Charakterystyka językoznawcza.
Klasyfikacja.
Esperanto jest językiem sztucznym, w związku z czym nie jest genealogicznie powiązane z żadnym językiem etnicznym. Można je opisać jako "język o wybitnie łacińskim i germańskim słownictwie. Z punktu widzenia morfologii jest językiem przeważnie aglutynacyjnym z niewielką tendencją analityczną". Fonologia, gramatyka, leksyka i semantyka są zasadniczo oparte na językach indoeuropejskich z Europy. Aspekty pragmatyczne i inne nie zostały zdefiniowane w oryginalnych pismach Zamenhofa.
Typologicznie esperanto jest językiem postpozycyjnym, a domyślny szyk zdania to SVO. Przymiotniki mogą być dowolnie umieszczane przed lub po rzeczownikach, które określają, jednak częściej stawia się je przed rzeczownikiem. Nowe wyrazy tworzy się poprzez rozbudowaną prefiksację i sufiksację.
Fonetyka i fonologia.
Esperanto liczy 23 fonemy spółgłoskowe i 5 samogłoskowych. Półsamogłoski /j/ i /w/ zostały poniżej zaliczone do spółgłosek. Mimo że ich wymowa przypomina wymowę samogłosek, funkcjonują one jako spółgłoski.
Norma wymowy esperanta nie przewiduje obowiązkowych alofonów, jednak istnieje tendencja do minimalizowania wariacji alofonicznej. Przykładowo nie istnieje reguła nakazująca wymowę /n/ przed /ɡ/ i /k/ jako [ŋ] – wymowa jako [n] jest również dozwolona i stosowana przez niektórych użytkowników przy starannej wymowie. Podobnie dla fonemów samogłoskowych /e/ i /o/ dopuszczalne są wszystkie realizacje odpowiednio pomiędzy [e] i [ɛ] oraz [o] i [ɔ], a wymowa średnia [e̞] i [o̞] jest postrzegana jako najbardziej modelowa.
Samogłoski.
Esperanckie dyftongi /aj/, /oj/, /uj/, /ej/, /aw/ i /ew/ nie są uznawane za osobne fonemy, lecz za kombinacje dwóch fonemów, tj. samogłoski i półsamogłoski.
Procesy fonetyczne.
Norma wymowy esperanckiej nie przewiduje reguł dotyczących procesów fonetycznych, a te spotykane u niektórych użytkowników są postrzegane jako niepożądany wpływ języków narodowych. Przykładowo nie występuje upodobnienie spółgłosek w zbitkach pod względem dźwięczności, chociaż wymowa niezgodna z tą zasadą jest tolerowana w praktyce, o ile nie jest źródłem nieporozumień. Podobnie toleruje się epentezę półsamogłoski pomiędzy dwoma różnymi samogłoskami, zwłaszcza przymkniętymi, np. [ˈmija] "mia" i [ˈpluwa] "plua" oraz zwarcia krtaniowego pomiędzy różnymi lub (zwłaszcza) identycznymi samogłoskami, np. [praˈʔavo] "praavo".
Od samego początku istnieje tendencja do eliminowania z pisowni i wymowy rzadkiej spółgłoski /x/ "ĥ" i zastępowania jej w wyrazach przez /k/, co sugerował już sam Zamenhof. Słowniki z reguły podają równolegle formy z "ĥ" i "k", jedynie sekwencja "rĥ" (np. "arĥeologio", "arĥitekto", "monarĥo") została tak dalece zastąpiona przez "rk" (np. "arkeologio", "arkitekto", "monarko") już we wczesnym XX wieku, że współcześnie niewiele słowników podaje "rĥ" jako opcję. Inne wyrazy, takie jak "ĥirurgo", "ĥaoso", "monaĥo", "teĥniko", wciąż występują w obu wersjach, jednak częściej z "k" ("kirurgo", "kaoso", "monako", "tekniko"). Tylko w niektórych przypadkach zamiana "ĥ" na "k" spowodowałaby dublowanie już istniejących wyrazów, dlatego zastąpiono je w nich przez "ĉ" ("ĉilo", "ĉino") lub "h" ("hamida", "Harbino" i inne chińskie nazwy geograficzne) lub zmieniono całkowicie ich formę ("ĥoro" → "koruso", "ĥolero" → "kolerao"). Tylko w dwóch słowach wciąż używa się niemal wyłącznie "ĥ" – "ĉeĥo" i "eĥo" (niekiedy spotyka się formę "ekoo").
Przyjmuje się, że oba wyrazy są pełnoprawne, zarówno starsza forma, zawierająca "ĥ", jak i nowsza, bez tej litery. Wybór zależy od gustu konkretnego użytkownika języka esperanto. Jedynie w kilku przypadkach forma zawierająca "ĥ" zanikła całkowicie (np. "ĥino") i używana jest jedynie jako środek stylistyczny – archaizm.
Prozodia.
Akcent pada zawsze na przedostatnią sylabę wyrazu (np. "radio", "matematiko", malgraŭ", "malgraŭe", dudek", "dudeka"), z wyjątkiem przypadków elizji końcówki "-o", która nie zmienia pozycji akcentu: "radi’", "matematik’". Akcentowana sylaba jest wymawiana głośniej i często także dłużej niż pozostałe, może również inny ton, zwłaszcza wyższy. Nie istnieją jednak precyzyjne reguły dotyczące sposobu wyróżniania akcentowanej sylaby.
Długość samogłosek nie jest fonemiczna w esperanto.
Słownictwo.
Leksykalny fundament esperanta został określony przez Zamenhofa w książce "Język międzynarodowy" w 1887 Słownik w niej zawarty zawierał 900 rdzeni leksykalnych. Reguły esperanta umożliwiają w razie potrzeby zapożyczanie słów, z zastrzeżeniem by miały one możliwie najbardziej międzynarodowy charakter. Możliwa jest również derywacja nowych wyrazów z użyciem już istniejących rdzeni i afiksów. W 1894 Zamenhof opublikował pierwszy słownik esperanta, "Universala vortaro", który zawierał większy zasób wyrazów. Od tego czasu zapożyczono do esperanta wiele słów z innych języków, zwłaszcza zachodnioeuropejskich.
Etymologia.
Słownictwo języka esperanto pochodzi w większości z istniejących języków europejskich. Są to głównie słowa o pochodzeniu romańskim oraz wyrazy międzynarodowe (typu "radio"), w mniejszym stopniu słowa o pochodzeniu germańskim (np. "hundo" – pies), rzadko słowiańskim (np. "bulko" – bułka). Słowa z innych języków weszły do słownictwa esperanckiego wyłącznie wtedy, gdy były powszechnie używane w językach, z których Zamenhof czerpał leksykę. W późniejszych latach do esperanto trafiały specyficznie regionalne pojęcia w językach oryginalnych, np. "haŝio" (pol. pałeczki) z japońskiego lub "boaco" (pol. renifer) z saami. Niektóre słowa esperantyści celowo wprowadzali do użycia ze swoich języków narodowych.
Przykłady etymologii:
Słowotwórstwo.
Esperanto jest językiem aglutynacyjnym z w większości regularnym słowotwórstwem.
Słowa można tworzyć przez sklejanie morfemów. By uniknąć skomplikowanych zbitek spółgłoskowych, można dodać między morfemy łącznik "-o-". Jest też bogata grupa morfemów przedrostkowych i przyrostkowych zmieniająca znaczenie słów.
We współczesnym esperancie nie ma ostrego podziału na morfemy znaczeniowe i gramatyczne.
Morfemy znaczeniowe w funkcji morfemów gramatycznych występują zazwyczaj na pozycji prefiksowej.
Ortografia.
Ortografia esperanta jest całkowicie fonemiczna – każda litera odpowiada dokładnie jednemu fonemowi i vice versa.
Do zapisu języka esperanto używa się alfabetu złożonego z 28 liter:
W alfabecie języka esperanto nie występują litery q, w, x ani y.
W przypadku gdy nie są dostępne czcionki z odpowiednimi znakami diakrytycznymi (ĉ, ĝ, ĥ, ĵ, ŝ oraz ŭ) stosuje się różne zastępcze systemy zapisu. Zamenhof rozwiązał ten problem, tworząc tzw. H-system, który polega na zastąpieniu liter z cyrkumfleksem poprzez dwuznak złożony z litery bez „daszka” oraz następującej po niej litery „h” (np. "ŝanĝo" → "shangho"), a w przypadku „ŭ” opuszczenie brewisa (np. "haŭto" → "hauto"). H system jest jedynym wymienionym w Fundamento de Esperanto. W dobie Internetu większą popularność zyskał jednak tzw. X-system, który w dwuznakach jako dookreślającą literę stosuje nieużywaną w esperancie, a jednocześnie zawsze obecną na klawiaturach komputerowych, literą „x” (np. "ŝanĝo" → "sxangxo", "haŭto" → "hauxto"). Najrzadziej używaną metodą zapisu jest tzw. "^-sistemo", w którym przy literze umieszcza się karetę (daszek „^”). Występuje on w dwóch odmianach: takiej, w której daszek następuje po literze (np. "ŝanĝo" → "s^ang^o"), oraz takiej, w której stoi on przed nią (np. "ŝanĝo" → "^san^go").
Aby uzyskać znaki zaproponowane w Unua Libro, pierwotnie używano systemu kodowania Latin 3, umożliwiającego znalezienie wszystkich sześciu potrzebnych znaków, który stopniowo został wyparty przez Unicode.
Ewolucja.
Choć powstał jako język sztuczny, w ciągu swojej historii podlegał wielu zmianom w stosunku do oryginalnej postaci tego języka. Żeby przedstawić skalę tych zmian, należy wymienić choćby:
Żadna z tych zmian nie może jednak naruszyć podstawowej zasady: Fundamento de Esperanto na zawsze ma pozostać nienaruszalne. Żadna osoba ani żadne stowarzyszenie nie ma prawa samowolnego wprowadzenia do Fundamento nawet najmniejszej zmiany. Do badania, czy rozwój języka dokonuje się w zgodzie z tą podstawową zasadą, powołano międzynarodową akademię ekspertów (Akademio de Esperanto).

</doc>
<doc id="1378" url="https://pl.wikipedia.org/wiki?curid=1378" title="Europejski Bank Centralny">
Europejski Bank Centralny

Europejski Bank Centralny, EBC (niem. "Europäische Zentralbank", "EZB"; ang. "European Central Bank", "ECB"; fr. "Banque centrale européenne", "BCE") – bank centralny wspólnej waluty Unii Europejskiej – euro – odpowiedzialny za emisję euro oraz ochronę jego siły nabywczej, a tym samym utrzymanie stabilności cen w strefie euro. W 2015 ochrona ta obejmowała 19 państw członkowskich Unii Europejskiej. Siedziba EBC mieści się we Frankfurcie nad Menem. Od 1 listopada 2019 EBC przewodniczy Christine Lagarde.
Kompetencje.
EBC jest bankiem centralnym strefy euro i w tym charakterze odpowiada m.in. za nadzorowanie systemów bankowych w państwach do niej należących, zbieranie danych statystycznych potrzebnych dla prowadzenia polityki pieniężnej, funkcjonowanie systemów płatniczych (zwłaszcza systemu TARGET), zapobieganie fałszerstwom banknotów, współpracę z innymi organami w zakresie regulacji rynków finansowych.
EBC współpracuje z bankami centralnymi 27 państw członkowskich Unii Europejskiej (w tym z Narodowym Bankiem Polskim). Wszystkie one tworzą Europejski System Banków Centralnych (ESBC).
EBC jest bankiem emitującym wspólną walutę euro i prowadzącym politykę pieniężną w strefie euro, m.in. poprzez ustalanie podstawowych bankowych stóp procentowych oraz operacje otwartego rynku. W tym zakresie EBC jest wspierany przez banki centralne państw UE, które przyjęły walutę euro – tworzą one ściślej współpracującą grupę w ramach ESBC, zwaną Eurosystemem. Po przystąpieniu wszystkich państw UE do unii walutowej EBC będzie pełnił funkcję banku centralnego Unii Europejskiej.
Kwestią pozostającą poza kompetencjami EBC, choć wpływającą bezpośrednio na warunki w jakich może on prowadzić politykę monetarną, jest dyscyplina budżetowa państw strefy euro. Są one zobowiązane w tym zakresie do przestrzegania Paktu Stabilności i Wzrostu.
W celu realizacji założeń polityki pieniężnej EBC wraz z narodowymi bankami centralnymi stosuje instrumenty, które dzielą się na rezerwę obowiązkową, operacje otwartego rynku oraz kredyt i depozyt na koniec dnia ("standing facilities").
Według artykułu 282 TFUE: „1. Europejski Bank Centralny i krajowe banki centralne stanowią Europejski System Banków Centralnych (ESBC). Europejski Bank Centralny i krajowe banki centralne Państw Członkowskich, których walutą jest euro, tworzące Eurosystem, prowadzą politykę pieniężną Unii.”
Niezależność EBC.
Europejski Bank Centralny jest niezależny w zakresie prowadzonej przez siebie polityki pieniężnej na czterech płaszczyznach:
W praktyce niezależność EBC jest w pewien sposób ograniczona przez naciski polityczne. Wynika to z przepisów traktatu z Maastricht, które określają wśród celów banku nie tylko dbanie o stabilność waluty, ale także „wspieranie ogólnej polityki gospodarczej Wspólnoty”. W rezultacie działania EBC podlegały licznym naciskom politycznym, głównie ze strony Francji i Niemiec.
Władze EBC.
Władza EBC jest sprawowana przez 3 organy.
Rada Prezesów jest naczelnym organem decyzyjnym. W jej skład wchodzi 25 członków, z czego 6 jest członkami Zarządu EBC, a 19 to prezesi banków centralnych państw UE, które przyjęły euro (patrz Eurosystem). Członkowie Zarządu są wybierani na 8-letnią kadencję. Prezesem Rady Prezesów jest od 1 listopada 2019 Christine Lagarde. Formą działalności są spotkania organizowane co najmniej 10 razy w roku. Obowiązkami Rady jest uchwalanie wytycznych i podejmowanie decyzji niezbędnych do wykonywania zadań powierzonych Eurosystemowi. W gestii tego organu leży też ustalanie polityki pieniężnej strefy euro oraz podejmowanie decyzji w sprawach polityki pieniężnej, stóp procentowych i w sprawach wielkości rezerw w Eurosystemie.
Zarząd składa się 6 członków, którymi są prezes Christine Lagarde, wiceprezes oraz 4 członków mianowanych przez rządy państw Eurosystemu po konsultacjach z Parlamentem Europejskim i Radą Prezesów. Zarząd jest organem wykonawczym, zajmuje się administrowaniem i organizacją pracy EBC. Realizuje politykę pieniężną strefy euro.
Rada Ogólna skupia w sobie prezesa i wiceprezesa EBC oraz 27 prezesów banków centralnych państw członkowskich UE (strefa euro i państw spoza jej obszaru). Do kompetencji Rady Ogólnej należy udział w działaniach doradczych EBC, zbieranie statystyk, sporządzanie raportów rocznych EBC oraz ustalanie warunków zatrudnienia personelu EBC. Przygotowuje dane niezbędne do nieodwołalnego ustalenia kursów walut państw członkowskich objętych derogacją wobec euro. Rada ustala też zasady konieczne do normalizacji procedur rachunkowych i sprawozdawczych stosowanych przez krajowe banki centralne państw UE. W myśl Statutu przewidywane jest rozwiązanie Rady Ogólnej, gdy wszystkie państwa członkowskie przyjmą euro.
Europejski Bank Centralny zatrudnia ponad 3600 osób.
Historia.
Poprzednikiem EBC był Europejski Instytut Walutowy, który nie dysponował kompetencjami władczymi i funkcjonował jedynie jako ciało doradcze krajowych banków centralnych. Jego głównym zadaniem było przygotowanie wprowadzenia wspólnej waluty na obszarze Unii.
EBC powstał 1 czerwca 1998, gdy weszły w życie nominacje na członków Zarządu EBC. 1 stycznia 1999 w 11 państwach UE wprowadzono w formie bezgotówkowej euro oraz powstał Eurosystem (obejmujący wtedy EBC oraz 11 krajowych banków centralnych). Dwa lata później do strefy euro dołączyła Grecja, a do Eurosystemu jej bank centralny.
Euro funkcjonowało początkowo jedynie w obrocie bezgotówkowym – w obiegu pozostały banknoty i monety reprezentujące dotychczasowe waluty krajowe (stały się one w tym czasie krajowymi odmianami euro). Zastąpienie banknotów i monet krajowych banknotami i monetami euro zostało przeprowadzone stopniowo w pierwszych miesiącach 2002.
W 2014 r. Europejski Bank Centralny wprowadził się do swojej nowej siedziby. Wcześniej EBC operował z Eurotower we Frankfurcie nad Menem.
Wpływ na politykę gospodarczą oraz zachowanie w czasie kryzysu.
Europejski Bank Centralny jako jedna ze stron rozmów w Grecji (pozostałymi byli przedstawiciele państwa greckiego, Międzynarodowy Fundusz Walutowy i Komisja Europejska) zdecydował, że posiadacze greckich obligacji dostaną maksymalnie 25% zainwestowanego kapitału, a sama Grecja musiała dokonać cięć świadczeń socjalnych. Europejski Bank Centralny nie był gotowy do zarządzania podażą pieniądza w czasie kryzysu 2008 r., dlatego zaczął korzystać z instrumentu luzowania ilościowego dopiero w 2015 r.

</doc>
<doc id="1379" url="https://pl.wikipedia.org/wiki?curid=1379" title="Epika">
Epika

Epika (gr. "epikós" „słowny”) – jeden z trzech rodzajów literackich (obok liryki i dramatu). Ukształtowała się z ustnych sag, podań, legend i mitów o przeszłości.
Składniki świata przedstawionego.
Między światem przedstawionym a narratorem zachodzi określony stosunek, gdy narrator jest albo niewidoczny, albo uwidacznia swoje stanowisko, lub w skrajnych przypadkach traktuje fabułę jako pretekst do własnych przemyśleń i wypowiedzi.

</doc>
<doc id="1380" url="https://pl.wikipedia.org/wiki?curid=1380" title="Egzogamia">
Egzogamia

Egzogamia – zakaz zawierania małżeństw wewnątrz określonej grupy (poszerzonej rodziny, klanu egzogamicznego), utożsamiany przez jej członków z zakazem kazirodztwa, mimo że wyznacza szerszą grupę, niż jednostki blisko spokrewnione.
Najczęstszą zbiorowością egzogamiczną w społeczeństwach pierwotnych jest klan egzogamiczny, zazwyczaj posiadający własny totem. W społeczeństwach podzielonych na dwa klany lub inne jednostki egzogamiczne, określane są one mianem mojetów (połów).
Każdy rodzaj egzogamii określa jakąś formę endogamii. Claude Lévi-Strauss podaje przykład wioski Bororo, gdzie małżeństwa mogą być zawierane wyłącznie krzyżowo między połowami (między klanami zamieszkującymi wschód i zachód wioski, określanymi przez Lévi-Straussa jako połowy pseudoegzogamiczne), a jednocześnie tylko wewnątrz „klas” wyższych, średnich i niższych, na jakie dzielą się klany.
Strukturę egzogamiczną tłumaczy się brakiem równowagi w proporcjach płci, które często występują wśród rozproszonych terytorialnie grup liczących poniżej 400 osób, zwłaszcza wśród łowców i zbieraczy. Okresowo grupy takie zbierają się, co umożliwia zawieranie małżeństw pomiędzy członkami grup. Według Bronisława Malinowskiego egzogamia oraz zakaz cudzołóstwa żony są formami regulacji, pozwalającymi uniknięcia swobody seksualnej prowadzącej do promiskuityzmu, a sama egzogamia także eliminuje rywalizację wewnątrz „rodów”. Odrzucał on jednak założenie Jamesa Frazera o tym, że egzogamia była formą świadomego aktu pierwotnego prawodawstwa, ponieważ potrzeby kulturowe na poziomie układu społecznego nie mają przełożenia na poziom indywidualnych motywacji w społecznościach pierwotnych.

</doc>
<doc id="1381" url="https://pl.wikipedia.org/wiki?curid=1381" title="Endogamia">
Endogamia

Endogamia (etym. gr. endon – „wewnątrz”, gameo – „zawieram małżeństwo”) – kulturowa reguła nakazująca jednostce zawieranie małżeństw (dobieranie sobie partnera) wewnątrz własnej grupy, w celu zabezpieczenia jej przed utratą członków, wzmocnienia izolacji i utrzymania odrębności. Endogamia występuje zazwyczaj w społeczeństwach uwarstwionych, służy względom prestiżowym i utrwala zróżnicowanie etniczne (kastowość). 
Endogamia w małej grupie prowadzi do związków między bliskimi krewnymi biologicznymi. Występuje zarówno w społecznościach matrylinearnych i patrylinearnych.
Dobór takiego małżeństwa odbywa się często na zasadzie przeznaczenia sobie z góry pewnych osób lub na zasadzie pierwszeństwa. Do tych ostatnich należy np. lewirat i sororat. 
Społeczności, w których często praktykowana jest endogamia, wykazują wyższy stopień występowania chorób dziedzicznych.
Recepcja małżeństw endogamicznych.
Jako przykłady endogamii można podać:
Małżeństwo kuzynowskie.
Inne bardziej skomplikowane zwyczaje to np. tzw. małżeństwo kuzynowskie „na krzyż”, polegające na tym, że mężczyzna bierze za żonę wujeczną siostrę lub inną kobietę o tym samym stopniu pokrewieństwa. W niektórych kulturach środkowej Australii mężczyzna może ożenić się także z wnuczką brata babki ze strony matki (lub kobietą o tym samym stopniu pokrewieństwa), jednak małżeństwa kuzynowskie to starszy zwyczaj. Bardzo rzadko natomiast dozwolone jest małżeństwo między „równoległymi krewnymi”, czyli dziećmi dwojga braci lub dwóch sióstr.

</doc>
<doc id="1382" url="https://pl.wikipedia.org/wiki?curid=1382" title="Eridanus">
Eridanus



</doc>
<doc id="1383" url="https://pl.wikipedia.org/wiki?curid=1383" title="Efekt mnożnikowy">
Efekt mnożnikowy

Efekt mnożnikowy – zjawisko o charakterze sprzężenia zwrotnego, polegające na rozwoju wielu różnych przedsiębiorstw (działalności gospodarczych) pod wpływem dodatkowego popytu konsumpcyjnego i zaopatrzeniowego powstałego w wyniku uruchomienia lub rozbudowy jakiegoś przedsiębiorstwa (działalności gospodarczej). Efekty mnożnikowe są korzystne dla rozwoju lokalnej gospodarki.
Można również mówić o "negatywnych efektach mnożnikowych" w przypadku kryzysu lokalnej gospodarki w wyniku zamknięcia lub zmniejszenia produkcji w jakimś przedsiębiorstwie.

</doc>
<doc id="1384" url="https://pl.wikipedia.org/wiki?curid=1384" title="Epoka paleomagnetyczna">
Epoka paleomagnetyczna

Epoka paleomagnetyczna – trwające od kilkuset tysięcy do kilku milionów lat okres o określonej polarności ziemskiego pola magnetycznego. W trakcie ich trwania mogły występować krótkotrwałe okresy odwrócenia pola magnetycznego tzw. epizody i ekskursje paleomagnetyczne
Można je odtworzyć na podstawie paleomagnetycznych zapisów w skałach osadowych i wulkanicznych utrwalonych w postaci tzw. magnetyzacji szczątkowej.
Najmłodsze epoki paleomagnetyczne noszą nazwy wywodzące się od nazwisk badaczy paleomagnetyzmu:
Starsze epoki oznaczone są kodami cyfrowo-literowymi.

</doc>
<doc id="1385" url="https://pl.wikipedia.org/wiki?curid=1385" title="Edward Jan Habich">
Edward Jan Habich

Edward Jan Habich (ur. 31 stycznia 1835 w Warszawie, zm. 31 października 1909 w Limie) – polski inżynier i matematyk; uczestnik powstania styczniowego, na emigracji osiedlił się w Peru, gdzie zorganizował szkołę inżynieryjną i otrzymał honorowe obywatelstwo, członek honorowy Towarzystwa Muzeum Narodowego Polskiego w Rapperswilu od 1890 roku.
Życiorys.
Urodził się w pochodzącej spod Osnabrück spolszczonej rodzinie – z ojca Ludwika, urzędnika Komisji Skarbu Królestwa Polskiego, i matki, Matyldy z Mauersbergerów. Uczęszczał do warszawskiego gimnazjum gubernialnego, z którego miał być (wedle rodzinnej tradycji) wydalony w ostatniej klasie za spoliczkowanie dyrektora; wstąpił (w 1852) do armii rosyjskiej w Petersburgu; jako słuchacz Akademii Wojennej na Wydziale Artylerii uzyskał promocję oficerską. Po wystąpieniu ze służby wyjechał w 1858 do Francji; w Paryżu ukończył École nationale des Ponts et Chaussées z dyplomem inżynierskim. Po wybuchu powstania w 1863 roku wrócił do Polski, został (w stopniu podpułkownika) dowódcą oddziału i na jego czele nocą z 14 na 15 sierpnia przeszedł granicę; towarzyszył mu brat, Gustaw Habich. Oddział został rozbity przez Rosjan tego samego dnia, zaś Habich następnego dnia wrócił do Krakowa. W początku października został mianowany komisarzem Rządu Narodowego. Gdy Gustaw 29 października dostał się do niewoli, Habich uwolnił go; bracia zdołali dotrzeć do Francji.
W Paryżu Edward Habich został profesorem mechaniki w Szkole Wyższej Polskiej, następnie zaś jej dyrektorem. Podniósł poziom nauczania, lecz z końcem roku szkolnego 1867/1868 zrezygnował, po czym wyjechał do Peru; było to możliwe dzięki zabiegom Ernesta Malinowskiego, który nakłonił rząd tego kraju do zatrudnienia polskich inżynierów-emigrantów.
W Limie otrzymał stanowisko rządowego inżyniera i dyrektora robót publicznych. Początkowo prowadził m.in. prace irygacyjne w południowej części kraju, rozbudowę portu w Arica i projekty urbanistyczne. Od 1872 organizował państwową służbę techniczną w Peru, wzorowaną na francuskim Korpusie Inżynierów Mostów i Dróg. W 1873 r. przebywał jako delegat rządu peruwiańskiego w Europie, m.in. na wystawie powszechnej w Wiedniu. Zwerbował wówczas do pracy w Peru inżynierów W. Folkierskiego, W. Klugera, K. Wakulskiego, A. Babińskiego oraz architekta T. Stryjeńskiego. 
Wraz z pozyskanymi polskimi współpracownikami zorganizował w Limie (otwartą w 1876) pierwszą w Ameryce Łacińskiej Wyższą Szkołę Inżynieryjno-Górniczą ("Escuela de Construcciones Civiles y de Minas del Perú", później przemianowana na "Escuela Especial de Ingenieros de Construcciones Civiles y de Minas del Perú", obecnie Universidad Nacional de Ingeniería); jako jej dyrektor (aż do śmierci) sprawował też nadzór nad robotami publicznymi w całym kraju. Był zwolennikiem oparcia samowystarczalności gospodarczej Peru w jak największym stopniu na eksploatacji własnych zasobów mineralnych oraz na rozwoju nowoczesnego rolnictwa, m.in. uprawy bawełny, trzciny cukrowej i winorośli.
W latach 1878–1884 kierował Centralną radą Inżynierów Rządowych, a w latach 1884–1902 był członkiem i doradcą technicznym Rady Robót Publicznych. W 1888 r. współpracował przy tworzeniu projektu peruwiańskiego prawa górniczego, które weszło w życie w 1896 r. Redagując w latach 1880–1887 periodyk "Annales de Construcciones Civiles y de Minas del Perú" zapoczątkował w tym kraju czasopiśmiennictwo techniczne. Przyczynił się wydatnie do założenia w 1888 r. Towarzystwa Geograficznego w Limie. Przebywając jako delegat Peru na wystawie światowej w Paryżu (1889 r.) uczestniczył w związanych z nią kongresach naukowych i technicznych, nawiązywał kontakty z przedstawicielami z przedstawicielami czołowych firm technicznych oraz dokonywał zakupów dla wielu instytucji peruwiańskich. Po powrocie do Peru w 1890 r. zajął się także wprowadzeniem w tym kraju systemu metrycznego. Powołane z jego inicjatywy w 1891 r. specjalne biuro zaczęło jednak praktycznie funkcjonować dopiero w roku 1906 .
Zmarł 31 października 1909; pochowany został na koszt rządu w mauzoleum na cmentarzu w Limie. Na placu noszącym jego nazwisko wystawiono mu pomnik.
Praca naukowa.
Większość życia Edward Habich poświęcił pracy inżyniera oraz dydaktyce. Redagował wspomniany rocznik poświęcony zagadnieniom budownictwa i górnictwa, był też członkiem Peruwiańskiego Towarzystwa Geograficznego. Zajęcia te nie pozwoliły mu na prowadzenie badań teoretycznych. Wydał zaledwie ok. 20 prac z dziedziny matematyki i kinematyki; nie zdołał w szczególności napisać polskiego podręcznika kinematyki. Opublikował za to 116 artykułów w peruwiańskich (m.in. "Boletin de Minas, Industrias i Construcciones") i francuskich czasopismach technicznych. Publikował głównie po hiszpańsku i francusku, ale drukował również rozprawy naukowe w języku polskim, m.in. w "Pamiętniku Towarzystwa nauk Ścisłych w Paryżu"" i "Rocznikach Towarzystwa Naukowego Krakowskiego".
Rodzina.
Ożenił się ok. 1885 z Peruwianką hiszpańskiego pochodzenia; miał córkę Jadwigę oraz czterech synów (jeden z nich, Eduardo, również został inżynierem).

</doc>
<doc id="1386" url="https://pl.wikipedia.org/wiki?curid=1386" title="Ernst Haeckel">
Ernst Haeckel

Ernst Haeckel (ur. 16 lutego 1834 w Poczdamie, zm. 9 sierpnia 1919 w Jenie) – niemiecki biolog, filozof i podróżnik; zwolennik darwinizmu. 
Życiorys.
Studiował medycynę na uniwersytetach w Berlinie, Würzburgu i Wiedniu. Interesował się badaniami niższych zwierząt morskich. W latach 1865–1909 był profesorem zwyczajnym anatomii porównawczej na Uniwersytecie w Jenie. Utworzył tam Instytut Zoologiczny. Uważany za prekursora niemieckiej myśli eugenicznej.
W filozofii łączył materializm przyrodniczy z ewolucjonizmem. Sformułował tzw. teorię rekapitulacji, twórca teorii gastrei wyprowadzającej Metazoa z jednokomórkowych pierwotniaków. Stworzył koncepcję monizmu, opracował pierwsze kompletne drzewo rodowe wszystkich organizmów i uwzględnił na nim człowieka. Jego system klasyfikacji istot żywych, odmiennie od tradycyjnego podziału bytów na królestwa minerałów, roślin i zwierząt (plus ludzi), uwzględniał trzy królestwa organizmów: Protista, Plantae i Animalia (z wyłączeniem minerałów jako bytów niebiologicznych). Wprowadzenie trzeciego królestwa w połowie XIX w. pojawiało się już wcześniej w propozycjach kilku przyrodników (Richarda Owena, Johna Hogga), jednak podział Haeckla nie spotkał się z uznaniem jemu współczesnych, którzy wybrali system Linneusza, uznając go za wygodniejszy i bardziej przemawiający do wyobraźni, mimo że – jak okazało się w drugiej połowie XX wieku – był oparty w dużej mierze na błędnych założeniach, a jednocześnie zauważając, że Protista to takson polifiletyczny. Haeckel modyfikował swój system. Początkowo do królestwa Protista włączył gąbki, czy toczkowce, które następnie przeniósł do zwierząt i roślin, a z roślin do protistów przeniósł grzyby i sinice. Wiązało się to z przedefiniowaniem protistów jako organizmów nierozmnażających się płciowo.
Wprowadził takie terminy jak ekologia, filogeneza, ontogeneza. Jego teorie przyczyniły się do wielkiego postępu biologii ewolucyjnej.
Dla upamiętnienia E. Haeckla nazwano szczyt Mount Haeckel (4090 m n.p.m.) w górach Sierra Nevada oraz planetoidę (12323) Häckel.

</doc>
<doc id="1387" url="https://pl.wikipedia.org/wiki?curid=1387" title="Edmond Halley">
Edmond Halley

Edmond Halley (imię zapisywane także jako "Edmund"; ur. w Haggerston, Shoreditch koło Londynu, zm. w Greenwich) – angielski astronom i matematyk. Odkrył ruchy własne gwiazd oraz istnienie eliptycznych orbit kometarnych, przepowiadając powrót komety znanej dziś jako kometa Halleya.
Życiorys.
Syn Edmonda Halleya, bogatego producenta mydła. W 1673 w wieku 17 lat Edmond Halley wstąpił do Queen’s College w Oksfordzie. Do 1678 obserwował niebo nad południową półkulą z Wyspy Świętej Heleny, tworząc rejestr 372 gwiazd. Następnie wrócił do Anglii. Do tego czasu nie dostał jeszcze dyplomu ukończenia uczelni. Ostatecznie na wniosek króla Karola II otrzymał go bez egzaminu końcowego.
W maju 1679 został wysłany do Gdańska przez Roberta Hooke’a, aby zweryfikować kwestionowane przez członków Towarzystwa Królewskiego (Royal Society) obliczenia położenia gwiazd dokonywane bez przyrządów optycznych przez Jana Heweliusza, skądinąd także członka Towarzystwa. Do lipca razem z gdańskim astronomem weryfikował obliczenia przy pomocy swych instrumentów, m.in. kwadranta z lunetami. Weryfikacja zakończyła się pomyślnie.
Zainteresowanie problemami grawitacji oraz prawami Keplera odnośnie do ruchów planet skłoniło go do odwiedzenia w sierpniu 1684 Isaaca Newtona, który przedstawił mu swoje nieupublicznione prace wyjaśniające wątpliwości. Halley przekonał Newtona do napisania pracy "Philosophiae Naturalis Principia Mathematica" (1687), po czym sfinansował jej druk.
W 1693 na podstawie zestawień narodzin i zgonów sporządzonych przez wrocławskiego pastora Caspara Neumanna opracował wzorzec obliczania składek emerytalnych dla powstających funduszy ubezpieczeniowych. W swej analizie potraktował Wrocław jako "miasto wzorcowe" – niebędące portem (który odwiedza większa liczba cudzoziemców) i leżące w spokojnym obszarze kontynentu. Według jego wyliczeń pod koniec XVII w. miasto miało mieć ok. 34 tys. mieszkańców, z czego mężczyzn w wieku poborowym, między 18 a 56 lat, 9027. Śmiertelność dzieci wynosiła 45% między 1. a 6. rokiem życia. Na podstawie swoich analiz sformułował także wnioski dla rządzących, sugerując zniechęcanie do bezżenności zarówno przez wysokie podatki, jak i przymus służby wojskowej oraz nawołując władze do wspierania rodzin wielodzietnych, tj. mających powyżej dwojga dzieci. Z kolei pomoc dla biednych polegać miałaby na tworzeniu miejsc pracy, aby ubodzy mieli szansę samodzielnego zarobienia na życie. Zaproponowany przez Halleya sposób wyliczania składek w zależności od wieku w niektórych towarzystwach ubezpieczeniowych przetrwał do końca XVIII w.
W 1693 zastosował rtęć jako ciecz termometryczną w termometrze. W 1720 objął stanowisko Astronoma Królewskiego.
Jego wkład w ówczesną naukę był ogromny. Jak pisze Bill Bryson w swojej książce („Krótka historia prawie wszystkiego”): „Edmond Halley (...) w ciągu swej (...) kariery był kapitanem statku, kartografem, profesorem geometrii na University of Oxford, (...), astronomem nadwornym, wynalazcą pełnomorskiego dzwonu nurkowego. Pisał autorytatywne teksty na temat magnetyzmu, prądów morskich i ruchów planet, a także o skutkach używania opium. Opracował koncepcję mapy pogody, (...) zaproponował sposób pomiaru Ziemi oraz jej odległość od słońca (...)”.
Upamiętnienie.
Aby uhonorować jego dokonania i wkład do astronomii, jego nazwiskiem nazwano krater na Księżycu, krater na Marsie, planetoidę oraz kometę (której wprawdzie nie odkrył, lecz jako pierwszy wysunął przypuszczenie, że kometa zaobserwowana w 1682 jest tym samym ciałem, które wcześniej widziane było w latach 1456, 1531 i 1607).

</doc>
<doc id="1388" url="https://pl.wikipedia.org/wiki?curid=1388" title="Edgar Douglas Adrian">
Edgar Douglas Adrian

Edgar Douglas Adrian (ur. 30 listopada 1889 w Londynie, zm. 4 sierpnia 1977 w Cambridge) – brytyjski arystokrata, baron, fizjolog, profesor Uniwersytetu Cambridge.
Życiorys.
Studiował w Trinity College na Uniwersytecie Cambridge. W latach 1937-1951 był profesorem uniwersytetu Cambridge. Był członkiem m.in. Towarzystwa Królewskiego Nauk w Londynie, gdzie w latach 1950-1955 pełnił funkcję prezesa, a także Narodowej Akademii Nauk w Waszyngtonie.
Od 1912 roku zajmował się badaniem czynności układu nerwowego i narządów zmysłów, głównie przewodzenia we włóknach nerwowych. 
Jest twórcą metody rejestrowania czynnościowych zmian elektrycznych w pojedynczych włóknach nerwowych. Przyczynił się do rozwoju elektroencefalografii i nauki o lokalizacji czynności w korze mózgowej.
Jego badania nad tzw. "rytmami Bergera" przyczyniły się do rozwoju badań nad padaczką i lokalizowaniem uszkodzeń mózgu.
Był autorem monografii:
W 1932 roku otrzymał nagrodę Nobla (razem z Charlesem Sherringtonem) „za odkrycia dotyczące funkcji neuronów”. W 1946 roku był także laureatem Medalu Copleya.

</doc>
<doc id="1389" url="https://pl.wikipedia.org/wiki?curid=1389" title="Epoka brązu">
Epoka brązu

Epoka brązu – epoka prehistorii, następująca po epoce kamienia, a poprzedzająca epokę żelaza. Epoka ta ma zróżnicowane ramy czasowe, zależne od terenu występowania. Najwcześniej, na południowym Kaukazie i w obszarze Morza Egejskiego, w III tysiącleciu p.n.e., wykształciły się ośrodki, w których opanowano umiejętność obróbki metali. W Egipcie i na Bliskim Wschodzie (Dżemdet Nasr), za początek epoki brązu przyjmuje się umownie rok 3400 p.n.e., w Europie Południowej 2800 p.n.e., na terenach dzisiejszych wschodnich Niemiec i zachodniej Polski 2200 p.n.e. Koniec epoki brązu przypada na lata 1000–700 p.n.e.
Nazwa epoki pochodzi od używanych wówczas powszechnie narzędzi z nowo wprowadzonego surowca – brązu, czyli stopu miedzi z cyną o stosunku 9:1. Przykładem przedmiotów z brązu są: siekiery, dłuta, młoty, motyki, sierpy, noże, ozdoby, broń (miecze, topory, ostrza do włóczni, groty, części pancerzy). Brąz pojawił się w Egipcie i Mezopotamii około 3500 p.n.e. Czasem zamiast cyny do produkcji stopu stosowano ołów lub antymon (Węgry). Brąz jest znacznie twardszy od miedzi, dlatego zastąpił ją po okresie eneolitu. Jednakże nadal był materiałem na tyle miękkim, że jeszcze w ciągu jednej bitwy wykuta z niego broń wyginała się, przez co była niezdatna do dalszego użytku.
Potrzebną do jego produkcji miedź i cynę uzyskiwano w kopalniach odkrywkowych.
Główne dziedziny gospodarki w czasie tej epoki to rolnictwo, hodowla bydła oraz pasterstwo. Powstanie ośrodków wytwórczych, wymiany towarów (wynalazek wozu na kołach oraz statków na wiosła i żagle sprzyjał rozwojowi handlu dalekosiężnego), gromadzenia bogactw, w konsekwencji doprowadziły do wzrostu walk międzyplemiennych i międzypaństwowych.
Najbardziej znane na świecie wykopaliska z epoki brązu: Ur w Mezopotamii, Ugarit w Syrii, Troja w Azji Mniejszej.
Początki.
Nie znamy dokładnego czasu i miejsca wynalezienia brązu, ale możliwe że brąz został wynaleziony w kilku miejscach naraz. Technologia wytwarzania brązu dotarła do Europy z Bliskiego Wschodu przez Anatolię, Bałkany i Kaukaz. Najstarsze wyroby brązowe, tzw. brązy arsenowe, wytwarzane były na Bliskim wschodzie już w V tysiącleciu p.n.e. Na Bałkanach brąz pojawia się dopiero pomiędzy IV a początkiem drugiej połowy III tysiąclecia. Prawdopodobnie wykorzystywano głównie surowiec pochodzenia anatolijskiego i kaukaskiego, gdyż brak jest dowodów na eksploatację w tym czasie miejscowych złóż miedzi. Przełom w wytwórczości nastąpił w środkowej epoce brązu, pojawiają się częściej klasyczne brązy cynowe, które wypierają brązy arsenowe. Słabną kontakty Płw. Bałkańskiego z Anatolią na rzecz kontaktów z Karpatami i środkową Europą. Z biegiem czasu doprowadza to do wytworzenia się autonomicznych karpackich ośrodków brązownictwa.
Bliski Wschód.
Epokę brązu na Bliskim Wschodzie możemy podzielić na trzy okresy:
Metalurgia po raz pierwszy została poświadczona w Anatolii (dzisiejsza Turcja), gdzie tamtejsze góry kryły bogate pokłady miedzi i cyny. Wczesna epoka brązu charakteryzuje się powstawaniem zorganizowanych miast, a także wynalezieniem piśmiennictwa. Środkową epokę brązu charakteryzują wędrówki ludów, które doprowadziły do zmiany ówczesnej mapy politycznej (Amoryci, Hetyci, Hyksosi, Huryci). Późna epoka brązu to czasy kształtowania i krystalizacji wielkich i potężnych królestw oraz ich wasali (Starożytny Egipt, Asyria, Mitanni, Babilonia). Istniały intensywne kontakty ze światem śródziemnomorskim, w których główną rolę odgrywała wymiana handlowa (miedź, cyna).
W 1200 r. p.n.e. zaczęto produkować żelazo w Anatolii.
Indie.
Epoka brązu w Indiach rozpoczyna się w 3300 r. p.n.e. i wiąże się ją z początkami cywilizacji Doliny Indusu oraz Drawidami, którzy wytwarzali już wyroby brązowe.
Wschodnia Azja.
Chiny.
Najwcześniejsze znaleziska brązowe pochodzą z obszarów kultury Majiayao, która datowana jest na 3100–2700 r. p.n.e. Jednak powszechnie przyjmuje się początek epoki brązu w Chinach od ok. 2000 r. p.n.e., czyli od panowania półlegendarnej dynastii Xia, ostrożnie identyfikowanej ze znaną z wykopalisk kulturą Erlitou, datowaną na 1900–1500 p.n.e.
Pełny rozkwit epoki brązu przypada na epokę Shang (ok. 2000–1500 p.n.e.), w której Chińczycy osiągają niebywałą biegłość w odlewach brązowych, zwłaszcza wielkowymiarowych naczyń rytualnych. Za czasów shangowskich zaistniało w Chinach złożone społeczeństwo o formie państwa, z dużymi miastami i rozbudowanymi formami rytualnymi oraz pismem. Obszar cywilizacji Shang zajmował większość basenu rzeki Żółtej i północną część basenu Jangcy. Zbliżone, choć oryginalne formy wyrobów brązowych prezentuje kultura Sanxingdui z Syczuanu.
Następująca po Shangach, dynastia Zhou była okresem formatywnym dla kultury i cywilizacji chińskiej, gdy ukształtowały się podstawowe zasady organizacji państwa i podstawy filozofii chińskiej. Wiele zabytków piśmienniczych tego okresu zachowało się na rytualnych naczyniach brązowych (tzw. napisy na brązach). Pod koniec epoki Zhou, po III w. p.n.e. następuje w Chinach przejście do epoki żelaza, aczkolwiek znane ono było od co najmniej VI w. p.n.e.
Korea.
Pierwsze wyroby brązowe były produkowane w Korei około 700–600 r. p.n.e. Był wykorzystywany w różnego rodzaju ceremoniach, aż do 100 r. n.e.
Sztuka.
Na wyspach Grecji rozwija się sztuka egejska. Na północy Europy wzrost znaczenia ognia, który uważany był za emisariusza słońca, oraz opanowanie technologii związanych z ogniem spowodowały wkroczenie w krąg tajemnic (misteriów) solarnych. W Europie w tym okresie bardzo powszechny staje się kult solarny i związany z nim obrządek ciałopalny. Brąz postrzegany jest jako substytut złota – słonecznego metalu. Naczynia gliniane w formie i kolorze próbują naśladować brązowe. Popularna staje się symbolika tarczy słonecznej – tzw. dysku solarnego, koła z wpisanym w nie równoramiennym krzyżem, mandali. Występuje nasilenie się symboli troistości – trójkąty, trzykrotne powtarzanie jednego symbolu. Równie popularny jest motyw labiryntu, symbolizującego narodziny i śmierć mistyczną w obrzędach inicjacyjnych oraz herosa solarnego. Pojawia się coraz więcej scen z życia codziennego i mitologii, następuje militaryzacja sztuki.
Epoka brązu w Europie.
Charakterystyczny dla epoki brązu jest niejednolity charakter rozwijających się i zanikających kultur. W środkowym jej okresie rozpoczął się proces wyodrębniania się i krystalizowania ludów europejskich, np. reprezentujących kulturę nordyjską Germanów zamieszkujących tereny obecnych Niemiec, Danii i południowej Szwecji.
Kultury epoki brązu.
Ważniejsze kultury epoki brązu w Europie.
Lista kultur epoki brązu i wczesnej epoki żelaza z podziałem na regiony występowania.
Najbardziej znane w Europie wykopaliska z epoki brązu: Mykeny w Grecji, Terramare we Włoszech, El Argar w Hiszpanii, Bad Buchau w Niemczech, Unětice w Czechach.
Epoka brązu w Polsce.
Na przełomie III i II tysiąclecia p.n.e. umiejętność obróbki metali dotarła na ziemie polskie. Kultury związane z wczesną epoką brązu w zasadzie jeszcze nie znały technologii wytwarzania brązu, jednak pojawiły się pierwsze wytwory z miedzi, srebra i złota pochodzące z importów. Przyniosły je w latach 2300–2100 p.n.e. nowe grupy ludzkie z południa Europy reprezentujące kultury oparte na tradycji kultur ceramiki sznurowej: kultura strzyżowska i kultura mierzanowicka. Po nich pojawiła się kultura madziarowska i kultury związane z kulturą unietycką, do nich należą kultura grobsko-śmiardowska i kultura iwieńska. W tym czasie powstały silne ośrodki metalurgiczne.
W połowie 2 tysiąclecia ziemie polskie, w dorzeczu Odry i Wisły, znalazły się w orbicie wpływów czeskopalatynackiej i środkowodunajskiej kultury mogiłowej. W późnej epoce brązu występowała kultura łużycka, zaliczana do kręgu kultur pól popielnicowych, z tego okresu znane jest stanowisko archeologiczne w Biskupinie.

</doc>
<doc id="1390" url="https://pl.wikipedia.org/wiki?curid=1390" title="Elia Kazan">
Elia Kazan

Elia Kazan (właśc. Elia Kazanjoglous; ur. 7 września 1909 w Stambule, zm. 28 września 2003 w Nowym Jorku) – amerykański reżyser filmowy i teatralny, scenarzysta i producent greckiego pochodzenia.
Życiorys.
Elia Kazan pochodził z rodziny greckiej żyjącej w Turcji. Przybył do Stanów Zjednoczonych w wieku 4 lat. Wtedy jego rodzice zmienili nazwisko na łatwiejsze do wymówienia dla Amerykanów. Uczył się w Williams College, gdzie czuł się obco wśród anglojęzycznych protestantów. Studiował dramat na Uniwersytecie Yale, następnie wstąpił do Group Theatre. W latach 30. przez półtora roku należał do amerykańskiej Partii Komunistycznej, z której odszedł w 1934, gdy dowiedział się o czystkach w Związku Radzieckim.
Po wojnie dał się poznać jako jeden z najlepszych reżyserów Broadwayu, m.in. dzięki inscenizacji "Tramwaj zwany pożądaniem". Jego filmy zawsze były kontrowersyjne i poruszały drażliwe tematy. W 1947 Kazan założył Actors Studio, gdzie nauczano wg metod Stanisławskiego. Najwybitniejszy uczeń Kazana – Marlon Brando – grał w kilku filmach swego nauczyciela, m.in. w "Viva Zapata!" (1952) i "Tramwaj zwany pożądaniem" (1951). Kazan odkrył też talent Jamesa Deana.
W 1952 Kazan został wezwany przed komisję senacką McCarthy’ego i pod groźbą znalezienia się na „czarnej liście Hollywood” złożył zeznania obciążające ośmiu kolegów z Partii Komunistycznej, co zostało negatywnie przyjęte przez środowiska artystyczne i przyczyniło się do zerwania na długie lata przyjaźni z wybitnym dramaturgiem Arthurem Millerem. Fakt ten został przypomniany opinii publicznej Ameryki w 1999 roku, kiedy sędziwy reżyser odebrał nagrodę Amerykańskiej Akademii Filmowej za całokształt działalności artystycznej.
Z bardziej znanych w Polsce filmów Kazana należy przypomnieć "Układ", który nakręcił na podstawie własnej książki pod tym samym tytułem.

</doc>
<doc id="1391" url="https://pl.wikipedia.org/wiki?curid=1391" title="Energetyka">
Energetyka

Energetyka – dział nauki i techniki, a także gałąź przemysłu, która zajmuje się przetwarzaniem dostępnych form energii na postać łatwą do wykorzystania przy zasilaniu wszelkich procesów przemysłowych, a także napędzaniu maszyn i urządzeń używanych w życiu codziennym.
W praktyce, energetyka obejmuje dostarczanie energii w dwóch postaciach:
Przemysł energetyczny składa się z dwóch części:
Energetyka należy do sektorów gospodarki o najbardziej szkodliwym wpływie na środowisko naturalne i zdrowie. Na poziomie Unii Europejskiej podejmuje się skoordynowane działania na rzecz ograniczenia tego szkodliwego wpływu poprzez integrację polityki energetycznej z polityką ekologiczną.

</doc>
<doc id="1392" url="https://pl.wikipedia.org/wiki?curid=1392" title="Energia geotermalna">
Energia geotermalna

Energia geotermalna (energia geotermiczna, geotermia) – energia cieplna skał, wody i gruntu pod powierzchnią Ziemi, zaliczana do odnawialnych źródeł energii. Proces odnawiania źródeł geotermalnych jest jednak powolny, stąd przy małym strumieniu ciepła geotermalnego pobieranie dużej ilości ciepła może doprowadzić do wychłodzenia skał lub spadku ciśnienia w zbiorniku. Energia geotermalna jest udostępniana za pomocą wierceń zbliżonych technologią wykonania do odwiertów naftowych, jednak odbiegających od nich w szczegółach wykonania i umiejscowienia. Energia geotermalna może być pobierana za pomocą gruntowych pomp ciepła lub głębszych odwiertów, które z reguły służą eksploatacji głęboko położonych warstw wodonośnych z gorącą wodą. Alternatywnie, możliwe jest wykorzystanie energii cieplnej skał nieprzepuszczalnych lub słabo zawodnionych, do których wtłaczana jest chłodna woda i po nagrzaniu odbierana gorąca. Jednym z przejawów obecności energii geotermalnej są źródła termalne.
Energię geotermalną wykorzystuje się w 64 krajach, a łączna moc działających elektrowni geotermalnych wynosi 11,4 GW (2012 rok). Jest ona najistotniejszym źródłem energii na Islandii i Filipinach. W Unii Europejskiej z energii geotermalnej pochodzi % produkowanej energii pierwotnej. W Polsce instalacje geotermalne dostarczające ciepło do systemu ciepłowniczego działają w sześciu miejscach, m.in. na obszarze Podhala i odpowiadają za % produkowanej energii pierwotnej.
Dostępność energii geotermalnej.
Temperatura Ziemi rośnie wraz z głębokością, osiągając 6600 °C w samym jądrze. Około 20% energii cieplnej wnętrza Ziemi pochodzi z kontrakcji grawitacyjnej w okresie formowania się planety, pozostałe 80% pochodzi z rozpadu radioaktywnych izotopów potasu (40K), uranu (238U i 235U) i toru (232Th), który zachodzi w płaszczu. Niewielki wkład w ciepło skorupy ziemskiej ma też tarcie wewnętrzne wywołane siłami pływowymi i zmianami w prędkości obrotu Ziemi. Część energii termicznej jądra transportowana jest do skorupy ziemskiej poprzez pióropusze płaszcza, które mogą powodować powstawanie plam gorąca i pokryw lawowych.
Energia geotermalna naturalnie wydostaje się na powierzchnię Ziemi z mocą około 46 TW.
Średni strumień geotermalny to około 0,063 W/m² – nie jest on zbyt duży, ale zasoby tej energii są praktycznie niewyczerpywalne, ze względu na ogromną objętość Ziemi. Strumień ten daje średni gradient temperatury (wzrost w kierunku środka) 25 K/km. Jest to niewystarczające do eksploatacji bezpośredniej, dlatego w geotermii istotne są tzw. rejony hipertermiczne (gradient większy od 80 K/km) i semitermiczne (od 40 do 80 K/km). Rejony hipertermiczne to przede wszystkim obszary radiogeniczne (duża zawartość pierwiastków radioaktywnych), obszary wysokiego strumienia ciepła (skały o bardzo dużej przewodności cieplnej) i punktowe źródła ciepła (zasoby magmy, wody geotermalne). W tych rejonach zasoby geotermalne występują jako petrotermiczne (energia zgromadzona w skałach) i hydrotermiczne (w wodzie).
Uzyskiwanie energii.
Głównym sposobem pozyskiwania energii geotermalnej jest tworzenie odwiertów do zbiorników gorących wód geotermalnych. W pewnej odległości od otworu czerpalnego wykonuje się drugi otwór, którym wodę geotermalną po odebraniu od niej ciepła, wtłacza się z powrotem do złoża. Wody geotermiczne są z reguły mocno zasolone, jest to powodem szczególnie trudnych warunków pracy wymienników ciepła i innych elementów armatury instalacji geotermicznych. Energię geotermiczną wykorzystuje się w układach centralnego ogrzewania jako podstawowe źródło energii cieplnej. Drugim zastosowaniem energii geotermicznej jest produkcja energii elektrycznej. Jest to opłacalne jedynie w przypadkach źródeł szczególnie gorących. Zagrożenie jakie niesie za sobą produkcja energii geotermicznej to zanieczyszczenia wód głębinowych, uwalnianie radonu, siarkowodoru i innych gazów.
Gorące źródła tzw. gejzery są charakterystycznym elementem krajobrazu Islandii, która wykorzystuje je jako źródło ogrzewania i ciepłej wody. Nie wpływa to ujemnie na środowisko naturalne.
Wykorzystanie energii geotermalnej na świecie.
Poniższa tabela przedstawia sumaryczną moc instalacji geotermalnych w krajach, które najintensywniej wykorzystują ten typ energii w MW:
Energia geotermalna w Polsce.
Polska ma bardzo dobre warunki geotermalne, gdyż 80% powierzchni kraju jest pokryte przez 3 prowincje geotermalne: centralnoeuropejską, przedkarpacką i karpacką. Temperatura wody dla tych obszarów wynosi od 30–130 °C (a lokalnie nawet 200 °C), a głębokość występowania w skałach osadowych od 1 do 10 km. Naturalny wypływ zdarza się bardzo rzadko (Sudety – Cieplice, Lądek-Zdrój). Możliwości wykorzystania wód geotermalnych dotyczą 40% obszaru kraju (wydobycie jest opłacalne, gdy do głębokości 2 km temperatura osiąga 65 °C, zasolenie nie przekracza 30 g/l, a także gdy wydajność źródła jest odpowiednia).
Powstał atlas wód geotermalnych występujących na terenie Polski pod redakcją prof. Wojciecha Góreckiego z Wydziału Geologii, Geofizyki i Ochrony Środowiska, Akademii Górniczo-Hutniczej, wskazujący obszary występowania wód geotermalnych na terenie Polski.
Pierwszy w Polsce Zakład Geotermalny w Bańskiej-Białym Dunajcu powstał w latach 1989–1993. Od 2001 z odwiertów i instalacji korzysta PEC Geotermia Podhalańska SA, która pokrywa 35% zapotrzebowania na ciepło w Zakopanem.
Koszt wybudowania instalacji o mocy około 10 MW wystarczającej do podłączenia około 1000 domów jednorodzinnych wyniósł w przypadku jednego z odwiertów na Podhalu 20 mln zł w 2012.
Wykorzystanie głębokiej geotermii.
Istniejące i budowane ciepłownie geotermalne w Polsce (geotermia głęboka)
W 2017 dotację z NFOŚiGW na rozpoznawanie możliwości wykorzystania zasobów geotermalnych otrzymały m.in. gmina Szaflary, gmina Koło, gmina Lądek-Zdrój, gmina Sochaczew oraz gmina Sieradz. Pięciokilometrowy, najgłębszy w Polsce, odwiert w Szaflarach wg planów ma posłużyć nie tylko do ogrzewania domów, ale także – pierwszy raz w Polsce – do produkcji prądu elektrycznego.
W 2019 roku rozpoczęła się rozbudowa Geotermii Stargard, która pozwoli na podwojenie mocy produkcyjnych. Planowany termin oddania do użytku nowych odwiertów to 2020.
W 2020 między MPEC-Konin oraz NFOŚiGW podpisana została umowa na dofinansowanie budowy ciepłowni geotermalnej o mocy 8,1 MWt w Koninie. Budowa planowana jest na lata 2021-2022.
Wykorzystanie płytkiej geotermii.
W Polsce funkcjonuje 35 tys. pomp ciepła w których źródłem ciepła jest grunt. Obiekty te wykorzystują to że temperatura gruntu w większości okresu grzewczego jest wyższa od temperatury otoczenia. Instalacje te są wykorzystywane do ogrzewania domów jednorodzinnych oraz obiektów publicznych. Moc tych instalacji to 390 MW, w ciągu roku wytwarzają one 2000 TJ energii.
Zalety i wady.
Zaletami geotermii są:
Wadami geotermii są:

</doc>
<doc id="1393" url="https://pl.wikipedia.org/wiki?curid=1393" title="Eurypides">
Eurypides

Eurypides (gr. "Euripídēs", ur. około 480 p.n.e., zm. 406 p.n.e.) – jeden z najwybitniejszych dramaturgów starożytnej Grecji. 
Życiorys.
Urodzony na Salaminie syn ateńskiego ziemianina Mnesarchosa i Klejto. Odebrał staranne wykształcenie atletyczne, muzyczne (obejmowało ono poza muzyką umiejętności poetyckie i choreograficzne) oraz filozoficzne. Próbował również swoich sił w malarstwie. Wiadomo, że był kapłanem Zeusa we Flyi, brał także udział w poselstwie Aten do Syrakuz, pełnił obowiązki proksenosa obywateli Magnezji w Atenach. Eurypides ożenił się dwa razy. Jego pierwszą żoną była Melito, drugą natomiast Chojrine, z którą doczekał się trzech synów. Około 408 r. p.n.e. wyprowadził się z Aten, najpierw skierował się do Magnezji w Tesalii, później do Pelli, gdzie zmarł na dworze króla Macedonii Archelaosa I śmiercią tragiczną w 406 r. p.n.e. rozszarpany przez królewskie psy gończe.
W sztukach Eurypidesa "Andromacha", "Medea" i "Ifigenia w Taurydzie" znalazły odbicie tragiczne dzieje Grecji z okresu wojny peloponeskiej, toczonej między Spartą i Atenami w V w. p.n.e. Eurypides był atakowany za zbytnią nowoczesność swojej twórczości. Jego nowatorstwo objawiało się zarówno w formie (prolog, pieśni chóru i arie nie musiały się łączyć z akcją sztuki – w jej przebieg interweniowali bogowie, pomagając w rozwiązywaniu skomplikowanej intrygi, tzw. "deus ex machina"), jak i w treści (m.in. bohaterowie byli często prostymi ludźmi, zaś technika monologu pozwalała głębiej sięgnąć do motywów ich działania). Głosił idee równości wszystkich ludzi, popadając w konflikt ze zwolennikami tradycyjnych stosunków społecznych.
Doceniony po śmierci bardziej niż za życia, wywiera wpływ na teatr europejski oraz na twórczość wybitnych pisarzy i humanistów po dziś dzień.
Twórczość.
Eurypides pierwszy raz wziął udział w agonie tragicznym w 455 r. p.n.e., lecz bez sukcesu. Zwycięstwo w konkursie odniósł dopiero w 441 r. p.n.e. To, czym dysponujemy z zachowanej twórczości tragika, stanowi dzieło dojrzałości i starości twórczej, tym bardziej że pierwszy z zachowanych utworów, tj. "Alkestis" powstał w 438 r. p.n.e., zatem Eurypides tworzył już od niespełna dwóch dekad.
Podział utworów Eurypidesa.
Jerzy Łanowski proponuje wyodrębnić w twórczości Eurypidesa następujące grupy utworów:
Konstrukcja.
Prologi w tragediach Eurypidesa mają formę monologów i precyzyjnie sytuują akcję danego utworu w jego kontekście mitologicznym. Niemal wszystkie dzieła zawierają sekwencję debaty (agonu), w której uczestniczą główne postacie i przekonują do własnych racji, ujawniając swoje zdolności oratorskie. Typową cechą Eurypidejskiej tragedii jest obszerna narracja, z którą występuje posłaniec, opisujący określone zdarzenie. Tragediopisarz ponadto rozwiązywał akcję utworów na zasadzie deus ex machina.
Postacie Eurypidesa tłumaczą się, usiłują się usprawiedliwiać, eksterioryzują własne myśli i uczucia, dokonują autoanalizy, próbują bronić swoich uczuć, racji i idei. Postacie znalazły się w centrum zainteresowania tragediopisarza. Ich tożsamość jest naznaczona przez cierpienie i odwagę. Najlepszymi przykładami są bohaterki z takich sztuk, jak "Alkestis", "Medea", "Hekabe", "Ifigenia w Taurydzie" i "Ifigenia w Aulidzie".
Przyjmuje się, że Eurypides jest wynalazcą intrygi. Akcja jego utworów opiera się na wybiegach, niespodziankach i rozpoznaniach. Dzięki zwiększeniu liczby i zróżnicowaniu postaci w jego tragediach urozmaiceniu ulega sama intryga. Za przykład mogą posłużyć "Fenicjanki", gdzie cała rodzina Edypa uczestniczy w dramacie, tj. w utworze obecni są Polinejkes i Eteokles, Jokasta, Antygona, zaś w środkowym momencie "Fenicjanek" Eurypides wprowadza Kreona, na scenie pojawiają się Tejrezjasz i Menojkeus. Wprowadzenie wielu postaci skutkuje akcją opartą na ruchu, przyspieszaniem jej rytmu i grą napięć, a wydarzenia ukazują się w całej różnorodności ludzkich interpretacji.
Eurypides dokonał redukcji roli chóru, co jest konsekwencją rozrostu akcji właściwej i stanowi wynik analizy psychologicznej, np. w "Fenicjankach" chór stanowią dziewczęta fenickie, które znajdują się w drodze do Delf. Dziewczęta nie mają większego związku z akcją, co najwyżej mogą wzbogacać tragedię o aspekt egzotyczny. Również w "Elektrze" rola chóru nie jest znacząca, zwłaszcza że jego wypowiedzi liczą 200 wersów na całkowitą liczbę 1360 wersów tragedii.
Eurypides rozwinął zatem akcję, wzmocnił efekty dramatyczne, nadał swobodę muzyce, zwiększył liczbę postaci oraz wprowadził perypetie, na skutek czego niektóre jego dzieła mogą wykazywać podobieństwa z melodramatem.
Formy gnomiczne.
To, co charakterystyczne dla Eurypidesa, to formy gnomiczne, którym została przyporządkowana funkcja moralna, estetyczna i retoryczna. Poeta wprowadza je w strukturę tragedii i za ich pomocą przekazuje pouczenia moralne, kreuje patos i etos postaci bądź wykorzystuje je jako riposty i pointy w sekwencjach agonistycznych. Formy gnomiczne dotyczą spraw losu, przeznaczenia, sprawiedliwości, wartości życia, przemijalności szczęścia, nieszczęścia, stosunku człowieka do bogów, roli bogów w życiu wspólnoty, miłości, przyjaźni, państwa i prawa, małżeństwa, dzieci. Szczególne miejsce zajmują gnomy na temat kobiet. Na przykład w "Alkestis" występują gnomy dotyczące śmiertelności: „Wszystkim śmiertelnym umrzeć przeznaczone” albo „Wytrwaj. Bo nigdy nie wskrzesisz przez płacz tych, którzy umarli”, zaś w "Fenicjankach" można znaleźć gnomę agonistyczną, która współtworzy wizerunek psychologiczny postaci: „Gdy trzeba krzywdzić, to krzywdzić dla władzy rzecz najpiękniejsza”.
Stosunek do opowieści mitycznych.
Eurypides – zgodnie z konwencją swoich czasów – opierał się na fabule mitu, choć traktował go bardzo swobodnie. Dokonał deheroizacji opowieści mitycznej, kiedy przedstawiał postacie i wydarzenia mitologiczne jako osoby i wydarzenia z dnia codziennego. Doprowadziło to do załamania się tradycyjnego wizerunku greckich bogów, a także do załamania się formy dotychczasowej tragedii greckiej. Eurypides potraktował mit jako wzorzec bądź szablon, który został wypełniony refleksją o współczesnym mu społeczeństwie i jego moralności. Nie oznacza to, że tragediopisarz rezygnował z motywacji boskiej, przeciwnie – mimo ustawienia na pierwszym planie człowieka jego utwory mają mitologiczny początek i koniec. Eurypides nie akceptował tradycyjnej greckiej religii i tradycyjnych bogów, będących odpowiednikami ludzi. Z tego względu współcześni – zwłaszcza Arystofanes – zarzucali mu bezbożność.
W tragediach Eurypidesa bogowie wpływają na ludzką egzystencję. Przede wszystkim ich ingerencja w porządek ziemski zmienia bieg akcji. Stopień ingerencji bóstw jest odmienny w poszczególnych utworach, np. w "Medei" rola Heliosa została zredukowana do udzielenia pomocy Medei w ucieczce w scenie finałowej, natomiast w "Bachantkach" Dionizos jest wprowadzony jako uosobienie siły, która powoduje klęskę Penteusa i jego rodziny. Negatywny aspekt relacji „bóg – człowiek” jest widoczny w takich utworach, jak "Hippolytos uwieńczony" (działanie Afrodyty), "Herakles szalejący" (Hera), "Trojanki" (Atena i Posejdon), "Bachantki" (Dionizos). W "Hippolycie" i "Bachantkach" bogów można potraktować jako symbole, będące reprezentacjami sfer ludzkiej psychiki, tym bardziej że to, jaki stosunek dane postacie mają do określonych bóstw, informuje o tym, jaka jest tożsamość tych postaci, np. Hippolytos otacza czcią Artemidę, a odrzuca Afrodytę. Eurypides operuje alegoryczną interpretacją bóstw mitologicznych i kwestie teologiczne wykorzystuje do celów psychologicznych.
Analiza psychologiczna.
Eros w ujęciu Eurypidesa jest równoznaczny z brakiem opanowania. To siła destrukcyjna. Poeta wyprowadza tragiczne implikacje takiego rozumienia Erosa. Los człowieka jest zdeterminowany przez psychikę i przeżycia, nie natomiast przez bóstwa. Wątek miłości jest praktycznie nieobecny w twórczości Ajschylosa i Sofoklesa. W twórczości tragicznej problem miłość występuje na szeroką skalę dopiero dzięki Eurypidesowi, co stanowi jedną z podstaw jego dyskusji z tradycją tragedii greckiej. W "Medei" można zaobserwować dramat wewnętrzny bohaterki, to, jak zmieniają się jej uczucia od bezgranicznej miłości do nienawiści, która znajduje finał w dokonanej przez Medeę zemście. Z kolei w "Hippolycie" namiętnej miłości poddała się Fedra, która zakochała się we własnym pasierbie, odczuwając bezsilność wobec tej namiętności. Namiętność Fedry przyniosła tragiczne konsekwencje, powodując śmierć bohaterki i Hippolyta. Eurypides zapewne wątpił w to, że właściwe myślenie, adekwatna ocena sytuacji i kwalifikacja moralna danej czynności uchronią człowieka przed złem i jego konsekwencjami. Tragiczny los człowieka to zwykle dzieło samego człowieka wtedy, gdy emocje dominują nad rozumem.
W "Heraklesie szalejącym" podejmowane przez badaczy rozbicie kompozycyjne tragedii pozostaje w związku z jej głównym tematem, tj. szaleństwem, np. pierwsza część utworu jest wypełniona przez procesy typowe dla pozycji paranoidalno-schizoidalnej, co ma związek z prześladowczym obrazem Lykosa. W wypowiedziach postaci (Megary, Amfitriona i Lykosa) można znaleźć cechy psychotyczne, wskazujące na rodzaj utraty kontaktu z rzeczywistością na rzecz fantazji. Część druga opiera się na mechanizmach psychotycznych halucynacyjno-urojeniowego epizodu Heraklesa. "Heraklesa szalejącego" można potraktować jako tragedię, będącą drogą od boskości do człowieczeństwa, od fantazji do realności i od psychozy do zdrowia. Także w tym przypadku Eurypides porusza zagadnienia irracjonalnych namiętności człowieka, jego życia psychicznego, dając bogaty materiał do analiz psychologicznych.
Prawo boskie a prawo ludzkie.
Sztukami, w których na pierwszy plan wysuwa się tematyka państwowa, są "Heraklidzi" i "Błagalnice". We wcześniejszych "Heraklidach" Eurypides porusza temat przeciwstawienia prawa boskiego i prawa ludzkiego oraz wskazuje, że sprawiedliwość to podstawa wspólnoty państwowej i relacji między obywatelami. Natomiast w "Błagalnicach" poeta ukazuje prawo jako fundamentu funkcjonowania państwa, dążąc do idealizacji tego obrazu. Bohaterowie "Błagalnic" również przywołują problem prawa niepisanego, które znajduje wyraz w praktykach religijnych oraz prawa spisanego, będącego podstawą państwa demokratycznego. W tej tragedii – inaczej niż np. w "Antygonie" Sofoklesa – prawo pochówku zmarłych jest zaprezentowane jako prawo boskie, które ma odzwierciedlenie w prawie ludzkim. W obu tragediach Eurypides oscyluje wokół takich zagadnień, jak wiara w bogów uznawanych przez państwo, prawo azylu i gościnności, prawo i tradycja składania ofiar, prawo i obowiązek grzebania zmarłych lub lojalność wobec państwa.
Arystofanejska krytyka Eurypidesa.
Eurypidesa, jego twórczość oraz krytykę tej twórczości można potraktować jako jedną z głównych obsesji Arystofanesa. Komediopisarz często podejmował dialog z tragediopisarzem, np. w "Acharnejczykach" kluczowe są zapożyczenia z niezachowanego "Telefosa", a sam tragik został ukazany jako „twórca łachmanowych tragedii”. Bohater Arystofanesa operuje stereotypem tragedii eurypidejskiej, aby przekonać chór do swoich racji, zaś sama sekwencja ma paratragiczne umotywowanie. Deheroizacja mitu i mitologicznych bohaterów dokonana przez Eurypidesa polegała na ubraniu ich w „łachmany”, tj. na poruszaniu spraw skrywanych i uznanych za niegodne pokazywania, a także na niechęci do „heroicznych postaci pozytywnych”, co skrytykował Arystofanes.
Utwory, które komediopisarz poświęcił niemal wyłącznie Eurypidesowi, to "Thesmoforie" i "Żaby". W "Thesmoforiach" tragediopisarz został skrytykowany za nowatorstwo, rezygnację z typowego dla tragedii patosu, za wprowadzanie elementów codzienności i skupianie się na sprawach kobiet i miłości, za realizm i sofistyczną retorykę. Natomiast w "Żabach" komediopisarz porównał twórczość tragiczną Ajschylosa z osiągnięciami Eurypidesa oraz wyłożył swój pogląd na społeczną funkcję tragedii greckiej.
Nowożytna recepcja utworów Eurypidesa.
Do popularyzacji twórczości Eurypidesa w nowożytnej Europie przyczyniły się przekłady jego tragedii na język łaciński i wcześnie udostępniane ich editiones principes. W 1495 r. we Florencji (Janus Lascaris) pojawiło się niepełne wydanie dzieł Eurypidesa, które zgromadziło 4 utwory: "Medea", "Hippolytus", "Alcestis", "Andromache". Natomiast w 1503 r. w Wenecji w oficynie Aldusa ukazały się "Euripidis Tragoediae septendecim [...] Hecuba, Orestes, Phoenissae, Medea, Hippolytus, Alcestis, Andromache, Supplices, Iphigenia in Aulide, Iphigenia in Tauris, Rhesus, Troades, Bacchae, Cyclops, Heraclidae, Helena, Ion". Później dzieła Eurypidesa były drukowane stosunkowo często. Udostępniły je takie oficyny, jak J. Hervagium (Basileae, 1537 r.), J. Oporinus (Basileae, 1544 r.), P. Vettori (Roma, 1545 r.), J. Oporinus (Basileae, 1551 r. – wydanie uchodzące za pełne), J. Oporinus (Basileae, 1562 r. – wydanie będące pierwszym wydaniem grecko-łacińskim), Plantinus (Antverpiae, 1571 r. – wydanie będące pierwszym wydaniem krytycznym). Ważnym osiągnięciem wydawniczym nowożytnej Europy w zakresie popularyzacji tragedii Eurypidesa było dzieło "Aristologia Euripidea" w opracowaniu Michaeli Neandri Soraviensi, które wydrukowała oficyna Jana Oprinusa w 1559 r. Jadwiga Czerwińska i Magdalena Koźluk nazywają je „perłą Eurypidejskich maksym”.
Eurypides na współczesnych scenach polskich.
Dramaty Eurypidesa były inscenizowane przez ważniejszych polskich reżyserów teatralnych ostatnich lat, tj. przez Krzysztofa Warlikowskiego, Włodzimierza Staniewskiego, Maję Kleczewską i Pawła Passiniego.
W 2001 r. Warlikowski zrealizował w Teatrze Rozmaitości w Warszawie "Bachantki". W przedstawieniu wystąpili Andrzej Chyra w roli Dionizosa, Jacek Poniedziałek jako Penteusz i Małgorzata Hajewska-Krzysztofik jako Agaue. Reżyser podjął temat władzy i tożsamości seksualnej, a także patologicznych relacji rodzinnych osadzonych w estetyzowanej przestrzeni, która przypominała starożytną łaźnię, świątynię bądź atrium. Warlikowski zrezygnował z poruszania problemu kultów religijnych, sytuując się na przeciwległym biegunie wobec tego, na którym znalazł się Staniewski.
W 2004 r. Staniewski w Ośrodku Praktyk Teatralnych Gardzienice przedstawił "Elektrę", mającą w inscenizacyjnym założeniu formę eseju teatralnego. "Elektra" powstała w ramach badań Gardzienic nad kulturą starożytną. Przed widzami dokonywała się rekonstrukcja antycznej cheironomii. Przedstawianie metod pracy Ośrodka współwystępowało z opowieścią o Eurypidesie (w tej roli wystąpił Mariusz Gołaj) i o innych twórcach antycznych. Staniewski prowadził grę mitem i grę z mitem, wprowadził wątki autotematyczne, pytał o stosunek do osiągnięć przodków i umożliwił spotkanie widzów i twórców z tradycją.
W 2006 r. Maja Kleczewska zrealizowała w Teatrze Narodowym w Warszawie spektakl, opierający się na kilku tekstach reinterpretujących mit o Fedrze: "Hippolytos uwieńczony" Eurypidesa, "Fedra" Seneki, "Dla Fedry" Pera Olova Enquista i "Fedra" Istvána Tasnádiego. W przedstawieniu wystąpili Danuta Stenka jako Fedra, Aleksandra Justa jako Enona, Patrycja Soliman jako Arycja, Kamilla Baar jako Panope, Jan Englert jako Tezeusz i Michał Czernecki jako Hipolit. Osią realizacji Kleczewskiej była walka. Akcja przedstawienia została osadzona w sterylnej przestrzeni szpitalnej, a także w sali cateringowej. Spektakl odczytywano jako projekcję świadomości Fedry, która w trakcie rozwoju akcji ulegała zapadaniu się w sobie i degradacji. Czytano go także jako refleksję o pragnieniu i o relacjach między Erosem i Tanatosem.
W 2012 r. Paweł Passini wystawił w Teatrze im. Wojciecha Bogusławskiego w Kaliszu "Tragedie antyczne", które opierały się na trzech utworach Eurypidesa: "Ifigenia w Aulidzie", "Orestes" i "Bachantki". Były one częścią projektu artystyczno-badawczego "Dynamika metamorfozy" prowadzonego w Instytucie im. Jerzego Grotowskiego. Passini zaprezentował spektakl, będący historią o mściwych kobietach i bogach oraz o żądnych sławy mężczyznach. Ważną rolę odgrywał chór, który w pierwszej części przedstawienia był tworzony przez mężczyzn, zaś w drugiej przez kobiety, które przypominały Erynie.
Wykaz dzieł.
Eurypides napisał przeszło 90 sztuk, z czego zachowało się 17 tragedii i jeden dramat satyrowy:
W zbiorach sztuk Eurypidesa zachowała się także tragedia "Resos" (), która zdaniem badaczy wyszła jednak spod pióra innego autora.
Spośród sztuk Eurypidesa, które zaginęły bądź zachowały się we fragmentach można wymienić takie, jak:

</doc>
<doc id="1394" url="https://pl.wikipedia.org/wiki?curid=1394" title="Email">
Email



</doc>
<doc id="1395" url="https://pl.wikipedia.org/wiki?curid=1395" title="E-mail">
E-mail



</doc>
<doc id="1396" url="https://pl.wikipedia.org/wiki?curid=1396" title="Ernest Hemingway">
Ernest Hemingway

Ernest Miller Hemingway (ur. 21 lipca 1899 w Oak Park w Illinois, zm. 2 lipca 1961 w Ketchum w Idaho) – amerykański pisarz i dziennikarz. Jest autorem takich powieści jak "Słońce też wschodzi", "Pożegnanie z bronią", "Komu bije dzwon" oraz opowiadań "Śniegi Kilimandżaro" i "Stary człowiek i morze". Często jest przedstawiany jako klasyczny przedstawiciel literatury amerykańskiej. Styl pisania Hemingwaya stał się znany jako „iceberg theory”. Miał cztery żony i troje dzieci. Jeden z najwybitniejszych pisarzy XX wieku.
Hemingway dorastał w Oak Park. Po skończeniu liceum pracował przez kilka miesięcy dla gazety „The Kansas City Star”. W 1918 roku w trakcie I wojny światowej został ciężko ranny i po odzyskaniu sił powrócił do domu. Jego doświadczenia wojenne stanowiły podstawę do napisania powieści "Pożegnanie z bronią". W 1921 roku poślubił Hadley Richardson, po czym razem zamieszkali w Paryżu. Tam przebywał wśród innych pisarzy ze straconego pokolenia. Bazując na wcześniejszych przeżyciach ze święta Sanfermines w 1926 roku wydał powieść "Słońce też wschodzi", która przyniosła mu światową sławę. W 1927 roku rozwiódł się z Hadley i ożenił się z Pauliną Pfeiffer.
W 1940 roku, po 13 latach małżeństwa, Hemingway i Paulina rozwiedli się. W tym samym roku autor poślubił Marthę Gellhorn i opublikował powieść "Komu bije dzwon". Hemingway rozstał się z Marthą, kiedy poznał w Londynie Mary Welsh. Podczas II wojny światowej brał udział między innymi w wyzwoleniu Paryża i ofensywie w Ardenach.
W 1952 roku podczas pobytu na safari dwukrotnie przeżył wypadki lotnicze. Został laureatem Nagrody Pulitzera za opowiadanie "Stary człowiek i morze" w 1953 roku oraz Nagrody Nobla w dziedzinie literatury rok później.
Hemingway popełnił samobójstwo w swoim domu w Ketchum w 1961 roku.
Życiorys.
Dzieciństwo.
Ernest Miller Hemingway urodził się 21 lipca 1899 roku na przedmieściach Chicago w Oak Park w stanie Illinois. Jego ojciec Clarence Edmonds Hemingway był z zawodu lekarzem, a matka Grace Hall-Hemingway muzykiem. Później Hemingway przyznał, że nie lubił swojego imienia, ponieważ przypominało mu o postaci ze sztuki Bądźmy poważni na serio autorstwa Oscara Wilde’a. Rodzina przeniosła się później do większego domu, w którym Grace miała własne studio, a Clarence biuro. Matka Hemingwaya często grała na koncertach w okolicy. Jej upór, żeby syn nauczył się grać na wiolonczeli stał się źródłem konfliktu między nimi, ale Hemingway później przyznał, że lekcje muzyki były przydatne w jego twórczości, co widać np. w „kontrapunktowej strukturze” powieści "Komu bije dzwon". Już jako dorosły, Hemingway twierdził, że nienawidził swojej matki, jednak biograf Michael S. Reynolds uważa, że odzwierciedlał jej entuzjazm i energiczność. Rodzina posiadała dom letniskowy „Windermere”, gdzie jako czterolatek nauczył się od swojego ojca polowania, łowienia i obozowania w lasach i nad jeziorami północnego Michigan. Częste przebywanie na łonie natury zaszczepiło w nim pasję do spędzania czasu na świeżym powietrzu i życia w odległych lub odizolowanych miejscach.
W latach 1913–1917 Hemingway uczęszczał do Oak Park and River Forest High School. Miał dobre stopnie z języka angielskiego i występował w orkiestrze szkolnej przez dwa lata ze swoją siostrą Marcelline. Na pierwszym roku chodził na zajęcia dziennikarskie, prowadzone przez Fannie Biggs, które zostały zorganizowane w taki sposób jakby w klasie była prowadzona redakcja gazety. Najlepsi pisarze w klasie mogli przedkładać swoje artykuły do gazetki szkolnej „The Trapeze”. Prace Hemingwaya i Marcelline kilkukrotnie pojawiły się w gazetce. Pierwszy utwór Hemingwaya opublikowany w styczniu 1916 roku, traktował o występach lokalnej Chicagowskiej Orkiestry Symfonicznej. Hemingway w dalszym ciągu edytował „The Trapeze” i „Tabula” (inna gazeta szkolna), gdzie naśladował styl pisania reporterów sportowych i używał pseudonimu „Ring Lardner Jr.” na cześć redaktora Ringa Lardnera z gazety „Chicago Tribune”. Po ukończeniu liceum rozpoczął pracę w gazecie „The Kansas City Star”. Spędził tam sześć miesięcy, a porady redakcyjne gazety (używaj krótkich zdań, stosuj krótkie pierwsze akapity, używaj energicznych słów, bądź pozytywny, a nie negatywny) zostały podstawą jego twórczości na całe życie.
I wojna światowa.
Na początku 1918 roku Hemingway stawił się na rekrutację Czerwonego Krzyża i został wpisany na listę kierowców ambulansów we Włoszech. W maju przyleciał do Paryża, który był bombardowany przez niemiecką artylerię. Przed końcem czerwca trafił na włoski front, gdzie prawdopodobnie poznał pisarza Johna Dos Passosa. Pierwszego dnia pobytu w Mediolanie został wysłany do zniszczonej fabryki, w której razem z innymi sanitariuszami szukał ciał kobiet. To zdarzenie zostało przez niego później opisane w książce "Śmierć po południu". Kilka dni później został przeniesiony do miasta Fossalta di Piave.
8 lipca podczas ostrzału moździerzowego został ciężko ranny. Pomimo odniesionych ran Hemingway ciągle pomagał włoskim żołnierzom, za co odznaczono go włoskim srebrnym Medalem za Męstwo Wojskowe. Doznał poważnych ran od odłamków w obu nogach, po czym przeszedł natychmiastową operację i spędził pięć dni w szpitalu polowym, zanim został przeniesiony na rekonwalescencję do szpitala Czerwonego Krzyża w Mediolanie. Podczas sześciomiesięcznego pobytu w szpitalu, dzielił swój pokój z późniejszym ambasadorem i pisarzem Henrym Serrano Villardem. Przebywając w szpitalu zakochał się w starszej od niego o siedem lat pielęgniarce Agnes von Kurowsky. Gdy Hemingway wyzdrowiał i powrócił do Stanów w styczniu 1919 roku, razem z Agnes postanowili jak najszybciej wziąć ślub. Jednakże w marcu Agnes oświadczyła listownie, że jest zaręczona z włoskim oficerem. Według biografa Jeffreya Meyersa Hemingway był zrozpaczony po odmowie Agnes i w każdym kolejnym związku to on pierwszy odchodził od żony, zanim zostałby ponownie porzucony. Wydarzenia, których był świadkiem we Włoszech stały się podstawą do napisania powieści "Pożegnanie z bronią".
Toronto i Chicago.
Hemingway wrócił do domu na początku 1919 roku. We wrześniu wyjechał z kolegami z liceum na wycieczkę kempingową na Górny Półwysep w Michigan. Wyjazd stał się inspiracją do napisania opowiadania "Rzeka dwóch serc", w którym to główny bohater Nick Adams wyjeżdża na prowincję, żeby odpocząć od wojny, w której brał udział. Przyjaciel rodziny zaproponował mu pracę w Toronto i nie mając innego zajęcia, zaakceptował ją. Później w tym samym roku zaczął tam pracować jako wolny strzelec, redaktor i korespondent zagraniczny dla „Toronto Star Weekly”. Wrócił do Michigan w czerwcu, a następnie przeniósł się do Chicago we wrześniu 1920, gdzie zamieszkał z przyjaciółmi, a jednocześnie pisał artykuły dla „Toronto Star”. W Chicago pracował jako redaktor miesięcznika „Cooperative Commonwealth”, gdzie poznał powieściopisarza Sherwooda Andersona. Hadley Richardson przybyła do Chicago, aby odwiedzić siostrę współlokatora Hemingwaya. Po kilku miesiącach znajomości zdecydowali się pobrać i wyjechać do Europy. Początkowo myśleli o Rzymie, jednak Anderson zasugerował im Paryż. Hemingway i Hadley wzięli ślub 3 września 1921, a dwa miesiące później wyjechali do Paryża po tym, jak Hemingway dostał tam pracę jako reporter „Toronto Star”.
Paryż.
W Paryżu Hemingway poznał takich autorów jak Gertrude Stein, James Joyce oraz Ezra Pound, którzy pomagali młodym pisarzom rozwijać karierę. Razem z Hadley zamieszkali w małym mieszkaniu w Dzielnicy Łacińskiej. Stein, będąc jedną z ważniejszych autorek modernizmu w Paryżu, stała się mentorką Hemingwaya. Wprowadziła go do świata artystów i pisarzy emigracyjnych dzielnicy Montparnasse, których określała „straconym pokoleniem”. Termin ten Hemingway spopularyzował wraz z publikacją "Słońce też wschodzi". Hemingway jako znajomy Stein poznał wpływowych malarzy, takich jak Pablo Picasso, Joan Miró i Juan Gris. Po pewnym czasie wycofał się spod jej wpływu i ich relacje zamieniły się w spór o podłożu literackim trwający przez dziesiątki lat. Amerykański poeta Ezra Pound poznał Hemingwaya przez przypadek w sklepie z książkami Shakespeare and Company w 1922 roku. Pomiędzy pisarzami zawiązała się silna przyjaźń, w 1923 wyjechali razem do Włoch, a rok później mieszkali na tej samej ulicy.
Podczas pierwszych 20 miesięcy w Paryżu Hemingway napisał 88 artykułów dla gazety „Toronto Star”. Jego reportaże obejmowały wojnę grecko-turecką, w tym wielki pożar Smyrny, którego był naocznym świadkiem. W tym samym czasie Hadley podróżująca do Genewy zgubiła na stacji Gare de Lyon walizkę ze szkicami Hemingwaya. We wrześniu 1923 para wróciła do Toronto, gdzie 10 października na świat przyszedł ich pierwszy syn Jack Hemingway. W tym samym czasie wydano pierwszy zbiór opowiadań Hemingwaya "Trzy opowiadania i dziesięć wierszy". Kilka miesięcy później wydano drugi zbiór "in our time" (małymi literami), który zawierał 6 winiet i 12 opowiadań napisanych poprzedniego lata w Hiszpanii. Pobyt w Toronto nudził Hemingwaya, ciągle tęsknił za Paryżem i chciał wrócić do życia pisarza, zamiast znowu być dziennikarzem.
Hemingway z Hadley i ich synem (nazywanym przez nich Bumbym) wrócili do Paryża w styczniu 1924 roku. W tym okresie Hemingway i Ford Madox Ford razem redagowali miesięcznik literacki „The Transatlantic Review”, w którym pojawiały się prace takich poetów jak Ezra Pound, John Dos Passos, a także wczesne prace Hemingwaya np. "Obóz indiański". W 1925 roku w Stanach wydano zbiór opowiadań "In Our Time" (dużymi literami), w którym krytycy docenili jego świeży styl. W tym samym roku jeszcze przed publikacją książki Hemingway poznał innego amerykańskiego pisarza F. Scotta Fitzgeralda. Kiedy Fitzgerald wydał w kwietniu powieść "Wielki Gatsby", Hemingway przeczytał ją, wyraził się o niej pozytywnie i postanowił, że jego kolejna praca będzie powieścią.
Hemingway wraz z żoną po raz pierwszy odwiedzili festiwal San Fermin w Pampelunie w Hiszpanii w 1923 roku. Wtedy też Hemingwaya zafascynowały walki byków. Para wróciła do Pampeluny kolejno w 1924 i 1925 roku; za trzecim razem przyjechali z grupą amerykańskich i brytyjskich ekspatriantów. Wśród nich byli: Bill Smith, Donald Ogden Stewart, Harold Loeb, niedawno rozwiedziona Lady Duff Twysden i jej narzeczony Pat Guthrie. Kilka dni po zakończeniu fiesty, Hemingway rozpoczął prace nad szkicem w dniu swoich urodzin (21 lipca). Po ośmiu tygodniach przekształci się w jego pierwszą powieść "Słońce też wschodzi". Kilka miesięcy później w grudniu 1925 Hemingway i Hadley przenieśli się do Schruns w Austrii. aby spędzić tam zimę. Będąc na miejscu, pisarz pracował nad poprawkami swojego rękopisu. Paulina Pfeiffer dołączyła do nich w styczniu i wbrew opinii Hadley, poprosiła Hemingwaya, aby podpisał umowę z wydawnictwem Scribner’s. Pisarz wyjechał do Nowego Jorku na szybkie spotkanie z wydawcami, a po powrocie zatrzymał się w Paryżu, gdzie zaczął romansować z Pauliną. Następnie wrócił do Schruns, gdzie zakończył korekty w marcu. Rękopis przybył w kwietniu do Nowym Jorku; ostatnie poprawki naniósł w Paryżu w sierpniu 1926, a Scribner’s opublikowało powieść w październiku.
Relacje pomiędzy Hemingwayem i Hadley pogorszyły się w trakcie, gdy on pracował nad książką "Słońce też wschodzi". Na wiosnę 1926 roku Hadley dowiedziała się o jego romansie z Pauliną Pfeiffer, która tego lipca przybyła z nimi do Pampeluny. W dniu ich powrotu do Paryża Hadley poprosiła o separację; w listopadzie oficjalnie wniosła o rozwód. Podzielili swój dobytek, a dodatkowo Hadley przyjęła ofertę Hemingwaya otrzymania zysków pochodzących ze "Słońce też wschodzi". Para rozwiodła się w styczniu 1927, a Hemingway ożenił się z Pfeiffer w maju tego samego roku.
Pfeiffer, która pochodziła z bogatej katolickiej rodziny z Arkansas, przeniosła się do Paryża, aby pracować dla magazynu „Vogue”. Przed zawarciem małżeństwa, Hemingway przeszedł na katolicyzm. Pomimo przejścia na katolicyzm, Hemingway był przez całe życie obojętny na sprawy religijnie. Wspólnie spędzili miesiąc miodowy w Le Grau-du-Roi, gdzie zachorował na wąglika. W tym samym okresie pracował nad kolejnym zbiorem opowiadań, który został opublikowany w październiku 1927 roku pod tytułem "Mężczyźni bez kobiet". Pod koniec roku Paulina, która była w ciąży, chciała wrócić do Ameryki. Znajomy pisarz John Dos Passos polecił im miasto Key West i para opuściła Paryż w marcu 1928 roku. Wiosną tego samego roku, jeszcze przed powrotem do Stanów, Hemingway doznał poważnych obrażeń w ich paryskiej łazience, kiedy pociągnął za świetlik myśląc, że ciągnie za łańcuch toaletowy. Ten wypadek pozostawił u niego bliznę na czole, która była widoczna przez resztę jego życia. Kiedy Hemingway był pytany o blizny – unikał odpowiedzi. Po wyjeździe z Paryża Hemingway już nigdy nie mieszkał w wielkim mieście.
Key West.
Późną wiosną Hemingway i Paulina udali się do Kansas City, gdzie ich syn Patrick urodził się 28 czerwca 1928 roku. Paulina miała trudny poród, co zostało później opisane w powieści "Pożegnanie z bronią". Zimą, kiedy był z Bumbym w Nowym Jorku i miał wsiąść do pociągu na Florydę, dostał telegram mówiący o samobójstwie jego ojca. Hemingway był załamany, chwilę po tym telegramie otrzymał list od ojca napisany jeszcze przed jego śmiercią, w którym ojciec napisał, żeby syn nie martwił się o pieniądze. Hemingway uświadomił sobie, jak musiała czuć się Hadley po samobójstwie jej własnego ojca w 1903 roku i całą sprawę skomentował słowami „pewnie czeka mnie to samo”.
Po powrocie do Key West w grudniu Hemingway pracował nad szkicem "Pożegnania z bronią" aż do wyjazdu do Francji w styczniu. Skończył nad nim prace w sierpniu, ale ciągle opóźniał korektę. Powieść została wydana w Nowym Jorku 27 września. W Hiszpanii latem 1929 roku Hemingway pracował nad kolejną książką "Śmierć po południu". Jego celem było napisać obszerny traktat o walkach byków, wyjaśniając takie pojęcia jak toreador czy korrida, dołączając glosariusz i załączniki, ponieważ wierzył, że walki byków są bardzo interesującym przeżyciem i dosłownie opisem życia i śmierci.
We wczesnych latach 30. Hemingway spędzał zimy w Key West i lata w Wyoming, gdzie polował na jelenie, łosie i niedźwiedzie grizzly. Dołączył do niego John Dos Passos. W listopadzie 1930, po doprowadzeniu Dos Passosa do stacji kolejowej w Billings, Hemingway złamał rękę w wypadku samochodowym. Chirurg opatrzył poprzeczne złamanie spiralne i związał kość za pomocą ścięgna kangura. Hemingway był hospitalizowany przez siedem tygodni, podczas których opiekowała się nim Paulina; przez kolejny rok odczuwał ból w ręce.
Jego trzeci syn Gregory Hancock Hemingway urodził się 12 listopada 1931 w Kansas. Wujek Pauliny kupił im dom w Key West razem z powozownią, której drugie piętro zaadaptowano na pracownię Hemingwaya. W 1933 Hemingway wraz z żoną udali się na safari we wschodniej Afryce. Najpierw odwiedzili Mombasę, Nairobi i Machakos w Kenii. Następnie udali się na safari w okolice jeziora Manyara oraz na zachód i południowy wschód od obecnego parku narodowego Tarangire. Ich przewodnikiem był Philip Hope Percival, który polował także z Theodorem Rooseveltem w 1909 roku. W trakcie polowań Hemingway zachorował, przez co musiał być transportowany samolotem do Nairobi. To wydarzenie opisał później w opowiadaniu "Śniegi Kilimandżaro". 10-tygodniowa podróż stała się źródłem dla książki "Zielone wzgórza Afryki" i opowiadań "Śniegi Kilimandżaro" i "Krótkie szczęśliwe życie Franciszka Macombera". W 1935 roku wydano "Zielone wzgórza Afryki", ale powieść ta spotkała się ze średnim zainteresowaniem ze strony krytyków.
W 1934 Hemingway kupił łódź, którą nazwał „Pilar” i pływał nią po Karaibach. Podczas podróży trafił do Bimini, gdzie zatrzymał się na kilka miesięcy i pracował tam nad powieścią "Mieć i nie mieć".
Hiszpańska wojna domowa.
W 1937 Hemingway zdecydował się być korespondentem dla agencji North American Newspaper Alliance. Jego zadaniem było relacjonowanie wydarzeń związanych z hiszpańską wojną domową. W marcu tego samego roku trafił do Hiszpanii razem z holenderskim reżyserem Jorisem Ivensem. Ivens, pracujący nad filmem Ziemia hiszpańska, chciał, by Hemingway zastąpił Dos Passosa w roli scenarzysty. Dos Passos opuścił projekt po tym, jak jego znajomy José Robles został aresztowany, a później stracony. Dos Passosa rozgniewał oficjalny i sugestywny sposób, w jaki Hemingway przekazał mu informacje o losie jego przyjaciela. Zdarzenie to było źródłem konfliktu na tle politycznym pomiędzy pisarzami. W Hiszpanii do Hemingwaya dołączyła amerykańska dziennikarka Martha Gellhorn, którą poznał rok wcześniej podczas świąt Bożego Narodzenia. W 1937 roku, podczas gdy Madryt był bombardowany, Hemingway pracował nad swoim jedynym utworem dramatycznym pt. "Piąta kolumna". Dzieło ukazało się w październiku 1938 w ramach antologii łączącej tę sztukę i niektóre z poprzednich opowiadań Hemingwaya. Książka spotkała się z mieszanym odbiorem krytyków literackich.
Kuba.
Wiosną 1939 roku Hemingway dopłynął na Kubę i wynajął pokój w hotelu na Hawanie. Krótko później dołączyła do niego Martha, po czym zdecydowali się wynająć posiadłość Finca Vigía niedaleko Hawany. Po okresie separacji Hemingway i Paulina rozwiedli się, a 21 listopada 1940 roku autor ożenił się z Marthą. Podobnie do tego, co miało miejsce po rozwodzie z Hadley, Hemingway przeniósł swoją letnią rezydencję do Ketchum w stanie Idaho, a zimowy dom na Kubę. Gellhorn zainspirowała go do napisania jednej z jego najbardziej znanych powieści, "Komu bije dzwon", którą rozpoczął w marcu 1939 roku i zakończył w lipcu 1940 roku. Została ona opublikowana w październiku 1940 roku. W ciągu kilku miesięcy od premiery książka sprzedała się w liczbie ponad pół miliona egzemplarzy, a także została nominowana do nagrody Pulitzera.
W styczniu 1941 roku Martha została wysłana do Chin jako reporterka magazynu „Collier’s”. Razem z nią do Chin trafił Hemingway, który podobnie jak Martha pisał reportaże dla gazety „PM”. Wrócili na Kubę przed dołączeniem Stanów Zjednoczonych do II wojny światowej. Autorzy książki "Spies: The Rise and Fall of the KGB in America" sugerują, że jeszcze przed wyjazdem do Chin Hemingway został tajnym agentem służb KGB pod kryptonimem „Agent Argo”.
27 czerwca 1942 roku rząd Stanów Zjednoczonych wydał oświadczenie, w którym prosił wszystkie osoby posiadające łódź lub statek o zgłoszenie się na ochotnika do patrolowania wód przybrzeżnych Ameryki Północnej. Głównym celem było poszukiwanie niemieckich łodzi podwodnych. W latach 1942–1944 na swojej łodzi Hemingway patrolował wody wzdłuż wybrzeża Kuby i w Zatoce Meksykańskiej.
II wojna światowa.
W okresie od maja 1944 do marca 1945 roku Hemingway przebywał w Europie. Kiedy po raz pierwszy przybył do Londynu, poznał tam korespondentkę czasopisma „Time” – Mary Welsh, w której się zauroczył. Martha została zmuszona do przepłynięcia przez Atlantyk na statku wypełnionym materiałami wybuchowymi, ponieważ Hemingway nie chciał jej pomóc w otrzymaniu legitymacji dla prasy uprawniającej do podróży samolotem. Później przybyła do Londynu, aby znaleźć Hemingwaya w szpitalu ze wstrząśnieniem mózgu doznanym w wypadku samochodowym. Nie patrząc na jego stan, oskarżyła go o bycie tyranem. Hemingway ostatni raz widział Marthę w marcu 1945 roku, kiedy to przygotowywał się do powrotu na Kubę. W międzyczasie podczas trzeciego spotkania z Mary Welsh poprosił ją, żeby wyszła za niego za mąż.
Hemingway był obecny podczas lądowania w Normandii, ale według biografa Meyersa, był uważany za ważną osobę i nie zezwolono mu na zejście na ląd. Carlos Mellow opisał, że w pierwszym dniu desantu żaden z korespondentów nie mógł lądować i Hemingway musiał wrócić na pokład statku „Dorothea Dix”. W lipcu tego samego roku został przydzielony do 22. pułku piechoty dowodzonego przez pułkownika Charlesa T. Lanhama, a także stał się przywódcą małej grupy wiejskiej bojówki z Rambouillet pod Paryżem. Będąc we Francji pojmał kilku Niemców. Prowadzenie oddziału i jednoczesne bycie korespondentem wojennym jest niezgodne z konwencjami genewskimi, jednak po przesłuchaniu przez Inspektora Generalnego Hemingway został oczyszczony z zarzutów.
W dniu 25 sierpnia był obecny przy wyzwoleniu Paryża, choć wbrew legendzie, nie był pierwszym w mieście, ani nie wyzwolił hotelu Ritz. W Paryżu już razem z Mary Welsh odwiedził znajomych – Sylvię Beach i Pabla Picassa, a także pogodził się z Gertrude Stein.
Później tego samego roku był świadkiem serii walk o las Hürtgen. Podczas walk w lesie był bardzo źle oceniany przez walczących tam żołnierzy – zarzucano mu pozerstwo. Porucznik Jack Crawford z 12. pułku piechoty tak wspominał spotkanie z Hemingwayem: „Zobaczyłem siedzących przy stole [Ernesta] Hemingwaya i pułkownika Lanhama [dowódcę 22. pułku]. Lanham mnie znał i zaprosił na drinka. Byłem bardzo podniecony spotkaniem z Hemingwayem. Czytałem wszystkie jego książki. Ale kiedy zaczął mówić, okazał się dupkiem wołowym. Miałem wrażenie, że pieprzy bzdury i to właściwie nie jest jego wojna. Opowiadał plotki o ważnych figurach w Paryżu. Wkurzyłem się, mówiąc coś w tym stylu: «Jeżeli chce pan zobaczyć walkę, niech pan jedzie ze mną do Hürtgen». Lanham mnie upomniał: «Zapominacie się, poruczniku.» Odpowiedziałem: «Tak jest, sir!», a do Hemingwaya: «Pieprz się!».”
17 grudnia 1944 roku w gorączce i złym stanie Hemingway samotnie dojechał do Luksemburga w celu relacji wydarzeń z bitwy, którą później nazwano ofensywą w Ardenach. Jak tylko tam dotarł, pułkownik Lanham przekazał go lekarzom, którzy zdiagnozowali u niego zapalenie płuc. Do czasu, gdy odzyskał siły minął tydzień i większość walk tej bitwy się skończyła.
W 1947 roku Hemingway otrzymał Brązową Gwiazdę za męstwo podczas II wojny światowej.
Afryka, nagrody.
W 1946 roku poślubił Mary Welsh. Rok wcześniej para miała wypadek samochodowy, w którym Hemingway ranił głowę i kolano, a Mary prawą kostkę. W 1947 roku Patrick Hemingway uległ wypadkowymi samochodowemu, po którym był ciężko chory. Przez kilka lat autor cierpiał na depresję spowodowaną śmiercią bliskich mu osób: w 1939 zmarli William Butler Yeats i Ford Madox Ford, w 1940 Francis Scott Fitzgerald; w 1941 Sherwood Anderson i James Joyce; w 1946 Gertrude Stein i w kolejnym roku Max Perkins – długoletni przyjaciel pisarza. W tym okresie cierpiał na cukrzycę, miewał bóle głowy, wysokie ciśnienie i problemy z nadwagą. Później autor sam określił, że w latach 1942–1945 nie był aktywny zawodowo. W styczniu 1946 powrócił do pisania. Do czerwca ukończył 800 stron powieści "Rajski ogród". Rozpoczął też prace nad trzyczęściową powieścią opisującą losy różnych ludzi z trzech perspektyw podczas II wojny światowej. Składały się na nią "The Land", "The Sea" i "The Air", które chciał wydać razem jako "The Sea Book" jednak oba projekty zostały przez niego zarzucone. Ostatecznie „część morska” przekształciła się w powieść "Wyspy na Golfsztromie" oraz opowiadanie "Stary człowiek i morze".
W 1948 roku Hemingway i Mary udali się do Europy zatrzymując się w Wenecji na kilka miesięcy. Podróż przez Atlantyk i z powrotem odbyli na polskim statku pasażerskim "Jagiełło". Podczas ich pobytu Hemingway zakochał się w 19-letniej Adrianie Ivancich. Ich platoniczna miłość była inspiracją do napisania książki "Za rzekę, w cień drzew". Powieść została wydana w 1950 roku i otrzymała negatywne recenzje. W kolejnym roku wściekły na nieprzychylne recenzje w ciągu 8 tygodni napisał wstępną wersję opowiadania "Stary człowiek i morze" mówiąc, że jest to najlepsze co może stworzyć w swoim życiu. Opowiadanie zostało dobrze przyjęte, a w 1953 roku autor został laureatem nagrody Pulitzera.
W 1954 roku, będąc w Afryce, Hemingway uczestniczył w dwóch katastrofach lotniczych. W ramach świątecznego prezentu dla Mary wynajął lot samolotem nad Kongiem Belgijskim. W drodze powrotnej niedaleko wodospadu Murchisona samolot zahaczył o nieużywaną linię telegraficzną i musiał lądować awaryjnie. Hemingway odniósł obrażenia głowy, natomiast Mary miała złamane dwa żebra. Następnego dnia para próbowała dostać się do placówki medycznej w mieście Entebbe. W tym celu wynajęli kolejny samolot, który zaczął się palić zaraz po tym, jak wzniósł się w powietrze. Hemingway dostał wstrząśnienia mózgu i poparzeń rąk. W tym samym roku podczas pożaru buszu autor doznał poparzeń drugiego stopnia na nogach, torsie i lewej dłoni. W październiku tego samego roku Hemingway otrzymał nagrodę Nobla w dziedzinie literatury. Z powodu doznanych ran zdecydował, że nie poleci do Sztokholmu by odebrać nagrodę. Zamiast tego wysłał swoje przemówienie opisujące życie pisarza.
W listopadzie, podczas pobytu w Paryżu, przypomniano mu o jego kufrze, którego nie zabrał z hotelu Ritz w 1928 roku. Kufer był wypełniony zapiskami i notatkami z jego wcześniejszych lat w Paryżu. Podekscytowany odkryciem, po powrocie na Kubę w 1957 roku, zaczął ponownie pracować nad swoim pamiętnikiem "Ruchome święto". Do 1959 roku zakończył okres intensywnej działalności: skończył "Ruchome święto" (które miało zostać wydane w następnym roku); "To co prawdziwe o świcie" liczyło 200 000 słów; dodał rozdziały do powieści "Rajski ogród"; pracował także nad "Wyspy na Golfsztromie". Ostatnie trzy były przechowywane w sejfie w Hawanie, ponieważ skupił się na wykończeniu "Ruchomego święta".
Posesja Finca Vigia stała się popularnym miejscem wśród turystów i złodziei, co zmusiło Hemingwaya do kupienia domu niedaleko Ketchum w stanie Idaho.
Idaho.
Do końca lat 50. Hemingway nadal pracował nad materiałem, który został opublikowany pośmiertnie jako "Ruchome święto". Latem 1959 odwiedził Hiszpanię, gdzie studiował artykuły traktujące o walkach byków na zlecenie magazynu „Life”. Powrócił na Kubę w styczniu 1960 w celu dokończenia prac nad książką. Redakcja magazynu poprosiła tylko o 10 000 słów, ale rękopis okazał się znacznie większy. Po raz pierwszy w swoim życiu Hemingway nie był w stanie zorganizować swojego pisania i poprosił A. E. Hotchnera o pomoc. Hotchner przyjechał na Kubę i pomógł mu skrócić wersję dla „Life” do 40 000 słów, a wydawnictwo Scribner’s zgodziło się na opublikowanie pracy w pełnej wersji ("The Dangerous Summer") zawierającą prawie 130 000 słów. 25 lipca 1960 Hemingway i Mary ostatecznie opuścili Kubę. Hemingway następnie poleciał sam do Hiszpanii, gdzie odbyła się sesja fotograficzna do okładki aktualnego numeru „Life”. W październiku opuścił Hiszpanię i poleciał do Nowego Jorku, gdzie nie chciał wyjść z mieszkania Mary twierdząc, że jest obserwowany.
W tym czasie Hemingway martwił się o pieniądze i swoje bezpieczeństwo. Obawiał się o rozliczenia podatkowe i tego, że nigdy nie powróci na Kubę, aby zabrać rękopisy, które zostawił tam w banku. Uważał, że FBI aktywnie monitoruje jego ruchy w Ketchum. FBI założyło mu teczkę w trakcie trwania II wojny światowej, kiedy to korzystał z łodzi „Pilar” w celu patrolowania wód przybrzeżnych Kuby w celu odkrycia niemieckich łodzi podwodnych. Ponadto J. Edgar Hoover miał agenta w Hawanie śledzącego Hemingwaya w latach 50. Trzy miesiące później w kwietniu 1961 w Ketchum o pierwszej w nocy w kuchni Mary zobaczyła Hemingwaya trzymającego strzelbę. Zadzwoniła do Saviersa, który po przyjechaniu opanował sytuację i przyjął go do szpitala w Sun Valley; stamtąd trafił do kliniki Mayo na kolejne zabiegi elektrowstrząsami. Został zwolniony pod koniec czerwca i wrócił do domu w Ketchum 30 czerwca. Dwa dni później nad ranem 2 lipca 1961 Hemingway zastrzelił się ze swojej ulubionej strzelby. Otworzył magazyn w piwnicy, w którym przechowywano jego broń, poszedł na górę do holu wejściowego i zastrzelił się z „dwulufowej strzelby, której używał tak często, że można ich relację nazwać przyjaźnią”.
Twórczość.
Hemingway, „obywatel świata”, choć spędził większą część życia poza granicami Stanów Zjednoczonych, patrzył na świat z perspektywy Amerykanina. W swojej twórczości poruszał różnorodną tematykę, zachowując w niej cechy typowe dla straconego pokolenia. Przejawiały się one w kompozycji jego utworów, zmianach linii narracyjnej lub w cechach charakteru bohaterów. Frederick Henry ("Pożegnanie z bronią"), Jake Barnes ("Słońce też wschodzi"), Henry Morgan ("Mieć i nie mieć"), Robert Jordan ("Komu bije dzwon"), a nawet Santiago ("Stary człowiek i morze") są swego rodzaju pokonanymi zwycięzcami – pod ich męstwem i mocnym charakterem ukryte są ból i napięcie. W powieści "Za rzekę, w cień drzew" Hemingway otwarcie powrócił do tematyki pierwszej wojny światowej wraz z charakterystyczną dla tego okresu stylistyką i poetyką, opowiadając historię miłości Richarda Cantwella do włoskiej arystokratki Renaty.
Ostra i oszczędna w środki stylistyczne proza Hemingwaya kształtowała się na bazie jego umiejętności dziennikarskich. Jednocześnie mistrzowska i prosta podkreślała bogactwo jego świata wewnętrznego i zawsze opierała się o osobiste doświadczenia twórcy. Dla przykładu, ojczyste strony pisarza lub zawód jego ojca znalazły odzwierciedlenia w losach Nicka Adamsa ("W naszych czasach"), a udział autora w pierwszej wojnie światowej stał się podstawą do napisania nowel ze zbioru "Mężczyźni bez kobiet" oraz powieści "Pożegnanie z bronią". Fakty biograficzne (praca w Czerwonym Krzyżu na froncie włosko-austriackim, pobyt w szpitalu wskutek ciężkich obrażeń, niespełniona miłość do sanitariuszki Agnes von Kurowsky) w prozie Hemingwaya są twórczo przekształcone w przejmujący obraz cierpienia i męstwa straconego pokolenia.
W powieści "Słońce też wschodzi" oraz pamiętniku "Ruchome święto" pisarz opisał Paryż lat dwudziestych jako tymczasowy azyl młodych Amerykanów, marnujących swoje życie w kawiarniach, podróżujących po świecie i znajdujących krótkie westchnienie w chwili obcowania z naturą (na przykład, scena łowienia pstrąga) czy podczas festynów (na przykład, hiszpańska fiesta). Takie podróżowanie bohaterów jest metaforą ich wewnętrznego niepokoju. Inną cechą postaci kreowanych przez Hemingwaya (jak i samego pisarza) jest pociąg do ekstremalnych wrażeń: śmiertelne ryzyko – na przykład, korrida ("Słońce też wschodzi", "Śmierć po południu", "Niebezpieczne lato") czy safari ("Zielone wzgórza Afryki", "Krótkie szczęśliwe życie Franciszka Macombera", "Śniegi Kilimandżaro"). W tych utworach śmierć i okrutność stają się estetyczną sztuką walki i polowania.
Hemingway uczestniczył we współczesnych mu wydarzeniach historycznych, opiniował je w swoich utworach literackich i publicystycznych. W zbiorze opowiadań "Zwycięzca nie otrzymuje nic", powieściach "Mieć i nie mieć" i "Komu bije dzwon", dramacie "Piąta kolumna" i publicystyce okresu hiszpańskiego ukazał atmosferę tzw. gniewnej dekady (ang. "angry decade", kryzysowe lata 30. XX wieku) i wojny domowej w Hiszpanii. Wydarzenia z lat 40. znalazły swoje odzwierciedlenie w powieści "Wyspy na Golfsztromie" i publicystyce okresu drugiej wojny światowej.
Dzieła.
Większość dzieł Hemingwaya przetłumaczył na język polski przyjaciel autora – Bronisław Zieliński. Zbiór nie opisuje nowszych wydań, które nie zawierają wcześniej nieopublikowanej twórczości.
Upamiętnienie.
Planetoida odkryta w 1978 roku przez radzieckiego astronoma Nikołaja Czernycha została nazwana (3656) Hemingway. W 1993 roku miał premierę film "Zapasy z Ernestem Hemingwayem" o przyjaźni dwóch emerytowanych mężczyzn, Irlandczyka i Kubańczyka mieszkających w nadmorskim miasteczku na Florydzie. W filmie zagrali Robert Duvall, Richard Harris, Shirley MacLaine, Sandra Bullock i Piper Laurie. Wiele restauracji zawiera w swojej nazwie „Hemingway”, a niektóre z barów mają w nazwie „Harry’s” (ukłon w stronę baru w "Za rzekę, w cień drzew"). Od 1977 roku prowadzony jest coroczny konkurs literacki International Imitation Hemingway Competition. Laureaci w nagrodę otrzymują wycieczkę do Włoch do baru „Harry’s”. W Key West odbywa się coroczny konkurs na najlepszego sobowtóra Hemingwaya.
W 1965 roku Mary Hemingway utworzyła fundację Hemingwaya i w 1970 roku podarowała dokumenty męża bibliotece John F. Kennedy. W 1980 roku grupa badaczy Hemingwaya zebrała się, aby przeanalizować dokumenty, a następnie zawiązała stowarzyszenie.
W 2012 roku premierę miał biograficzny film w reżyserii Philipa Kaufmana, pt. "Hemingway i Gellhorn", o jego związku z Marthą.
Wpływ na kulturę.
Hemingway poprzez swoją pierwszą powieść "Słońce też wschodzi" spopularyzował określenie stracone pokolenie, do którego sam należał. Ponadto powieść pomogła rozreklamować gonitwy byków podczas święta Sanfermines. Główna bohaterka powieści stała się inspiracją dla młodych kobiet, które zaczęły ją naśladować ścinając włosy na krótko i nosząc pulowery. Od 1947 roku jego prace są włączane do kanonu literatury pięknej.

</doc>
<doc id="1398" url="https://pl.wikipedia.org/wiki?curid=1398" title="Erich Fromm">
Erich Fromm

Erich Fromm (ur. 23 marca 1900 we Frankfurcie nad Menem, zm. 18 marca 1980 w Muralto) – niemiecki filozof, socjolog, psycholog i psychoanalityk pochodzenia żydowskiego. Zdeklarowany ateista.
Życiorys.
Młodość.
Erich Fromm urodzony w 1900 roku, sam o sobie pisze: 
Na zainteresowania i postawę Fromma miały wpływ doświadczenia związane z I wojną światową i śmiercią wielu jego bliskich i znajomych, a także narastające w ówczesnych Niemczech nastroje szowinistyczne i antysemickie. Doświadczenia te spowodowały u Fromma zainteresowanie psychologią i socjologią. Pragnienie znalezienia odpowiedzi na pytania dotyczące prawa społecznego istnienia ludzi wzbudziło jego zainteresowanie poglądami Marksa i Freuda, co miało bardzo duży wpływ na jego późniejszą twórczość. W swoich książkach bardzo często powołuje się na teorie Marksa, a także dokonuje rewizji teorii Freuda.
Studia.
Studiował na wydziale filozofii uniwersytetu frankfurckiego, a także monachijskiego i heidelberskiego, gdzie otrzymał tytuł doktora nauk filozoficznych (1922), oraz w Berlinie, gdzie rozpoczął praktykę psychoanalityczną. Bardzo ważna była współpraca Fromma z tak zwaną szkołą frankfurcką, skupiającą wielu ludzi związanych z lewicą społeczną, próbujących łączyć niedogmatycznie pojmowany materializm historyczny z psychoanalizą, heglizmem i neokantyzmem. Prowadzono tam również studia nad wpływem formacji kapitalistycznych na kulturę i ludzką osobowość. Fromm miał duży wpływ na te badania, ponieważ w latach 1929–1932 był wykładowcą w Instytucie Badań Społecznych istniejącym przy uniwersytecie frankfurckim. Fromm miał również duży udział w opracowaniu teorii osobowości autorytarnej (sadomasochistycznej).
Kariera naukowa.
W 1932 roku na zaproszenie Chicagowskiego Instytutu Psychoanalitycznego Fromm wyjechał do Stanów Zjednoczonych, gdzie po dojściu Hitlera do władzy w styczniu 1933 roku postanowił pozostać. Kontynuacją ośrodka frankfurckiego był Międzynarodowy Instytut Badań Społecznych przy Columbia University, gdzie był wykładowcą.
W latach 1941–1942 Fromm pracował w Amerykańskim Instytucie Psychoanalitycznym założonym przez Karen Horney, którą poznał w Berlińskim Instytucie Psychoanalitycznym. Od 1943 roku współkierował Instytutem Psychoanalitycznym im. Williama A. White’a w Nowym Jorku, którego dyrektorem był jeden z czołowych przedstawicieli neopsychoanalizy Harry Stack Sullivan. W latach 1942–1951 wykładał w Bennington College w stanie Vermont. W 1951 roku został profesorem psychologii Szkoły Medycznej przy Narodowym Uniwersytecie Autonomicznym Meksyku, gdzie także założył własny instytut psychoanalityczny.
Zainteresowanie buddyzmem zen.
Erich Fromm interesował się również buddyzmem zen; w swoich pracach powoływał się często na nauki Buddy, a także na pisma D.T. Suzukiego. Uczestniczył między innymi w warsztatach na temat buddyzmu zen i psychoanalizy pod patronatem Wydziału Psychoanalizy Szkoły Medycznej Autonomicznego Narodowego Uniwersytetu Meksyku w 1957 roku. Na podstawie teorii buddyzmu zen Fromm poszerzał swoje idee dotyczące takich kwestii psychoanalizy jak nieświadomość i przechodzenie treści w niej ukrytych do świadomości, a także celu terapii psychoanalitycznej.
Twórczość.
Lata czterdzieste i pięćdziesiąte stanowiły najbardziej płodny okres w twórczości Fromma. W 1941 roku powstała "Ucieczka od wolności" – pierwsza książka, która przyniosła mu międzynarodowa sławę. Inne ważniejsze dzieła to "Niech się stanie człowiek" (1947), "Psychoanaliza a religia" (1950), "Zdrowe społeczeństwo" (1955), "O sztuce miłości" (1956), później pojawiły się dwie książki, które zyskały wielki rozgłos: "Rewolucja nadziei" (1968) oraz "Mieć czy być?" (1976).
Przez cały czas Fromm zajmował się psychologią społeczną, badał relacje i oddziaływania między jednostką a społeczeństwem. Już w najwcześniejszych publikacjach Fromm polemizował z biologizmem w psychoanalizie Freuda, w opozycji do którego tworzył własną teorię charakteru i osobowości społecznej. Fromm przez cały okres swojej twórczości próbował znaleźć środki zaradcze na negatywne zjawiska społeczne, zwłaszcza te charakterystyczne dla cywilizacji zachodnioeuropejskiej. Twórczość Fromma charakteryzują wątki moralno-utopistyczne oraz wiara, że ludzkość mogłaby dojść do ukształtowania „zdrowego społeczeństwa” ("sane society").
Dzieła (dostępne w języku polskim).
Kolejno podano: tytuł książki, rok wydania oryginału, rok pierwszego polskiego wydania
Po śmierci Ericha Fromma zebrano jego artykuły oraz eseje i wydano w następujących tomach:
Ponadto w Polsce w 1966 r. ukazał się zbiór "Szkice z psychologii religii" zawierający wymieniane już wyżej dzieła Fromma: "Zdrowe społeczeństwo" (fragmenty), "O sztuce miłości" (fragmenty), "Psychoanaliza a religia" oraz "Psychoanaliza i buddyzm zen".
Inne eseje, artykuły i fragmenty dzieł Ericha Fromma przetłumaczone na język polski zostały opublikowane w piśmie "Colloquia Communia" nr 3-6(44-47)/1989 oraz nr 1-6(48-53)/1990.

</doc>
<doc id="1399" url="https://pl.wikipedia.org/wiki?curid=1399" title="Eric Raymond">
Eric Raymond

Eric Steven Raymond (ur. 4 grudnia 1957 w Bostonie) – amerykański haker i libertarianin oraz krytyk fantastyki, a zarazem jedna z czołowych postaci ruchu open source. Większą część życia spędził w Pensylwanii. Znany jest pod swymi inicjałami ESR.
Działalność.
Jest autorem znanych esejów (zwłaszcza „The Cathedral and the Bazaar”) oraz opiekunem słownika żargonu hakerskiego (Jargon file), wydanego w postaci drukowanej jako "The New Hacker Dictionary". Wiele jego listów można znaleźć na grupie dyskusyjnej rec.humor.funny. Jest twórcą translatora języka INTERCAL do C ("C-INTERCAL"). Napisał niektóre z trybów pracy edytora EMACS, pracował też nad narzędziem konfiguracyjnym jądra Linux.
Prawo Linusa.
Jest autorem powiedzenia: „Wystarczająca liczba przyglądających się oczu sprawia, że wszystkie błędy stają się banalne” (ang. „Given enough eyeballs, all bugs are shallow”). Twierdzi, że inspiracją dla tego stwierdzenia był Linus Torvalds i nazywa je Prawem Linusa.
Oficjalnym źródłem tego cytatu jest najsłynniejszy esej Raymonda – „Katedra i bazar”, opublikowany w Internecie oraz w książce "The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary" wydanej przez O’Reilly &amp; Associates w 1999 roku.

</doc>
<doc id="1400" url="https://pl.wikipedia.org/wiki?curid=1400" title="Etnografia">
Etnografia

Etnografia – dyscyplina naukowa zajmująca się całościowym opisem i analizą kultur ludowych różnych społeczności i grup etnicznych. Jej zakres obejmuje teorię kultury ludowej, jak i badanie poszczególnych jej dziedzin i wytworów materialnych. W zależności od tradycji naukowej, pod pojęciem etnografia rozumie się wszystkie nauki etnologiczne bądź też jedną z nich.
Będąc jakościową metodą badawczą, etnografia koncentruje się na rozumieniu fenomenów kulturowych, które odzwierciedlają wiedzę na temat systemów rozumienia w życiu grup kulturowych. Metoda ta była pionierska dla społecznokulturowej antropologii, ale znalazła też zastosowanie także na innych polach nauk społecznych, m.in. w socjologii, badaniach nad komunikacją oraz w historii. Zajmuje się studiami nad ludźmi, grupami etnicznymi, formacjami etnicznymi, m.in. ich etnogenezą, kompozycją, zmianami, charakterystyką dobrobytu społecznego, a także ich materialną oraz duchową kulturą. Etnografia znajduje zastosowanie w pozyskiwaniu danych empirycznych na temat ludzkich społeczności oraz kultury. Zbiór danych jest przygotowywany w oparciu o obserwację uczestniczącą, wywiady, kwestionariusze itd. Celem etnografii jest opis przedmiotu studiów, tych którzy stanowią przedmiot badań. Zamiennie są wykorzystywane także takie określenia jak „badania terenowe” ("field study") czy „opis przypadku” ("case study"), które są używane jako synonim etnografii.
Metody pozyskiwania danych.
Celem etnografii jako metody badawczej jest pozyskanie danych, które mówią o znaczeniu społecznym i potocznym rozumieniu, ludzi – informatorów, w ich naturalnym środowisku życia, czyli terenie badawczym etnografa (antropologa, etnologa). Pewnym ideałem były badania prowadzone w sposób, który ogranicza wpływ badacza na obserwowane środowisko, a także umożliwiające stworzenie pogłębionej charakterystyki, a także bardziej pogłębionego portretu informatorów oraz ich środowiska kulturowego, które stanowi przedmiot zainteresowania etnografów. Metody badawcze, które prowadzą do takich wyników, to m.in. obserwacja uczestnicząca, notatki terenowe, wywiad, badania terenowe. Wywiady są zazwyczaj nagrywane, a następnie spisywane, co pozwala na zachowanie całości wywiadu w formie bez zniekształceń, a także umożliwia dostęp do danych potrzebnych w dalszej analizie. Powtórne badania oraz analiza zgromadzonej dokumentacji umożliwia również późniejszy wgląd w zagadnienie. W przeszłości m.in. w badaniach nad pokrewieństwami (wykresy pokrewieństw) była powszechnie używana do odkrywania logicznych wzorców oraz struktur społecznych w niezachodnich społeczeństwach. Jakkolwiek dzisiejsza antropologia skupia się częściej na badaniu społeczności miejskich, a
do wykresów nad pokrewieństwami wraca dość rzadko.
Od badacza, którego celem jest pozyskanie neutralnej obserwacji, wymagana jest duża refleksywność. Refleksywność w etnografii stara się odpowiedzieć na pytanie w jaki sposób etnograf wpływa na przedmiot swojego badania, a także na jego opis. Mimo podjętych prób refleksywności tak naprawdę nie jest możliwa całkowita bezstronność badacza, co czasem stanowiło przedmiot krytyki etnografii.
Tradycyjnie etnografowie poszukiwali wiedzy na temat badanej społeczności przez pozyskiwanie informatorów posiadających dużą wiedzę na temat danej wspólnoty, a także takich, którzy byli w stanie dostarczyć etnografowi kolejnych informatorów, jak również przez długotrwałe pobyty badawcze w miejscu będącym przedmiotem zainteresowania badacza. Jest to nadal stosowane w etnografii technika badawcza. Proces ten pozwala na odkrywanie wspólnych kulturowych podobieństw związanych z tematem badania. Etnografia jest bardzo mocno związana także z osobistym doświadczeniem badacza. Kluczem do tego procesu jest raczej partycypacja i uczestnictwo niż sama obserwacja. Należy także stwierdzić, że etnografia jest bardzo skuteczną metodą badań społecznych, która pozwala oprzeć zdobytą wiedzę na danych jakościowych, a nie tylko ilościowych, charakterystycznych bardziej dla socjologii, czy demoskopii, nie tracąc przy tym wartości empirycznej pozyskanych danych. Znajduje zastosowanie w badaniach opinii publicznej oraz badaniach marketingowych.
Za Joanną Tokarską-Bakir można spróbować dokonać rozróżnienia na etnografię nowoczesną oraz etnografię ponowoczesną. Pewnym hasłem etnografii ponowoczesnej są słowa Paula Rabinova mówiące o nieistnieniu etnografii przezroczystych. Nie istnieje zatem możliwość osiągnięcia przez badacza obiektywizmu, ani abstrahowania od jego kontekstu społecznego, kulturowego, a także politycznego. Zdaniem Herzfelda każde badanie etnograficzne posiada w sobie polityczną naturę.
Jednym z prominentnych przedstawicieli współczesnej polskiej etnografii był Jacek Olędzki, a jego projekt tzw. "badacza osobnego" można uznać za ciekawy wkład w namysł nad metodologią etnograficzną.

</doc>
<doc id="1401" url="https://pl.wikipedia.org/wiki?curid=1401" title="Eyvind Johnson">
Eyvind Johnson

Eyvind Johnson (ur. 29 lipca 1900 w Svartbjörnsbyn, zm. 25 sierpnia 1976 w Sztokholmie) – prozaik szwedzki, laureat Nagrody Nobla w dziedzinie literatury za rok 1974.
Życiorys.
Dzieciństwo i wczesna młodość.
Eyvind Johnson urodził się w Svartbjörnsbyn w pobliżu Boden w regionie Szwecji Norrbotten jako Olof Edvin Werner Jonsson. Był synem kamieniarza Olofa Petera Jonssona pochodzącego z regionu Värmland oraz pochodzącej z Blekinge Cevii Gustafsdotter. W roku 1904 ojciec Eyvinda Johnsona zachorował chronicznie na silikozę, więc wielodzietna rodzina Jonssonów nie mogła się sama utrzymać i Eyvind został oddany na wychowanie bezdzietnej siostrze matki Amandzie i jej mężowi Andersowi Johanowi Rostowi. Chociaż Eyvind darzył swoich przybranych rodziców wielkim szacunkiem, to w wieku lat 14 odszedł od nich i zaczął się utrzymywać sam. Chwytał się różnych zajęć. Był m.in. drwalem, robotnikiem w tartaku, palaczem w lokomotywie, mył lokomotywy, sprzedawał bilety do kina, obsługiwał projektor filmowy. Przez cały ten czas samodzielnie kształcił się, czytając.
W roku 1919 dostał się do Sztokholmu, gdzie najął się do pracy w fabryce Ericssona. W tym czasie zaczął działać w ruchu lewicowym i związkowym oraz podejmował pierwsze próby literackie. Był jednym z założycieli literackiego pisma "Vår Nutid" ("Nasza współczesność"), które miało sześć numerów. Stał się członkiem stowarzyszenia przyszłych pisarzy "De gröna" ("Zieloni") oraz pisał do magazynu "Brand" ("Ogień").
Okres pobytów zagranicznych.
Począwszy od roku 1921 Johnson przebywał większość czasu w Europie
kontynentalnej, początkowo w Berlinie, potem w Paryżu. Zarabiał tam,
chwytając się jak wcześniej różnych zawodów, ale też pisząc do rozmaitych pism szwedzkich, z którymi utrzymywał kontakt, odwiedzając raz na jakiś czas swój kraj rodzinny. W roku 1924 zerwał z socjalizmem. W tym samym roku opublikował swój debiut "De fyra främlingarna" ("Czterech obcych"). Lektura Johna Dos Passos, Marcela Prousta, André Gide'a i Jamesa Joyce’a, a także Henri Bergsona i Zygmunta Freuda silnie wpłynęła na budowę jego utworów z tego okresu i ich awangardowy charakter.
Małżeństwo z Aase Christoffersen.
W Paryżu Eyvind Johnson ożenił się z Norweżką Aase Christoffersen,
która w roku 1928 urodziła mu syna Tore. W roku 1929
książka "Kommentar till ett stjärnfall" ("Komentarz do upadku gwiazdy") zdobyła Johnsonowi uznanie krytyki. Rok później wrócił on z rodziną do Szwecji. Tutaj w latach 1934-1937 wydał
swoją najbardziej cenioną książkę "Powieść o Olofie", 1977
(szw. "Romanen om Olof"). Opisał w niej, korzystając z doświadczeń swojej młodości, drogę młodego chłopaka wychowującego się w czasie I wojny światowej za kołem polarnym. W okresie przedwojennym i w czasie wojny działał przeciwko nazizmowi, pisząc książki antytotalitarne i wspierając norweski ruch oporu.
Małżeństwo z Cillą Frankenhauser.
W roku 1938 umarła jego żona Aase. Jego drugą żoną stała się Cilla Frankenhauser. Razem przetłumaczyli na szwedzki liczne książki Alberta Camusa, Anatole’a France’a, Jeana-Paula Sartre’a i in.
Po II wojnie światowej.
Po wojnie Eyvind Johnson mieszkał przez jakiś czas w Szwajcarii (1947-49), która stanowiła tło dla niektórych napisanych przez niego utworów. Powojenne jego utwory to głównie powieści historyczne. Do najważniejszych z nich należą "Fale Przyboju", 1975 (szw. "Strändernas svall", 1946), które stanowią współczesną wersję historii Odyseusza, a także "Chmury nad Metapontem", 1981 (szw. "Molnen över Metapontion", 1957), które łączyły "Wyprawę Cyrusa" Ksenofonta z losem ludzi w obozie koncentracyjnym.
Nagrody i wyróżnienia.
Po wojnie Eyvind Johnson otrzymywał liczne wyróżnienia. W roku 1953 przyznany mu zostaje doktorat honoris causa
Uniwersytetu w Göteborgu. W roku 1957 zostaje wybrany do Akademii Szwedzkiej
(miejsce nr 11), a w roku 1962 przyznano mu nagrodę literacką Rady Nordyckiej. W roku 1974 został razem z Harrym Martinsonem wyróżniony Nagrodą Nobla z literatury "za sztukę narracji oraz dalekie spojrzenie na lądy i w głąb czasu używane w służbie wolności".
Kontrowersje wokół Nagrody Nobla.
Przyznanie nagrody spowodowało falę krytyki pod adresem Johnsona oraz Martinsona – obaj byli członkami Akademii Szwedzkiej, która przyznawała nagrody. Nieuchronny w tym kontekście był zarzut, że Akademia nagrodziła "swoich". Ten zarzut był tym silniejszy, że utwory obu autorów nie były tak szeroko znane na świecie, jak w wypadku innych laureatów, a przyznanie nagrody nie wpłynęło na większe ich rozpowszechnienie. Należy jednak zwrócić uwagę na fakt, że utwory te są bardzo silnie osadzone w języku szwedzkim, co powoduje, że bardzo trudno je przełożyć na inne języki.
Eyvind Johnson zmarł w Sztokholmie w 1976 roku.
Utwory (wybór).
Był tłumaczony na polski przez: Marię Olszańską, Emilię Bielicką, Zdzisława Wawrzyniaka i Zygmunta Łanowskiego.

</doc>
<doc id="1402" url="https://pl.wikipedia.org/wiki?curid=1402" title="Empiryzm">
Empiryzm

Empiryzm (od "empeiría" – „doświadczenie”) – kierunek filozoficzny głoszący, że źródłem ludzkiego poznania są wyłącznie lub przede wszystkim bodźce zmysłowe docierające do naszego umysłu ze świata zewnętrznego, natomiast wszelkie idee, teorie itp. są w stosunku do nich (bodźców zmysłowych) wtórne. Empiryzm stoi w ostrej sprzeczności z racjonalizmem filozoficznym, który głosi, iż źródłem poznania są właśnie idee, zaś bodźce zmysłowe mają znaczenie drugorzędne.
Pierwszym filozofem, który krytykował takie poznanie, był Heraklit z Efezu. Zgodnie z głoszonymi przez niego tezami:
Współczesna koncepcja empiryzmu została wysunięta przez Francisa Bacona, a następnie rozwinięta przez Johna Locke’a, George’a Berkeleya oraz Davida Hume’a.
W XXI wieku wyróżnia się "empiryzm metodologiczny", który głosi nieistnienie sądów syntetycznych a priori, oraz "empiryzm genetyczny," który głosi, że umysł ludzki jest pierwotnie pozbawiony treści poznawczych (umysł jako "tabula rasa" – łac. „niezapisana tablica”) i że dopiero doświadczenie bezpośrednio lub pośrednio powoduje zapełnienie tej pustki sądami. Skrajną postacią empiryzmu genetycznego jest sensualizm, który głosi, że w umyśle nie znajduje się nic czego nie było wpierw w zmysłach ("nihil est in intellectu quin prius fuerit in sensu"). Poglądem przeciwstawnym do empiryzmu genetycznego jest natywizm. Z nurtu empiryzmu wykształciło się szereg innych prądów filozoficznych: kantyzm, pozytywizm, pozytywizm logiczny oraz fenomenologia.
Do szczególnie znanych empirystów należeli między innymi:

</doc>
<doc id="1403" url="https://pl.wikipedia.org/wiki?curid=1403" title="Elektron">
Elektron

Elektron, negaton, "e−", "β−" – trwała cząstka elementarna (lepton), jeden z elementów atomu.
Elektron ma ładunek elektryczny równy e = −1,602 176 6208(98) C (ujemny ładunek elektryczny elementarny – stąd też nazwa "negaton") i masę spoczynkową me ≈ 9,109 382 91 kg.
Rozmiary liniowe elektronu.
Obecnie nie wiadomo, czy elektron ma jakąkolwiek strukturę wewnętrzną. Wielokrotnie powtarzane eksperymenty w największych akceleratorach, polegające na zderzaniu ze sobą przeciwbieżnych wiązek elektronów rozpędzonych do prędkości bliskich prędkości światła w próżni, nie dały argumentów za istnieniem struktury wewnętrznej. W zderzeniach traktowanych klasycznie elektron zachowuje się jak kulka o promieniu 2,817 940 3227(19) ⋅  m (klasyczny promień elektronu). Doświadczenia z pułapkowaniem elektronów w polu magnetycznym wykazały, że promień elektronu jest mniejszy niż  m.
Historia odkrycia elektronu.
Nazwę elektron wprowadził George Johnstone Stoney w 1891, dla elementarnej jednostki elektryczności ujemnej w procesie elektrolizy. Jako cząstka o ładunku ujemnym i niezerowej masie elektron został zaobserwowany w roku 1897 przez J.J. Thomsona. Na podstawie wyników badań właściwości promieniowania katodowego uznał, że to promieniowanie jest strumieniem cząstek o ładunku ujemnym, emitowanych w rurze próżniowej (lampa elektronowa) przez rozgrzaną katodę. Cząstki te zostały nazwane elektronami.
W 1916 Gilbert Newton Lewis zauważył, że właściwości chemiczne pierwiastków chemicznych wynikają z oddziaływań elektronów zawartych w ich atomach.
Elektron w atomie.
Elektrony w atomach zajmują określony obszar w przestrzeni wokół stosunkowo małego dodatniego jądra. Obszary zajmowane przez elektrony nazywają się orbitalami. Orbitale z kolei zgrupowane są w powłoki elektronowe. Parametry każdego orbitala (energia, kształt) zdeterminowane są przez energię elektromagnetycznego oddziaływania z jądrem atomu i pozostałymi elektronami oraz parametry elektronu. Rozmiary orbitali atomowych są rzędu  m, czyli dziesiątej części nanometra, ale dla stanów wzbudzonych mogą być kilkadziesiąt razy większe. Orbitale elektronowe są od 10 do 100 tysięcy razy większe od jądra atomowego, którego średnica wynosi od do  m (około femtometra).
Obojętny atom ma tyle samo protonów w jądrze (ładunek dodatni) co elektronów (ładunek ujemny). Atom może być zjonizowany w wyniku oderwania lub przyłączenia elektronu, wtedy liczba protonów jest różna od liczby elektronów. Dostarczenie energii powoduje wzbudzenie elektronów do wyższych stanów, bądź jonizację atomu (oderwanie elektronu). Zwykle w procesach takich wzbudzane są tylko elektrony z najwyższych powłok zwanych walencyjnymi, jednak promieniowanie o dużej energii wzbudza lub odrywa od atomu elektrony z głębszych powłok (patrz np. ekscyton Mahana – osobliwość w widmie na krawędzi Fermiego ("Fermi-edge singularity") lub promieniowanie charakterystyczne).
Zachowanie elektronów na powłokach atomowych determinuje własności atomów w reakcjach chemicznych.
Elektron w fizyce materii skondensowanej.
Elektron odgrywa ogromną rolę w zjawiskach dotyczących materii skondensowanej. Wynika to przede wszystkim stąd, że oddziaływania elektromagnetyczne stanowią dominujący czynnik wpływający na własności układów fizycznych w zakresach energii i odległości charakterystycznych materii ciała stałego i cieczy.
Głównymi cząstkami biorącymi udział oddziaływaniach w fizyce materii skondensowanej są rdzenie atomowe oraz elektrony walencyjne i swobodne oraz dziury. Ze względu na to, że w fizyce materii skondensowanej, by uprościć opis ruchu elektronu lub dziury, pomija się ich oddziaływanie z polem rdzeni atomowych. Równocześnie, aby równania ruchu elektronu pozostawały prawdziwe, zamiast masy elektronu wprowadza się jego masą efektywną. Jest ona zwykle różna od masy elektronu swobodnego, a w materiałach anizotropowych masa efektywna jest tensorem.
W fizyce ciała stałego elektrony i oddziaływania elektromagnetyczne są odpowiedzialne za tworzenie się wiązań w kryształach, a tym samym wpływają na własności sieci krystalicznej.
Przez elektron w fizyce materii skondensowanej (dotyczy to zarówno materii miękkiej i fizyki ciała stałego) rozumie się zwykle kwazicząstkę o zrenormalizowanych własnościach (patrz np. ciecz Fermiego, ciecz Luttingera, stany Pankratowa, funkcja Blocha, masa efektywna). Chcąc wyrażać się ściśle, należałoby mówić np. elektron w ciele stałym, jednak zwykle zakłada się, że fakt mówienia o kwazicząstce wynika z kontekstu, w jakim używa się sformułowania elektron.
Relacja dyspersji elektronu zależy od struktury pasmowej i modelu jaki używany jest do opisu konkretnego zjawiska. W najprostszych modelach przyjmuje się kwadratową zależność dyspersyjną (np. niektóre półprzewodniki) i wprowadza nieparaboliczne poprawki. W metalach, gdzie mamy do czynienia z częściowo wypełnionym pasmem przewodnictwa, bardzo często stosuje się model, w którym relacja dyspersji jest liniowa (liniowe rozwinięcie relacji dyspersji wokół powierzchni Fermiego).
Przybliżenie takie jest słuszne, gdy rozważane jest niskoenergetyczne wzbudzenia cząstka-dziura wokół powierzchni Fermiego.
Elektron w fizyce ciała stałego przedstawiany jest w różnych reprezentacjach. Podstawowymi z nich są
Efektem, w którym manifestują się własności elektronowe w materii skondensowanej, jest tunelowanie elektronów wykorzystywane w układach półprzewodnikowych oraz skaningowym mikroskopie tunelowym, a także wiele innych własności i zjawisk jak
Elektron w mechanice kwantowej.
Zjawiska zachodzące z udziałem elektronów zwykle należą do mechaniki kwantowej i jako takie podlegają zasadzie nieoznaczoności Heisenberga.
Elektron ma spin ¹⁄₂, jest więc zaliczany do fermionów i podlega statystyce Fermiego-Diraca. Elektrony są nierozróżnialne. Aby całkowicie opisać elektron, wystarczy podać jego stan kwantowy.
Antycząstką elektronu, tj. odpowiadającą elektronowi cząstką antymaterii, jest "antyelektron", zwany krócej pozytonem (lub elektronem dodatnim). Jeżeli spotka się elektron z antyelektronem, dochodzi do anihilacji, w wyniku której w miejsce elektronu i pozytonu powstają dwa fotony gamma (γ) o energii 0,511 MeV. Podczas zderzenia fotonu gamma o takiej lub większej energii może zajść zjawisko odwrotne: kwant gamma zostaje pochłonięty, a pojawia się pozyton i elektron.
Reakcje jądrowe z udziałem elektronu.
Elektron może brać udział w reakcjach jądrowych. Elektron może być emitowany z jądra atomowego – nazywany jest wówczas promieniowaniem beta (β) a przemiana jądrowa rozpad beta minus. Wyemitowane cząstki beta mają bardzo dużą energię i zdolność jonizacji materii. Niektóre jądra atomowe emitują antyelektrony, przemiana ta zwie się rozpadem beta plus.
Jądro atomowe może też pochłonąć elektron, jest to zazwyczaj elektron z najniższej powłoki elektronowej, przemiana taka nazywana jest wychwytem elektronu.
Elektron w teorii standardowej i modelu standardowym.
W modelu standardowym elektron jest cząstką elementarną pierwszej generacji i tworzy dublet z neutrinem elektronowym.
Elektron w klasyfikacji cząstek subatomowych jest zaliczany do leptonów. Wchodzi w interakcje z innymi leptonami poprzez oddziaływania elektromagnetyczne i słabe.
Elektron w technice.
Elektrony mogą swobodnie poruszać się w próżni, co jest wykorzystywane w próżniowych lampach elektronowych. W innych środowiskach (np. powietrzu) ich ruch jest hamowany, bo przyłączają się do atomów substancji, tworząc jony ujemne. W gazach szybko poruszający się elektron może wywołać wzbudzenie atomu lub jego jonizację, a w konsekwencji emisję fotonów. Zjawisko to jest przyczyną zorzy polarnej, zaś w technice znalazło zastosowanie w lampach wyładowczych (np. lampy jarzeniowe, tzw. świetlówki).
Zgodnie z teorią fal materii elektron może być postrzegany jako odpowiadająca mu fala. Może ona podlegać dyfrakcji i interferencji na przeszkodach. Ze względu na długość fali, znacznie mniejszą od długości fali świetlnej, elektrony nadają się doskonale jako czynnik przenoszący informację w mikroskopach – mikroskopach elektronowych.
Makroskopowe zjawiska z udziałem elektronu.
Elektrony poruszające się w sposób uporządkowany w określonym kierunku, np. w polu elektrycznym powstałym w wyniku przyłożenia napięcia elektrycznego, stanowią prąd elektryczny.

</doc>
<doc id="1406" url="https://pl.wikipedia.org/wiki?curid=1406" title="Eugenio Montale">
Eugenio Montale

Eugenio Montale (12 października 1896 w Genui, zm. 12 września 1981 w Mediolanie) – włoski eseista, krytyk literacki, poeta, polityk, tłumacz. Laureat Nagrody Nobla w dziedzinie literatury za rok 1975.
Jako młody człowiek przygotowywał się do zawodu śpiewaka operowego. Służył w armii w czasie I wojny światowej. W 1927 przeniósł się z Genui do Florencji, gdzie przyłączył się do literackiego ruchu hermetyków, poezji, w której częsta była świadoma niejasność sensu, a w języku dominowały wypowiedzi nominalne i wieloznaczność. W 1938 zwolniono go ze stanowiska dyrektora biblioteki Gabinetto Vieusseux Library we Florencji za poglądy antyfaszystowskie. W 1948 został krytykiem literackim gazety "Corriera della Sera". Od 1967 zasiadał w senacie włoskim.
Eseje Montale wywarły znaczny wpływ na środowisko włoskich intelektualistów. Przekładał m.in. utwory Williama Szekspira, Pierre’a Corneille’a i T.S. Eliota. Jako krytyk odkrył twórczość I. Sveva.
Przekłady.
Na język polski wiersze Eugenia Montale tłumaczyli Anna Cierniakówna, Cezary Geroń, Elżbieta Jamrozik, Anna Kamieńska, Radosław Kłos, Urszula Kozioł, Zygmunt Kubiak, Władysław Lark, Zygmunt Ławrynowicz, Artur Międzyrzecki, Jarosław Mikołajewski i Renata Wojdan. 

</doc>
<doc id="1407" url="https://pl.wikipedia.org/wiki?curid=1407" title="Elias Canetti">
Elias Canetti

Elias Canetti (ur. 25 lipca 1905 w Ruszczuku, zm. 14 sierpnia 1994 w Zurychu) – austriacki pisarz żydowskiego pochodzenia, prozaik i eseista, poeta, dramaturg, tłumacz; laureat Nagrody Nobla w dziedzinie literatury (1981).
Życiorys.
Elias Canetti urodził się w rodzinie Żydów sefardyjskich, której przodkowie, noszący nazwisko "Canete", zostali wygnani z Hiszpanii po ogłoszeniu edyktu z Alhambry (1492). W 1911 jego rodzina przeniosła się z Bułgarii do Manchesteru w Anglii. Po śmierci ojca w 1912 zamieszkali w Wiedniu. W latach 1916–1924 wraz z matką mieszkał w Zurychu i Frankfurcie. Do Wiednia wrócił w 1924 i podjął studia chemiczne na Uniwersytecie Wiedeńskim, które ukończył w 1929, uzyskując stopień doktora. W 1928 w Berlinie poznał Bertolta Brechta. Po Anschlussie Austrii w 1938 wyemigrował do Wielkiej Brytanii, gdzie mieszkał do roku 1988.
W 1932 zadebiutował sztuką "Hochzeit", a w 1935 napisał powieść "Auto da fé" (w oryginale "Die Blendung"). Po udaniu się na emigrację do Anglii pisarz zrezygnował z działalności literackiej, by oddać się badaniom nad psychologią tłumu i magnetyzmem faszyzmu. Esej "Masse und Macht" ("Masa i władza") z 1960 rozpoczął nowy okres w twórczości Canettiego. Pisarz porzucił prozę fabularyzowaną. Najważniejsze dzieła tego okresu to autobiograficzna trylogia: "Ocalony język", "Pochodnia w uchu" i "Gra oczu". Oprócz powieści i dramatów Canetti wydał także fragmenty swoich dzienników "Die Provinz des Menschen: Aufzeichnungen 1942–1972" (1978; w wyborze pol. pt. "Myśli") oraz szkice o osobowościach "Der Ohrenzeuge: Fünfzig Charaktere" (1974).
W swojej twórczości Canetti analizował emocje tłumu, psychopatologię władzy i sytuację jednostki w obliczu konfliktu ze społeczeństwem. Zainteresowanie pisarza ruchami masowymi datuje się od czasu zamieszek ulicznych wywołanych wysoką inflacją w latach 20. we Frankfurcie, których kulminacją stały się rozruchy w 1927, kiedy wściekły tłum podpalił wiedeński Pałac Sprawiedliwości (zob. austriacka wojna domowa). Z zaplanowanej ośmiopowieściowej sagi o gniewie tłumu powstała tylko "Die Blendung" (1935; "Auto da fé," wyd. pol. 1966). Jest to powieść o degradacji i zagładzie uczonego, odizolowanego w groteskowym świecie.
W 1981 został laureatem Nagrody Nobla w dziedzinie literatury.
Canetti był związany z wieloma kobietami, oprócz żony Vezy były to m.in. pisarka Frieda Benedikt (Anna Sebastian) i malarka Marie-Louise von Motesiczky.

</doc>
<doc id="1409" url="https://pl.wikipedia.org/wiki?curid=1409" title="Encje HTML">
Encje HTML



</doc>
<doc id="1410" url="https://pl.wikipedia.org/wiki?curid=1410" title="EMac">
EMac

eMac – komputer firmy Apple wprowadzony 29 kwietnia 2002 r., będący linią rozwojową komputera iMac. Seria eMac skierowana jest na rynek edukacyjny (stąd nazwa). Pierwsza wersja w jednolitej białej obudowie.
Do najważniejszych zmian należą: płaski monitor 17 cali (w miejsce wybrzuszonego 15"), oraz procesor PowerPC G4 w miejsce G3, a także znacznie mocniejsze głośniki (18W w miejsce 2,5). Całość (łącznie z monitorem i głośnikami), podobnie jak w komputerach iMac, w zintegrowanej obudowie (+ klawiatura i mysz) wykonanej z polikarbonatu.
Modele komputera eMac różniły się między sobą budową wewnętrzną płyty głównej. Pierwsze modele miały możliwość rozszerzenia pamięci w standardzie SD RAM do 1GB, następne (od 2004 roku) DDR RAM do 2 GB. Montowane procesory miały kolejno 700 MHz, 800 MHz i 1 GHz wyposażone były w kartę graficzną Nvidia GeForce2 MX, później ATI Radeon 7500, a następne modele miały taktowanie 1,25 GHz (ATI Radeon 9200) i 1,42 GHz (ATI Radeon 9600).
Komputery były wyposażone w karty sieciowe (LAN i Wi-Fi Airport); modem; 3xUSB; 2xFirewire; 1xMini-VGA. Systemy operacyjne wspierające architekturę PowerPC i działają na eMac:
– Mac OS 9; Mac OS X (10.3 Panther, 10.4 Tiger, 10.5 Leopard)
– MorphOS
– ArOS
– Linux
Produkcję zakończono 5 lipca 2006 roku.

</doc>
<doc id="1412" url="https://pl.wikipedia.org/wiki?curid=1412" title="Eparchius Avitus">
Eparchius Avitus



</doc>
<doc id="1413" url="https://pl.wikipedia.org/wiki?curid=1413" title="Eudoksja (imię)">
Eudoksja (imię)

Eudoksja () – imię żeńskie pochodzenia greckiego, żeński odpowiednik męskiego imienia Eudoksjusz. Oznacza „dobra sława”, od ("ew") – "dobra" i (doksa) – "sława, chwała". 
Eudoksja imieniny obchodzi 31 stycznia, jako wspomnienie św. Eudoksji z Canope.
Zob. też Eudokia.

</doc>
<doc id="1414" url="https://pl.wikipedia.org/wiki?curid=1414" title="Eudoxia">
Eudoxia



</doc>
<doc id="1415" url="https://pl.wikipedia.org/wiki?curid=1415" title="Enya">
Enya

Enya, właśc. Eithne Patricia Ní Bhraonáin (wym. /'ɛnʲə ni: vri:əna:nʲ/), w języku angielskim Enya Patricia Brennan (ur. 17 maja 1961 w Gaoth Dobhair) – irlandzka instrumentalistka, kompozytorka i wokalistka. Urodzona i wychowana w rodzinie muzyków, zamieszkałej w irlandzkojęzycznym regionie Gweedore w hrabstwie Donegal na północy Irlandii, Enya rozpoczęła karierę muzyczną w 1980 roku, kiedy to dołączyła do rodzinnego zespołu Clannad, gdzie grała partie klawiszowe. Po nagraniu dwóch albumów, opuściła zespół w 1982 roku za namową swego menadżera i producenta Nicky'ego Ryana, aby kontynuować karierę solową. Od tego momentu Enya rozwijała swój muzyczny styl, oparty na własnych kompozycjach, łączących tradycje muzyczne (wywodzące się z celtyckiej muzyki ludowej, muzyki kościelnej i muzyki klasycznej) z rozwiniętą przez Ryana techniką dźwiękową wielokrotnego nakładania głosu ("layering"), zainspirowaną efektem Ściany Dźwięku, wymyślonym przez amerykańskiego producenta Phila Spectora. Za oprawę tekstową jej utworów odpowiada irlandzka poetka i tekściarka Roma Ryan, żona Nicky'ego Ryana, która napisała teksty na wszystkie dotychczasowe albumy Enyi, głównie po angielsku i irlandzku, nieraz sięgając do języków rzadszych lub nieistniejących. Dotychczas Enya śpiewała w dziesięciu językach.
Z powodu wyłącznej współpracy z małżeństwem Ryanów od początku solowej kariery, wokalistka podkreśla w wywiadach, że Enya to tak naprawdę trio: Enya Brennan (kompozycje i wykonanie), Nicky Ryan (dźwięk i produkcja) i Roma Ryan (teksty). 
Pierwsze projekty Enyi jako solistki obejmowały muzykę do ścieżki dźwiękowej do filmu "The Frog Prince" (1984) i serialu dokumentalnego produkcji BBC "The Celts" z 1987 roku. Materiał z tego drugiego projektu został wydany jako jej debiutancki album, zatytułowany "Enya" (1987). W tym samym roku Enya podpisała kontrakt z Warner Music UK, który zapewnił jej artystyczną swobodę i minimalną ingerencję ze strony wytwórni. Enya zyskała światową sławę po wydaniu drugiego albumu solowego "Watermark" (1988), za sprawą międzynarodowego hitu "Orinoco Flow". Następnie pojawiły się sprzedające się w milionach sztuk albumy "Shepherd Moons" (1991), "The Memory of Trees" (1995) i "A Day Without Rain" (2000). Sprzedaż pochodzącego z tego ostatniego albumu singla "Only Time" gwałtownie wzrosła w Stanach Zjednoczonych po jego wykorzystaniu przez media jako tła do reportaży o zamachu na World Trade Center. Po "Amarantine" (2005) i "And Winter Came" (2008) Enya zrobiła dłuższą przerwę od muzyki. Po powrocie do studia w 2012 roku, wydała trzy lata później "Dark Sky Island" (2015).
Enya znana jest w świecie muzyki z pilnie strzeżonej prywatności, nigdy też nie odbyła solowej trasy koncertowej. Jest najlepiej sprzedającą się solową artystką Irlandii i najlepiej sprzedającą się irlandzką artystką, zaraz po U2. Sprzedała 26,5 miliona albumów w Stanach Zjednoczonych i ponad 80 milionów płyt na całym świecie, co czyni ją jednym z najlepiej sprzedających się i najbogatszych artystów na świecie. "A Day Without Rain" (2000) pozostaje najlepiej sprzedającym się albumem New Age, z szacowaną liczbą 16 milionów sprzedanych egzemplarzy na całym świecie. Enya zdobyła wiele nagród, w tym siedem World Music Awards oraz cztery nagrody amerykańskiego przemysłu fonograficznego Grammy za najlepszy album New Age. Była nominowana do Oscara i Złotego Globu za utwór "May It Be", napisany do filmu "" (2001). W 2017 roku dwa irlandzkie uniwersytety (National University of Ireland i University of Ulster), w uznaniu zasług i wkładu w rozwój przemysłu muzycznego, nadały jej tytuł doktor honoris causa.
Dzieciństwo i edukacja.
Eithne Pádraigín Ní Bhraonáin urodziła się 17 maja 1961 r. w Dore, na terenie parafii Gaoth Dobhair, w północno-zachodnim hrabstwie Donegal w Irlandii. Jest to region Gaeltacht, w którym irlandzki jest językiem podstawowym. Jej imię anglicyzowane jest jako Enya Patricia Brennan, gdzie Enya jest fonetyczną pisownią tego, jak Eithne jest wymawiana w jej rodzimym dialekcie irlandzkim Ulster. „Ní Bhraonáin” oznacza „córka Brennan”.
Urodzona w rzymskokatolickiej rodzinie o tradycjach muzycznych jako czwarta z dziewięciorga dzieci. Wokalistka posiada 4 braci i 4 siostry. Jej ojciec Leo Brennan był liderem irlandzkiego showbandu Slieve Foy Band i prowadził restaurację Leo's Tavern w Meenaleck. Matka wokalistki Máire Brennan (z domu Duggan), której przodkowie osiedlili się na Wyspie Tory i mieli odległe hiszpańskie korzenie, była muzykiem amatorem. Grała w zespole swojego męża i uczyła w Gweedore Community School. Dziadek Enyi ze strony matki, Aodh, był dyrektorem szkoły podstawowej w Dore, a jej babcia była tam nauczycielką. Aodh był także założycielem firmy Gweedore Theatre. Enya określiła swoje wychowanie jako „bardzo ciche i szczęśliwe”. W wieku trzech lat wzięła udział w swoim pierwszym konkursie śpiewu na corocznym festiwalu muzycznym Feis Ceoil. Brała udział w pantomimach w Teatrze Gweedore i śpiewała z rodzeństwem w chórze matki w kościele św. Marii w Derrybeg. Nauczyła się języka angielskiego w szkole podstawowej i rozpoczęła lekcje gry na fortepianie w wieku czterech lat. W wieku jedenastu lat dziadek Enyi zapłacił za edukacjęw szkole z internatem w klasztorze w Milfordprowadzonym przez zakonnice zakonu Loreto, gdzie zapoznała się z muzyką klasyczną i sztuką. Enya opuściła szkołę w wieku 17 lat i przez rok studiowała muzykę klasyczną w college'u, aby zostać nauczycielem gry na fortepianie.
Kariera.
1976–1985: Clannad i wczesna kariera solowa.
W latach siedemdziesiątych kilku członków rodziny Enyi założyło Clannad, celtycki zespół z Nickym Ryanem jako menadżerem i producentem, a jego przyszła żona Roma Ryan pomagała w zarządzaniu trasami koncertowymi. W 1980 r., po roku studiów, Enya zdecydowała się nie studiować muzyki na uniwersytecie, a zamiast tego zaakceptowała zaproszenie Ryana do dołączenia do grupy w celu urozmaicenia ich brzmienia poprzez włączenie instrumentów klawiszowych i pomocniczego wokalu. Koncertowała po całej Europie i zagrała niewymienioną rolę na ich szóstym albumie, "Crann Úll" (1980), razem ze swoim rodzeństwem Máire, Pólem i Ciarán Brennan i bliźniakami, Noelem i Pádraig Duggan. Enya stała się oficjalnym i uznanym członkiem od czasu wydania kolejnego albumu "Fuaim" (1981), na którego okładce znajduje się jej zdjęcie wraz z zespołem. Nicky utrzymuje, że nigdy nie miał zamiaru uczynić Enyi stałym członkiem i zdał sobie sprawę, że była „zaciekle niezależna z zamiarem grania własnej muzyki. Po prostu nie była pewna, jak się do tego zabrać”. To wywołało dyskusje między nimi na temat idei wykorzystania głosu Enyi do stworzenia chóru jednoosobowego, koncepcji opartej na technice „ściany dźwięku” Phila Spectora, która zainteresowała ich obu.
W 1982 roku, podczas trasy Clannad po Szwajcarii, Nicky wezwał spotkanie zespołu, ponieważ pojawiło się kilka problemów i poczuli, że należy się nimi zająć. Enya zdecydowała się na karierę solową z Ryanami, co początkowo spowodowało pewne problemy między trojgiem a jej rodziną, ale wolała być niezależna Następnie Nicky zasugerował Enyi, że albo wróci do Gweedore „bez szczególnej przyszłości”, albo zamieszka z nim i Romą w ich domu, a następnie w północnej dzielnicy Artane w Dublinie, „i zobaczy, co się stanie, muzycznie”. Po tym, jak ich bank odmówił im wzięcia pożyczki, Enya sprzedała swój saksofon i udzielała lekcji gry na fortepianie, a Ryanowie wykorzystali to, na co mogli sobie pozwolić ze swoich oszczędności, na budowę studia do nagrywania w ich ogrodzie o nazwie Aigle Studio, nazwanego na cześć francuskiego słowa „aigle”, oznaczającego orła.Wynajmowali ją innym artystom, aby pokryć koszty budowy. W tym czasie Eithne utworzyła partnerstwo muzyczne z Nickym jako producentem, i Romą jako jej autorką tekstów i zostali dyrektorami swojej firmy muzycznej Aigle Music. W ciągu następnych dwóch lat, Enya rozwinęła swoją grę i komponowanie, przez nagrywanie siebie grającej klasyczne utwory na fortepianie i słuchając ich. Powtarzała to, aż zaczęła improwizować sekcje i opracowywać własne aranżacje fortepianowe. Jej pierwszą kompozycją była „An Taibhse Uaighneach”, co po irlandzku oznacza "Samotny Duch". W tym czasie Enya grała na syntezatorze w "Ceol Aduaidh" (1983) Mairéada Ní Mhaonaigha i Frankiego Kennedy'ego oraz występowała z duetem i bratem Mhaonaigha Gearóide w ich krótkotrwałej grupie Ragairne.
Pierwsze solowe przedsięwzięcie Enyi pojawiło się w 1983 roku, kiedy to nagrała dwa fortepianowe utwory An Ghaoth Ón Ghrian i Miss Clare Remembers w Windmill Lane Studios w Dublinie, które zostały wydane na "Touch Travel" (1984), kasecie audio z muzyką różnych artystów. Po kilku miesiącach przygotowań, debiutancki solowy występ Enyi odbył się 23 września 1983 r. Na Stadionie Narodowym w Dublinie, który był transmitowany przez telewizyjny program muzyczny RTÉ "Festival Folk". Nial Morris, muzyk, który pracował z nią w tym czasie, przypomniał sobie, że „była tak zdenerwowana, że ledwo mogła wejść na scenę i kuliła się za fortepianem, aż koncert się skończył”.
Na sugestię Romy, którzy uważała, że muzyka Enyi będzie pasować do towarzyszących obrazów wizualnych, wykonano taśmę demonstracyjną jej kompozycji z Morris i wysłano do różnych producentów filmowych. Wśród nich był David Puttnam, któremu spodobała się taśma i wybrał Enyę do skomponowania ścieżki dźwiękowej do komedii romantycznej "The Frog Prince" (1984), którego był producentem. Enya napisała dziewięć utworów do tego filmu, ale odkryła, że jej utwory zostały zmienione i zaaranżowane wbrew jej życzeniom wobec Richarda Myhilla, z wyjątkiem dwóch utworów, które zaśpiewała, „The Frog Prince” i „Dreams”, z tekstami napisanymi przez Charliego McGettigana. Redaktor filmowy Jim Clark stwierdził później, że zmiany były konieczne, ponieważ Enya miała trudności z komponowaniem obrazu. Wydany w 1985 r. przez Island Visual Arts, album jest pierwszym komercyjnym wydawnictwem, które przyznaje jej tytuł „Enya”. Zmiana z Eithne na Enya pochodzi od Nicky'ego Ryana, który uważał, że jej nazwisko będzie zbyt trudne dla osób spoza Irlandii. Aby poprawnie je wymawiano, zasugerował fonetyczną pisownię jej imienia. Enya po latach uznała to jako dobry krok w jej karierze. Następnie zaśpiewała trzy utwory w "Ordinary Man" (1985) Christy Moore. Mike Oldfield zaprosił Enyę do nagrania harmonii wokalnej w singlu Pictures in the Dark z 1985 r., ale odmówiła.
1985–1989: "The Celts i Watermark".
W 1985 roku producent Tony McAuley zlecił Enyi napisanie piosenki do sześcioczęściowego serialu dokumentalnego BBC2 "The Celts". Napisała już piosenkę z motywem celtyckim The March of the Celts i przesłała ją do projektu. Każdy odcinek miał początkowo zawierać innego kompozytora, ale reżyser David Richardson tak bardzo polubił ten utwór, że wybrał Eithne do skomponowania całej ścieżki dźwiękowej. Enya nagrała 72 minuty muzyki w 1986 r. w Aigle Studio i studiach BBC w Wood Lane w Londynie. W przeciwieństwie do "The Frog Prince", pracowała z niewielką ingerencją, która dała jej swobodę w ustalaniu brzmienia, które przyjęła w swojej karierze, wykorzystując wielościeżkowe wokale, klawiatury i perkusję z elementami muzyki celtyckiej, klasycznej, kościelnej i ludowej.
W marcu 1987 roku, dwa miesiące przed wyemitowaniem serii w telewizji, 40-minutowy wybór ścieżki dźwiękowej został wydany jako pierwszy solowy album "Enyi", zatytułowany "Enya", autorstwa BBC Records w Wielkiej Brytanii i Atlantic Records w Stanach Zjednoczonych. Ta ostatnia promowała go z napisem "New Age" na opakowaniu. Nicky później uznał to za „tchórzliwą rzecz do zrobienia”. Album zyskał wystarczająco dużą uwagę publiczną, aby osiągnąć numer 8 na irlandzkiej liście przebojów i numer 69 na brytyjskiej liście albumów. "I Want Tomorrow" został wydany jako pierwszy singiel Enyi. "Boadicea" została wykorzystana przez The Fugees w piosence z 1996 roku "Ready or Not". Grupa nie zwróciła się o pozwolenie, ani nie wyraziła uznania, co spowodowało, że Enya zagroziła działaniem prawnym. Grupa uznała Eithne i uiściła opłatę w wysokości około 3 mln USD. Później w 1987 roku pojawiła się w debiutanckim albumie Sinéad O'Connor "The Lion and the Cobra", recytując Psalm 91 po irlandzku w utworze "Never Get Old".
Kilka tygodni po wydaniu debiutanckiego albumu, Enya podpisała kontrakt z Warner Music UK po tym, jak Rob Dickins, przewodniczący wytwórni i fan Clannad, polubił "Enyę" i "słuchał jej każdego wieczora przed pójściem spać". Przypadkiem spotkał Enyę i Ryanów podczas ceremonii wręczenia nagród Irish Recorded Music Association w Dublinie i dowiedział się, że Enya myśli o podpisaniu z konkurencyjną wytwórnią. Dickins skorzystał z okazji i podpisał kontrakt z Warner Music za cenę funtów, przyznając jej możliwość pisania i nagrywania z artystyczną swobodą, minimalną ingerencją wytwórni i bez ustalonych terminów zakończenia albumów. Dickins powiedział: „Czasami podpisujesz akt, aby zarabiać pieniądze, a czasem podpisujesz akt, by tworzyć muzykę. To było wyraźnie to drugie. Chciałem po prostu zaangażować się w tę muzykę”. Enya następnie opuściła Atlantic i podpisała kontrakt z Geffen Records, aby obsłużyć jej amerykańską dystrybucję.
Dzięki zielonemu światłu do produkcji nowego albumu, Enya nagrywała "Watermark" od czerwca 1987 r. do kwietnia 1988 r.. Początkowo nagrano ją w Aigle Studio w wersji analogowej, zanim Dickins poprosił o ponowne nagranie jej cyfrowo w Orinoco Studios w Bermondsey w Londynie. "Watermark" został wydany we wrześniu 1988 r. i stał się niespodziewanym hitem, osiągając 5 miejsce w Wielkiej Brytanii i numer 25 na "Billboard" 200 w Stanach Zjednoczonych po jego wydaniu w styczniu 1989 r. Główny singiel "Orinoco Flow" był ostatnim utworem napisanym na ten album. Początkowo nie był to singiel, ale Enya i Ryans wybrali go po tym, jak Dickins kilkakrotnie poprosił o singiel jako żart, wiedząc, że muzyka Enyi nie nadaje się na Top 40. Dickins i Ross Cullum są wymienieni w tekstach piosenek. "Orinoco Flow" stał się międzynarodowym hitem w pierwszej dziesiątce i przez trzy tygodnie był numerem jeden w Wielkiej Brytanii pierwszym z wytwórni Warner, który osiągnął pierwsze miejsce w ciągu sześciu lat. Nowo odkryty sukces spowodował, że Enya zyskała międzynarodową sławę i otrzymała oferty wykorzystania jej muzyki w reklamach telewizyjnych. Spędziła rok podróżując po całym świecie, aby promować album, który zwiększył jej ekspozycję poprzez wywiady i występy na żywo. W 1996 r. "Watermark" sprzedał się w ilości przekraczającej 1,2 miliona egzemplarzy w Wielkiej Brytanii i 4 miliony w Stanach Zjednoczonych.
1989–1997: "Shepherd moons" i "The Memory of Trees".
Po wypromowaniu "Watermark", Enya kupiła nowy sprzęt do nagrywania i rozpoczęła pracę nad swoim następnym albumem "Shepherd Moons". Okazało się, że sukces "Watermark" spowodował znaczną presję dla piosenkarki, gdy przyszło do pisania nowych piosenek. Enya napisała piosenki na podstawie kilku pomysłów, w tym wpisów z jej pamiętnika, The Blitz w Londynie i jej dziadków. "Shepherd Moons" został wydany w listopadzie 1991 r. Był to jej pierwszy album wydany pod szyldem Reprise Records, prowadzonego przez Warnera w Stanach Zjednoczonych. Stał się większym sukcesem komercyjnym niż "Watermark", osiągając numer jeden w Irlandii w ciągu tygodnia i numer 17 w Stanach Zjednoczonych. "Caribbean Blue" - główny singiel uzyskał 13 miejsce na listach w Wielkiej Brytanii. W 1997 roku album osiągnął wiele platynowych płyt za sprzedaż przekraczającą 1,2 miliona egzemplarzy w Wielkiej Brytanii i 5 milionów w Stanach Zjednoczonych.
W 1991 roku Warner Music wydało kolekcję pięciu teledysków Enya o nazwie "Moonshadows". W 1993 roku Enya zdobyła swoją pierwszą nagrodę Grammy za najlepszy album New Age za "Shepherd Moons". Wkrótce potem Enya i Nicky weszli w dyskusję z Industrial Light &amp; Magic, założoną przez George'a Lucasa, dotyczącą skomplikowanego systemu oświetlenia scenicznego dla proponowanej trasy koncertowej, lecz nic nie wyszło z tych spotkań. W listopadzie 1992 Warner uzyskał prawa do "Enyi" i ponownie wydał album jako "The Celts" z nowymi utworami. Album przekroczył początkowe wyniki sprzedaży, osiągając 10 miejsce w Wielkiej Brytanii [39] i osiągnął platynową płytę w Stanach Zjednoczonych w 1996 r. za milion sprzedanych kopii.
Po podróży na całym świecie w celu promowania "Shepherd Moons", Enya zaczęła pisać i nagrywać swój czwarty album, "The Memory of Trees". Album został wydany w listopadzie 1995 r. Szczyt osiągnął piątą pozycję w Wielkiej Brytanii i dziewiąty w Stanach Zjednoczonych, gdzie sprzedał się w ponad 3 milionach egzemplarzy. Jej wiodący singiel "Anywhere Is" osiągnął siódme miejsce w Wielkiej Brytanii. Drugi "On My Way Home" osiągnął dwudziesty szósty w tym samym kraju. Pod koniec 1994 r. Enya wydała rozszerzoną, świąteczną wersję albumu "The Christmas EP". Enyi zaproponowano, aby skomponowała soundtrack do filmu "Titanic", ale odmówiła. Nagranie jej śpiewu "Oíche Chiúin", irlandzkiej wersji Cichej nocy pojawiło się na charytatywnym albumie "A Very Special Christmas 3", wydanym na rzecz Olimpiady Specjalnej w październiku 1997 r.
Na początku 1997 roku Enya zaczęła wybierać utwory na swój pierwszy album kompilacyjny, „starając się wybrać oczywiste piosenki, hity i inne”. Zdecydowała się na pracę nad kolekcją po trasie promocyjnej "The Memory of Trees", ponieważ czuła, że to właściwy moment w jej karierze, a jej kontrakt z WEA wymagał od niej wydania „najlepszego” albumu. Zestaw, zatytułowany "Paint the Sky with Stars: The Best of Enya", zawiera dwa nowe utwory "Paint the Sky with Stars" i "Only If ...". Wydany w listopadzie 1997 r. album był światowym sukcesem komercyjnym, osiągając 4 miejsce w Wielkiej Brytanii i nr 30 w USA, gdzie sprzedał się w ponad 4 milionach egzemplarzy. Only If ... został wydany jako singiel w 1997 roku.
1998–2007: "A Day Without Rain" i "Amarantine".
Enya rozpoczęła pracę nad swoim piątym albumem studyjnym, zatytułowanym "A Day Without Rain", w połowie 1998 roku. W odróżnieniu od swoich poprzednich albumów, włączyła użycie sekcji smyczkowej do swoich kompozycji, co początkowo nie było świadomą decyzją, ale Enya i Nicky Ryan zgodzili się, że uzupełniają utwory, które były pisane. Album został wydany w listopadzie 2000 r. i osiągnął numer 6 w Wielkiej Brytanii i 17 w Stanach Zjednoczonych. W następstwie ataków z 11 września sprzedaż albumu i jego wiodącego singla "Only Time" gwałtownie wzrosła po tym, jak piosenka została szeroko wykorzystana podczas transmisji radiowych i telewizyjnych z wydarzeń prowadząc do jej opisu jako „hymn po 11 września”. Ekspozycja spowodowała, że "A Day Without Rain" osiągnęło drugie miejsce "listy Billboard" 200. Enya wydała maxi singiel zawierający oryginalny i popowy remiks utworu "Only Time" w listopadzie 2001. Enya przekazała swoje dochody na rzecz Międzynarodowego Stowarzyszenia Strażaków. Piosenka znalazła się na szczycie listy "Billboard" Hot Adult Contemporary Tracks i znalazła się na 10 miejscu w rankingu Hot 100. Był to singiel Enyi najwyżej notowany w USA. Drugi singiel "Wild Child" został wydany w grudniu 2001 roku. "A Day Without Rain" pozostaje najlepiej sprzedawanym albumem Enyi z 7 milionami sprzedanych egzemplarzy w USA i najlepiej sprzedającym się albumem New Age wszech czasów, szacowanym na 13 milionów sprzedanych egzemplarzy na całym świecie.
W 2001 roku Enya zgodziła się napisać i zagrać w dwóch utworach do ścieżki dźwiękowej "" (2001) na prośbę reżysera Petera Jacksona. Jego kompozytor Howard Shore „wyobrażał sobie jej głos”, gdy pisał partyturę filmu, co czyni wyjątkowy wyjątek włączeniem innego artysty do jednej ze ścieżek dźwiękowych. Po locie do Nowej Zelandii, aby obserwować filmowanie i obejrzeć fragment filmu, Enya wróciła do Irlandii i skomponowała "Aníron (Theme for Aragon and Arwen)" z tekstami Romy Ryan w JRR Tolkienowskim fikcyjnym język elfów Sindarin oraz "May It Be", śpiewany, w języku angielskim i innym języku tolkienowskim quenyi. Shore oparł swoje orkiestracje wokół nagranych wokali i motywów Enyi, aby stworzyć „płynny dźwięk”. W 2002 r. Enya wydała "May It Be" jako singiel, który przyniósł jej nominację do Oscara za najlepszą oryginalną piosenkę. Wystąpiła na żywo podczas ceremonii rozdania nagród 74. Akademii wraz z orkiestrą w marcu 2002 r. a później przytoczyła moment jako wyróżnienie jej kariery.
Enya podjęła dodatkowe projekty studyjne w 2001 i 2002 roku. Pierwszym z nich była praca nad ścieżką dźwiękową do japońskiego filmu romantycznego "Calmi Cuori Appassionati" (2001), który został następnie wydany jako "Themes z Calmi Cuori Appassionati" (2001). Album składa się z utworów obejmujących karierę od "Enyi" po "A Day Without Rain" z dwoma stronami B. Album trafił na numer 2 w Japonii i stał się drugim, w którym Enya sprzedała milion kopii w kraju. W listopadzie 2002 ukazał się album "," składający się z 51 utworów nagranych w trakcie jej kariery, wydany w limitowanej liczbie kopii.
We wrześniu 2003 roku Enya powróciła do Aigle Studio, aby rozpocząć pracę nad swoim szóstym albumem studyjnym "Amarantine". Roma powiedział, że tytuł oznacza „wieczny”. Album jest pierwszym przykładem śpiewu Enyi w "Loxian" - fikcyjnym języku stworzonym przez Romę, który powstał, gdy Enya pracowała nad "Water Shows the Hidden Heart". Po wielu próbach zaśpiewania piosenki po angielsku, irlandzku i łacinie, Roma zaproponowała nowy język oparty na dźwiękach, które Enya śpiewała podczas tworzenia swoich piosenek. Okazało się to być sukcesem, a Enya zaśpiewała "Less Than a Pearl" i "The River Sings" w ten sam sposób. Roma pracowała nad tym językiem dalej, tworząc „kulturę i historię” za sobą otaczającą ludność "Loxian", którzy są z innej planety. "Sumiregusa (Wild Violet)" jest zaśpiewany po japońsku. "Amarantine" odniosła globalny sukces, osiągając 6 pozycję na liście "Billboard" 200 i 8 na liście w Wielkiej Brytanii. W Stanach Zjednoczonych sprzedano ponad milion certyfikowanych kopii, co stanowi znaczny spadek sprzedaży w porównaniu z jej poprzednimi albumami. Enya zadedykowała album producentowi BBC Tony'emu McAuleyowi, który zlecił Enyi napisanie ścieżki dźwiękowej do "The Celts", po jego śmierci w 2003 roku. Singiel Amarantine został wydany w grudniu 2005 roku.Świąteczna edycja specjalna "Christmas Special Edition" została wydana w 2006 r., a następnie wydana została wersja Deluxe.
W 2006 roku Enya wydała "Sounds of the Season: The Enya Holiday Collection", świąteczną EP-kę wydaną wyłącznie w USA po wyłącznej współpracy z siecią NBC i siecią domów towarowych Target. Zawiera dwie nowe piosenki „Christmas Secrets” i „The Magic of the Night”.
W czerwcu 2007 r. Enya otrzymała tytuł doktora honoris causa Narodowego Uniwersytetu Irlandii w Galway. Miesiąc później otrzymała drugą z University of Ulster.
Po 2008: "And Winter Came ..." i "Dark Sky Island".
Enya kontynuowała pisanie muzyki z zimowym i świątecznym motywem do swojego siódmego albumu studyjnego "And Winter Came."Początkowo zamierzała stworzyć album z sezonowymi piosenkami i hymnami, który miał być wydany pod koniec 2007 roku, ale zamiast tego postanowiła stworzyć album o tematyce zimowej. Utwór "My! My! Time Flies!" to hołd złożony zmarłemu irlandzkiemu gitarzyście Jimmy'emu Faulknerowi, który zawiera gitarowe solo w wykonaniu Pata Farrella będące pierwszym użycie gitary na albumie Enyi od czasu "I Want Tomorrow" z "Enyi". Po wydaniu w listopadzie 2008 r., "And Winter Came ..." osiągnął 6 miejsce w Wielkiej Brytanii i nr 8 w USA i sprzedał prawie 3,5 miliona kopii na całym świecie do 2011 r.
Po promocji "And Winter Came ..." Enya zrobiła sobie dłuższą przerwę od pisania i nagrywania muzyki. Spędziła czas odpoczywając, odwiedzając rodzinę w Australii i remontując swój nowy dom na południu Francji. W marcu 2009 roku jej pierwsze cztery albumy studyjne zostały wznowione w Japonii w formacie Super High Material CD z dodatkowymi utworami. Jej drugi album kompilacyjny i DVD, "The Very Best of Enya", został wydany w listopadzie 2009 r. i zawiera utwory z lat 1987–2008, w tym wcześniej niepublikowaną wersję "Aníron". W 2013 roku "Only Time" został użyty w reklamie „Epic Split” przez Volvo Trucks z Jean-Claude Van Damme. Film stał się bardzo popularny, co doprowadziło do licznych parodii reklamy przesłanej na YouTube również z utworem wokalistki. Ta uwaga zaowocowała osiągnięciem pozycji 43 na liście singli "Billboard" Hot 100.
W 2012 roku Enya wróciła do studia, aby nagrać swój ósmy album, "Dark Sky Island". Jego nazwa odnosi się do wyspy Sark, która stała się pierwszą wyspą wyznaczoną, jako rezerwat ciemnego nieba. Nowy album zaczął być promowany w październiku 2015 r. z premierą jego głównego singla "Echoes in Rain" w audycji radiowej Kena Bruce'a oraz z wydaniem tego samego miesiąca singla w wersji cyfrowej. Po premierze w dniu 20 listopada 2015 r. "Dark Sky Island" trafił na 4. miejsce w Wielkiej Brytanii, najwyższy album studyjny Enyi na tej liście od czasu, gdy "Shepherd Moons" trafił na 1. miejsce. Deluxe Edition zawiera trzy dodatkowe utwory. Enya zakończyła trasę promocyjną po Wielkiej Brytanii i Europie, Stanach Zjednoczonych i Japonii.
Życie prywatne.
W 1997 roku Enya za 2,5 miliona funtów kupiła na aukcji Manderley Castle, wiktoriański dom klasy A w Killiney w hrabstwie Dublin. Dawniej znana jako "Victoria and Ayesha Castle", przemianowała zamek po domu z książki "Rebecca" autorstwa Daphne du Maurier. W 2009 roku, podczas trzyletniej przerwy w muzyce, Enya kupiła dom w południowej Francji.
Od lat 80. Enya przyciągnęła uwagę kilku stalkerów. W 1996 r. Włoch, który widziany był w Dublinie ze zdjęciem Enyi na szyi, dźgnął się przed pubem rodziców piosenkarki po wyrzuceniu z lokalu. W maju 2005 r. Enya wydała około funtów na poprawę bezpieczeństwa, pokrycie luk w zewnętrznej ścianie zamku oraz zainstalowanie pachołków i żelaznych balustrad. Pomimo tych ulepszeń, w październiku 2005 r. dwie osoby włamały się do jej domu. Jedna zaatakowała i związała jedną z pokojówek wokalistki i uciekła z kilkoma przedmiotami Enyi po tym, jak podniosła alarm w swoim pokoju bezpieczeństwa.
Enya znana jest z utrzymywania prywatnego stylu życia, mówiąc: „Muzyka jest tym, co się sprzedaje. Nie ja ani to, za czym stoję ... zawsze tak chciałam”. Nie jest zamężna i jest ciotką zastępczą dla dwóch dziewczynek. W 1991 roku powiedziała: „Boję się małżeństwa, ponieważ obawiam się, że ktoś może mnie chcieć z powodu tego, kim jestem, a nie dlatego, że mnie kocha...”. Jej związek z „hiszpańskim mężczyzną” zakończył się w 1997 r. - mniej więcej wtedy, gdy rozważała ograniczenie czasu na muzykę, aby mieć rodzinę, ale stwierdziła, że wywiera to na nią presję i „poszła drogą, którą chciała iść". Deklaruje się jako „bardziej duchowa niż religijna... czerpię z religii to, co lubię”.
W 2006 r. Enya uplasowała się na trzecim miejscu na liście najbogatszych irlandzkich artystów estradowych z szacowaną fortuną 75 milionów funtów i numerem 95 w liście "Sunday Times" najbogatszych 250 Irlandczyków.
W 2017 roku nowy gatunek ryb, "Leporinus enyae", znaleziony w obszarze rzeki Orinoko, został nazwany na cześć Enyi.
Występy na żywo.
Enya nigdy nie odbyła trasy koncertowej, mimo licznych próśb z całego świata i wspominania o pomyśle od późnych lat 80. Powiedziała, że początkowo nie zgadzała się w tej sprawie z Warner Music, ponieważ wytwórnia wyobrażała sobie jej występ na scenie „z fortepianem... może z dwoma lub trzema syntezatorami i to wszystko”. Enya wyjaśniła, że czas poświęcony jej albumom powoduje, że pozostaje jej już niewiele czasu na planowanie innych projektów. Wyraziła również trudność w odtworzeniu na scenie jej muzyki. W 1996 roku Nicky Ryan powiedział, że Enya otrzymała ofertę wartą prawie funtów na wykonanie koncertu w Japonii. W 2016 wokalistka opowiedziała o perspektywie koncertu na żywo, kiedy ujawniła rozmowy z Ryanami podczas jej trzyletniej przerwy po "And Winter Came ..." (2008), aby wykonać koncert w Metropolitan Opera House w Nowym Jorku, który miał być transmitowany do kin na całym świecie. Zanim mogło się to wydarzyć, Nicky zasugerował, aby weszła do studia i nagrała „wszystkie hity” na żywo z orkiestrą i chórem, aby zobaczyć, jak będą brzmieć.
Enya śpiewała na żywo i z playbacku podczas różnych koncertów, wydarzeń i ceremonii w trakcie całej swojej kariery, zwykle podczas swoich ogólnoświatowych wycieczek prasowych każdego albumu. W grudniu 1995 roku zaśpiewała "Anywhere Is" na koncercie świątecznym w Watykanie z udziałem papieża Jana Pawła II, który spotkał się z nią i podziękował jej za występ. W kwietniu 1996 piosenkarka zaśpiewała tę samą piosenkę podczas swojego niespodziewanego pojawienia się na pięćdziesiątych obchodach urodzin Karola XVI Gustawa, króla Szwecji i fana Enyi. W 1997 r. Enya wzięła udział w transmisji wigilijnej na żywo w Londynie, a następnie poleciała do hrabstwa Donegal, by dołączyć do swojej rodziny na coroczny mszalny występ chóralny o północy, w którym co roku uczestniczy. W marcu 2002 roku zaśpiewała "May It Be" z orkiestrą podczas ceremonii rozdania Oscarów. Enya i jej siostry występowały w lokalnym chórze Cor Mhuire w lipcu 2005 r. w kościele St. Mary w Gweedore podczas dorocznego Earagail Arts Festival.

</doc>
<doc id="1416" url="https://pl.wikipedia.org/wiki?curid=1416" title="Energia (fizyka)">
Energia (fizyka)

Energia (gr. "ενεργεια" energeia od "ἔργον" ergon „praca”) – skalarna wielkość fizyczna charakteryzująca stan układu fizycznego (materii) jako jego zdolność do wykonania pracy.
Energia występuje w różnych postaciach np.: energia kinetyczna, energia potencjalna, energia sprężystości, energia cieplna, energia jądrowa.
Energia może zmieniać swoją postać, jednak nie może być tworzona ani niszczona (zasada zachowania energii). Np. "produkcja energii" w elektrowni węglowej oznacza tylko przekształcenie energii chemicznej w elektryczną.
Z punktu widzenia termodynamiki niektóre formy energii są funkcjami stanu i potencjałami termodynamicznymi. Energia i jej zmiany opisują stan i wzajemne oddziaływania obiektów fizycznych (ciał, pól, cząstek, układów fizycznych), przemiany fizyczne i chemiczne oraz wszelkiego rodzaju procesy występujące w przyrodzie. W termodynamice, energię która może zostać zamieniona na pracę w określonych warunkach nazywa się energią swobodną.
Energia jest wielkością addytywną.
Energię we wzorach fizycznych zapisuje się najczęściej za pomocą symbolu "E".
Gęstość energii.
Stan ośrodka ciągłego lub pola fizycznego charakteryzuje gęstość energii – skalarna wielkość fizyczna równa energii "zawartej" w jednostce objętości oraz strumień energii – wektorowa wielkość fizyczna równa iloczynowi gęstości energii i prędkości przemieszczania się jej w danym ośrodku.
Stan układu.
Energia charakteryzuje stan równowagi układu i odchylenia od tego stanu. Układy fizyczne w tak zwanych stanach stacjonarnych lub podstawowych charakteryzowane są energią, której wartość jest minimalna. W związku z rozpraszaniem się (dyssypacją) energii obserwuje się "samorzutne" przechodzenie układów ze stanów scharakteryzowanych dużą wartością energii do stanów podstawowych (przykładem jest postawiony na sztorc ołówek, który "samorzutnie" się przewraca osiągając stan o najmniejszej możliwej energii).
Energia a praca.
Jeśli dany układ fizyczny ma w pewnym stanie X energię większą o pewną wartość od energii w stanie Y, oznacza to, że jest on w stanie wykonać pracę nad innymi ciałami. Wartość tej pracy równa jest różnicy energii między tymi stanami, jeżeli energia wewnętrzna pozostaje stała.
Energia jest miarą zdolności układu fizycznego (materii) do wykonania pracy lub spowodowania przepływu ciepła. W procesach, w których jeden rodzaj energii zamienia się w inny (np. w procesie grzania grzejnikiem energia ładunków elektrycznych w spirali może zamienić się w energię wewnętrzną otaczającego spiralę powietrza i energię wewnętrzną samego grzejnika), związanych zawsze z jakiegoś rodzaju oddziaływaniami (w przywołanym przykładzie jest to oddziaływanie elektronów z siecią krystaliczną spirali) praca sił opisujących te oddziaływania jest równa ilości przemienianej energii.
Przepływ energii.
Zgodnie z przyjętym sposobem opisu procesów fizycznych energia może być w tych procesach przekazywana (przenoszona) z jednego obiektu (układu) fizycznego do drugiego, a różnym procesom fizycznym odpowiadają różne postacie (formy) energii, które mogą w tych procesach zmieniać się (przekształcać) w inne.
Energia układu odosobnionego (izolowanego) jest stała, choć mogą zmieniać się jej formy i może być przekazywana z jednej części układu do innej (zasada zachowania energii). Zgodnie z twierdzeniem Noether zasada zachowania energii wynika z symetrii translacji czasowej (co można interpretować jako taką właściwość świata, zgodnie z którą prawa fizyki dzisiaj są takie same jak były wczoraj).
Ze względu na zasadę zachowania energii i związek tej zasady z symetrią translacji czasowej, energia jest jedną z podstawowych wielkości fizycznych.
Energia w teorii względności.
W szczególnej teorii względności całkowita energia relatywistyczna danego obiektu fizycznego jest składową czasową czteropędu tego obiektu.
Zgodnie z wynikającą ze szczególnej teorii względności zasadą równoważności masy i energii masa spoczynkowa danego obiektu fizycznego jest jego energią spoczynkową (energią w układzie odniesienia związanym z obiektem, nazywanym układem spoczynkowym tego obiektu), określoną wzorem formula_1 i w pewnych warunkach może być przekształcona w energię kinetyczną (oraz energia kinetyczna w spoczynkową), zaś całkowite energie relatywistyczne poszczególnych części układu (mierzone w układzie odniesienia środka pędu układu) są składnikami energii (masy) spoczynkowej układu.
Według ogólnej teorii względności rozkład energii i pędu jest źródłem zakrzywienia czasoprzestrzeni, które to zakrzywienie opisuje grawitację.
Jednostki energii.
Jednostką energii w układzie SI jest dżul [J].
Inne jednostki:
Metody uzyskiwania energii.
Najbardziej wydajną metodą uzyskiwania energii, z jednostki masy nośnika, leżącą w zasięgu możliwości technicznych ludzkości jest reakcja syntezy jądrowej. Kilkadziesiąt razy mniejszą wydajność teoretycznie można uzyskać w wyniku rozpadu jąder atomowych. Największą praktyczną wydajność osiągają już istniejące elektrownie atomowe, w których z jednostki masy uzyskuje się mniej niż jeden procent energii rozpadu jąder izotopu uranu , co odpowiada około 1/30000 energii odpowiadającej masie paliwa. Ilość utraconej przez układ określa defekt masy:

</doc>
<doc id="1417" url="https://pl.wikipedia.org/wiki?curid=1417" title="Emisja">
Emisja

Emisja – w ujęciu ogólnym: działanie polegające na przenoszeniu jakiegoś elementu układu do jego otoczenia. Czasem może się wydawać, że emisja polega na tworzeniu czegoś przez układ.
W szczególności dla różnych środowisk znaczenia mogą być następujące:
Fizyka.
Zjawisko polegające na wysyłaniu energii w dowolnej postaci.
Rodzaje emisji:

</doc>
<doc id="1418" url="https://pl.wikipedia.org/wiki?curid=1418" title="Emilian">
Emilian

Emilian – imię męskie pochodzenia łacińskiego a. etruskiego.
Imię wywodzi się od nazwiska, pochodzącego z Etrurii, rzymskiego rodu patrycjuszy Emiliuszów (łac. "Aemilianus"). Według tradycji imię to oznacza tyle co "żarliwy", "rywal", "zazdrosny" (odnosząc do łacińskiego źródłosłowu "aemulus" – rywal, lub "emulus" – zazdrosny), a. po prostu: "pochodzący z rzymskiego rodu Emiliuszów". Utarło się kilka zdrobnień tego imienia: Mila, Milek, Milan, itd. oraz Emil (które jako odrębne imię zostało spopularyzowane w XIX w. przez twórczość J-J. Rousseau). Występuje ono także w żeńskich odpowiednikach: Emiliana a. Emilia.
Emilian imieniny obchodzi: 28 kwietnia, 18 lipca (wspomnienie św. Emilian z Durostorum), 31 lipca, 8 sierpnia, 21 sierpnia, 11 września, 11 października, 12 listopada (św. Emilian z Cogolli) i 6 grudnia (św. Emilian Męczennik). Największą popularnością imię to cieszy się w krajach latynoskich, ruskich i Rumunii. W 2010 imię zajęło 218. pozycję pod względem najczęściej nadawanych nowo urodzonym obywatelom Polski.

</doc>
<doc id="1421" url="https://pl.wikipedia.org/wiki?curid=1421" title="Eksa">
Eksa

Eksa (E) – przedrostek jednostki miary oznaczający mnożnik 1 000 000 000 000 000 000 = 1018 (trylion). Na przykład 1018 m = 1 Em (eksametr).
Eksa a eksbi.
W informatyce oznacza on częściej 260 = 10246 = 1 152 921 504 606 846 976, np. 1 EB (eksabajt) to 260 bajtów. Ilość pamięci jaką teoretycznie mogą zaadresować procesory 64-bitowe to 264 bajtów, czyli 16 EB.

</doc>
<doc id="1422" url="https://pl.wikipedia.org/wiki?curid=1422" title="E (ujednoznacznienie)">
E (ujednoznacznienie)

E – piąta litera alfabetu łacińskiego, siódma litera alfabetu polskiego.

</doc>
<doc id="1423" url="https://pl.wikipedia.org/wiki?curid=1423" title="Ewrotas">
Ewrotas

Ewrotas, dawniej Eurotas, (gr. Eurṓtas) – główna rzeka Lakonii, krainy w południowej Grecji, o długości 82 km. Wypływa z góry Chelmos, przepływa przez Spartę i wpada do Morza Egejskiego poprzez Zatokę Lakońską na wschód od Githio. Według starożytnych Greków oddzielała podziemie od Alfejosu.

</doc>
<doc id="1424" url="https://pl.wikipedia.org/wiki?curid=1424" title="Ekslibris (znak)">
Ekslibris (znak)



</doc>
<doc id="1425" url="https://pl.wikipedia.org/wiki?curid=1425" title="Elagabalus">
Elagabalus



</doc>
<doc id="1426" url="https://pl.wikipedia.org/wiki?curid=1426" title="Eugeniusz (cesarz)">
Eugeniusz (cesarz)

Flawiusz Eugeniusz, łac. "Flavius Eugenius" (ok. 350 r. – 6 września 394) – cesarz rzymski w latach 392–394.
Życiorys.
Pochodzenie i pierwszy okres rządów.
Eugeniusz był nauczycielem literatury łacińskiej i retoryki. W 389 roku zaprzyjaźnił się z wodzem Arbogastem, który uczynił go naczelnikiem kancelarii na dworze cesarza Walentyniana II. Dzięki temu posunięciu rzymski wódz miał wgląd do listów cesarza. W wyniku konfliktu pomiędzy Arbogastem a Walentynianem ten ostatni poniósł śmierć. Trzy miesiące później, 22 sierpnia 392, Arbogast wyniósł Eugeniusza na tron.
Nowemu cesarzowi podlegał zachód cesarstwa (początkowo bez Italii). Na wschodzie rządził cesarz Teodozjusz. Eugeniusz zabiegał początkowo o uznanie dla swojej władzy przez Teodozjusza. Na wybijanych monetach widniały postacie obu cesarzy, a do Konstantynopola wysłano poselstwo, któremu jednak nie udało się osiągnąć zamierzonego celu, ponieważ Teodozjusz parł do wojny. Zanim doszło do militarnego rozstrzygnięcia, Eugeniusz i Arbogast umocnili obronę prowincji nadreńskich. Zimą 393 wojska rzymskie spacyfikowały tereny barbarzyńców leżące w tym rejonie.
Rządy w Rzymie, wojna i śmierć.
Następnie wiosną 393 r. Eugeniusz opanował bez walki Italię. W Rzymie popierała go wciąż liczna, mimo prześladowań ze strony chrześcijan, politeistyczna elita intelektualna i polityczna (Senat). Wiązała ona z panowaniem Eugeniusza nadzieje na powrót do wiary przodków lub przynajmniej tolerancję religijną. Eugeniusz, mimo iż sam był chrześcijaninem, zaczął realizować propoliteistyczną politykę. Zezwolił na powrót do sali zgromadzeń senatu posągu Wiktorii, przywrócił świątyniom bogów starożytnego Rzymu dobra skonfiskowane przez poprzednich chrześcijańskich cesarzy. Odrestaurowano również świątynię Wenus i Romy, odbudowano świątynię Marsa w Ostii, oraz zburzono kilka kościołów. Działania Eugeniusza wspierali wyznawcy wiary przodków: Virius Nicomachus Flavianus – prefekt pretorium w Italii – i jego syn Nicomachus Flavianus – prefekt Rzymu. Mimo licznych działań na rzecz dawnej religii, za rządów Eugeniusza nie doszło do krwawych prześladowań religijnych, chociaż wyruszając na wojnę z Teodozjuszem, Eugeniusz zapowiedział, że w przypadku zwycięskiego powrotu zamieni kościoły w stajnie, a mnichów wcieli do armii.
Do jedynej bitwy doszło nad Frygidusem w dniach 5–6 września 394. Pierwszego dnia triumfowały wojska Eugeniusza i Arbogasta, które zadały oddziałom Teodozjusza poważne straty. Cesarscy wodzowie rozważali nawet uznanie się za pokonanych i wycofanie z pola walki. Teodozjusz postanowił jednak zaryzykować kolejne starcie następnego dnia. 6 września wojska Teodozjusza ponownie zeszły w dolinę, zaskakując wojska Eugeniusza, który nie spodziewał się, że jego przeciwnik zdecyduje się na kontynuowanie walki. Podczas powstałego zamieszania Eugeniusz został pojmany przez żołnierzy i doprowadzony do Teodozjusza, gdzie podobno błagał o łaskę. Teodozjusz rozkazał ściąć jeńca, a jego głowę obnosić po polu bitwy.

</doc>
<doc id="1427" url="https://pl.wikipedia.org/wiki?curid=1427" title="Eugeniusz">
Eugeniusz

Eugeniusz – imię męskie pochodzenia greckiego. Oznacza "zacny lub szlachetnie urodzony". W całej populacji Polaków Eugeniusz zajmował w 2017 r. 70 miejsce (82 921 nadań).
Żeńskim odpowiednikiem tego imienia jest imię Eugenia.
Eugeniusz imieniny obchodzi 4 stycznia, 4 marca, 2 czerwca, 8 lipca, 13 lipca, 18 lipca, 29 lipca, 6 września, 13 listopada, 13 grudnia, 20 grudnia i 30 grudnia.

</doc>
<doc id="1428" url="https://pl.wikipedia.org/wiki?curid=1428" title="Europa Północna">
Europa Północna

Europa Północna – północna część Europy. 
W jej skład wchodzą:
Języki.
Kraje Europy Północnej posługują się głównie językami germańskimi (Dania, Islandia, Norwegia, Szwecja, Wielka Brytania). Na Litwie i Łotwie używane są języki bałtyckie. W Estonii i Finlandii używane są języki ugrofińskie, a w Irlandii celtyckie i częściowo germańskie.
Religia.
W tej części Europy dominuje protestantyzm, w Islandii, Szwecji, Norwegii, Wielkiej Brytanii, Finlandii, Estonii i na Łotwie jest to religia dominująca. Katolickimi krajami są Litwa i Irlandia, gdzie ok. 90% społeczeństwa jest wyznania rzymskokatolickiego. Ponadto w Estonii i w Szwecji dominuje również bezwyznaniowość, w Estonii jest to ok. 70% społeczeństwa, w Szwecji natomiast 46-85% (w zależności od badań).

</doc>
<doc id="1429" url="https://pl.wikipedia.org/wiki?curid=1429" title="Europa Zachodnia">
Europa Zachodnia

Europa Zachodnia – państwa zaliczane do zachodniej części Europy ze względu na ich przynależność geograficzną, historyczną i kulturową.
Według klasyfikacji geograficznej ONZ.
Według podziału używanego przez Wydział Statystyczny Organizacji Narodów Zjednoczonych, Europę Zachodnią tworzą:
Państwa te zajmują powierzchnię ponad 1,1 mln km2, a liczba ludności przekracza 185 mln mieszkańców (2008).
Należy jednak zwrócić uwagę, iż zakwalifikowanie konkretnych państw lub obszarów do danego regionu ma na celu ułatwienie badań statystycznych i nie jest wyrazem uznania przez Organizację Narodów Zjednoczonych przynależności politycznej lub innej danego państwa lub obszaru.
Według klasyfikacji CIA.
Amerykańska Centralna Agencja Wywiadowcza, w swoim corocznym raporcie The World Factbook, do krajów Europy Zachodniej zalicza:
Europa Południowo-Zachodnia:
Kwestia państw niemieckojęzycznych.
Większość geografów i historyków zalicza jednak Niemcy, Austrię, Szwajcarię i Liechtenstein do Europy Środkowej (Europa Środkowo-Zachodnia), która nie istnieje w – powstałym w czasie zimnej wojny – podziale statystycznym ONZ.
Określenie polityczno-gospodarcze.
Określenia tego używa się najczęściej w stosunku do wszystkich państw „starej” Unii Europejskiej oraz krajów EFTA (Islandii, Liechtensteinu, Norwegii i Szwajcarii). Jednak w ostatnim czasie coraz częściej (choć znacznie rzadziej niż w odniesieniu do wyżej wymienionych) do Europy Zachodniej zalicza się niektóre kraje przyłączone do Unii Europejskiej w 2004, tj. (Polskę, Węgry, Czechy i Słowację).

</doc>
<doc id="1430" url="https://pl.wikipedia.org/wiki?curid=1430" title="Europa Środkowa">
Europa Środkowa

Europa Środkowa – region położony pomiędzy różnie definiowanymi Europą Zachodnią i Europą Wschodnią. Europa Północna, Południowa i Południowo-Wschodnia również wpływają na zakres tego pojęcia, w zależności od ujęcia ich granic. Pojęcie rozumiane jest różnie w zależności od okresu historycznego.
Definicja.
Część publikacji naukowych traktuje Europę Środkową jako synonim Grupy Wyszehradzkiej. Według Ronalda Tiersky’ego i The Economist Europa Środkowa w najbardziej ścisłym znaczeniu to właśnie kraje konstytuujące tę grupę:
Bank Światowy i OECD do Europy Środkowej także zaliczają kraje tworzące Grupę Wyszehradzką, dodając do nich Słowenię ze względu na podobieństwa etniczno-kulturowe i gospodarcze. Lonnie R. Johnson w swoich publikacjach na ten temat pisze, że dwa najbardziej na wschód wysunięte kraje Europy Zachodniej, czyli Niemcy i Austria, nie są krajami stricte środkowoeuropejskimi, a określanie ich w ten sposób prowadzi do rozmycia istoty pojęcia Europa Środkowa.
Na konferencji Międzynarodowej Unii Geograficznej w Pradze (1994) do państw środkowoeuropejskich zaliczone zostały kraje Grupy Wyszehradzkiej i część krajów alpejskich:
Nieco inaczej określono obszar regionu w unijnym programie Europa Środkowa. Program ten obejmuje następujące kraje:
W porównaniu z definicją Międzynarodowej Unii Geograficznej z unijnego programu wyłączona jest północno-zachodnia część Niemiec, Szwajcaria i Liechtenstein, natomiast włączono rejony Ukrainy i Włoch, w znacznej części historycznie powiązane z monarchią habsburską.
Region objęty unijnym programem Europa Środkowa zajmuje powierzchnię ponad 1 mln km² z liczbą ludności wynoszącą około 148 mln. Jest to obszar wspólnej historii i kultury, które odróżniają go od sąsiednich regionów. Na wschód i południowy wschód od Europy Środkowej położone są terytoria opanowane przez długi okres przez imperium osmańskie lub rosyjskie, z silnym wpływem kultury helleńskiej (np. mająca swe źródła w alfabecie greckim cyrylica). Są to obszary, na których dominuje prawosławie, kościół unicki oraz islam, natomiast Europa Środkowa pozostaje regionem zdominowanym przez katolicyzm. Starożytne cesarstwo rzymskie nie sięgało do tej części kontynentu i dopiero od X wieku Europa Środkowa znalazła się w zasięgu cywilizacji zachodniej.
Koncepcja "Mitteleuropy".
W XIX wieku postulowano utworzenie zdominowanej przez Niemcy federacji krajów środkowoeuropejskich, mającej stanowić kontynuację Świętego Cesarstwa Rzymskiego. Uznawano, że narody sąsiadujące z Niemcami skorzystałyby na realizacji tego projektu. Ideę tę propagowali m.in. Konstantin Frantz oraz Friedrich Naumann, który używał wobec tego hipotetycznego bytu określenia "Mitteleuropa" (niem. Europa Środkowa).
Europa Środkowa pod względem kulturowym.
Grupa ekspertów Organizacji Narodów Zjednoczonych w 2006 roku zaproponowała następujące kulturowe kryteria wyróżnienia regionu „Europa Środkowa”:
Pod innym kątem, choć odwołując się do niektórych z tych kryteriów, patrzył na Europę Środkową Csaba Kiss: "Gdzież jest więc ten obszar? Według jednej z możliwych definicji jest nim ta strefa naszego kontynentu, w której w podobny sposób odbywało się powstawanie narodów, ów ważny składnik procesu modernizacji. Na początku tego procesu nie było niepodległej państwowości [...] Obszar ten był zamieszkany przez ludność o skomplikowanej strukturze narodowościowej, gdzie zazwyczaj współistniały różne wyznania religijne i, co za tym idzie, różniące się od siebie tradycje cywilizacyjne. Gdzie idea nowoczesnego narodu zawitała z zewnątrz, była niejako towarem importowanym z Zachodu. Mówiąc krótko: na wschód od niemieckiego i na zachód od rosyjskiego obszaru językowego. Zalicza się do niego nie tylko dawna Monarchia Austro-Węgierska, ale zarówno pozostające poza nią tereny polskie, jak i Bałkany". Milan Kundera napisał w 1983 roku esej „Zachód porwany albo tragedia Europy Środkowej”, w którym stwierdził: "Europa środkowa nie jest państwem, lecz kulturą, losem"; owym wspólnym losem było przymusowe wcielenie do bloku wschodniego. Z kolei w 2000 Jurij Andruchowycz scharakteryzował przeznaczenie Europy Środkowej jako "bycie pomiędzy Rosjanami a Niemcami".
Kultura środkowoeuropejska wykracza poza dzisiejsze granice krajów uznawanych za przynależące do Europy Środkowej i obejmuje obszary historycznie należące do Świętego Cesarstwa Rzymskiego, Królestwa Węgier, monarchii habsburskiej czy Rzeczypospolitej Obojga Narodów. Należą do nich następujące regiony:
Wielu środkowoeuropejskichkich intelektualistów niechętnie odnosi się do pojęcia „Europa Środkowa” jako podważającego przynależność ich krajów do Europy jako takiej oraz do cywilizacji zachodniej; przykładowo – jak podaje Timothy Garton Ash – Adam Michnik w żadnej swojej publikacji nie użył tego sformułowania i "pod tym względem jest w swym kraju dość typowy".

</doc>
<doc id="1431" url="https://pl.wikipedia.org/wiki?curid=1431" title="Europa Środkowo-Wschodnia">
Europa Środkowo-Wschodnia

Europa Środkowo-Wschodnia – nazwa stosowana dla określenia europejskich państw mających wspólne korzenie kulturowe i historyczne, a także wspólną przeszłość jako buforowe socjalistyczne republiki podlegające ZSRR lub będące jego częścią składową jako republiki radzieckie. Jest to zbitka dwóch określeń tej części Europy – geograficznego (środkowa) i politycznego (Wschodnia).
Jednym ze współtwórców tego określenia był Oskar Halecki. Stało się ono bardziej popularne od lat 80., gdy trzej intelektualiści (Milan Kundera, Czesław Miłosz i István Bibó) użyli go jako przeciwwagi dla terminu Europa Wschodnia.
Obecnie do tego regionu zalicza się:
Łącznie do tego regionu zalicza się 19 państw (lub 20, wliczając także Kosowo, uznawane przez część państw świata).

</doc>
<doc id="1432" url="https://pl.wikipedia.org/wiki?curid=1432" title="Europa Wschodnia">
Europa Wschodnia

Europa Wschodnia – termin określający wschodnią część kontynentu europejskiego. Region ten jest różnie definiowany.
Definicje.
Według ONZ.
Grupa Ekspertów ONZ ds. Nazw Geograficznych.
Grupa Ekspertów ONZ ds. Nazw Geograficznych, wchodząca w skład Wydziału Statystycznego Rady Gospodarczej i Społecznej ONZ, została założona w celu rozpatrzenia technicznych problemów standaryzacji nazw geograficznych. Grupa ta składa się z ekspertów wchodzących w skład różnych sekcji geograficznych i językowych, powołanych podczas Konferencji Narodów Zjednoczonych ds. Standaryzacji Nazw Geograficznych.
W skład sekcji „Europa Wschodnia oraz Azja Północna i Środkowa” wchodzą przedstawiciele następujących państw europejskich:
Sekcję tę tworzą również następujące państwa azjatyckie: Armenia, Azerbejdżan, Mongolia, Uzbekistan i Kirgistan.
Ponieważ poszczególne państwa mają pełną dowolność w wyborze sekcji regionalnej, do której będą należeć, podział taki nie jest formalny.
Wydział Statystyczny ONZ.
Według podziału używanego przez Wydział Statystyczny Organizacji Narodów Zjednoczonych do własnych celów w skład Europy Wschodniej wchodzą:
Zakwalifikowanie konkretnych państw lub obszarów do danego regionu ma na celu ułatwienie badań statystycznych i nie jest wyrazem uznania przez Organizację Narodów Zjednoczonych przynależności politycznej lub innej danego państwa lub obszaru.
Grupa regionalna w ONZ.
Kraje członkowskie ONZ samodzielnie decydują o swojej przynależności do poszczególnej grupy regionalnej ONZ. W ONZ do "Eastern European Group" przystąpiły:
Turcja jednocześnie przystąpiła i do "Asia-Pacific Group".
Według klasyfikacji CIA.
Amerykańska Centralna Agencja Wywiadowcza, w swoim corocznym raporcie The World Factbook, do krajów Europy Wschodniej zalicza:
Natomiast do krajów Europy Południowo-Wschodniej CIA zalicza:
 zaklasyfikowana jest jako państwo transkontynentalne.
Klasyfikacja kulturowa.
Europa Wschodnia, w znaczeniu kulturowym, należy do bizantyjsko-prawosławnego (bizantyjsko-słowiańskiego) kręgu kulturowego – pod względem kulturowym zalicza się do niej następujące państwa:
Ponadto, do kręgu tego należą następujące państwa Europy Południowo-Wschodniej:
 przynależy częściowo do Europy Wschodniej (Mołdawia zachodnia), Południowo-Wschodniej (Wołoszczyzna) i Środkowej (Siedmiogród, Banat, Bukowina).
Definicja kulturowa.
Naukowcy zajmujący się podziałami Europy wyraźnie odróżniają, w ujęciu kulturowym, Europę Południowo-Wschodnią: dawne bizantyjskie cesarstwo wschodnie i państwa stworzone przez Słowian na Półwyspie Bałkańskim – terytorium niegdyś podbite przez Imperium Osmańskie, od Europy Wschodniej, której centrum kulturowym jest Rosja, mająca za sobą doświadczenie wieloletniego jarzma tatarskiego i która wykształciła swój specyficzny model kulturowy.

</doc>
<doc id="1433" url="https://pl.wikipedia.org/wiki?curid=1433" title="Europa Południowa">
Europa Południowa

Europa Południowa (Europa Śródziemnomorska) – państwa trzech wielkich półwyspów na południu Europy: Iberyjskiego ("Europa Południowo-Zachodnia"), Apenińskiego i Bałkańskiego ("Europa Południowo-Wschodnia") oraz szeregu wysp na Morzu Śródziemnym. Kraje Europy Południowej łączy dziedzictwo Starożytnej Grecji i Starożytnego Rzymu oraz powiązania gospodarcze w basenie Morza Śródziemnego.
Zgodnie z danymi Światowej Organizacji Turystyki (UNWTO), w 2015 roku kraje Europy Południowej (Europy Śródziemnomorskiej) odwiedziło ponad 225 milionów turystów (4,8% więcej niż w roku poprzednim), generując przychody na poziomie 176 mld dolarów. Jest to najwyższa liczba turystów wśród wszystkich części świata.
Najbogatsze państwa Europy Południowej utworzyły zrzeszenie EuroMed.
Klimat.
Dominującym klimatem w Europie Południowej jest klimat subtropikalny trzech typów: klimat śródziemnomorski, klimat subtropikalny wilgotny (), subtropikalny klimat morski, natomiast w wysokich górach – klimat alpejski.
Państwa.
Według klasyfikacji ONZ w Europie Południowej są to następujące państwa, w których mieszka ponad 153 mln mieszkańców na powierzchni 1,3 mln km²:
Klasyfikacja ONZ nie obejmuje części wybitnie południowo-europejskie jak np. część Francji w szczególności – Oksytanię i Korsykę (francuską wyspę na Morzu Śródziemnym) oraz wschodnią część Bałkanów np. , i Kosowo.
Dodatkowo, do Europy Południowej zaliczany jest i (np. przez Światową Organizację Turystyki (UNWTO)), choć Cypr geograficznie leży w Azji Zachodniej oraz tylko Tracja, mała część Turcji leży w Europie. Rzadziej do Europy Południowej zaliczane są państwa Kaukazu: , , (leżące generalnie w zachodniej Azji, gdzie fragmenty leżą w Europie).
Miasta.
Spośród 10 największych zespołów miejskich Unii Europejskiej, sześć znajduje się w Europie Południowej. Największe metropolie Południowej Europy (zespół miejski powyżej 1 miliona mieszkańców):
Miasta w Europie Południowej poza klasyfikacją ONZ:

</doc>
<doc id="1434" url="https://pl.wikipedia.org/wiki?curid=1434" title="Era kalendarzowa">
Era kalendarzowa

Era kalendarzowa – okres zapoczątkowany jakimś ważnym wydarzeniem (rzeczywistym lub legendarnym), który stanowi podstawę rachuby lat w kalendarzu.
Wyróżnia się "ery krótkie" i "ery długie".
Era krótka.
Era krótka to era kilkuletnia lub kilkunastoletnia, w najlepszym przypadku licząca sobie kilkadziesiąt lat. W świadomości użytkowników takiej ery zostanie ona w dającej się wyobrazić przyszłości zastąpiona nową erą.
Kalendarze liczone według er krótkich najczęściej związane są z okresem panowania konkretnego władcy (np. „w 3. roku panowania cesarza Augusta”). Ery takie ustanawia się i liczy się w praktyce już od pierwszego roku jego używania. Lat przed panowaniem danego władcy nie liczy się w systemie lat ujemnych, bo są oznaczone inna erą krótką (nazwą okresu panowania innego władcy). Kalendarze o erach krótkich są więc praktycznie kalendarzami o wielu następujących po sobie krótkich erach o różnej długości. Przykładem jest epoka wiktoriańska.
W historii konkretnych państw, np. Chin czy Japonii, często bywało tak, że władca w ciągu swego okresu panowania zmieniał tytuł czy dewizę, pod jaką panował. Powodowało to rozpoczęcie nowej ery w odpowiednim kalendarzu chińskim czy japońskim. W kalendarzach tych często też posługiwano się równolegle innym (najczęściej cyklicznym) sposobem mierzenia lat, związanym ze zjawiskami astronomicznymi, w związku z czym rok pierwszy i ostatni danej ery praktycznie nigdy nie pokrywa się z pełnym rokiem słonecznym, księżycowo-słonecznym czy księżycowym – początek kolejnych lat bowiem liczono od Nowego Roku, określanego metodami astronomicznymi, a nie od rocznicy wejścia na tron (ogłoszenia nowej dewizy panowania) danego władcy. Czas interregnum (okres między śmiercią lub abdykacją poprzedniego władcy a objęciem panowania przez nowego władcę) zaliczano najczęściej do ostatniego roku ery poprzedniego władcy (bardzo rzadko - liczono odrębnie). W związku z tym dany rok (astronomiczny) może obejmować dwa lata liczone według er krótkich: poprzedniego władcy i nowego władcy.
Kalendarze o krótkiej erze na ogół mają zastosowanie lokalne - ograniczają się do datowania wydarzeń w obrębie danego państwa (cesarstwa, królestwa czy nawet księstwa) i poza nim nie są używane (nawet rzadko używane są przez inną stronę w dwustronnych relacjach dyplomatycznych, gdyż w takiej sytuacji każde państwo używa własnych dat). Historycznie rzecz biorąc był to jednak najstarszy i najbardziej rozpowszechniony sposób liczenia czasu. Dziś w praktyce zanika i używany jest obecnie głównie w Japonii.
Era długa.
Ery długie związane są najczęściej z wydarzeniem uznanym za na tyle wyjątkowe, że nie ma szans, by pojawiło się wydarzenie „konkurencyjne”, które mogłoby je - teoretyczne nawet - zastąpić. W związku z tym liczenie czasu przebiega linearnie od tego momentu - „w nieskończoność” (np. „w 325. roku od założenia Miasta”). Najczęściej ery długie i kalendarze posługujące się erami długimi związane są genetycznie z konkretnymi religiami (i wydarzeniami religijnymi), choć część z nich dziś nabiera charakteru świeckiego (np. kalendarz gregoriański i tzw. era powszechna (ang. Common Era - "C.E"), czyli pierwotnie era chrześcijańska (ang. Christian Era - "C.E."), rzadziej z wydarzeniami z historii świeckiej (np. indyjskie ery Śaka i Wikrama).
Ery długie najczęściej ustanawiane są post factum - musi upłynąć jakiś czas od danego wydarzenia, by zostało ono uznane za wystarczająco wyjątkowe. Czasem wiąże się z tym problem błędnego określenia (obliczenia wstecz) daty tego początkowego wydarzenia (np. problem obliczenia daty urodzenia Jezusa Chrystusa dla kalendarza chrześcijańskiego).
Kalendarze takie uznawane są za uniwersalne i w praktyce używane są w wielu krajach równocześnie. Najczęściej obecnej ery długiej nie poprzedza żadna inna era długa, zatem wydarzenia sprzed obecnego okresu liczone są w systemie lat ujemnych.
Kalendarze takie dominują dziś w świecie. Najnowsze próby administracyjnego ustanawiania nowych er (np. kalendarz republikański francuski, zwany u nas błędnie „rewolucyjnym”, czy kalendarz rewolucji październikowej wprowadzany w Rosji Sowieckiej w latach 20. XX wieku lub "era faszystowska" liczona przez włoskich faszystów od daty puczu 28 października 1922) nie przyjmują się i szybko wychodzą z użycia (są odwoływane przez odpowiednie władze).
Inne.
Część wyznawców zaratusztrianizmu przyjmuje za początkową datę założenia tej religii tj. według obliczeń i przekazów dzień równonocy wiosennej 1737 p.n.e.

</doc>
<doc id="1435" url="https://pl.wikipedia.org/wiki?curid=1435" title="Euskera">
Euskera



</doc>
<doc id="1436" url="https://pl.wikipedia.org/wiki?curid=1436" title="Elektron (stop magnezu)">
Elektron (stop magnezu)

Elektron – stop magnezu z glinem, krzemem, manganem i cynkiem, wynaleziony w Niemczech podczas I wojny światowej jako substytut aluminium.
Głównym składnikiem stopu jest magnez, który stanowi 85%-98% w zależności od rodzaju produkcji. Bardzo lekki (gęstość ok. 1,8 g/cm³), a przy tym wytrzymały. Używany do produkcji części maszyn szczególnie ważny jest w przemyśle lotniczym, samochodowym oraz zbrojeniowym. Nie jest odporny na korozję, przez dużą aktywność chemiczną magnezu. Ma zbliżone właściwości do żeliwa, podczas obróbki jest łatwo zapalny, przy czym powstaje tlenek magnezu.

</doc>
<doc id="1438" url="https://pl.wikipedia.org/wiki?curid=1438" title="Reaktor EWA">
Reaktor EWA

Reaktor EWA – pierwszy w Polsce badawczy reaktor jądrowy, znajdujący się w dawnym Instytucie Badań Jądrowych (obecnie w Zakładzie Unieszkodliwiania Odpadów Promieniotwórczych) w otwockim Świerku. Nazwa reaktora była akronimem od wyrazów: eksperymentalny, wodny, atomowy.
Historia.
Po 1955 roku, kiedy zdjęto klauzulę tajności z tematu pokojowego wykorzystania energii jądrowej, Związek Radziecki mógł zaoferować krajom socjalistycznym sprzedaż reaktorów doświadczalnych opracowanych w ZSRR. Wartość kontraktu strona radziecka wyceniła na 15 mln USD i taką też ofertę przedstawiła krajom zainteresowanym zakupem. Jednakże przeprowadzona przez Instytut Badań Jądrowych analiza (mająca za podstawę porównanie kosztów zachodnich urządzeń podobnej klasy) wykazała, iż kwota ta jest poważnie zawyżona. W wyniku podjętych negocjacji ostateczną wartość transakcji ustalono na 5,5 mln USD za gotowy reaktor wraz ze wsadem paliwowym.
Budowa reaktora rozpoczęła się wiosną 1956 roku. Gotowa konstrukcja została przekazana przez Związek Radziecki. 31 maja 1958 roku reaktor osiągnął stan krytyczny, jego uruchomienie i przekazanie do eksploatacji nastąpiło 14 czerwca 1958 roku. Podobne reaktory powstały w tym czasie także w instytutach w Leningradzie, Obninsku, Ałma-Acie, Taszkencie i Budapeszcie.
24 lutego 1995 roku reaktor wyłączono, ze względu na zużycie poszczególnych elementów i materiałów. Proces likwidacji rozpoczęto w roku 1997. Do 2002 roku usunięto paliwo jądrowe i substancje wysokoaktywne oraz zdemontowano reaktor. Planowane jest wykorzystanie korpusu reaktora jako suchego przechowalnika wypalonego paliwa.
Paliwo z reaktora, po zamknięciu w szczelnych pojemnikach wypełnionych gazem obojętnym (helem), przechowywane jest w mokrych przechowalnikach na terenie Instytutu. Jego część, wraz z paliwem z reaktora Maria (łącznie 450 kg wysoko wzbogaconego wypalonego paliwa), została w latach 2009–2010 wywieziona w pięciu transportach do Rosji (kraju pochodzenia).
Wizerunek reaktora został umieszczony na odwrotnej stronie banknotu 20 000 zł (PLZ). Na stronie przedniej zamieszczono wizerunek Marii Skłodowskiej-Curie.
W północnym narożniku hali reaktora EWA powstał w 1963 r. reaktor mocy zerowej Maryla.
Budowa i parametry reaktora.
Pierwotna konstrukcja.
Reaktor EWA (akronim słów eksperymentalny, wodny, atomowy) był reaktorem lekkowodnym o mocy cieplnej 2 MW, produkcji radzieckiej, typu WWR-S (ros. ВВР-С) o konstrukcji zbiornikowej. Woda destylowana spełniała w nim funkcje moderatora i chłodziwa.
Rdzeń reaktora, o objętości około 0,1 m³, umieszczony był w aluminiowym zbiorniku, wypełnionym wodą chłodzącą. W rdzeniu, przy pełnym załadunku, umieszczone było około 800 prętów paliwowych, zgrupowanych w 52 kasety paliwowe, zawierające 16 prętów każda. Pręty paliwowe miały długość 50 cm, w kasecie tworzyły siatkę kwadratową o skoku 17,5 mm. Kasety wstawiane były do aluminiowego separatora, umożliwiającego przepływ chłodziwa i utrzymanie stałej odległości między kasetami. W rdzeniu znajdowało się także 9 prętów regulacyjnych i awaryjnych. Rdzeń otaczało 8 pionowych kanałów stosowanych do produkcji izotopów promieniotwórczych.
Zastosowane paliwo prętowe typu EK-10 miało postać dyspersji uranu w magnezie, otoczone było koszulką aluminiową. Było wzbogacone w 10% w 235U. Przy pełnym załadunku, w reaktorze znajdowało się 65 kg uranu, w tym 6,5 kg izotopu 235U. Minimalna masa krytyczna wynosiła 3,2 kg 235U, co odpowiadało załadowaniu 25 kaset paliwowych. W początkowej fazie kampanii paliwowej reaktora, znajdowało się w nim 4,1 kg 235U – 32 kasety paliwowe.
Przy pracy z pełną mocą, w środku rdzenia osiągany był strumień neutronów termicznych 2 neutronów/s×cm². Woda otaczająca rdzeń spełniała rolę reflektora neutronów, co umożliwiało zmniejszenie ubytku strumienia. Jego średnia wartość w reaktorze wynosiła neutronów/s×cm².
Chłodzenie reaktora, zapobiegające wrzeniu wody i uszkodzeniu prętów paliwowych, zapewniała woda przepływająca przez jego rdzeń. Woda ogrzana w rdzeniu do temperatury około 35 °C, krążąca w obiegu pierwotnym chłodzenia, kierowana była na rurowe wymienniki ciepła. W wymiennikach tych oddawała ciepło wodzie krążącej w drugim obiegu, chłodzonej w basenie rozbryzgowym. Podczas pracy reaktora, temperatura powierzchni prętów paliwowych osiągała około 90 °C – poziom niestwarzający zagrożenia uszkodzenia aluminiowych koszulek prętów.
Aktywność rdzenia reaktora, podczas pracy z pełną mocą, wynosiła około 1 miliona Ci (~3,7 Bq). Osłony przed promieniowaniem obejmowały warstwę wody (otaczającą zbiornik aluminiowy z rdzeniem), zbiornik żeliwny oraz warstwę betonu. Łączna grubość osłon wynosiła ponad 3 metry. W wodzie następowało spowolnienie neutronów prędkich. Beton, z dodatkiem limonitu (rudy żelaznej), zapewniał pochłanianie głównie promieniowania gamma. Górną osłonę reaktora stanowiła żeliwna pokrywa, w której umieszczona była maszyna załadowcza.
W osłonie reaktora umieszczone było 9 poziomych kanałów eksperymentalnych, rozchodzących się promieniście od rdzenia reaktora. Umożliwiały one kontrolowane wyprowadzenie strumieni neutronów i promieniowania gamma do celów doświadczalnych. Dodatkowy, dziesiąty kanał, stanowiła tzw. kolumna termiczna, służąca do wyprowadzania silnych wiązek neutronów termicznych.
Poniżej reaktora umieszczone były 4 komory gorące, w których możliwe było wykonywanie prac z materiałami promieniotwórczymi. Komory połączone były z reaktorem przez kanały izotopowe. Każda komora wykonana była ze stali kwasoodpornej i otoczona warstwą betonu. Prace z wysokoaktywnymi materiałami w komorach umożliwiały manipulatory.
Modernizacje.
W latach 1964 i 1967 przeprowadzono modernizacje reaktora – m.in. wprowadzono paliwo wzbogacone do 36% – zestawy paliwowe typu WWR-SM, dodano reflektor berylowy. Uzyskano wzrost mocy do poziomów 4 MW w roku 1964, a następnie w roku 1967 początkowo do 8 MW, później do 10 MW. Zwiększono strumień neutronów do 8 neutronów/s×cm². Od roku 1992 stosowano nieznacznie zmodyfikowane zestawy paliwowe typu WWR-M2.
Eksploatacja.
Reaktor EWA rocznie pracował około 3500 godzin. Nigdy nie uległ awarii. 
Reaktor był wykorzystywany przede wszystkim do produkcji izotopów promieniotwórczych. Izotopy wytwarzane w reaktorze EWA, podobnie jak obecnie w reaktorze Maria, stosowane były w medycynie, przemyśle i innych dziedzinach nauki – do leczenia nowotworów, prześwietlania spoin, odlewów, kontroli grubości blach walcowanych.
Przeprowadzano szereg badań związanych z techniką reaktorową i energetyką jądrową. Badania materiałów obejmowały pomiary parametrów neutronowych (spowalniania i dyfuzji), pomiary właściwości jądrowych materiałów konstrukcyjnych i pochłaniających, badanie uszkodzeń materiałów pod wpływem promieniowania. W tzw. pętli energetycznej badano chłodziwa i moderatory, poddając je działaniu dużych strumieni neutronów. Wyznaczano liczby neutronów powstających w rozszczepieniu przy różnych energiach neutronów, badano pochłanianie neutronów w pasmach rezonansowych, badano dyfrakcję i rozpraszanie neutronów na strukturach krystalicznych i wiele innych.
Badania i prace przeprowadzane na reaktorze EWA umożliwiły rozwój fizyki reaktorowej, inżynierii reaktorowej czy elektroniki jądrowej.
Podczas eksploatacji reaktora przeprowadzano próby wykorzystania wody chłodzącej z drugiego obiegu do upraw szklarniowych w pobliżu budynku reaktora. Reaktor nie był jednak nigdy wykorzystywany w celach gospodarczych.

</doc>
<doc id="1439" url="https://pl.wikipedia.org/wiki?curid=1439" title="Ewa">
Ewa

Ewa – imię żeńskie, które pierwszy raz pojawia się 2000 lat p.n.e. w języku sumeryjskim jako „Awa” gdzie oznacza „życie”.
W języku hebrajskim, który zapożyczył to imię od Sumerów wywodzi się od rdzenia חוה "hajja" lub hawwa – i również oznacza 'dająca życie'. Imię wyprowadzane też z arabskiego słowa "hajja" 'wąż'.
Według Biblii pierwsza kobieta, matka wszystkich ludzi (zob. Adam i Ewa). Z Septuaginty – greckiego przekładu Biblii – zostało przejęte do łaciny w formie Eva.
Pierwsza stworzona przez Boga kobieta (według niebiblijnych legend – druga, zob. Lilith). Stworzona, jak podaje wersja rabinistyczna, z ciała (słowo tłumaczone jako „żebro”) męża, kobieta urodziła synów: Kaina, potem Abla, Seta (przodka Noego, z jego linii wywodzili się Abraham, Dawid i Jezus) oraz innych synów i córki, o których niewiele wiadomo.
Według opisu biblijnego Ewa, skuszona przez węża, namówiła swego męża do spróbowania zakazanego owocu (często przedstawianego jako jabłko) z Drzewa Poznania Dobra i Zła, przez co sprowadzili śmierć na Ziemię i zostali wygnani z Edenu (Raju).
Wśród imion nadawanych nowo narodzonym dzieciom, Ewa w 2017 r. zajmowała 56. miejsce w grupie imion żeńskich. W całej populacji Polek Ewa zajmowała w 2017 r. 7. miejsce (492 688 nadań).
Ewa imieniny obchodzi:

</doc>
<doc id="1443" url="https://pl.wikipedia.org/wiki?curid=1443" title="Er">
Er

Er lub er:
eR:
ER:
.er

</doc>
<doc id="1444" url="https://pl.wikipedia.org/wiki?curid=1444" title="Es">
Es



</doc>
<doc id="1445" url="https://pl.wikipedia.org/wiki?curid=1445" title="Eu">
Eu



</doc>
<doc id="1446" url="https://pl.wikipedia.org/wiki?curid=1446" title="Empire Helford">
Empire Helford



</doc>
<doc id="1448" url="https://pl.wikipedia.org/wiki?curid=1448" title="Empire Helford statek">
Empire Helford statek



</doc>
<doc id="1449" url="https://pl.wikipedia.org/wiki?curid=1449" title="EHF">
EHF



</doc>
<doc id="1450" url="https://pl.wikipedia.org/wiki?curid=1450" title="Efedryna">
Efedryna

Efedryna – organiczny związek chemiczny, alkaloid roślinny, pochodna fenyloetyloaminy. Stosowana jako stymulant, reduktor apetytu, środek zwiększający koncentrację i uwagę, lekarstwo na nieżyt nosa oraz do leczenia niedociśnienia związanego z narkozą. Występuje w roślinach z rodzaju przęśl ("Ephedra equisetina", Ephedra sinica – "", "Ephedra distachya") oraz w cisie ("Taxus baccata"). Jest najczęściej dostępna w formie chlorowodorku i siarczanu.
Występuje w postaci dwóch enancjomerów o konfiguracji 1"R",2"S" i 1"S",2"R", pozostałe dwa diastereoizomery znane są jako pseudoefedryna. Preparaty handlowe zawierają (−)-(1"R",2"S")-efedrynę.
Historia.
Roślina "" (, "Ephedra sinica"), zawierająca efedrynę oraz pseudoefedrynę, stosowana jest w tradycyjnej chińskiej medycynie.
Efedryna po raz pierwszy została wyizolowana z rośliny "Ephedra vulgaris" przez Nagayoshi Nagai w 1885 roku.
Produkcja.
Produkcja efedryny w Chinach stała się dochodowym przemysłem eksportowym o wartości 13 mln $ rocznie. Z przetworzenia 30 tys. ton surowca roślinnego otrzymuje się 10 razy więcej substancji niż wynosi roczne zapotrzebowanie w tradycyjnej chińskiej medycynie.
Syntetyczna efedryna.
Oprócz efedryny otrzymywanej ze źródeł naturalnych uzyskuje się ją na drodze syntezy chemicznej. Jedną z pierwszych metod było działanie na mieszaninę 1-fenylopropano-1,2-dionu i metyloaminy wodorem w obecności katalizatora:
Reakcję przeprowadza się w środowisku czystego alkoholu etylowego, katalizatorem redukcji jest tlenek platyny(IV). Po zakończeniu redukcji katalizator jest usuwany przez filtrację, natomiast nieprzereagowana metyloamina jest oddestylowana pod zmniejszonym ciśnieniem. Następnie mieszaninę traktuje się roztworem chlorowodoru w alkoholu etylowym i wytrąca się kryształy przez odparowanie rozpuszczalnika. Tak przygotowany chlorowodorek efedryny przemywa się zimnym acetonem i suszy. Produkt zawiera oba stereoizomery efedryny oraz pewne ilości pseudoefedryny.
Komercyjnie dostępna efedryna syntezowana jest jedną z dwóch poniższych metod:
Ponadto w literaturze naukowej informowano o innych możliwościach syntezy efedryny; koncentrują się one zwykle na otrzymaniu selektywnie jednego z enancjomerów. Poniżej podano wybrane przykłady:
Działanie.
Działa bezpośrednio, pobudzająco na układ współczulny (na receptory α-adrenergiczne i β-adrenergiczne) oraz pośrednio poprzez uwalnianie noradrenaliny z zakończeń nerwowych. Z tego względu przy powtarzanym podawaniu występuje zjawisko tachyfilaksji. Każda następna dawka podawana w krótkim czasie powoduje mniejszy skutek farmakologiczny. Obecnie coraz rzadziej stosowana w lecznictwie, zostaje zastąpiona środkami o bardziej specyficznym działaniu (np. synefryną).
Efedryna pomaga utrzymać szybkie tempo przemiany materii dzięki stymulowaniu konwersji nieaktywnej formy hormonu tarczycy T4 w postać aktywną T3. Indukowanie metabolizmu tkanki tłuszczowej w procesie termogenezy oraz działanie pobudzające efedryny są wynikiem jej zdolności do pobudzania wydzielania katecholamin: adrenaliny i noradrenaliny. Obie te substancje przyspieszają uwalnianie tłuszczu z komórek tłuszczowych i pobudzają układ nerwowy. Proces termogenezy gwałtownie spada po kilku tygodniach.
Najważniejsze działania efedryny to:
Przypomina adrenalinę, ale nie ulega rozkładowi w układzie pokarmowym.
Dawniej była stosowana w leczeniu astmy oskrzelowej. W medycynie chińskiej stosowana od 4 tysięcy lat. Obecnie najczęściej bywa stosowana w preparatach leczniczych takich jak: "Tussipect, Proasthmin, Allergoasthmin".
Bywa używana jako środek dopingujący i w postaci ECA jako silny i skuteczny środek odchudzający (patrz wyżej termogeneza). Może powodować uzależnienie psychiczne u niektórych osób (ze względu na początkowy efekt euforii – nie powoduje fizycznego), z powodu rosnącej tolerancji nie można jej długo stosować (tolerancja wynika z tego że receptory są po pewnym czasie zablokowane i niewrażliwe na działanie efedryny).
Efekty niepożądane.
Skutki uboczne najczęściej występują przy regularnym stosowaniu (iniekcje, bądź przyjmowanie doustne), rzadziej w przypadku okresowego korzystania z inhalatorów zawierających efedrynę (np. do nosa). Możliwe efekty uboczne stosowania efedryny:
Przedawkowanie może prowadzić do śmierci (m.in. przez obciążenie serca), aczkolwiek w przypadku zażycia zalecanej dawki (poniżej 60 mg – zależne też od masy ciała) rzadko występują efekty niepożądane.
Przyjmowanie wysokich dawek efedryny może prowadzić do uszkodzenia mózgu z powodu ciągłego oddziaływania na neurotransmitery; może także powodować uszkodzenia naczyń krwionośnych z powodu towarzyszącego nadciśnienia. Efedryna może powodować zmniejszenie napięcia mięśniowego oraz psychozy paranoidalne. Badania na zwierzętach wskazują na możliwość uszkodzeń mózgu, mogących prowadzić do „tików” podobnych do występujących w chorobie Parkinsona.
Neurotoksyczność.
Ponieważ efedryna jest substancją sympatykomimetyczną, podobną strukturalnie oraz pod względem aktywności do amfetamin, efedryna bywa używana jako prekursor do produkcji narkotyków (metamfetaminy i metkatynonu). Efedryna ze względu na swoje właściwości pobudzające bywa używana jako domieszka do narkotyków np. dostępny w USA narkotyk zwany Cloud Nine, uważany za „całkowicie naturalny” odpowiednik MDMA (Ecstasy) zawiera w swym składzie efedrynę.
Zbadane zostało, czy może powodować ona efekty neurodegeneracyjne. W poszczególnych badaniach porównano poziom takich neurotransmiterów jak serotonina, dopamina, glutaminian – kwas glutaminowy czy epinefryna przy równoległej administracji efedryny oraz różnych amfetoaminopodobnych substancji. W badanym obszarze efedryna nie wykazała działania neurotoksycznego. Stwierdzono, że efedryna zwiększa poziom uwalniania dopaminy w minimalnym stopniu w porównaniu z identyczną dawką dekstroamfetaminy. Słabsze działanie efedryny na układ nerwowy wynika prawdopodobnie z utrudnionego przenikania bariery krew-mózg.

</doc>
<doc id="1451" url="https://pl.wikipedia.org/wiki?curid=1451" title="Elf">
Elf



</doc>
<doc id="1452" url="https://pl.wikipedia.org/wiki?curid=1452" title="Skrajnie niska częstotliwość">
Skrajnie niska częstotliwość

Skrajnie niska częstotliwość, skrajnie mała częstotliwość, ELF (od ang. "extremely low frequency") – zakres fal radiowych o częstotliwości 3–30 Hz (i długości fali od 10 000 do 100 000 kilometrów), wykorzystywany przez Marynarkę Wojenną Stanów Zjednoczonych oraz
Marynarkę Wojenną Rosji do łączności z zanurzonymi okrętami podwodnymi.
Ze względu na duże przewodnictwo elektryczne wody morskiej przekazywanie okrętom podwodnym informacji za pomocą fal elektromagnetycznych jest utrudnione. Najgłębiej docierającymi sygnałami są właśnie fale radiowe o niskiej częstotliwości. Niewielka szerokość pasma dostępna przy użyciu ELF uniemożliwia podział na kanały transmisyjne i wykorzystanie przekazu do przesyłania złożonych informacji. Zazwyczaj ELF stosuje się do zasygnalizowania zanurzonemu okrętowi konieczności przejścia na głębokość peryskopową lub wynurzenia w celu nawiązania transmisji na wyższych częstotliwościach.
Jednym z problemów związanych z nadawaniem na zakresie częstotliwości ELF jest rozmiar anteny. W początkowym etapie prac nad systemem łączności z użyciem częstotliwości 30 Hz wyliczenia wskazywały, że konieczne będzie użycie macierzy antenowej o łącznej długości przewodów wynoszącej 96 tys. kilometrów. Stany Zjednoczone utrzymywały 2 ośrodki nadawcze, Chequamegon National Forest w stanie Wisconsin (antena o długości 45 km) oraz the Escanaba State Forest w Michigan (antena o długości 90 km). W obu stacjach jako anteny nadawczej używano linii przesyłowych wysokiego napięcia. Z uwagi na niską sprawność anten w tym pasmie nadajniki muszą dostarczać duże ilości energii. W roku 1984 do nawiązania łączności zastosowano antenę ciągniętą przez łódź przy korzystaniu z mocy nadawczej równej 2,2 MW. Oba ośrodki zlikwidowano we wrześniu 2004 roku.
Możliwy wpływ ELF na środowisko naturalne wzbudzał obawy – w 1984 roku zawieszono pracę nad budową systemu nadawczego, aby zbadać ekologiczne aspekty technologii. Na badania przeznaczono 25 milionów dolarów, aby ostatecznie stwierdzić, że efekty działania anten ELF są bardzo podobne do efektów tworzonych przez zwykłe linie wysokiego napięcia.
Nadajniki pracujące na częstotliwości 20 Hz są również spotykane w urządzeniach stosowanych do kontroli rurociągów.
Radioamatorzy nagrywają sygnały ELF odbierane przy wykorzystaniu własnoręcznie wykonanych anten, aby odtworzyć je w przyspieszeniu. Pozwala to „usłyszeć” naturalne fluktuacje pola magnetycznego Ziemi.
Linki zewnętrzne.
Nadajniki ELF w serwisie Google Maps:

</doc>
<doc id="1453" url="https://pl.wikipedia.org/wiki?curid=1453" title="Emil Abderhalden">
Emil Abderhalden

Emil Abderhalden (ur. 9 marca 1877 w Oberuzwil, zm. 5 sierpnia 1950 w Zurychu) – szwajcarski biochemik i fizjolog, przewodniczący Niemieckiej Akademii Przyrodników Leopoldina; twórca teorii o enzymach obronnych, zarzuconej w latach 30. Nie wyjaśniono, czy błędne wyniki Abderhaldena wynikały z braku naukowego rygoru, czy były przykładem naukowego oszustwa.
Życiorys.
Syn nauczyciela Nikolausa Abderhaldena (1842–1923) i jego żony Anny Barbary z domu Stamm. Studiował medycynę na Uniwersytecie w Bazylei. Od 1902 roku współpracował z Emilem Fischerem. W latach 1911-1945 wykładał chemię fizjologiczną w Uniwersytecie w Halle.
Dorobek naukowy.
Prowadził badania nad przemianą materii, biochemią aminokwasów, hormonów i enzymów. Uważany za twórcę nowoczesnej nauki o żywieniu (dietetyki). Swoimi badaniami naukowymi wspierał także walkę z alkoholizmem, w 1904 sporządził obszerną bibliografię naukową tego zagadnienia.
Abderhalden łączył działalność naukową z działalnością na rzecz podniesienia poziomu moralności. Służyły temu założone przez niego czasopisma „Fortschritte der naturwissenschaftlichen Forschung” i „Etik”. Pierwsze z nich założył w 1918 – publikował w nich artykuły zwalczające alkoholizm, w których opierał się na swoich badaniach chemicznych i biologicznych. Drugie z nich założył w 1922, a od 1938 także redagował – zamieszczał w nich artykuły dotyczące etyki seksualnej. W 1947 stanął na czele szwajcarskiego związku pomocy duchowej dla Niemiec – owocem jego pracy społecznej w tym okresie jest gromadzące refleksje o wspólnocie ludzkiej i trwałym pokoju dzieło "Gedanken eines Biologen zur Schaffung einer Völkergemeinschaft und eines dauerhaften Friedens" (Zurych 1947).
Był członkiem Rosyjskiej Akademii Nauk. 

</doc>
