<doc id="12844" url="https://pl.wikipedia.org/wiki?curid=12844" title="Adam Małysz">
Adam Małysz

Adam Henryk Małysz (ur. 3 grudnia 1977 w Wiśle) – polski skoczek narciarski i kierowca rajdowy, uprawiający także kombinację norweską. W latach 2016–2022 dyrektor koordynator ds. skoków narciarskich i kombinacji norweskiej w Polskim Związku Narciarskim. Od 2022 prezes Polskiego Związku Narciarskiego.
Czterokrotny olimpijczyk. Zdobywca czterech medali olimpijskich (srebrnego i brązowego w 2002 i dwóch srebrnych w 2010) i sześciu medali mistrzostw świata (złotego i srebrnego w 2001, dwóch złotych w 2003, złotego w 2007 i brązowego w 2011). Czterokrotny zdobywca Pucharu Świata (w sezonach 2000/2001, 2001/2002, 2002/2003 i 2006/2007), trzykrotny zwycięzca Letniego Grand Prix (2001, 2004 i 2006) oraz dwukrotny zdobywca Pucharu KOP (w sezonach 2002/2003 i 2006/2007). Triumfator 49. Turnieju Czterech Skoczni (2000/2001), trzech edycji Turnieju Nordyckiego (2001, 2003 i 2007) oraz Turnieju Czterech Narodów 2010. Zdobywca 39 indywidualnych złotych medali mistrzostw Polski (21 zimą i 18 latem). W trakcie kariery wyrównał rekord świata w długości skoku narciarskiego (225 m w 2003) i osiem razy poprawiał rekord Polski (po raz ostatni w 2011, gdy uzyskał 230,5 m).
W latach 1995–2011 wystąpił w 349 konkursach Pucharu Świata. Odniósł 39 zwycięstw, 92 razy stał na podium, 198 razy zajmował miejsce w pierwszej dziesiątce zawodów, a 307 razy zdobywał punkty PŚ. Łącznie zgromadził 13070 punktów PŚ. Jako zawodnika cechowało go mocne odbicie z progu i bardzo niska pozycja w locie. W trakcie kariery skakał na nartach marki Elan (1994–1996 oraz 1999–2004), Rossignol (1996–1998) i Fischer (2004–2011).
Po sezonie 2010/2011 zakończył karierę skoczka narciarskiego i rozpoczął starty w rajdach samochodowych. W 2012 zdobył tytuł międzynarodowego rajdowego mistrza Polski i Czech, a w 2013 odniósł pierwsze w karierze zwycięstwo w rajdach terenowych. W latach 2012–2016 pięciokrotnie uczestniczył w Rajdzie Dakar.
Za wybitne osiągnięcia sportowe został trzykrotnie odznaczony Orderem Odrodzenia Polski przez Prezydenta RP. Czterokrotnie wybierany najlepszym sportowcem Polski w plebiscycie „Przeglądu Sportowego” (w 2001, 2002, 2003 i 2007). W 2019 wybrany najlepszym polskim narciarzem w plebiscycie „Gwiazdy 100-lecia PZN”. Przez wielu uważany za najlepszego polskiego sportowca pierwszej dekady XXI wieku. Honorowy obywatel miasta Zakopanego i patron skoczni narciarskiej w Wiśle.
Życie prywatne.
Urodził się 3 grudnia 1977 w Wiśle jako syn Jana i Ewy z domu Szturc (pobrali się w 1974); ma starszą siostrę Iwonę (ur. 1975). Jest wujem Tomasza Pilcha, również skoczka narciarskiego.
Pierwszy skok oddał w 1983, kiedy to miał sześć lat. W 1992 ukończył Szkołę Podstawową nr 4 w Wiśle Głębcach. Trzy lata później w Zasadniczej Szkole Zawodowej w Ustroniu zdobył zawód (specjalizacja: blacharz-dekarz). W 2010 zdał maturę i uzyskał wykształcenie średnie. W 2018 obronił pracę licencjacką, a w 2020 magisterską na Wydziale Zarządzania Politechniki Częstochowskiej. Zna język niemiecki.
16 czerwca 1997 ożenił się z Izabelą Polok (ur. 4 grudnia 1978). Ślub odbył się w ewangelickim kościele im. apostołów Piotra i Pawła w Wiśle (Adam jest luteraninem, Izabela – katoliczką). 31 października tego samego roku urodziła się ich córka, Karolina.
Przebieg kariery.
Początki.
Narciarskie tradycje były w rodzinie Małysza od dawna. Jego pradziadek miał własną skocznię, na której beskidzcy zawodnicy osiągali odległości w granicach pięćdziesięciu metrów. Ojciec pracował jako kierowca w Klubie Sportowym Wisła, zaś wuj – Jan Szturc, najpierw był skoczkiem, kombinatorem i piłkarzem, a po zakończeniu kariery – trenerem klubowym. Właśnie za namową ojca i wuja, w wieku sześciu lat rozpoczął treningi narciarskie. Pierwszy skok oddał mając 6 lat na obiekcie K17 w Wiśle-Centrum, a po lądowaniu na 7 metrze doszło do upadku, ponieważ buty Małysza miały zbyt duży rozmiar.
Skoki narciarskie.
18 stycznia 1991 wystąpił w mistrzostwach TOZN na Maleńkiej Krokwi w Zakopanem. 28 lutego 1993, na skoczni K40 w Wiśle, został wicemistrzem Polski juniorów młodszych i młodzików w skokach (dwa dni wcześniej był 4. na obiekcie K60). 12 marca 1993, na skoczni Skalite w Szczyrku, wziął udział w aż dwóch konkursach mistrzostw Polski (MP). Najpierw wywalczył brązowy medal MP Juniorów, a następnie – w barwach KS „Wisła” Wisła – zajął 6. miejsce w konkursie drużynowym 68. seniorskich mistrzostw kraju na skoczni normalnej K85. Dwa dni później zadebiutował w konkursie indywidualnym MP seniorów (na normalnej skoczni K85), plasując się na 14. pozycji. 29 grudnia 1993 zadebiutował na arenie międzynarodowej w zmaganiach seniorskich, zajmując 48. lokatę konkursu Pucharu Kontynentalnego na "Klaushoferschanze" (K73) w Sankt Aegyd (sezon 1993/1994). 26 (bądź 30) stycznia 1994 zajął 46. lokatę w indywidualnym konkursie skoków podczas Mistrzostw Świata Juniorów 1994 na Raimund-Ertl-Schanze w Breitenwangu, a 27 stycznia 1994 wywalczył z polską reprezentacją 10. pozycję w konkursie drużynowym. 4 lutego 1994 na Średniej Krokwi, wraz z kolegami z KS Wisła, sięgnął po brąz w konkursie drużynowym 69. Mistrzostw Polski na skoczni normalnej. Dzień później – jeszcze jako junior – został wicemistrzem Polski seniorów na Wielkiej Krokwi, a 6 lutego 1994 – seniorskim mistrzem kraju na Średniej Krokwi.
Kombinacja norweska.
W 1992 wziął udział w drużynowych mistrzostwach Polski młodzików w kombinacji norweskiej, a 1 stycznia 1993 – razem z Łukaszem Kruczkiem – w noworocznych zawodach w Oberstdorfie, zajmując dalekie miejsce. W dniach 2–3 stycznia 1994 wziął udział w drużynowych zawodach dwubojowych w Oberwiesenthal. Zdobył także indywidualne, parowe i drużynowe mistrzostwo Polski juniorów młodszych w kombinacji na zawodach odbywających się w dniach 25–27 marca 1994.
Kariera w skokach narciarskich.
1994/1995.
Jesienią 1994 – pod wpływem sugestii trenera Szturca – zdecydował się zarzucić kombinację norweską i poświęcić się tylko skokom narciarskim. W tym samym roku trafił do kadry narodowej polskich skoczków, prowadzonej wówczas przez Czecha Pavla Mikeskę. 9 grudnia na Srednjej velikance w Planicy zadebiutował w Pucharze Świata, zajmując w kwalifikacjach do konkursu głównego 55. miejsce i nie awansując do niego.
Pierwszy występ Adama Małysza w zawodach Pucharu Świata miał miejsce 4 stycznia 1995 na Bergisel w Innsbrucku. Podczas tego konkursu zajął 17. miejsce, co dało mu pierwsze w karierze punkty do klasyfikacji tego cyklu. Nie startował w pozostałych konkursach Turnieju Czterech Skoczni i w jego końcowej klasyfikacji zajął 55. miejsce. W tym samym sezonie jeszcze cztery razy zajął miejsce w czołowej trzydziestce konkursu PŚ. 14 stycznia w Engelbergu zajął 27. lokatę, dzięki czemu zdobył cztery punkty do klasyfikacji. Podczas konkursu na Lugnet w Falun (4 lutego) został sklasyfikowany na 23. miejscu. Dzień później na tej samej skoczni był 28. W sezonie 1994/1995 po raz ostatni punktował 12 lutego na Holmenkollbakken w Oslo, gdzie był 20. W łącznej klasyfikacji Adam Małysz uplasował się na 51. miejscu z dorobkiem 40 punktów.
1 marca 1995 wystąpił na mistrzostwach świata juniorów w Gällivare, gdzie zajął 10. miejsce. Później wystartował także w seniorskim czempionacie w kanadyjskim Thunder Bay, gdzie był 10. i 11.
1995/1996.
Podczas debiutu w Letniej Grand Prix Adam Małysz zajął 66. miejsce. Wziął udział w tylko jednym konkursie, w którym został sklasyfikowany na 42. pozycji, nie kwalifikując się do finałowej serii.
Sezon zimowy 1995/1996 Adam Małysz rozpoczął od 12. miejsca w Lillehammer. Sześć dni później w Villach był 22. 16 grudnia na skoczni w Chamonix zajął 21. lokatę. 28 grudnia w Oberhofie uplasował się na 11. miejscu.
W TCS wziął udział w trzech spośród czterech konkursów. 30 grudnia na Schattenbergschanze w Oberstdorfie zajął 18. miejsce, 1 stycznia na Große Olympiaschanze w Garmisch-Partenkirchen był 16. a 4 stycznia w Innsbrucku zajął jedenastą lokatę. Cały Turniej zakończył na 28. miejscu.
13 stycznia w Engelbergu Małysz pierwszy raz w karierze zajął miejsce w czołowej dziesiątce zawodów Pucharu Świata. Był wówczas dziewiąty. Dzień później na tej samej skoczni zajął ósmą lokatę; podobnie 20 stycznia na normalnej skoczni w Sapporo. 21 stycznia na skoczni Ōkurayama w tym mieście był 23. Podczas konkursów na zakopiańskiej Wielkiej Krokwi był dziewiąty i szósty (ex aequo z Espenem Bredesenem). 10 lutego na skoczni Kulm w Tauplitz Małysz zajął ósme miejsce, pierwszy raz w karierze punktując na skoczni mamuciej. Dzień później na tej samej skoczni był osiemnasty. Po połączeniu punktacji obu konkursów zaliczanych do mistrzostw świata w lotach Polak znalazł się na 14. pozycji. 17 lutego podczas konkursu PŚ na skoczni w Iron Mountain zajął dziewiątą lokatę.
Dzień później na tym obiekcie pierwszy raz w karierze stanął na podium zawodów Pucharu Świata. Zajął drugą lokatę, przegrywając jedynie z Masahiko Haradą, który wyprzedził Małysza o 37,2 pkt. Było to pierwsze pucharowe podium reprezentanta Polski od 1987 roku. 28 lutego na normalnej skoczni w Kuopio zajął 13. lokatę. W Lahti natomiast po raz drugi w karierze stanął na podium zawodów Pucharu Świata. Tym razem był trzeci, przegrywając tylko z Haradą i Miką Antero Laitinenem. Dwa dni później na mniejszej skoczni był czwarty. Nie pojechał na konkursy lotów do Harrachova, lecz wybrał się do Falun, gdzie na Lugnet wygrał konkurs Pucharu Kontynentalnego. Tydzień później na tej skoczni zajął drugą lokatę w PŚ, tuż za Primožem Peterką.
17 marca 1996 w Oslo, w ostatnim konkursie Pucharu Świata w tamtym sezonie, Adam Małysz zwyciężył pierwszy raz w swojej karierze. Tego samego dnia karierę zakończył Niemiec Jens Weißflog, wieloletni idol Małysza. W związku z tym, przez wielu komentatorów i kibiców konkurs ten nazywany był „zmianą warty”. Było to pierwsze pucharowe zwycięstwo reprezentanta Polski od 1986 roku. W końcowej klasyfikacji PŚ w tym sezonie Małysz zajął siódme miejsce.
1996/1997.
W Letniej Grand Prix Adam Małysz został sklasyfikowany na szóstym miejscu. Nie skakał w pierwszym z konkursów, 18 sierpnia w Trondheim. Trzy dni później na Hans-Renner-Schanze w Oberhofie stanął na najniższym stopniu podium, tuż za Miką Laitinenem i Ari-Pekka Nikkolą. 25 sierpnia na Adlerschanze w Hinterzarten Małysz ponownie był trzeci, ponownie za Nikkolą i Laitinenem. 28 sierpnia na skoczni w Predazzo uplasował się na 18. lokacie. 1 września podczas ostatniego konkursu LGP w Stams Małysz zajął ostatnie, 49. miejsce po skoku na 62 metry. Jesienią skakał także w PK w Hakubie (był tam na 4. i 2. miejscu).
W sezonie zimowym 1996/1997 Małysz pierwszy raz punktował 30 listopada na skoczni w Lillehammer. Zajął tam 28. miejsce. Podczas konkursu na Rukatunturi w Ruce 7 grudnia był 19. Dzień później na tej samej skoczni uplasował się na trzynastym miejscu. 15 grudnia w Harrachovie zajął czwarte miejsce, tuż za Primožem Peterką, Andreasem Goldbergerem i Kristianem Brendenem.
Podczas Turnieju Czterech Skoczni 1996/1997 Adam Małysz startował we wszystkich czterech konkursach. Podczas inauguracyjnego konkursu w Oberstdorfie zajął 22. miejsce. W noworocznym konkursie w Ga-Pa był 12. 4 stycznia na Bergisel pierwszy raz zajął miejsce w czołowej dziesiątce konkursu Turnieju Czterech Skoczni – był szósty. Dwa dni później na Paul-Ausserleitner-Schanze w Bischofshofen pierwszy raz stanął na podium w konkursie TCS, przegrywając jedynie z Dieterem Thomą. Cały Turniej zakończył na ósmej pozycji.
11 stycznia w Engelbergu skoczek z Wisły stanął na najniższym stopniu podium. Dzień później na tej samej skoczni był 17. 18 stycznia na normalnej skoczni w Sapporo drugi raz w karierze zwyciężył w zawodach Pucharu Świata. Dzień później na dużej skoczni w tym mieście był 24. 26 stycznia w Hakubie ponownie odniósł zwycięstwo. Podczas następnych dwóch konkursów na Kulm w Tauplitz (8 i 9 lutego) był 47. i 26.
Na mistrzostwach świata w Trondheim zajął 14. miejsce na normalnej i 36. na dużej skoczni. Był też 10. w konkursie drużynowym.
Po powrocie do zawodów PŚ w konkursie na skoczni w Lahti zajął szesnastą lokatę. Na Puijo w Kuopio był czternasty, a na skoczni Lugnet w Falun zajął piątą pozycję, przegrywając tylko z Primožem Peterką, Dieterem Thomą, Hiroya Saitō i Håvardem Lie. Trzy dni później na Holmenkollbakken w Oslo Małysz był dziewiętnasty. Turniej Skandynawski ukończył na piątym miejscu.
W konkursach w Planicy Małysz już nie wystąpił. W końcowej klasyfikacji Pucharu Świata zgromadził łącznie 612 punktów, co dało mu dziesiąte miejsce.
1997/1998.
W 1997 roku Adam Małysz zajął 21. miejsce w Letniej Grand Prix w skokach narciarskich na igelicie. Wyprzedził wówczas o jedno miejsce Wojciecha Skupnia. Podczas pierwszego z konkursów, 14 sierpnia na skoczni w Courchevel Małysz był 23. Trzy dni później na skoczni w Trondheim nie wystartował. 24 sierpnia podczas konkursu w Hinterzarten zajął najwyższe w cyklu GP miejsce ósme. 27 sierpnia w Predazzo został sklasyfikowany na 23. pozycji. Podczas konkursu na skoczni Stams (31 sierpnia) zajął 18. lokatę. Łącznie Małysz zdobył 61 punktów, 7 punktów mniej od wyprzedzającego go bezpośrednio Kenta Johanssena. Stanął także na podium po konkursie PK w Velenje, w którym znalazł się na drugim miejscu.
Sezon 1997/1998 to najgorszy okres w karierze Adama Małysza. Tylko kilka razy zdobywał on punkty Pucharu Świata. Sezon Pucharu Świata zaczął od startów w Lillehammer, gdzie zajął w obu konkursach odległe miejsca (odpowiednio 44. i 42.). Pierwsze punkty w Pucharze Świata zdobył 6 grudnia na skoczni w Predazzo, gdzie był 21. Dwa dni później w Villach zajął 31. miejsce, nie zdobywając ani jednego punktu do klasyfikacji. 12 grudnia w Harrachovie zdobył dziesięć punktów do Pucharu Świata, zajmując 21. miejsce w konkursie. Podczas konkursów na skoczni w Engelbergu (20 i 21 grudnia) dwa razy uplasował się na 28. miejscu.
W Turnieju Czterech Skoczni Małysz tylko raz zakwalifikował się do finałowej serii zawodów. W pierwszym konkursie, w Oberstdorfie zajął 41. miejsce. 1 stycznia w konkursie na Große Olympiaschanze zajął najwyższe w całym Turnieju, 24. miejsce. Trzy dni później w Innsbrucku był 46. wyprzedzając tylko Roara Ljøkelsøya, Takanobu Okabe, Jussiego Hautamäkiego i Simona Ammanna. W Bischofshofen, w ostatnim z konkursów, zajął 33. miejsce. W całym Turnieju ostatecznie uplasował się na 30. miejscu.
Potem jeszcze tylko dwa razy zdobywał pucharowe punkty. 17 stycznia na Wielkiej Krokwi w Zakopanem był 23., a dzień później na tej samej skoczni 29. Porażką zakończył się występ na Igrzyskach Olimpijskich w Hakubie/Nagano – 51. miejsce na skoczni K-90 oraz 52. na K-120. W konkursie drużynowym zajął 8. miejsce.
Po igrzyskach olimpijskich wystartował jeszcze w dwóch konkursach lotów w Vikersund. W pierwszym konkursie porannym 1 marca ograniczonym do jednej serii zajął 48. miejsce, w drugim konkursie tego samego dnia zajął 55. miejsce – najgorsze w historii występów Adama Małysza w Pucharze Świata. Ostatecznie sezon Adam Małysz zakończył na 57. miejscu, zdobywając razem 43 punkty.
Po sezonie skoczek miał zamiar zakończyć karierę.
1998/1999.
W trakcie sezonu 1998/1999 Adam Małysz wciąż poważnie myślał o zakończeniu kariery sportowej i podjęciu pracy w wyuczonym zawodzie dekarza.
W pierwszej części sezonu 1998/1999 Adam Małysz nie wystąpił ani razu. Pierwszy start w sezonie miał miejsce dopiero podczas Turnieju Czterech Skoczni. W nim Małysz ani razu nie awansował do drugiej serii. 30 grudnia w Oberstdorfie był najbliżej awansu, na 34. miejscu. Poza tym, w konkursach w Innsbrucku (3 stycznia) i Bischofshofen (6 stycznia) zajął 40. pozycję. Do konkursu na skoczni w Garmisch-Partenkirchen (1 stycznia 1999) nie zakwalifikował się. Turniej zakończył ostatecznie na 43. pozycji.
16 stycznia na Wielkiej Krokwi w Zakopanem uplasował się na 27. miejscu. Dzień później na tej samej skoczni był 23. Na Ōkurayamie w Sapporo był 19. i 31. 29 stycznia w Willingen Małysz zdobył pięć punktów do klasyfikacji Pucharu Świata po zajęciu 26. miejsca w pierwszym z konkursów. W drugim był 40. i nie zdobył punktów do klasyfikacji. Na mistrzostwach świata w Ramsau był 37. na skoczni dużej i 27. na normalnej.
6 marca na normalnej skoczni w Lahti zajął najwyższe w sezonie, 17. miejsce. Trzy dni później w Trondheim zajął miejsce poza czołową trzydziestką, trzydzieste ósme. 11 marca na Lugnet w Falun uplasował się na 24. pozycji. 14 marca na skoczni Holmenkollbakken w Oslo zajął 27. lokatę. W klasyfikacji końcowej Turnieju Nordyckiego był szesnasty.
Podczas ostatniego weekendu sezonu w Planicy Adam Małysz zajmował kolejno: 35., 28. i 30. pozycję. Sezon zakończył na 46. miejscu zdobywając 58 punktów.
1999/2000.
W 1999 roku Małysz w generalnej klasyfikacji LGP zajął 54. miejsce. Jedynie 11 września w Hakubie zakwalifikował się do drugiej serii konkursu, gdzie zajął 29. miejsce. W Hinterzarten i Sapporo uplasował się kolejno na 46. i 43. miejscu. W konkursach w Courchevel i Stams nie skakał. Stanął za to na drugim stopniu podium na Średniej Krokwi podczas konkursu Pucharu Kontynentalnego, przegrywając jedynie z Dirkiem Elsem.
Sezon 1999/2000 był przełomem w karierze Adama Małysza. Nowe metody szkoleniowe oraz współpraca z psychologiem Janem Blecharzem i fizjologiem Jerzym Żołądziem przyniosły na tyle dobre efekty, że zaczął uzyskiwać punktowane miejsca w zawodach. Był 19 razy w czołowej trzydziestce zawodów Pucharu Świata i zajął 28. miejsce w generalnej klasyfikacji.
Podczas inauguracji sezonu 99/00 Pucharu Świata, 28 listopada w Kuopio Adam Małysz zajął 38. miejsce i nie zdobył punktów do klasyfikacji. 4 grudnia w Predazzo zakwalifikował się do drugiej serii zawodów, zajmując 26. pozycję. Dzień później na tej samej skoczni był 23. 12 grudnia na średniej skoczni w Villach był 28. 18 grudnia na Wielkiej Krokwi w Zakopanem zajął trzynastą lokatę. Na drugi dzień był 38.
W Turnieju Czterech Skoczni zajął 31. miejsce. Nie startował w pierwszym z konkursów, w Oberstdorfie, gdyż nie przeszedł kwalifikacji. 1 stycznia 2000 na skoczni w Garmisch-Partenkirchen był 17. Dwa dni później w Innsbrucku zajął 26. pozycję, a 6 stycznia w Bischofshofen – 46.
Po zakończeniu turnieju Małysz nie zdobywał punktów Pucharu Świata aż do 26 stycznia, kiedy to zajął 25. lokatę na skoczni w Hakubie. Podczas weekendu na skoczni w Willingen (5–6 lutego) Adam Małysz był kolejno 24. i 25. Najwyższe w sezonie miejsce zajął 26 lutego na skoczni w Iron Mountain, gdzie był czwarty, przegrywając jedynie z Martinem Schmittem, Tommym Ingebrigtsenem i Stefanem Horngacherem. Dzień później na tej samej skoczni był 22.
Podobnie 4 marca na dużej skoczni w Lahti. Następnego dnia na tej samej skoczni uplasował się na 27. miejscu. 10 marca w konkursie na skoczni w Trondheim został sklasyfikowany na 21. pozycji. Dwa dni później na skoczni Holmenkollbakken w Oslo uplasował się na dwunastym miejscu. Turniej Nordycki ukończył na 20. miejscu.
Podczas ostatniego w sezonie konkursu, 19 marca na Velikance w Planicy zajął siódme miejsce. Przegrał wówczas ze Svenem Hannawaldem, Janne Ahonenem, Andreasem Goldbergerem, Tommym Ingebrigtsenem, Noriakim Kasaim i Kazuyoshim Funakim. Pobił wtedy swój rekord życiowy; od tamtej pory wynosił on 191,5 metra. Adam Małysz ostatecznie został sklasyfikowany w PŚ na 28. miejscu, zdobywając razem 214 punktów. W MŚ w lotach w Vikersund znalazł się na 16. miejscu.
2000/2001.
W Letniej Grand Prix 2000 „Orzeł z Wisły” zajął 19. miejsce w klasyfikacji generalnej, uzyskując 93 punkty. W pięciu konkursach znalazł się w finale. 12 sierpnia w Villach uplasował się na czwartej pozycji. W Hakubie (K-120) skoczył 101,5 i 94,5 metra, zajmując 24. miejsce. Pięć dni później na tej samej skoczni poszybował na odległość 114 metrów i zajął 20. lokatę. W Sapporo był dwunasty, skacząc 113,5 i 117,5 metra.
Wygrał ponadto konkurs PK w Oberstdorfie.
Sezon 2000/2001 rozpoczął się 23 listopada kwalifikacjami do konkursu na skoczni Puijo w Kuopio. Wygrał je Małysz, lecz został zdyskwalifikowany za zbyt długie narty, przez co w inauguracyjnym konkursie sezonu nie wystąpił. Wynik ten był jednak zapowiedzią sukcesów, jakie już wkrótce miały czekać Polaka. Zanim jednak do nich doszło, odbyły się dwa kolejne konkursy w Kuopio, oba w bardzo niestabilnych warunkach atmosferycznych. W pierwszym z nich, jednoseryjnym, w dniu 2 grudnia Małysz zajął najniższe w sezonie, 26. miejsce. Podczas drugiego z konkursów na tej skoczni, 3 grudnia był jedenasty, notując znaczny awans po drugim skoku. Później z powodu zbyt wysokich jak na grudzień temperatur i braku śniegu, odwołano pięć konkursów Pucharu Świata i skoczkowie do rywalizacji powrócili dopiero na Turniej Czterech Skoczni.
Adam Małysz wygrał Turniej Czterech Skoczni jako pierwszy reprezentant Polski w historii. 29 grudnia 2000 roku na skoczni w Oberstdorfie zajął czwarte miejsce. W noworocznym konkursie w Garmisch był trzeci, przegrywając tylko z Kasaim i Dmitrijem Wasiljewem. W konkursie tym ustanowił też rekord skoczni Große Olympiaschanze (129,5 metra), który nie został pobity aż do jej zburzenia i zbudowania nowej w 2007. Pozostałe dwa konkursy (4 stycznia w Innsbrucku i 6 stycznia w Bischofshofen) Małysz wygrał, w obu uzyskując kilkadziesiąt punktów przewagi nad drugim zawodnikiem. W Innsbrucku wyprzedził Janne Ahonena o 44,9 punktów, a w Bischofshofen wyprzedził go o 31,9 punktów. Zwyciężył w całym turnieju z przewagą ponad 100 punktów nad drugim zawodnikiem, czyniąc to jako pierwszy i dotąd jedyny skoczek w historii. Zebrał także jako pierwszy skoczek w historii ponad 1000 pkt. w czterech konkursach. Adam Małysz podczas TCS 2000/2001 wygrał też kwalifikacje do każdego z czterech konkursów, dzięki czemu w każdym z nich startował z numerem 1.
W tydzień po zakończeniu turnieju skoczkowie pojechali do czeskiego Harrachova, gdzie w dniach 13–14 stycznia odbyły się dwa konkursy na skoczni mamuciej. W obydwu Polak zwyciężył. Tamtego weekendu kilkakrotnie bił rekordy Polski w długości skoku narciarskiego. Ostatecznie, po zakończeniu zawodów rekord ten wynosił 212 metrów. 20 stycznia w Park City ponownie odniósł zwycięstwo i został liderem klasyfikacji PŚ. 24 stycznia w Hakubie stracił koszulkę lidera na rzecz Martina Schmitta. W zawodach zajął wówczas ósme miejsce po upadku na zeskoku. Zdaniem Małysza, powodem upadku było sztuczne oświetlenie, przy którym Małysz nie czuł się komfortowo. Żółtą koszulkę odzyskał już podczas następnych zawodów Pucharu Świata – 27 stycznia w Sapporo, gdzie odniósł triumf po raz szósty w sezonie. Dzień później na tej samej skoczni odniósł siódme zwycięstwo. 3 lutego w konkursie na skoczni w Willingen Małysz po pierwszej serii zajmował ósme miejsce. W drugiej turze skoczył jednak 151,5 metra (na skoczni K120) i dzięki temu awansował na drugą pozycję, przegrywając jedynie z Ville Kantee. Wynik uzyskany w drugiej kolejce przez Adama Małysza (151,5 m) był wówczas nieoficjalnym rekordem świata na dużej skoczni (został poprawiony o pół metra cztery lata później przez Janne Ahonena). Następnego dnia na tej samej skoczni po raz kolejny w sezonie triumfował, osiągając 36,5 punktów przewagi nad drugim skoczkiem w zawodach, Risto Jussilainenem oraz otrzymując za dwa 142,5-metrowe skoki notę 316 pkt., najwyższą jaką do tamtej chwili przyznano na skoczniach mniejszych niż mamucie.
W lutym podczas mistrzostw świata w Lahti Adam Małysz zdobył srebrny medal na dużej skoczni i złoty na normalnej – zamieniając się miejscami z Martinem Schmittem. Były to pierwsze medale mistrzostw świata w narciarstwie klasycznym reprezentantów Polski od 1978 r., kiedy Józef Łuszczek zdobył złoto w biegu na 15 km i brąz na 30 km. Później po powrocie z Finlandii Małysz z powodu choroby nie wystartował w mistrzostwach Polski.
3 marca podczas konkursu lotów na skoczni w Oberstdorfie Małysz zajął czwarte miejsce. Oddał jednak najdłuższy skok drugiej serii, na 197,5 metra. Z trzecim skoczkiem zawodów, Mattim Hautamäkim przegrał o 0,1 punktu. Dzień później na tej samej skoczni zajął drugą lokatę, przegrywając tylko z Martinem Schmittem o 0,4 punktu. Adam Małysz dwukrotnie skoczył na odległość 201,5 metra, a Schmitt osiągnął 200 i 202,5 metra.
W roku 2001 Adam Małysz jako pierwszy skoczek w historii wygrał wszystkie konkursy Turnieju Nordyckiego. 7 marca na skoczni Lugnet w Falun zdobył 259,8 pkt i wyprzedził drugiego Martina Schmitta o 4,6 pkt. Dwa dni później na skoczni w Trondheim wygrał z notą 254,6 pkt, o 1,1 pkt wyprzedzając Andreasa Goldbergera i bijąc rekord obiektu (138,5 m). Podczas ostatniego z konkursów, 11 marca na skoczni Holmenkollbakken w Oslo zwyciężył z przewagą 13,6 pkt nad Stefanem Horngacherem.
W ostatnich zawodach sezonu, 18 marca w Planicy był czwarty, i mimo zwycięstwa Martina Schmitta, triumfował w ogólnej klasyfikacji PŚ. Podczas konkursu w Słowenii pobił własny rekord Polski, skacząc 218,5 metra.
W całym sezonie 2000/2001 odniósł jedenaście zwycięstw w zawodach Pucharu Świata, wyrównując tym samym rekord Martina Schmitta z sezonu 1998/1999. Jest pierwszym skoczkiem, który wygrał więcej niż połowę konkursów rozgrywanych w danym sezonie (11 z 21, a z mistrzostwami świata 12 z 23; kolejnym skoczkiem, który tego dokonał był Peter Prevc – bijąc rekord 15 zwycięstw w sezonie 2015/2016 dokonał tego w 29 konkursach). Jako pierwszy Polak w historii zdobył Puchar Świata w skokach narciarskich, a zarazem w ogóle pierwszy w dyscyplinie zimowej pod egidą FIS. Sukces ten powtórzył w sezonach 2001/2002, 2002/2003 i 2006/07. Jest pierwszym i jedynym do tej pory skoczkiem w historii, który wygrał kryształową kulę Pucharu Świata trzy razy z rzędu, a drugim (po Mattim Nykänenie), który zdobył ją w sumie czterokrotnie.
2001/2002.
W 2001 roku Małysz po raz pierwszy w karierze wygrał w Letniej Grand Prix. Już w pierwszym konkursie w Hinterzarten Polak odniósł zwycięstwo wyprzedzając o 4,5 punktów Martina Schmitta. W drugim konkursie na skoczni Adlerschanze w Hinterzarten Małysz był dziewiąty. W kolejnym konkursie, rozegranym w Courchevel na skoczni Tremplin Le Praz, skoczek z Wisły stanął na drugim stopniu podium, przegrywając z Andreasem Widhölzlem o 1,1 punktu. 18 sierpnia w Stams Małysz uplasował się na dziewiątej pozycji. 5 września na skoczni w Sapporo był tuż za podium, na czwartym miejscu. 8 września w Hakubie był drugi, wygrał Stefan Horngacher. Dzień później, także w Hakubie, po raz trzeci zajął ósme miejsce, ale nie przeszkodziło mu to w zajęciu pierwszego miejsca w klasyfikacji generalnej.
W sezonie zimowym 2001/2002 Adam Małysz ani razu nie zajął miejsca poza czołową dziesiątką zawodów Pucharu Świata oraz przez cały sezon prowadził w klasyfikacji generalnej PŚ. Podczas inauguracyjnego konkursu w Kuopio (23 listopada) wygrał, a dzień później był drugi za Risto Jussilainenem. 1 grudnia podczas pierwszego w historii konkursu PŚ na skoczni w Titisee-Neustadt odniósł zwycięstwo. Dzień później był drugi, zaraz za Svenem Hannawaldem. 8 grudnia na normalnej skoczni w Villach zwyciężył po skokach na 99,5 i 98 metrów. Następnego dnia na tej samej skoczni w konkursie drużynowym wraz z Robertem Mateją, Łukaszem Kruczkiem i Wojciechem Skupniem zajął trzecie miejsce. Reprezentacja Polski stanęła wtedy po raz pierwszy w historii PŚ na podium i przegrała tylko z Finlandią i Japonią. 15 grudnia na skoczni w Engelbergu Małysz zajął czwarte miejsce. W owym konkursie został surowo potraktowany przez sędziów, którzy ocenili jego skok notami 16,5-17,5. Dzień później podczas zawodów na tej samej skoczni zwyciężył, a wygrany z poprzedniego dnia, Stephan Hocke został sklasyfikowany na 22. miejscu. W ostatnich dwóch konkursach przed świętami Bożego Narodzenia w Predazzo (21–22 grudnia) Adam Małysz dwukrotnie zwyciężył, za każdym razem oddając dwa najdłuższe skoki w konkursie.
Przed 50. Turniejem Czterech Skoczni polscy kibice skoków zastanawiali się czy Adam Małysz jako pierwszy w historii wygra wszystkie cztery konkursy Turnieju. Tak się nie stało, wiślak zakończył imprezę na czwartym miejscu, a wszystkie konkursy wygrał Sven Hannawald. 30 grudnia w Oberstdorfie Polak zajął piąte miejsce, 1 stycznia w Ga-Pa był trzeci, trzy dni później w Innsbrucku drugi, a 6 stycznia w Bischofshofen dziewiąty.
Pierwszy konkurs Pucharu Świata po zakończeniu turnieju miał miejsce 12 stycznia na skoczni w Willingen. Adam Małysz zajął w nim 4. miejsce. W pierwszym konkursie na Wielkiej Krokwi w Zakopanem 19 stycznia był siódmy. Nazajutrz na tej samej skoczni zwyciężył. Później Polak (podobnie jak cała czołówka PŚ poza Austriakami) nie wziął udziału w zawodach PŚ w Hakubie i Sapporo, szykując się do igrzysk olimpijskich w Salt Lake City.
Na amerykańskiej olimpiadzie Adam Małysz zdobył dwa medale na skoczniach w Park City. W pierwszym konkursie na normalnej skoczni wywalczył brązowy medal. Był to pierwszy medal zimowej olimpiady reprezentanta Polski od 1972, kiedy złoto w konkursie skoków zdobył Wojciech Fortuna. W zawodach na dużej skoczni Małysz zdobył wicemistrzostwo olimpijskie. Został tym samym pierwszym polskim zawodnikiem, który zdobył dwa medale podczas zimowych igrzysk olimpijskich. Małysz został również pierwszym w XXI wieku polskim sportowcem, który zdobył medal igrzysk olimpijskich.
Trener Apoloniusz Tajner stwierdził, że Małysz miał podczas konkursu na K-120 problemy techniczne przy wyjściu z progu. Mimo dużej siły odbicia, było ono opóźnione o ok. 20 cm. Zawodnik znalazł się w powietrzu wyżej niż konkurenci, jednak szybko zaczął tracić prędkość i „spadać”.
W Turnieju Nordyckim Polak zajął drugie miejsce ustępując jedynie Mattiemu Hautamäkiemu. W pierwszym konkursie rozegranym w Lahti zajął drugie miejsce, przegrywając z Martinem Schmittem (Niemiec w generalnej klasyfikacji zajął trzecie miejsce). Na skoczni w Falun Małysz był piąty, by w Trondheim znowu zająć drugie miejsce, tym razem za Hautamäkim. W ostatnim konkursie w Oslo uplasował się na najniższym stopniu podium. W klasyfikacji generalnej turnieju zgromadził 1033,2 punktów, przegrywając z pierwszym Finem o 14,8 punktów.
Mistrzostwa świata w lotach odbyły się w Harrachovie, na skoczni Čerťák K-185, skoczni na której rok wcześniej Małysz odniósł dwa zwycięstwa. Pierwsze dwie serie odbyły się 9 marca. Małysz po pierwszym skoku na odległość 184 m był piąty. Skok był jednak o osiemnaście metrów krótszy od prowadzącego Svena Hannawalda. Drugi skok Małysza był gorszy – 142 metry, który spowodował spadek na 18. miejsce, pozbawiając Polaka nadziei na medal. Pozostałe dwie serie z powodu zbyt silnego wiatru zostały odwołane. Mistrzem został Sven Hannawald, 18. miejsce Małysza było wówczas jego najgorszym startem na mistrzostwach świata w lotach (cztery lata później był dwudziesty).
23 marca w drużynowym konkursie na Velikance w Planicy wraz z innymi reprezentantami Polski zajął ostatnie, dziewiąte miejsce. Następnego dnia podczas kwalifikacji do indywidualnego konkursu PŚ, Adam Małysz pobił dotychczasowy rekord Polski, skacząc na 223,5 metra. Sam konkurs został odwołany z powodu niekorzystnych warunków atmosferycznych. W sezonie Małysz zgromadził łącznie 1475 punktów do klasyfikacji Pucharu Świata i wyprzedził drugiego Svena Hannawalda o 216 punktów.
2002/2003.
W klasyfikacji generalnej w Letniej Grand Prix 2002 Adam Małysz zajął 10. miejsce, mając na koncie 126 punktów, ze stratą 434 do zwycięzcy owych zawodów, Andreasa Widhölzla. Najlepszymi jego występami były skoki w Hinterzarten (K-95) i Courchevel (K-120), gdzie w obu konkursach uplasował się na czwartej pozycji.
W pierwszym konkursie PŚ w sezonie 2002/2003 na skoczni w Ruce 29 listopada Adam Małysz zajął drugie miejsce za Primožem Peterką. Tym samym stracił żółtą koszulkę lidera Pucharu Świata pierwszy raz od 27 stycznia 2001 roku. 30 listopada na tej samej skoczni był czwarty. 7 grudnia na Granasen w Trondheim skoczek z Wisły zajął piątą pozycję. Następnego dnia na tej samej skoczni był szósty. 14 grudnia w Titisee-Neustadt Adam Małysz stanął na najniższym stopniu podium, przegrywając tylko z Martinem Höllwarthem i Sigurdem Pettersenem. Dzień później na tej samej skoczni uplasował się na szóstym miejscu. 21 grudnia w Engelbergu zajął jedną z trzech w sezonie pozycji poza pierwszą dziesiątką zawodów. Był piętnasty. Dzień później w ostatnim konkursie przed świętami Polak sklasyfikowany został na czwartym miejscu.
W 51. Turnieju Czterech Skoczni Adam Małysz zajął trzecie miejsce, przegrywając tylko z Janne Ahonenem i Svenem Hannawaldem. Podczas inauguracji w Oberstdorfie (29 grudnia) został sklasyfikowany na najniższym spośród wszystkich zajętych miejsc w tym Turnieju. Był trzynasty. W konkursie na Große Olympiaschanze zajął drugie miejsce ex aequo z Andreasem Goldbergerem. 4 stycznia na skoczni Bergisel był szósty, a w święto Trzech Króli na Paul-Ausserleitner-Schanze siódmy. W całym Turnieju łącznie zgromadził 959,7 punktu.
11 stycznia na skoczni Ještěd w Libercu zajął 16. miejsce, co było jego najgorszym występem w sezonie. 18 i 19 stycznia podczas zawodów Pucharu Świata w Zakopanem Małysz dwa razy zajął trzecie miejsce, za każdym razem przegrywając ze Svenem Hannawaldem i Florianem Lieglem. 23 stycznia w Hakubie zajął piąte miejsce, bezpośrednio wyprzedzając Janne Ahonena, z którym rywalizował o zwycięstwo w Pucharze Świata. 25 stycznia na Ōkurayamie w Sapporo był szósty i wyprzedził Ahonena o dwie pozycje. Dzień później na tej samej skoczni Małysz ponownie zajął szóstą lokatę przy 11. miejscu Janne Ahonena. 1 lutego na Kulm w Tauplitz stanął na najniższym stopniu podium, przegrywając tylko z Lieglem i Hannawaldem. Następnego dnia na tej samej skoczni był czwarty. Po konkursie Adam Małysz nadal zajmował drugie miejsce w klasyfikacji Pucharu Świata, przegrywając z Janne Ahonenem o jeden punkt. Polak nie wystartował w konkursach w Willingen, chcąc lepiej przygotować się do mistrzostw świata w Val di Fiemme. W efekcie spadł na 4. miejsce w klasyfikacji, wyprzedzony jeszcze przez Svena Hannawalda (który został liderem PŚ) i Andreasa Widhölzla.
Na mistrzostwach świata w Val di Fiemme na skoczniach w Predazzo Małysz, jako pierwszy skoczek od 29 lat, został mistrzem świata zarówno na normalnej, jak i na dużej skoczni. Dokonał tego, co udało się przed nim tylko trzem zawodnikom – Wirkoli z Norwegii w 1966, Napałkowowi z ZSRR w 1970 i Aschenbachowi z NRD w 1974. Przy okazji pobił rekordy tych obiektów (odpowiednio 107,5 i 136 m).
Pierwszymi zawodami po mistrzostwach świata były trzy konkursy rozegrane w ramach Turnieju Nordyckiego. We wszystkich triumfował Małysz, co dało mu drugie w karierze zwycięstwo w całym turnieju. 9 marca 2003 na skoczni Holmenkollbakken w Oslo zdobył 133,6 pkt (odbyła się tylko jedna seria konkursowa) i wyprzedził drugiego Floriana Liegla o 14,8 pkt, odnosząc swoje pierwsze pucharowe zwycięstwo w sezonie. Słabe występy trzech najgroźniejszych konkurentów w walce o Kryształową Kulę (Widhölzl był 10., Hannawald 14. a Ahonen 19.) sprawiły, że Adam Małysz po raz pierwszy w całym sezonie został liderem łącznej punktacji Pucharu Świata. Pięć dni później na skoczni w Lahti wygrał z notą 267,4 pkt, o 4,8 pkt wyprzedzając Mattiego Hautamäkiego. Podczas ostatniego z konkursów, 15 marca w Lahti Małysz zwyciężył z przewagą 8,1 pkt nad Hautamäkim.
22 marca na Velikance w Planicy był drugi, przegrywając o 1,2 punktu z Hautamäkim. W ostatnim konkursie sezonu, 23 marca Małysz był czwarty, przegrywając z Hautamäkim, Hannawaldem i Hideharu Miyahirą. W całym sezonie PŚ wiślak zdobył 1357 punktów i wyprzedził drugiego Hannawalda o 122 punkty. Dzięki temu Adam Małysz został pierwszym i dotąd jedynym skoczkiem w historii, który zdobywał Kryształową Kulę trzy sezony z rzędu.
Podczas jednego z treningów na największej na świecie skoczni – Letalnicy w Planicy ustanowił swój rekord życiowy i rekord Polski skacząc 225 m. Tym samym wyrównał ówczesny nieoficjalny rekord świata Andreasa Goldbergera. Dwa dni później uzyskał dokładnie tę samą odległość, ustanawiając nowy nieoficjalny rekord Polski w długości lotu.
2003/2004.
Adam Małysz podjął decyzję o rezygnacji ze startów w Letniej Grand Prix 2003 i zdecydował się wyłącznie skupić na przygotowaniach do sezonu zimowego.
Sezon 2003/2004 Adam Małysz rozpoczął od dwóch drugich miejsc w konkursach Pucharu Świata w Ruce. 28 listopada przegrał z Mattim Hautamäkim, a dzień później z Sigurdem Pettersenem. W efekcie, po dwóch pierwszych konkursach prowadził w klasyfikacji Pucharu Świata. 6 grudnia na skoczni w Trondheim zajął dziewiąte miejsce. W trakcie tego konkursu „Orłowi z Wisły" puściły gogle, które, jak się okazało później, miały wpływ na jego dyspozycję zarówno w tym konkursie, jak i w dalszej części sezonu. Osiem dni później w Titisee-Neustadt uplasował się na 12. pozycji. Na skoczni w Engelbergu 20 grudnia był dziewiąty, przez co stracił żółtą koszulkę i pozycję lidera Pucharu Świata.
W Turnieju Czterech Skoczni Adam Małysz tylko raz zajął miejsce w czołowej dziesiątce zawodów. 29 grudnia w Oberstdorfie był dziewiąty. 1 stycznia w Garmisch-Partenkirchen zajął 19. pozycję, 4 stycznia w Innsbrucku był 25., a 6 stycznia w Bischofshofen – 20. W całym Turnieju został sklasyfikowany na 15. miejscu, zdobywając łącznie 908,6 punktów, o 158 punktów mniej od zwycięzcy – Sigurda Pettersena. Nieudane występy w TCS sprawiły, że Adam Małysz zdecydował się nie wziąć udziału w dwóch kolejnych konkursach Pucharu Świata na skoczni Ještěd w Libercu i skupić się na zawodach PŚ w Zakopanem.
17 i 18 stycznia na Wielkiej Krokwi w Zakopanem Adam Małysz dwukrotnie był drugi. W pierwszym konkursie przegrał tylko z Michaelem Uhrmannem, a w drugim z Martinem Höllwarthem. 23 stycznia na skoczni w Hakubie zajął 32. miejsce, pierwszy raz od ponad trzech lat nie kwalifikując się do drugiej serii. Konkurs rozgrywany był w nierównych warunkach atmosferycznych. Polak skoczył wówczas 91,5 metra (na skoczni K-120). Następnego dnia na Ōkurayamie w Sapporo Małysz był 12. 25 stycznia na tej samej skoczni zajął 11. pozycję. 7 lutego na mamuciej skoczni w Oberstdorfie uplasował się na 22. miejscu. 14 lutego w Willingen był dziewiętnasty.
Mistrzostwa świata w lotach Adam Małysz rozpoczął od skoku na odległość 187,5 metra, co dało mu 6. miejsce. Tracił do prowadzącego Tommy Ingebrigtsena 21,4 pkt. W drugim skoku Małysz uzyskał 215,5 metra i utrzymał szóstą pozycję, tracąc do medalu po pierwszym dniu 13,4 pkt. Drugi dzień rozpoczął od skoku na odległość 203,5 metra. Po tym skoku spadł na dziewiąte miejsce. Ostatni skok na odległość 196,5 metra nie pozwolił Małyszowi utrzymać się w pierwszej dziesiątce. Zajął 11. miejsce, tracąc do mistrza świata Roara Ljøkelsøya 55 punktów. Wówczas był to najlepszy indywidualny wynik Adama Małysza w karierze podczas mistrzostw świata w lotach. W konkursie drużynowym wraz z Robertem Mateją, Mateuszem Rutkowskim i Wojciechem Skupieniem zajął 8. miejsce.
Podczas piątkowego treningu na skoczni w Park City, 27 lutego 2004 Adam Małysz miał groźny upadek. Na kilkadziesiąt sekund stracił przytomność, jednak ostatecznie skończyło się tylko na otarciach i obiciach. Z zeskoku skoczka zabrała karetka sanitarna. Do końca sezonu Małysz nie startował i zajął ostatecznie 12. miejsce w końcowej klasyfikacji generalnej Pucharu Świata.
2004/2005.
W 2004 Małysz wygrał Letnią Grand Prix. W całych zawodach zgromadził 520 punktów. Czterokrotnie stanął na najwyższym stopniu podium. Wygrał w Hinterzarten (K-95), Courchevel (K-120), Zakopanem (K-120) i Predazzo (K-120).
W inauguracji PŚ sezonu 2004/2005 27 listopada na Rukatunturi w Ruce zajął 19. miejsce. Podczas drugiego konkursu na tej samej skoczni ponownie był 19. 4 grudnia na skoczni w Trondheim został sklasyfikowany na 15. pozycji. Dzień później zajął siódme miejsce, dzięki czemu awansował do czołowej „piętnastki” Pucharu Świata i tym samym nie musiał brać udziału w kwalifikacjach. 11 grudnia na dużej skoczni w Harrachovie odniósł zwycięstwo, przerywając tym samym passę czterech zwycięstw Janne Ahonena. Następnego dnia Małysz zajął 11. miejsce. 18 grudnia w Engelbergu uplasował się na ósmej lokacie. Na drugi dzień, w konkursie na tej samej skoczni, był piąty.
W Turnieju Czterech Skoczni Małysz zajął czwarte miejsce, przegrywając z Janne Ahonenem, Martinem Höllwarthem i Thomasem Morgensternem. W pierwszym z konkursów, 29 grudnia na Schattenbergschanze zajął trzecie miejsce. 1 stycznia na skoczni w Garmisch-Partenkirchen był siódmy. Dwa dni później na Bergisel zajął drugą pozycję, tuż za Janne Ahonenem. Podczas ostatniego z konkursów, na skoczni w Bischofshofen był siódmy. W całym Turnieju zdobył łącznie 985,3 punktów, o 58 mniej od zwycięzcy Ahonena.
9 stycznia w Willingen uplasował się na dziewiątym miejscu. Sześć dni później na Kulm w Tauplitz polski skoczek stanął na najniższym stopniu podium. Przegrał wówczas tylko z Andreasem Widhölzlem i Roarem Ljøkelsøyem. Dzień później na tej samej skoczni Małysz zdecydowanie wygrał. 22 stycznia na Hochfirstschanze w Titisee-Neustadt zajął siódmą pozycję. Dzień później na tej samej skoczni był drugi, tuż za Jakubem Jandą. 29 stycznia na Wielkiej Krokwi zwyciężył ex aequo z Roarem Ljøkelsøyem. Następnego dnia ponownie wygrał, tym razem już niepodzielnie. W dwóch kolejnych konkursach, które odbyły się w Sapporo, nie wystartował. 11 lutego podczas próby przedolimpijskiej na skoczni w Pragelato był dziewiąty, dwa miejsca za Kamilem Stochem.
Na mistrzostwach świata w Oberstdorfie nie udało się Małyszowi obronić tytułów mistrza świata sprzed dwóch lat z Predazzo. Zajął kolejno 6. miejsce na skoczni K-90 oraz 11. miejsce na skoczni K-120.
W TN Małysz zajął 11. lokatę. W pierwszym konkursie, 6 marca w Lahti, uplasował się na siódmej pozycji (125 m i 122 m). Następnie w Kuopio razem z Jakubem Jandą stanął na podium, notując trzecie miejsce. W Lillehammer zajął 22. pozycję, skacząc 125 i 114 metrów. W ostatnim konkursie, w Oslo, uzyskując 117,5 i 118,5 metra, uplasował się na 19. miejscu. Turniej zakończył mając na koncie 976,9 punktu.
19 marca na Letalnicy Polak uplasował się na piątej pozycji, przegrywając tylko z Mattim Hautamäkim, Andreasem Widhölzlem, Bjørnem Einarem Romørenem i Roarem Ljøkelsøyem. Podczas ostatniego konkursu w sezonie, 20 marca w Planicy Małysz zajął 15. miejsce. Sezon 2004/2005 zakończył w PŚ na czwartym miejscu, zdobywając łącznie 1201 punktów do klasyfikacji.
2005/2006.
W Letniej Grand Prix 2005 Małysz uplasował się na 42. pozycji. Startował w trzech konkursach. W Hinterzarten zajął 18. miejsce. W Zakopanem był 26., a konkurs w Bischofshofen zakończył na 20. pozycji.
Pierwszy konkurs Pucharu Świata w sezonie 2005/2006 miał odbyć się 25 listopada w Ruce, jednak z powodu silnego wiatru zawody były kilkakrotnie przekładane. W efekcie 26 listopada odbyły się dwa konkursy. W pierwszym z nich Adam Małysz zajął siódme miejsce, a w drugim był piąty. 3 grudnia na skoczni w Lillehammer był dziesiąty. Dzień później na tej samej skoczni uplasował się na piątej lokacie. 10 grudnia na dużej skoczni w Harrachovie skoczek z Wisły zajął ósmą lokatę. Dzień później był 7. Tydzień później w zawodach na skoczni Gross-Titlis-Schanze w Engelbergu uplasował się na 13. miejscu.
Małysz wystąpił tylko w dwóch pierwszych konkursach Turnieju Czterech Skoczni. Po startach w konkursach w Oberstdorfie (13. miejsce) i w Garmisch-Partenkirchen (21. miejsce) ówczesny trener reprezentacji – Heinz Kuttin postanowił przygotować go do zawodów Pucharu Świata w Zakopanem i do konkursów olimpijskich w Turynie. W efekcie Adam Małysz zajął 35. miejsce w końcowej klasyfikacji TCS.
Małysz, mimo wycofania się z Turnieju, wziął udział w MŚ w lotach w Kulm. Były one w jego wykonaniu jednak najgorsze w całej karierze. Po treningach wydawało się, że nawet może mieć problem z awansem do drugiej serii. Ostatecznie po pierwszym skoku na 177,5 m zajmował 22. miejsce. Drugi był jeszcze słabszy (163 m) i Małysz po pierwszym dniu zajmował 24. miejsce. Drugi dzień był nieco lepszy. Skoki na 171,5 m oraz 181,5 m pozwoliły mu przesunąć się na 20. miejsce, jedną pozycję za Robertem Mateją. W konkursie drużynowym polska reprezentacja, wraz z Adamem Małyszem w składzie, zajęła 9. miejsce.
28 stycznia na Wielkiej Krokwi w Zakopanem „Orzeł z Wisły” zajął czwarte miejsce, przegrywając tylko z Mattim Hautamäkim, Tami Kiuru i Janne Ahonenem. Drugiego dnia na tej samej skoczni był 14. Tydzień później odbyły się dwa konkursy w Sapporo, w których Polak nie wystartował.
Niepowodzeniem zakończył się start Małysza w zimowych igrzyskach olimpijskich w Turynie na skoczniach w Pragelato. W pierwszym konkursie na normalnej skoczni Polak zajął 7. miejsce. Mistrz olimpijski, Norweg Lars Bystøl, w dwóch seriach pokonał Małysza zaledwie o metr (101,5 m i 103,5 m przy 101,5 m i 102,5 metra Polaka). Dawało to Małyszowi nadzieje na walkę o medal w konkursie na dużej skoczni. Tam jednak Polak spisał się dużo gorzej. Zajął dopiero 14. miejsce, do zwycięzcy, Thomasa Morgensterna, tracąc prawie 55 punktów. Strata do brązowego medalisty wyniosła 28 punktów. W konkursie drużynowym zajął 5. miejsce. Występ w Turynie Adam Małysz przyjął jako porażkę i nie krył rozczarowania swoim występem.
W sezonie 2005/2006 „Orzeł z Wisły” uplasował się na piątej pozycji w Turnieju Skandynawskim. 5 marca na skoczni Salpausselkä w Lahti był szósty. Dwa dni później w Kuopio zajął pierwsze w sezonie miejsce na podium; był trzeci, tuż za Andreasem Küttelem i Thomasem Morgensternem. 10 marca na skoczni Lysgårdsbakken w Lillehammer był 11. Dwa dni później na Holmenkollbakken w stolicy Norwegii, Oslo Adam Małysz zwyciężył, czwarty raz w karierze na tej skoczni. W owym konkursie uzyskał w pierwszej serii 130,5 metra, a w drugiej – 124,5 m. W całym Turnieju zdobył 1068,7 punktu i, jako piąty zawodnik w stawce, stracił do czwartego Andreasa Koflera 0,1 punktu.
18 marca na Letalnicy w Planicy zajął szóstą lokatę. Dzień później w ostatnim konkursie sezonu był ósmy. W końcowej klasyfikacji Pucharu Świata w sezonie 2005/2006 Adam Małysz zajął dziewiąte miejsce, zdobywając łącznie 634 punkty.
2006/2007.
W Letniej Grand Prix 2006 Małysz odniósł trzecie zwycięstwo jako pierwszy skoczek w historii. W pierwszym konkursie, 6 sierpnia na skoczni w Hinterzarten, zajął szóste miejsce. Dwa dni później w Predazzo zwyciężył. 12 sierpnia w Engelbergu został sklasyfikowany na piątej pozycji, za Andreasem Koflerem, Gregorem Schlierenzauerem, Simonem Ammannem i Wolfgangiem Loitzlem. 14 sierpnia w Courchevel Małysz był trzeci. Pozostałe trzy konkursy, w których wziął udział, tj. 26 sierpnia w Zakopanem, 30 września w Klingenthal i 3 października w Oberhofie Małysz rozstrzygnął na swoją korzyść.
Sezon 2006/2007 Adam Małysz rozpoczął od 34. pozycji na skoczni w Ruce. Konkurs rozgrywany był jednak w niekorzystnych warunkach atmosferycznych. Z czołowej piętnastki PŚ sezonu 2005/2006 do finałowej serii konkursu w Ruce awansował tylko Thomas Morgenstern i Matti Hautamäki. 2 grudnia w Lillehammer Małysz uplasował się na piętnastym miejscu, po upadku w pierwszej serii. Następnego dnia na tej samej skoczni stanął na najniższym stopniu podium, przegrywając tylko z Gregorem Schlierenzauerem i Andersem Jacobsenem. Podobnie 16 grudnia w Engelbergu. Dzień później na tej samej skoczni Małysz został sklasyfikowany na szóstej pozycji.
Małysz zajął siódme miejsce w 55. Turnieju Czterech Skoczni. 30 grudnia podczas pierwszego z turniejowych konkursów na Schattenbergschanze w Oberstdorfie zajął trzecie miejsce z notą 280,3 punktów (miał skoki na 132 m i 134 m). Przegrał wówczas tylko ze Schlierenzauerem i Andreasem Küttelem. 1 stycznia podczas konkursu na skoczni w Garmisch-Partenkirchen zajął 12. miejsce z notą 123,9 punktów (w I serii 120,5 m; druga seria skoków została odwołana). 4 stycznia na Bergisel w Innsbrucku został sklasyfikowany na szóstej pozycji z notą 249,9 punktów (124 m i 126,5 m). 6 stycznia w ostatnim spośród czterech konkursów Turnieju Czterech Skoczni w Bischofshofen był ósmy, bezpośrednio wyprzedzając Kamila Stocha. Adam Małysz uzyskał wówczas 252,4 punktów po skokach na 129,5 i 133,5 metra. W łącznej klasyfikacji zdobył 906,5 punktów, o 55,4 mniej od zwycięskiego Andersa Jacobsena.
13 stycznia Małysz zajął ósme miejsce na mamuciej skoczni w Vikersund. 20 stycznia podczas konkursu na Wielkiej Krokwi w Zakopanem zajął piąte miejsce, przegrywając z Rokiem Urbancem, Roarem Ljøkelsøyem, Mattim Hautamäkim i Tomem Hildem. Tydzień później na skoczni w Oberstdorfie wygrał pierwsze zawody w sezonie. Było to jednocześnie jego 30. wiktoria w konkursach Pucharu Świata. Następnego dnia na tej samej skoczni był czwarty. 3 i 4 lutego w Titisee-Neustadt skoczek z Wisły dwukrotnie triumfował. 7 lutego na skoczni w Klingenthal zajął trzecią lokatę, przegrywając jedynie ze Schlierenzauerem i Ammannem. Trzy dni później na skoczni w Willingen uplasował się na siódmym miejscu.
Na mistrzostwach świata w Sapporo wiślak zdobył złoty medal na skoczni K-90 z przewagą 21,5 pkt. nad drugim Simonem Ammannen. Tym samym Małysz stał się najbardziej utytułowanym skoczkiem w historii mistrzostw (4 złote medale i jeden srebrny). Nigdy wcześniej zwycięzcy od wicemistrza nie dzieliła tak znaczna różnica punktowa. W pierwszym z konkursów o mistrzostwo świata na obiekcie K-120 Małysz zajął czwarte miejsce.
W sezonie 2006/07 Adam Małysz po raz trzeci w karierze wygrał Turniej Nordycki. Uczynił to jako pierwszy skoczek w historii. 11 marca podczas konkursu w Lahti odniósł swoje 33. zwycięstwo w konkursach Pucharu Świata, tym samym zrównując się z zajmującym drugie miejsce na liście wszech czasów Niemcem Jensem Weißflogiem. Dwa dni później na Puijo w Kuopio ponownie odniósł zwycięstwo. 17 marca na Holmenkollbakken w Oslo po raz piąty i ostatni w karierze wygrał zawody Pucharu Świata w tym miejscu. Dzięki temu pierwszy raz od 2003 roku awansował na pierwszą pozycję w klasyfikacji Pucharu Świata. W drugim konkursie na tej samej skoczni zajął 54. miejsce, jednak skok oddał w niekorzystnych warunkach atmosferycznych. Wylądował na 89 metrze, broniąc się przed upadkiem. Tym samym utracił prowadzenie w Pucharze Świata na rzecz Andersa Jacobsena. W klasyfikacji generalnej Turnieju Skandynawskiego zgromadził 822,4 punktu, o 2,1 pkt. więcej od drugiego w klasyfikacji Andreasa Koflera.
Podczas ostatniego weekendu w sezonie na Letalnicy w Planicy (23–25 marca) Adam Małysz wygrał wszystkie trzy konkursy. Pierwszy raz w karierze zwyciężał na tej skoczni. Ponadto pierwszy raz był najlepszy w trzech konkursach Pucharu Świata w przeciągu jednego weekendu. W końcowej klasyfikacji PŚ wygrał z łączną liczbą punktów 1453, wyprzedzając drugiego Jacobsena o 134 punkty. Tym samym Adam Małysz jako drugi skoczek w historii, po Mattim Nykänenie czwarty raz sięgnął po Kryształową Kulę.
2007/2008.
W pierwszym z konkursów Letniej Grand Prix 2007, 12 sierpnia w Hinterzarten Adam Małysz zajął drugie miejsce, przegrywając z Thomasem Morgensternem. Dwa dni później na skoczni w Courchevel Polak ponownie był drugi, dzięki czemu został liderem klasyfikacji generalnej. 16 sierpnia w Pragelato Małysz zajął trzecie miejsce, tuż za Gregorem Schlierenzauerem i Morgensternem. Dwa dni później w Einsiedeln Małysz zajął drugą pozycję, przegrywając z Morgensternem. 24 sierpnia w pierwszym konkursie na Wielkiej Krokwi Małysz uplasował się na trzecim miejscu. Dzień później wygrał. W późniejszych konkursach LGP nie wystartował, przez co przegrał ogólną rywalizację z Thomasem Morgensternem i zajął drugie miejsce w klasyfikacji generalnej LGP.
Sezon 2007/2008 Pucharu Świata w skokach narciarskich Małysz rozpoczął od 16. miejsca w konkursie rozegranym 1 grudnia roku w fińskiej Ruce. W konkursach rozgrywanych w dniach 8–9 grudnia w Trondheim zajął odpowiednio siódme i ósme miejsce. 13 grudnia na skoczni Alpenarena w Villach zajął 10. miejsce. Drugiego dnia był dziewiąty, skacząc na odległość 91 i 90 metrów. W przedświątecznych konkursach w Engelbergu – 22 i 23 grudnia – zajął 10. i 13. miejsce.
W pierwszym konkursie TCS w Oberstdorfie na Schattenbergschanze Małysz zajął 17. miejsce. W noworocznym konkursie na nowo wybudowanej skoczni w Garmisch-Partenkirchen był piąty. Z powodu silnego wiatru zawody w Innsbrucku nie odbyły się, ale zostały przeniesione w Bischofshofen, gdzie Małysz zajął dziewiąte miejsce. W ostatnim konkursie, w tym samym mieście, był szósty. 56. Turniej Czterech Skoczni zakończył na czwartej pozycji.
Tydzień po ostatnich zawodach TCS, w konkursie w Predazzo, po nieudanym skoku, zajął 46. miejsce. Dzień później na tej samej skoczni również nie awansował do drugiej serii zawodów, zajmując 40. miejsce po skoku na odległość 111,5 m. Tydzień później na mamuciej skoczni w Harrachovie Małysz skoczył 130 m. Zawody zostały jednak anulowane z powodu niekorzystnych warunków atmosferycznych. Następnego dnia Małysz po raz kolejny nie zakwalifikował się do finałowej serii. Został sklasyfikowany na 36. miejscu. W kolejny weekend zawody odbywały się na Wielkiej Krokwi w Zakopanem. Piątkowy konkurs Małysz ukończył na jedenastym miejscu, niedzielny, przeniesiony z soboty, na czwartym. Następne zawody w japońskim Sapporo Małysz opuścił. Do rywalizacji w Pucharze Świata powrócił 8 lutego w Libercu, gdzie zajął 7. miejsce. Dzień później był dziewiąty. Podczas kolejnego konkursu rozegranego 17 lutego w Willingen Małysz zajął 11. miejsce.
Adam Małysz na MŚwL do Oberstdorfu na skocznię K-185 nie jechał jako faworyt, ale mimo to w skokach treningowych plasował się w czołówce. W pierwszej serii mistrzostw uzyskał 207,5 metra i zajmował 6. miejsce, tracąc do lidera 10,4 pkt. W drugiej serii skoczył 211,5 metra i po pierwszym dniu mistrzostw plasował się na 5. miejscu. Do brązowego medalu tracił 11,5 pkt. W trzeciej serii lotów Małysz uzyskał odległość 192,5 metra i spadł na 7. miejsce. W ostatniej serii skoczył 196 metrów i ostatecznie mistrzostwa świata w lotach ukończył na dziewiątym miejscu, ze stratą 57,4 pkt do mistrza świata Gregora Schlierenzauera. W konkursie drużynowym Polska zajęła 10. miejsce. Małysz uzyskał odległość 199,5 metra.
Adam Małysz zajął ósme miejsce w Turnieju Nordyckim, łącznie gromadząc 820,2 pkt. W Kuopio zajął siódme i dwunaste miejsce, zaś w Lillehammer i Oslo był jedenasty.
Sezon zakończył się dla Polaka dziewiątym i dwunastym miejscem na skoczni mamuciej w Planicy. W końcowej klasyfikacji Pucharu Świata zajął on 12. miejsce. Był to jednocześnie pierwszy od ośmiu lat sezon w którym Małysz ani razu nie stanął na podium żadnego z konkursów Pucharu Świata.
2008/2009.
Letnią Grand Prix 2008 wiślak zakończył na 34. pozycji w klasyfikacji końcowej. Polak wystartował w pięciu konkursach. W Hinterzarten uplasował się na 22. miejscu. W Zakopanem zajął 30. i 15. lokatę. W Klingenthal był 18. Ostatnimi zawodami w Libercu Adam Małysz zakończył starty w LGP na 9. pozycji.
Sezon 2008/2009 Małysz rozpoczął 14. miejscem w Ruce (29 listopada). W następny weekend (6–7 grudnia) w norweskim Trondheim zajął 25. i 27. miejsce. Słabe wyniki zdecydowały o wycofaniu się z kolejnych zawodów (13–14 grudnia) we włoskim Pragelato. Do rywalizacji powrócił na przedświąteczne konkursy w szwajcarskim Engelbergu (20–21 grudnia). W pierwszym konkursie był 21., a drugie zawody ukończył na 18. miejscu.
W pierwszym konkursie niemiecko-austriackiego TCS wiślanin zajął 27. miejsce. Do drugiej serii konkursu w Oberstdorfie wszedł jako tzw. lucky loser, przegrywając swój pojedynek z Romanem Koudelką. W Garmisch-Partenkirchen odnotował jeden z najgorszych wyników w historii swoich występów w Turnieju. Nie zdołał awansować do drugiej serii, przegrywając rywalizację z niemieckim zawodnikiem Andreasem Wankiem i ostatecznie został sklasyfikowany na 37. miejscu. Trzeci konkurs rozgrywany w Innsbrucku Polak ukończył na 15. miejscu. Po zawodach w stolicy Tyrolu, wycofał się z TCS i nie wystąpił w Bischofshofen.
Nie wziął także udziału w konkursach lotów narciarskich w austriackim Tauplitz (10–11 stycznia). Skoczek zwrócił się o pomoc do swojego byłego szkoleniowca, Hannu Lepistoe. W kolejnych konkursach, w Zakopanem (16–17 stycznia), Małysz zajął 8. i 12. miejsce. Podczas próby przedolimpijskiej w kanadyjskim Whistler (24–25 stycznia) Małysz powtórzył swój dotychczasowy najlepszy wynik w sezonie (8. miejsce w Zakopanem) i otrzymał tytuł Man of the Day. W drugim konkursie uplasował się na 4. pozycji, ponownie otrzymując tytuł zawodnika dnia. Następne konkursy w japońskim Sapporo (31 stycznia-1 lutego) Małysz opuścił. 8 lutego polski skoczek w loteryjnym konkursie w Willingen zajął 27. miejsce. Trzy dni później, w Klingenthal, był 9. W kolejnych zawodach na mamuciej skoczni w Oberstdorfie (14 lutego) nie wystartował.
Na mistrzostwach świata rozgrywanych w czeskim Libercu Małyszowi nie udało się obronić tytułu sprzed dwóch lat. 21 lutego na skoczni normalnej po skokach na 96 m i 89,5 m zajął 22. miejsce. 6 dni później, na skoczni K-120, w jednoseryjnym konkursie uzyskał 127 metrów i został sklasyfikowany na 12. pozycji. W konkursie drużynowym reprezentacja Polski w składzie: Adam Małysz, Stefan Hula, Kamil Stoch i Łukasz Rutkowski zajęła czwarte miejsce, przegrywając brązowy medal o 9,2 punktu ze skoczkami japońskimi.
W pierwszym konkursie turnieju, na normalnej skoczni w Lahti, Małysz uplasował się na 24. pozycji. Dwa dni później, 10 marca w fińskim Kuopio Adam Małysz podczas swego 300. startu w Pucharze Świata zajął 3. miejsce. Było to jego pierwsze podium w zawodach Pucharu Świata od blisko dwóch lat. W kolejnych zawodach w norweskim Lillehammer był czwarty. 15 marca na mamuciej skoczni w Vikersund, skokami na odległość 186 m i 190 m wywalczył 8. miejsce. Ostatecznie w TN był piąty.
Po Turnieju Skandynawskim przyszedł czas na weekend w Planicy. 20 marca Małysz w jednoseryjnym konkursie lotów zajął 2. miejsce. Dzień później, razem ze Stefanem Hulą, Łukaszem Rutkowskim i Kamilem Stochem, zajął 2. miejsce w drużynie. Wygrali Norwegowie. W ostatnim konkursie sezonu, 22 marca, ponownie zajął 2. miejsce, przegrywając w finale z Harrim Ollim. Zdobył także tytuł Man of the Year, przyznawany za zdobycie największej liczby tytułów Man of the Day w sezonie.
2009/2010.
Małysz rozpoczął rywalizację w LGP od szóstego miejsca w Hinterzarten, a trzy dni później w Pragelato stanął na drugim stopniu podium przegrywając z Simonem Ammannem. Dzięki temu zajmował drugie miejsce w klasyfikacji generalnej LGP oraz Turnieju Czterech Narodów. W trzecim konkursie tych cyklów, w Courchevel, Polak ponownie był drugi i znów przegrał z Ammannem. W Einsiedeln zajął miejsce tuż poza pierwszą dziesiątką. Nie przeszkodziło mu to jednak w utrzymaniu drugiego miejsca w klasyfikacji Turnieju Czterech Narodów i w klasyfikacji generalnej Grand Prix. Tydzień później w Zakopanem odbyły się dwa konkursy, w których skoczek z Wisły zajął kolejno trzecie i dwudzieste pierwsze miejsce. 29 i 30 sierpnia w Hakubie oraz 3 października w Klingenthal Małysz nie wystartował.
Adam Małysz w kwalifikacjach do inauguracyjnego konkursu w Ruce skacząc w bardzo niekorzystnych warunkach atmosferycznych uzyskał 101 metrów, przez co pierwszy raz od grudnia 1999 roku (nie licząc dyskwalifikacji w kwalifikacjach do konkursu PŚ w Kuopio w 2000 roku) nie zdołał się zakwalifikować do konkursu. Tego samego dnia rozegrano również konkurs drużynowy, w którym wraz z Kamilem Stochem, Krzysztofem Miętusem oraz Piotrem Żyłą zajął 5. miejsce, skacząc 141,5 m i 143 m. Tydzień później (5–6 grudnia) w norweskim Lillehammer wiślanin uplasował się kolejno na 3. i 8. pozycji. Zawody, które odbyły się 18 grudnia na skoczni w Engelbergu ukończył na 12. miejscu. Dzień później zajął 23. lokatę. W jednoseryjnym konkursie, który odbył się 20 grudnia Małysz zajął 8. pozycję.
Adam Małysz w inaguracyjnym konkursie 58. Turnieju Czterech Skoczni, który odbył się w niemieckim Oberstdorfie, uplasował się na 8. pozycji ze stratą 35,5 pkt. do zwycięzcy Andreasa Koflera. Noworoczny konkurs na skoczni w Garmisch-Partenkirchen Polak ukończył na 11. pozycji. Dwa dni później na skoczni Bergisel w Innsbrucku po skokach na odległość 123,5 m oraz 118 m wywalczył 7. lokatę. W ostatnim konkursie TCS w Bischofshofen zajął 18. lokatę. W klasyfikacji generalnej Turnieju uplasował się na dziewiątej pozycji.
Konkurs lotów 9 stycznia na skoczni w Tauplitz Polak ukończył na 7. pozycji. Oddał wówczas skoki na odległość 187,5 m oraz 190,5 m. Uzyskał za nie notę 357,6 pkt. i do zwycięzcy zawodów, Roberta Kranjca, stracił 24,9 pkt. W drugim konkursie na tej samej skoczni oddał podobne skoki; 188,5 m oraz 190 m pozwoliły mu zająć 8. miejsce. Małysz nie wziął udziału w japońskich konkursach w Sapporo. Wystąpił dopiero 22 i 23 stycznia na Wielkiej Krokwi w Zakopanem. W pierwszym konkursie zajął piątą lokatę, natomiast w drugim był czwarty ze stratą dwóch punktów do trzeciego Thomasa Morgensterna. Konkurs lotów w Oberstdorfie ukończył na 6. miejscu ze stratą ponad 20 punktów do zwycięzcy Andersa Jacobsena. 3 lutego na skoczni w Klingenthal Małysz zajął najwyższą w sezonie drugą lokatę. Przegrał tylko z Simonem Ammannem.
13 lutego 2010 w Vancouver na igrzyskach olimpijskich w konkursie na normalnej skoczni Adam Małysz zdobył srebrny medal z notą 269,5 pkt, przegrywając z Simonem Ammannem o 7 punktów. 20 lutego Polak oddał skoki na odległość 137 m i 133,5 m i ponownie zdobył srebrny medal, ponownie przegrywając ze Szwajcarem. Konkurs drużynowy reprezentacja Polski ukończyła na szóstej pozycji, przegrywając z Austriakami, Niemcami, Norwegami, Finami i Japończykami. Małysz oddał skoki na odległość 136,5 m oraz 139,5 m.
Po powrocie z olimpiady Małysz wziął udział w konkursie skoków w ramach Pucharu Kontynentalnego, które odbywały się w Wiśle na skoczni jego imienia. Zwyciężył w tych zawodach, dwukrotnie oddając skoki na odległość 126,5 metra.
7 marca w pierwszym konkursie Turnieju Nordyckiego na skoczni w Lahti Adam Małysz zajął drugą lokatę, podobnie jak na igrzyskach olimpijskich przegrywając ze Szwajcarem Simonem Ammannem. Było to jego 80. pucharowe podium w karierze. W kolejnym konkursie turnieju, 9 marca w Kuopio, Małysz oddał skoki na odległość 123 m i 123,5 m i ponownie przegrał tylko z Ammannem. W norweskim Lillehammer Polak również znalazł się na podium. Tym razem jednak wywalczył trzecią lokatę. Po raz kolejny najlepszy okazał się dwukrotny mistrz olimpijski z Vancouver, a na drugim stopniu podium stanął Austriak Gregor Schlierenzauer. Na skoczni Holmenkollbakken w Oslo Małysz zajął ponownie drugą pozycję za Ammannem, pomimo iż po pierwszej serii był trzynasty. Za swoje skoki uzyskał notę 258,7 pkt. i ze zwycięzcą konkursu przegrał o 9 punktów.
19 marca 2010 odbyły się dwie serie w ramach mistrzostw świata w lotach w Planicy. W pierwszej próbie Małysz uzyskał 217,5 m i z niewielką przewagą prowadził w konkursie. Drugi skok Polaka był o 2,5 metra krótszy, w związku z czym spadł on na drugie miejsce. Dzień później lądował na 211 m oraz 211,5 m i mistrzostwa ukończył na czwartym miejscu. Do trzeciego Andersa Jacobsena stracił zaledwie 0,4 pkt.
2010/2011.
8 sierpnia w Hinterzarten po raz pierwszy od 2007 roku Adam Małysz zwyciężył w indywidualnych zawodach Letniej Grand Prix. Drugiego w zawodach Thomasa Morgensterna wyprzedził o 3,8 pkt., natomiast trzeciego Kalle Keituriego o 14,9 pkt. 13 sierpnia w Courchevel Małysz zajął 4. lokatę przegrywając z Daiki Itō i dwoma Austriakami – Zaunerem i Morgensternem, którzy zostali sklasyfikowani na 2. miejscu. 15 sierpnia w Einsiedeln Małysz zajął 2. pozycję przegrywając o 1,7 pkt. z Japończykiem Itō i wyprzedzając trzeciego w konkursie, zwycięzcę kwalifikacji, Macieja Kota. Tym wynikiem zapewnił sobie zwycięstwo w ogólnej klasyfikacji Turnieju Czterech Narodów. 20 sierpnia w Wiśle zajął 1. miejsce wyprzedzając o 0,6 pkt swojego rodaka Kamila Stocha. Dzień później na tej samej skoczni uplasował się tuż za podium. 1 października w czeskim Libercu wiślak odniósł trzynaste, ostatnie zwycięstwo w zawodach LGP w karierze. Po skokach na odległość 126 m i 127,5 m wyprzedził drugiego w klasyfikacji Toma Hildego o 9,6 pkt. Dwa dni później w Klingenthal Małysz został zdyskwalifikowany w pierwszej serii konkursowej za start przy czerwonym świetle.
W połowie listopada, na treningach w Lillehammer "Orzeł z Wisły" przeskoczył skocznię, czego skutkiem okazało się być przeciążenie kolana. Kontuzja ta mogła spowodować rezygnację ze startów w Ruce. Udało się jednak doprowadzić skoczka do sprawności; zdecydował się on na start w obu konkursach na skoczni Rukatunturi, zarówno w drużynowym, jak i indywidualnym. Małysz zainaugurował sezon piątym miejscem w konkursie drużynowym, dwukrotnie skacząc najdalej w polskim zespole (140 m i 132,5 m). Indywidualnie zajął 9. lokatę. 1 grudnia w Kuopio powtórzył ten wynik, skacząc 119,5 metra i 120,5 metra. W pierwszym konkursie w Lillehammer zajął 5. miejsce, skacząc w I serii 136,5 m, a w II kolejce 133,5 m. Dzień później znowu uplasował się na 9. pozycji. W zawodach w Engelbergu, pierwszy raz w sezonie Małysz wypadł poza czołową „10” (był 14., w jedynej kolejce osiągnął 124,5 m). W sobotę, skacząc 137 metrów, objął prowadzenie po pierwszych pięćdziesięciu skokach. W drugiej serii nie skakał jednak jako ostatni, ponieważ Thomas Morgenstern zgłosił awarię zamka i startował po Polaku. Małysz skoczył 135 m; Austriak, który zdołał wystartować, pofrunął pół metra dalej, co przy lepszych notach zapewniło mu wygraną o 2,2 punktu nad drugim Małyszem. Następnego dnia pierwszy skok na odległość 119,5 m dał Małyszowi 17. pozycję (był to jednak 4. rezultat pierwszej dziesiątki zawodników PŚ). W drugiej kolejce skoczył najdalej w całym konkursie – 137 metrów. Dzięki słabszym skokom zawodników będących przed reprezentantem Polski, awansował on na trzeci stopień podium. Małysza wyprzedzili Andreas Kofler i Morgenstern.
W pierwszej serii pierwszego konkursu Turnieju Czterech Skoczni w Oberstdorfie Małysz wystąpił w parze z liderem Pucharu Świata Morgensternem (Austriak, podobnie jak Andreas Kofler i Simon Ammann, zrezygnował ze skoku kwalifikacyjnego, co oznaczało przesunięcie go na koniec stawki). Rywalizację zdecydowanie przegrał, skacząc 115 metrów, ale zakwalifikował się jednak do drugiej serii z 21. miejsca jako tzw. „szczęśliwy przegrany”. Dzięki drugiemu skokowi, w którym osiągnął 131,5 metra, Małysz ostatecznie zajął 11. miejsce. W składającym się z jednej serii konkursie w Garmisch-Partenkirchen Polak startował w parze z Japończykiem Yūtą Watase. Oddając skok na odległość 132 metrów pokonał rywala o 36,9 punktu i stanął na najniższym stopniu podium, przegrywając z Simonem Ammannem i Pawłem Karelinem. Austriacką część turnieju rozpoczął od kolejnego miejsca na podium. W Innsbrucku po pierwszej serii zajmował drugie miejsce (skok na 128 m) i w drugiej obronił tę lokatę skokiem 123,5 metra. Przegrał z Morgensternem. W klasyfikacji generalnej TCS po trzech konkursach Małysz plasował się na trzeciej pozycji. W konkursie w Bischofshofen nie utrzymał jednak tej lokaty. Pierwszą kolejkę zakończył 13. rezultatem, szybując na odległość 124,5 metra – pół metra przed punktem K. W drugiej serii skoczył dwa metry dalej i awansował na 10. miejsce, ale Turniej ukończył na 6. pozycji.
W kolejnych zawodach PŚ, na mamucie w Harrachovie, Małysz po raz piąty w sezonie wskoczył na podium. Zajął 3. miejsce po skokach na odległość 197,5 m i 189 m. Został wyprzedzony jedynie przez Martina Kocha i Morgensterna. W konkursie niedzielnym ponownie był trzeci po pierwszej części zawodów (pofrunął 201 metrów), jednak w drugiej skoczył 183,5 metra i spadł na 4. miejsce. W Sapporo Małysz drugi raz w sezonie prowadził po pierwszej kolejce, skacząc najdalej – 132,5 metra, ale w kolejnej próbie lądował 14,5 m krócej. Szósty raz zajął pozycję w pierwszej trójce, ale Polaka wyprzedził Niemiec Severin Freund i po raz piąty z kolei Morgenstern. Drugi konkurs był mniej udany, gdyż Małysz zajmował 3. lokatę po pierwszej serii (131 metrów, dalej skoczył tylko Freund), a w drugiej doleciał jedynie do 114 metra i spadł o dwa miejsca, na 5. pozycję. 21 stycznia odniósł pierwsze od prawie czterech lat zwycięstwo w konkursie Pucharu Świata. W Zakopanem, w pierwszym konkursie, skoczył najdalej w I serii – 138,5 m i miał 4 punkty przewagi nad Freundem, który skoczył 137 m z wyższej belki. W drugiej Małysz skoczył dziesięć metrów bliżej, ale mniejsze punkty ujemne za wiatr i przewaga po pierwszym skoku pozwoliła na 39. wygraną w PŚ i znaczne zbliżenie się w klasyfikacji generalnej do trzeciego Andreasa Koflera, który w tym konkursie zajął 2. miejsce, oraz do drugiego w klasyfikacji Simona Ammanna. Konkurs sobotni skończył się dla Małysza gorzej. Dwa skoki na 133,5 m i 125 m umieściły go na szóstym miejscu, jedną pozycję przed Kamilem Stochem. Podczas trzeciego konkursu na Wielkiej Krokwi 23 stycznia Małysz w pierwszym skoku miał upadek przy lądowaniu na odległość punktu K. Choć nie odniósł poważnych obrażeń, to jednak nie wystąpił w II serii, choć miał do tego prawo. Przez ten fakt, po raz pierwszy od 1 stycznia 2009 nie zdobył punktów w konkursie PŚ, zajmując 32. miejsce.
W konkursie drużynowym w Willingen Małysz zajął 3. miejsce; razem z Kamilem Stochem, Piotrem Żyłą i Stefanem Hulą. Było to trzecie drużynowe podium w jego karierze. Lepsze były drużyny Austrii i gospodarzy konkursu – Niemiec. Następnego dnia, w konkursie indywidualnym, Małysz zajął 9. miejsce po skokach na odległość 135,5 m i 135 m. Zawody wygrał Severin Freund. 2 lutego w niemieckim Klingenthal Małysz zajął 7. miejsce. 5 lutego zawody odbyły się na skoczni mamuciej w Oberstdorfie. Małysz po dwóch skokach na 201,5 m i 184,5 m zajął 6. pozycję. 12 i 13 lutego zawody PŚ odbyły się na największej skoczni świata w Vikersund. Pierwszego dnia Małysz zajął piąte miejsce, następnego trzecie, ustanawiając swój nowy rekord życiowy, a jednocześnie rekord Polski (pobity rok później przez Piotra Żyłę) – 230,5 m. Zawody wygrał Gregor Schlierenzauer.
26 lutego Adam Małysz zdobył brązowy medal MŚ na skoczni normalnej Midtstubakken (K-95) w Oslo. Polak oddał skoki na odległość 97,5 m oraz 102,5 m. Był to już szósty medal mistrzostw w karierze Małysza. Złoto wywalczył Thomas Morgenstern. Podczas odbywanego dzień później konkursu drużynowego na tej samej skoczni oddał skoki na odległość 104,5 m i 106,5 m. Polska ulokowała się na 4. pozycji. 3 marca rozegrano konkurs indywidualny na skoczni Holmenkollbakken (K-120). Małysz oddał skoki o długości 126 m oraz 130,5 m i uplasował się na 11. miejscu. Tego samego dnia w wywiadzie telewizyjnym dla TVP zapowiedział zakończenie sportowej kariery z końcem bieżącego sezonu. 26 marca 2011 w Zakopanem miały się odbyć specjalne pożegnalne zawody. 5 marca, podczas zawodów drużynowych na skoczni Holmenkollbakken Małysz oddał skok na odległość 135,5 m (druga seria nie odbyła się), a Polska zajęła 5. miejsce.
Po powrocie do cyklu PŚ Małysz czwarty raz w karierze zajął miejsce na podium drużynowego konkursu. Trzecie miejsce zapewnił skokiem na 131,5 w II serii rywalizacji w Lahti. Dzień później indywidualnie był 15. W finałowych zawodach sezonu w Planicy, w piątek wiślak zajął ośmą pozycję. W niedzielnym, ostatnim w swojej karierze konkursie Pucharu Świata, zajął 3. miejsce. Zwycięzcą konkursu był Kamil Stoch. Było to pierwsze pucharowe podium, na którym stanęło dwóch Polaków, od 1980 roku. Adam Małysz zajął 3. miejsce w klasyfikacji generalnej Pucharu świata w sezonie 2010/2011. Zajął także 4. miejsce w klasyfikacji lotów. Polska po raz pierwszy w historii znalazła się na podium Pucharu Narodów, zajmując 3. miejsce.
26 marca 2011 odbył się benefis Małysza, zorganizowany przez szwajcarską spółkę Transcontinental Services AG i Testa Communications na Wielkiej Krokwi w Zakopanem. Było to uroczyste zakończenie kariery.
Klasyfikacje wszech czasów.
Adam Małysz jest na pierwszej pozycji w klasyfikacji wszech czasów mistrzostw świata, jeśli nie uwzględniać medali z konkursów drużynowych oraz medali z igrzysk olimpijskich. Do 1980 każdy medalista igrzysk olimpijskich zostawał automatycznie medalistą mistrzostw świata.
W historii MŚ, łącznie z medalami igrzysk, lepsi od niego są tylko Norweg Birger Ruud i Szwajcar Simon Ammann. Pierwszy zdobył w latach 1931–1939 pięć złotych i dwa srebrne medale, trzy z nich (dwa złote i jeden srebrny) wywalczył na IO. Ammann natomiast posiada pięć złotych, jeden srebrny i dwa brązowe medale. Trzecie miejsce w zestawieniu zajmuje polski skoczek, mając łącznie cztery złote, cztery srebrne i dwa brązowe medale. 13 lutego 2010 roku zdobywając srebrny medal na skoczni normalnej podczas igrzysk olimpijskich w Vancouver wyprzedził Fina Mattiego Nykänena oraz Niemca Jensa Weißfloga. Małysz jednakże może się poszczycić największą liczbą indywidualnych krążków, ogółem zdobył ich aż dziesięć (sześć na mistrzostwach świata i cztery na igrzyskach olimpijskich).
Mając na koncie 39 zwycięstw w Pucharze Świata jest trzeci (ex aequo z Kamilem Stochem), za Gregorem Schlierenzauerem i Mattim Nykänenem, pod względem liczby zwycięstw w zawodach Pucharu Świata (w momencie zakończenia kariery był to drugi wynik po Nykänenie). Pod względem liczby miejsc na podium Małysz jest trzeci. Lokaty w pierwszej trójce konkursów zajmował 92 razy i w klasyfikacji ustępuje miejsca Finowi Janne Ahonenowi, który stawał na podium 108 razy oraz Stefanowi Kraftowi, który dalej jest aktywnym skoczkiem (96 podiów).
Puchar Świata.
Adam Małysz, który w sumie ma na swoim koncie 39 wygranych w Pucharze Świata, jest jednym z dwóch skoczków narciarskich w historii (obok Mattiego Nykänena – 46 wygranych konkursów), który czterokrotnie zwyciężył w klasyfikacji generalnej Pucharu Świata.
Zwycięstwa w konkursach indywidualnych Pucharu Świata chronologicznie.
Małysz, mając na koncie 39 zwycięstw, jest trzecim zawodnikiem w historii pod względem liczby zwycięstw w konkursach Pucharu Świata, za Gregorem Schlierenzaurem i Mattim Nykänenem. Jako jedyny skoczek narciarski pięć razy wygrał zawody Pucharu Świata na skoczni Holmenkollbakken w Oslo. Nikt poza Małyszem nie zwyciężył trzykrotnie w jednym roku na mamuciej skoczni w słoweńskiej Planicy.
Miejsca na podium w konkursach indywidualnych Pucharu Świata chronologicznie.
Adam Małysz 92 razy stawał na podium zawodów Pucharu Świata (lepszy jest tylko Janne Ahonen – 108), z czego 39 na najwyższym jego stopniu.
Oprócz tego 27 razy był drugi i 26-krotnie zajmował najniższy stopień podium. Najwięcej razy w pierwszej trójce konkursu był klasyfikowany podczas zawodów rozgrywanych w Zakopanem (ośmiokrotnie), w Kuopio, Oslo i Planicy (siedmiokrotnie), natomiast sześciokrotnie stawał na podium na skoczniach w Lahti i Titisee-Neustadt.
Miejsca na podium w konkursach drużynowych Pucharu Świata chronologicznie.
Adam Małysz czterokrotnie stawał na podium zawodów drużynowych Pucharu Świata, zajmując z reprezentacją Polski raz drugie i trzy razy trzecie miejsce.
Miejsca w poszczególnych konkursach drużynowych Pucharu Świata.
W sezonach 1993/1994–2000/2001 obowiązywała inna punktacja za konkurs Pucharu Świata.
Puchar Świata w lotach.
Miejsca w klasyfikacji generalnej.
Miejsca Adama Małysza w Pucharze Świata w lotach narciarskich:
Letnie Grand Prix w skokach narciarskich.
Adam Małysz jako jeden z dwóch skoczków narciarskich w historii trzykrotnie wygrał Letnie Grand Prix na igelicie. Oprócz niego dokonał tego Thomas Morgenstern.
Zwycięstwa w konkursach indywidualnych LGP chronologicznie.
Adam Małysz trzynastokrotnie wygrywał konkursy zaliczane do Letniego Grand Prix, a całą klasyfikację trzykrotnie. Trzy z tych zwycięstw odniósł w Zakopanem. Poniżej lista zwycięstw uszeregowana chronologicznie:
Miejsca na podium w konkursach indywidualnych LGP chronologicznie.
Oprócz 13 zwycięstw Adam Małysz piętnastokrotnie stawał na podium w zawodach o Letnie Grand Prix – ośmiokrotnie na drugim i siedmiokrotnie na trzecim stopniu. Pełna lista wszystkich miejsc Adama Małysza na podium, włącznie z pierwszymi lokatami, poniżej:
Miejsca na podium w konkursach drużynowych LGP chronologicznie.
Adam Małysz dwukrotnie stanął na podium zawodów drużynowych Letniego Grand Prix, zajmując z reprezentacją Polski trzecie miejsce w 2004 i pierwsze miejsce w 2010 roku w konkursach w Hinterzarten w Niemczech.
Miejsca w poszczególnych konkursach drużynowych LGP.
Do sezonu 2000 obowiązywały inne punktacje za konkurs.
Mistrzostwa Polski w skokach narciarskich.
Małysz 39 razy zdobył indywidualny tytuł mistrza Polski seniorów w skokach narciarskich (21 zimą i 18 latem), sześciokrotnie zdobywał srebro (6 zimą) i dwukrotnie brąz (jeden latem i jeden zimą). W ramach drużynowych konkursów mistrzostw Polski zdobył 8 złotych medali, 5 srebrnych oraz jeden brązowy.
W mistrzostwach Polski juniorów Adam Małysz zdobył sześć indywidualnych medali (3 złote, 2 srebrne, 1 brązowy) oraz 3 złote w rywalizacji zespołowej.
Jako kombinator norweski w mistrzostwach Polski juniorów, juniorów młodszych i młodzików w kombinacji norweskiej wywalczył 5 złotych, 1 srebrny oraz 1 brązowy medal.
Zimowe mistrzostwa Polski seniorów w skokach narciarskich.
Adam Małysz uczestniczył w 31 indywidualnych konkursach zimowych mistrzostw Polski w skokach narciarskich. Zdobył 21 tytułów mistrza Polski, sześć razy był drugi i raz trzeci. Łącznie zdobył 28 medali.
Letnie mistrzostwa Polski seniorów w skokach narciarskich.
Adam Małysz zdobył 18 złotych medali indywidualnych letnich mistrzostw Polski w skokach narciarskich oraz dwa srebrne medale i jeden brązowy; łącznie 21 medali
Kariera w sportach motorowych.
22 kwietnia 2011 na Torze Wyścigów Konnych Służewiec Adam Małysz ogłosił, iż dołączył do zespołu RMF Caroline Team i ze swoim pilotem Rafałem Martonem samochodem Porsche Cayenne wezmą udział w kilku rajdach, a jego głównym celem będzie Rajd Dakar.
W maju Małysz miał wziąć udział w Volkswagen Scirocco R-Cup na torze Red Bull Ring, jednak nie doszło to do skutku. W czerwcu, z pilotem Albertem Gryszczukiem wziął udział w rajdzie Drezno-Wrocław, jednak nie był klasyfikowany – wystartował z numerem 000 i otworzył rajd we Wrocławiu.
Podczas debiutu Orzeł z Wisły osiągnął drugi czas, dzień później ponownie wystartował. Jechał w klasie cross-country, trasa rajdu dla tej grupy kierowców zakończyła się po pokonaniu ok. 200 km w Żaganiu, Małysz pokonał ok. 120 km odcinków specjalnych.
9 sierpnia Małysz pomyślnie zdał egzamin przed komisją Polskiego Związku Motorowego i otrzymał licencję kierowcy rajdowego uprawniającą do startów we wszystkich rajdach terenowych. 15 września na poligonie wojskowym w Żaganiu Małysz pobił rekord prędkości jazdy samochodem w terenie.
Podczas pierwszego etapu Rajdu Dakar 2012 zajął 70. miejsce. Po czterech etapach awansował na 40. pozycję w klasyfikacji generalnej. Podczas jedenastego etapu doznał poważnej awarii sprzęgła, która spowodowała wielogodzinne opóźnienie i ukończenie go na 67. pozycji.
Ostatecznie pierwszy w karierze Rajd Dakar ukończył na 38. pozycji w klasyfikacji generalnej, ze stratą ponad 29 godzin do zwycięzcy, po czym opuścił RMF Caroline Team. Do rajdu Dakar 2013 Małysz przystąpił z nowym samochodem – Toyotą Hilux zbudowaną i serwisowaną przez belgijską firmę Overdrive Racing. Rajd Adam Małysz i Rafał Marton ukończyli na 15. pozycji, ze stratą ponad 6 godzin do zwycięzcy.
13 marca 2013 Małysz dołączył do zespołu Orlen Team. 14 kwietnia 2013 odniósł pierwsze w karierze kierowcy rajdowego zwycięstwo. Tego dnia okazał się lepszy w rajdzie Tolimpex Cup na Węgrzech.
W październiku 2016 roku, przy okazji rozpoczęcia ponownej współpracy z Polskim Związkiem Narciarskim, poinformował o przerwie w uczestnictwie w rajdach samochodowych związanej z objęciem w nim stanowiska dyrektora kadry w skokach narciarskich i kombinacji norweskiej oraz niezadowalającymi wynikami.
Kultura masowa, media i inna działalność.
Sukcesy Adama Małysza w Pucharze Świata 2000/2001 spowodowały wzrost zainteresowania skokami narciarskimi w Polsce, z kolei sam Małysz stał się jednym z najpopularniejszych polskich sportowców oraz znalazł się w centrum uwagi mediów i opinii publicznej.
Adam Małysz w mediach.
W listopadzie 2011 roku został ekspertem Pucharu Świata w skokach narciarskich na antenie Eurosportu, a od sezonu 2012/13 komentował zawody skoków narciarskich dla polskiego oddziału tej telewizji. Podczas Zimowych Igrzysk Olimpijskich 2014 był jednym z ekspertów Telewizji Polskiej. W 2015 został felietonistą Przeglądu Sportowego.
W listopadzie 2016 został ekspertem i komentatorem skoków narciarskich w TVP, kończąc tym samym współpracę z Eurosportem.
Management i reklama.
Menedżerem Adama Małysza był Edi Federer, austriacki sportowiec i przedsiębiorca, zaproszony do Polski w 1996 przez Czecha Pavla Mikeskę, ówczesnego trenera kadry polskich skoczków. Mikeska zdradził wówczas Federerowi, że „ma skoczka o wielkim potencjale” – 18-letniego Adama Małysza. Koncern Red Bull (należący do salzburskiego przemysłowca i miliardera Dietricha Mateschitza), dzięki staraniom Federera, był oficjalnym sponsorem Adama Małysza . Wziął on udział w wielu kampaniach reklamowych i marketingowych.
W okresie kariery w sportach motorowych, sponsorem Małysza był także PKN Orlen.
Adam Małysz znajdował się także na liście najbogatszych Polaków show-biznesu Forbes:
Działalność w Polskim Związku Narciarskim.
Od października 2016 r. pełni funkcję dyrektora-koordynatora PZN ds. skoków narciarskich i kombinacji norweskiej. W ramach swoich obowiązków odpowiada za tworzenie programów szkoleniowych, koordynację współpracy między kadrami i doradztwo w kwestiach sprzętowych.
W maju 2022 został kandydatem na stanowisko prezesa PZN, zaś na Walnym Zjeździe Sprawozdawczo-Wyborczym Delegatów PZN, odbywającym się 25 czerwca 2022 w Krakowie, został wybrany nowym prezesem Związku.
Galeria trofeów.
W 2007 roku w Wiśle otwarto galerię trofeów sportowych i pamiątek związanych z Adamem Małyszem.
Fundacja Izabeli i Adama Małyszów.
25 kwietnia 2002 wraz z żoną Izabelą założył fundację wspierającą rozwój dzieci uzdolnionych sportowo, m.in. poprzez udostępnienie sprzętu sportowego oraz zaangażowanie trenerów. Pomagała również sportowcom, którzy uprawiając sport, stali się niepełnosprawni, organizując rehabilitacje fizyczne i psychologiczne. Fundacja wspierała finansowo szkoły, kluby sportowe, domy dziecka oraz przedsięwzięcia charytatywne. 1 stycznia 2008 fundacja zawiesiła swoją działalność na czas nieokreślony.

</doc>
<doc id="12845" url="https://pl.wikipedia.org/wiki?curid=12845" title="Prawa zachowania">
Prawa zachowania

Prawa zachowania – prawa fizyki stwierdzające, że w układach fizycznych izolowanych od otoczenia określone wielkości fizyczne pozostają stałe. Istnieją zarówno zasady zachowania obowiązujące bezwzględnie, jak i zasady zachowania słuszne tylko dla niektórych procesów.
Wielkości zachowywane bezwzględnie to energia, pęd, moment pędu, ładunek elektryczny, a także – według danych doświadczalnych – liczba barionowa i liczba leptonowa.
Do wielkości zachowywanych tylko w niektórych procesach zalicza się parzystość (zachowywana w oddziaływaniach silnych i elektromagnetycznych, a nie zachowywana w oddziaływaniach słabych) oraz izospin (zachowywany jedynie w oddziaływaniach silnych).
Zasady zachowania są związane z niezmienniczością (symetrią) teorii fizycznych względem określonych grup przekształceń. Zasady zachowania energii, pędu i momentu pędu są związane z symetriami czasoprzestrzeni, odpowiednio z: przesunięciami w czasie, przesunięciami w przestrzeni i obrotami; zasada zachowania ładunku elektrycznego jest związana z niezmienniczością względem tzw. transformacji cechowania.

</doc>
<doc id="12846" url="https://pl.wikipedia.org/wiki?curid=12846" title="Ogólna teoria względności">
Ogólna teoria względności

Ogólna teoria względności (OTW) – teoria grawitacji formułowana przez Alberta Einsteina w latach 1907–1915, a opublikowana 20 marca 1916 roku.
Zgodnie z ogólną teorią względności siła grawitacji wynika z lokalnej geometrii czasoprzestrzeni. Aparat matematyczny teorii opiera się na różniczkowym ujęciu geometrii stworzonym przez Gaussa, Riemanna, Christoffela, Ricciego, oraz Levi-Civitę. Podstawy geometrii nieeuklidesowej zostały stworzone przez Janosa Bolyai, ale prawdziwie dojrzałą postać nadał jej uczeń Gaussa, Riemann. Zastosowanie metod geometrii nieeuklidesowej w fizyce zapoczątkował Hermann Minkowski, który w 1907 r. sformułował szczególną teorię względności Einsteina w języku geometrii, wprowadzając pojęcie czterowymiarowej przestrzeni, znanej dziś jako czasoprzestrzeń Minkowskiego.
Teoria Einsteina zbudowana jest na podstawowym fakcie eksperymentalnym, iż masa „bezwładna” i „grawitacyjna” są nieodróżnialne (masa bezwładna to masa występująca w zasadach dynamiki Newtona, a masa grawitacyjna – to masa występująca w prawie powszechnego ciążenia). Fakt ten jest kluczowy, podobnie jak kluczowym do sformułowania szczególnej teorii grawitacji. Teoria ta uogólnia szczególną teorię względności obowiązującą dla inercjalnych układów odniesienia na dowolne, także nieinercjalne, układy odniesienia. Korzysta ona z metod rachunku tensorowego, geometrii nieeuklidesowej, teorii przestrzeni Riemanna.
Droga do OTW, geometrie nieeuklidesowe.
Gauss dostrzegł jako pierwszy, że geometria przestrzeni fizycznej nie musi być euklidesowa. Zauważył on, że możliwe jest budowanie logicznie spójnej i prawidłowej z matematycznego punktu widzenia geometrii, odrzucając piąty z aksjomatów Euklidesa o prostych równoległych. Nigdy jednak nie opublikował swoich przemyśleń na ten temat, uważając, że nie zostaną właściwie zrozumiane. Gauss nie odnosił swoich idei do rzeczywistości fizycznej, a rozwijał je jedynie jako teorie matematyczne.
Za twórcę geometrii nieeuklidesowych uważa się współcześnie Janosa Bolyai, który jako pierwszy ogłosił prace, w których podał przykłady tego rodzaju geometrii. Poważny wkład do tej dziedziny wniósł Georg Riemann, konstruując swoją teorię rozmaitości różniczkowych. Bardzo istotną, choć czysto techniczną rolę otwierającą możliwości budowy OTW Einsteina odegrali Christofel, Ricci i inni twórcy rachunku tensorowego. Znaczący wkład należał zwłaszcza do Bianchiego, który udowodnił tożsamości nazwane jego imieniem.
W życiu codziennym można także zaobserwować geometrie nieeuklidesowe. Na przykład powierzchnia Ziemi jest sferą i jako taka posiada pewną krzywiznę, zaś suma kątów w trójkątach na globusie jest większa niż 180 stopni. Istnieją także pomiary, w przypadku których można bezpośrednio wykryć, że geometria czasoprzestrzeni jest nieeuklidesowa. Przykładem jest doświadczenie Pounda-Rebki (1959), w którym wykryto zmianę długości fali światła pochodzącego od źródła kobaltowego, wznoszącego się przeciwko sile grawitacji na wysokość 22,5 metra, w szybie znajdującym się w Jefferson Physical Laboratory w Harvard University. Także zegary atomowe w satelitach GPS krążących wokół Ziemi muszą uwzględniać poprawkę związaną z efektami grawitacji. Przykłady te jednak nie były dostępne w czasach Gaussa i Riemanna.
OTW Einsteina.
Podstawową ideą teorii względności jest to, że nie możemy mówić o wielkościach fizycznych takich jak prędkość czy przyspieszenie, nie określając wcześniej układu odniesienia, oraz że układ odniesienia definiuje się poprzez wybór pewnego punktu w czasoprzestrzeni, z którym jest on związany. Oznacza to, że wszelki ruch określa się i mierzy względem innych określonych układów odniesienia. W ramach tej teorii, inaczej niż w szczególnej teorii względności, która podawała opis ruchu w inercjalnych (nieprzyspieszających) układach odniesienia, opis ruchu prowadzony jest w dowolnych układach odniesienia, inercjalnych lub nieinercjalnych. Podstawowym założeniem jest takie sformułowanie praw fizycznych i opisu ruchu, aby miały one identyczną postać matematyczną bez względu na używany do opisu układ odniesienia, stąd konieczność zastosowania rachunku tensorowego. Jednym z postulatów ogólnej teorii względności jest zasada równoważności, mówiąca, że nie można (lokalnie) rozróżnić spadku swobodnego w polu grawitacyjnym od ruchu w układzie inercjalnym. Z postulatu tego wynika, że masa bezwładna i grawitacyjna są sobie równoważne. Dokładniej równość mas: grawitacyjnej i bezwładnej określana jest mianem słabej zasady równoważności (WEP), natomiast pełna zasada równoważności Einsteina głosi, że wynik dowolnego, lokalnego doświadczenia niegrawitacyjnego jest niezależny od prędkości swobodnie spadającego układu odniesienia i jest zgodny z przewidywaniami STW (tzw. lokalna niezmienniczość lorentzowska) i wynik ten jest niezależny od miejsca i czasu (tzw. lokalna niezmienniczość na położenie). W badaniach wykazano, że ogólna teoria względności jest sprzeczna z zasadą Macha.
OTW mówi, że z daną dokładnością można definiować jedynie lokalne układy odniesienia, dla skończonych przedziałów czasu i ograniczonych obszarów w przestrzeni. Jest to analogia z rysowaniem map fragmentów powierzchni Ziemi – nie można sporządzić mapy obejmującej całą powierzchnię Ziemi bez deformacji. Zasady dynamiki Newtona są w ogólnej teorii względności zachowane w lokalnych układach odniesienia. W szczególności cząstki, na które nie działa żadna siła, poruszają się po liniach prostych w lokalnych inercjalnych układach odniesienia. Jednak jeżeli linie te się przedłuży, to nie otrzymujemy linii prostych, lecz krzywe zwane geodezyjnymi. Dlatego też pierwsza zasada dynamiki Newtona zostaje zastąpiona przez zasadę poruszania się po geodezyjnej.
Odróżniamy inercjalne układy odniesienia, w których ciała fizyczne nie zmieniają swojego stanu ruchu, jeżeli nie oddziałują z żadnym innym ciałem fizycznym, od nieinercjalnych układów odniesienia, w których poruszające się ciała mają przyspieszenie pochodzące od układu odniesienia. W tych drugich pojawia się pozorna siła wynikająca z przyspieszenia samego układu odniesienia, a nie z oddziaływania z innym ciałem fizycznym. W związku z tym np. odczuwamy siłę odśrodkową wtedy, gdy samochód, będący naszym układem odniesienia, skręca. Podobnie obserwujemy Efekt Coriolisa i tzw. siłę odśrodkową wtedy, gdy układem odniesienia jest ciało będące w ruchu obrotowym (na przykład bąk-zabawka lub Ziemia). Zasada równoważności w ogólnej teorii względności mówi, że w układzie lokalnym nie można przeprowadzić doświadczenia, dzięki któremu dałoby się odróżnić spadek swobodny w polu grawitacyjnym od ruchu jednostajnego przy braku pola grawitacyjnego. Mówiąc w skrócie, w układzie odniesienia związanym z ciałem spadającym swobodnie nie ma grawitacji. Oznacza to, że obserwowana na powierzchni Ziemi grawitacja jest siłą obserwowaną w układzie odniesienia związanym z materią na powierzchni, która nie jest „wolna”, lecz na którą oddziałuje materia z wnętrza Ziemi i sytuacja ta jest analogiczna do sytuacji w skręcającym samochodzie.
Matematycznie, Einstein modeluje czasoprzestrzeń przy pomocy czterowymiarowej pseudoriemannowskiej rozmaitości, a z jego równania pola wynika, że krzywizna rozmaitości w punkcie jest bezpośrednio związana z tensorem napięć-energii w tym punkcie; tensor ten jest miarą gęstości materii i energii. Krzywizna określa sposób, w jaki materia się porusza, a materia określa sposób, w jaki przestrzeń się zakrzywia. Równanie pola nie jest dowiedzione w sposób jednoznaczny i istnieje możliwość zaproponowania innych modeli, pod warunkiem, że nie będą stały w sprzeczności z obserwacjami.
Ogólna teoria względności wyróżnia się spośród innych teorii grawitacji swoją prostotą powiązania materii i krzywizny, chociaż wciąż nie istnieje teoria unifikacji pomiędzy ogólną teorią względności a mechaniką kwantową i nie potrafimy zastąpić równania pola bardziej ogólnym prawem kwantowym. Niewielu fizyków wątpi w to, że taka teoria wszystkiego będzie zawierała w sobie ogólną teorię względności, tak jak ogólna teoria względności zawiera w sobie prawo powszechnego ciążenia Newtona w zakresie nierelatywistycznym.
Równanie pola Einsteina zawiera parametr zwany stałą kosmologiczną formula_1 która została wprowadzona przez Einsteina po to, aby Wszechświat pozostał statyczny (tzn. nierozszerzający i niezapadający się). Ta próba zakończyła się niepowodzeniem z dwóch powodów: statyczny Wszechświat opisywany przez tę teorię byłby niestabilny, co więcej, obserwacje prowadzone przez Hubble’a dekadę później pokazały, że nasz Wszechświat nie jest statyczny, lecz się rozszerza. Dlatego też zrezygnowano ze stałej formula_1 lecz ostatnie obserwacje supernowych typu Ia wskazują na to, że być może należy ją ponownie wprowadzić do równań.
Równania teorii.
Ogólna teoria względności wiąże geometrię czasoprzestrzeni z rozkładem materii. Czasoprzestrzeń jest zbiorem punktów (dokładniej rozmaitością różniczkową), której punktom przyporządkowuje się cztery współrzędne formula_3 Odległość między dwoma punktami o współrzędnych formula_4 i formula_5 zadaje:
Gdy czasoprzestrzeń jest globalnie płaska – teoria przechodzi w szczególną teorię względności. W tym przypadku tensor metryczny
opisuje czasoprzestrzeń Minkowskiego. Poczucie lokalnej płaskości zakrzywionej czasoprzestrzeni (zasada równoważności) oznacza możliwość przejścia do takiego układu współrzędnych, by
Pola formula_6 nazywamy polami reperów. Cała informacja o zakrzywieniu czasoprzestrzeni zawarta jest w tych polach. Z punktu widzenia matematycznego pola reperów są formami różniczkowymi.
Formy te można przeskalować (lokalna transformacja cechowania), a tensor metryczny nie ulega zmianie
gdzie formula_7 są macierzami Lorentza tworzącymi grupę Lorentza.
Linie najkrótsze łączące dwa punkty (linie geodezyjne) nie są już liniami prostymi. Spełniają one równanie
gdzie formula_8 jest symbolem Christoffela
W OTW ciała w spadku swobodnym poruszają się po liniach geodezyjnych, gdy ich masa i rozmiary są zaniedbywalnie małe.
W czasoprzestrzeni Minkowskiego wszystkie symbole Christoffela się zerują i linie najkrótsze są prostymi.
Zakrzywienie czasoprzestrzeni określa tensor krzywizny formula_9 i związany z nim tensor krzywizny Ricciego
oraz skalar krzywizny Ricciego formula_10 Oczywiście w płaskiej czasoprzestrzeni Minkowskiego wszystkie te wielkości są równe zero.
Równanie Einsteina opisuje związek między zakrzywieniem czasoprzestrzeni (grawitacją) opisanym tensorem metrycznym formula_11 a rozkładem materii opisanym tensorem energii-pędu formula_12 Równanie Einsteina można wyprowadzić z ekstremum całki działania dla pola grawitacyjnego. Równanie to ma następującą postać:
gdzie:
Natomiast formula_15 opisuje metrykę rozmaitości i jest tensorem symetrycznym 4 × 4, ma więc 10 niezależnych składowych. Biorąc pod uwagę dowolność przy wyborze czterech współrzędnych czasoprzestrzennych, liczba niezależnych równań wynosi 6.
Rozkład materii w czasoprzestrzeni opisany jest przez tensor energii-pędu
gdzie formula_22 jest wektorem jednostkowym formula_23 formula_24 jest przestrzennym rozkładem energii, a formula_25 rozkładem ciśnienia.
W próżni gdy formula_26 i formula_27 rozwiązaniem równań Einsteina jest przestrzeń Ricci płaska (formula_28 np. przestrzeń Minkowskiego, ale również rozwiązanie z metryką Karla Schwarzschilda).
Jeżeli układ fizyczny opisuje ciało masywne, a ciśnienie jest niewielkie, wtedy formula_29 i źródłem grawitacji jest tylko rozkład masy formula_30 W granicy gdy prędkość światła w próżni formula_19 dąży do nieskończoności, otrzymujemy teorię grawitacji Newtona.
Potwierdzenie teorii.
Anomalie orbity Merkurego.
Świadectwem przeciw teorii Newtona i jednocześnie za teorią Einsteina była niezgodność ruchu Merkurego. Ruch tej planety wykazywał niewielkie odchylenia znane od drugiej połowy XIX stulecia, względem obliczeń wynikających z newtonowskich praw ruchu i grawitacji. Anomalia orbity Merkurego jest bardzo niewielka, wynosi 43 sekundy kątowe na każde sto lat. Żadne z proponowanych na gruncie teorii Newtona rozwiązań tego problemu nie okazało się skuteczne. W roku 1916 Einstein wyjaśnił ową niezgodność przy pomocy praw grawitacji w ogólnej teorii względności.
Ruch światła w zakrzywionej czasoprzestrzeni.
Newton stwierdził w swojej "Optyce", że światło może ulegać wpływowi grawitacji. Na mocy swojej teorii grawitacji przyjął on, że światło gwiazdy przechodzące w pobliżu Słońca na swojej drodze ku Ziemi odchyli się skutkiem grawitacji o kąt 0,87″. Do zaobserwowania tego zjawiska niezbędne jest wystąpienie zaćmienia Słońca. Teoria Einsteina przewiduje, że odchylenie to będzie dwukrotnie większe, czyli 1,74″.
Obserwacje potwierdziły (w granicach błędu eksperymentalnego), obliczenia wynikające z teorii Einsteina i po dziś dzień uważane są za jej kluczowe świadectwo. Powyższy eksperyment przeprowadzano wielokrotnie, przy jednoczesnym uściślaniu wyników pomiaru. Znacznie dokładniejsze pomiary przeprowadzone w latach 70. przez Hulsego i Taylora, przy obserwacji podwójnego układu pulsarów, również potwierdziły przewidywania tej teorii.
Do tej pory nie istnieją dane obserwacyjne mogące podważyć ogólną teorię względności, choć wiadomo, że nawet przy próbach połączenia z mechaniką kwantową, nie tłumaczy ona obecnego kształtu Wszechświata (patrz ciemna materia i ciemna energia).
Zobacz też.
Aparat matematyczny
Linki zewnętrzne.
Polskojęzyczne
Anglojęzyczne

</doc>
<doc id="12847" url="https://pl.wikipedia.org/wiki?curid=12847" title="Broń">
Broń

Broń – termin występuje w dwóch znaczeniach:
Definicja broni nie została do dziś ustalona i wymyka się próbom jednoznacznego określenia. Łatwiej natomiast definiowalne jest pojęcie "systemu broni", który tworzy kombinacja broni oraz wyposażenia używanego do dostarczenia jej destrukcyjnej siły do celu. System broni składa się z:
Nowe rodzaje broni.
Prowadzone są badania nad nowymi rodzajami broni np. laserową (zob. laser), innymi broniami energetycznymi, działami magnetycznymi, bronią wykorzystującą impuls elektromagnetyczny (EMP), środkami walki elektronicznej (WRE, ang. EW) itd. Rozwijane są projekty robotów bojowych.

</doc>
<doc id="12849" url="https://pl.wikipedia.org/wiki?curid=12849" title="Międzynarodówka (organizacja)">
Międzynarodówka (organizacja)

Międzynarodówka – organizacja międzynarodowa skupiająca partie polityczne o podobnej orientacji ideologicznej. Pierwsze międzynarodówki były tworzone w XIX wieku przez organizacje socjalistyczne.
Międzynarodówki socjalistyczne i komunistyczne:
Ważniejsze istniejące międzynarodówki:
Ponadto działają np. Zieloni Globalni, Progressive Alliance czy Pirate Parties International.

</doc>
<doc id="12850" url="https://pl.wikipedia.org/wiki?curid=12850" title="Międzynarodówka Socjalistyczna">
Międzynarodówka Socjalistyczna

Międzynarodówka Socjalistyczna (ang. "Socialist International", SI, fr. "l’Internationale Socialiste", IS, hiszp. "Internacional Socialista", IS) – największa z istniejących obecnie międzynarodówek, skupiająca partie socjaldemokratyczne, socjalliberalne i socjalistyczne. Siedzibą Międzynarodówki Socjalistycznej jest Londyn.
Historia.
Międzynarodowe organizacje ruchu robotniczego przed 1940 rokiem.
Pierwszą międzynarodową organizacją reprezentującą klasą robotniczą było Międzynarodowe Stowarzyszenie Robotników. Międzynarodowe Stowarzyszenie Robotników zostało założone w Londynie dnia 28 września 1864 roku przez grupy polityczne i związki zawodowe o charakterze socjalistycznym i anarchistycznym. Napięcia między rewolucyjnymi anarchistami a umiarkowanymi marksistami doprowadziły do rozwiązania Stowarzyszenia w 1876 roku.
Największą następczynią MSR była Druga Międzynarodówka utworzona w Paryżu w dniu 14 lipca 1889 roku, międzynarodówka ta działała jako stowarzyszenie partii o profilu socjalistycznym. Różnice które powstały w ruchu robotniczym w okresie I wojny światowej doprowadziły do rozwiązania organizacji w 1916 roku.
Podczas spotkania w Bernie w lutym 1919 roku powstała Międzynarodowa Komisja Socjalistyczna, inicjatorami powołania grupy byli zwolennicy reaktywacji II Międzynarodówki. W marcu 1919 roku partie komunistyczne powołały konkurencyjną względem socjaldemokracji Międzynarodówkę Komunistyczną. Partie które nie chciały dołączyć ani do reformistycznej Międzynarodowej Komisji Socjalistycznej ani leninowskiego Kominternu powołały Międzynarodową Wspólnotę Pracy Partii Socjalistycznych (zwana też "Międzynarodówką Wiedeńską"), do inauguracji nowej międzynarodówki doszło 27 lutego 1921 roku na socjalistycznej konferencji w Wiedniu.
W maju 1923 roku na spotkaniu w Hamburgu doszło do oficjalnego połączenia Międzynarodowej Komisji Socjalistycznej i Międzynarodowej Wspólnoty Pracy Partii Socjalistycznych, w wyniku zjednoczenia się tychże organizacji utworzono nową organizację pod nazwą Socjalistyczna Międzynarodówka Robotnicza.
Geneza.
W 1940 roku zaprzestała działalności Socjalistyczna Międzynarodówka Robotnicza, co było spowodowane wybuchem II wojny światowej. Gdy wojna się kończyła, potrzebna była koordynacja działalności międzynarodową organizacja politycznych ruchu robotniczego. Dlatego w grudniu 1944 zwołano pierwszą Konferencję Partii Robotniczych, w której uczestniczyli delegaci Francuskiej Sekcji Międzynarodówki Robotniczej, Szwedzkiej Socjaldemokratycznej Partii Robotniczej, oraz niektóre partie na uchodźstwie (Polskiej Partii Socjalistycznej, Norweskiej Partii Robotniczej, Belgijskiej Partii Robotniczej oraz Włoskiej Partii Socjalistycznej)
Konferencja w Clacton-on-Sea (maj 1945) uwidocznił się podział na organizacje prokomunistyczne i dążące do odbudowy niezależnej międzynarodówki. Na konferencji w Bournemouth (3-8 listopada 1946) oficjalnie rozwiązano poprzednie struktury Międzynarodówki Partii Socjalistycznych i Robotniczych.
Konferencja w Antwerpii (21 listopada 1 grudnia 1947) zakończyła się przyjęciem Socjaldemokratycznej Partii Niemiec, mimo niechęci Polskiej Partii Socjalistycznej, Czechosłowackiej Partii Socjaldemokratycznej, Socjaldemokratycznej Partii Węgier, Robotniczej Partii Ziemi Izraela i Bundu. Konferencja zakończyła się utworzeniem Komitetu Międzynarodowej Konferencji Socjalistycznej.
Konferencja w Londynie (20-23 marca 1948) okazała się ostatecznym rozdzieleniem frakcji prokomunistycznej i niezależnej, nakazano także opuszczenie przez Włoską Partię Socjalistyczną Kominformu. Konferencja w Baarn (14-17 maja 1949) utworzyła Unię Socjalistyczną Europy Środkowo-Wschodniej, pod przewodnictwem Zygmunta Zaremby (członka i lidera Polskiej Partii Socjalistycznej).
Historia.
Powołanie organizacji.
Międzynarodówka Socjalistyczna powstała na I Kongresie w 1951 roku we Frankfurcie nad Menem. Największą rolę w powołaniu Międzynarodówki miała brytyjska Partia Pracy i to właśnie ta partia przez wiele lat w dużym stopniu wyznaczała kierunek organizacji. W latach 80. większe wpływy zdobyli socjaldemokraci z Niemiec, Szwecji i Austrii a tym samym zmalały wpływy socjaldemokratów francuskich i belgijskich
Podstawą nowej organizacji była dotychczas istniejąca COMISCO. Od tego czasu odbyły się aż 23 kongresy IS. Przyjęto tam także deklarację ideową pod nazwą: Cele i zadania demokratycznego socjalizmu, których współautorem był Adam Ciołkosz, lider Polskiej Partii Socjalistycznej. Międzynarodówka w niewielkim stopniu jest kontynuacją wcześniej istniejących; przedwojennej Socjalistycznej Międzynarodówki Robotniczej i działającego od 1947 roku COMISCO (Komitet Międzynarodowych Konferencji Socjalistycznych). Międzynarodówka odwołuje się do tradycji II Międzynarodówki i Socjalistycznej Międzynarodówki Robotniczej.
Na pierwszym kongresie Międzynarodówki uchwalono deklarację organizacji - "O celach i zadaniach socjalizmu demokratycznego". Teorią ideową organizacji został socjalizm demokratyczny, który zdaniem autorów deklaracji charakteryzował się; powszechną i pozaklasową demokracją, połączeniem prywatnej własności z państwowym programowaniem, solidarnością społeczną oraz harmonią grupowych i jednostkowych interesów.
Przy Międzynarodówce działała Unia Socjalistyczna Europy Środkowo-Wschodniej, skupiała ona partie socjalistyczne z dziewięciu krajów bloku wschodniego (znajdujące się na emigracji).
Działalność Międzynarodówki.
Po II wojnie światowej, Międzynarodówka wspomagała grupy socjaldemokratyczne walczące z autorytarnymi rządami państw bloku wschodniego, Portugalii i Hiszpanii. Do Kongresu w Genewie z 1976 roku, Międzynarodówka miała kilku pozaeuropejskich członków i nie prowadziła formalnego zaangażowania w Ameryce Łacińskiej.
Międzynarodówka jest systematycznie powiększana o nowe partie (równocześnie niektóre partie są z tej organizacji usuwane). Na XIV Kongresie w Vancouver w Kanadzie w 1978 roku przyjęto trzech nowych członków MS - Partię Ludowo-Republikańską (Turcja), Ruch Ludowo-Rewolucyjny Salwadoru oraz Partię Pracy Barbadosu. Na XV Kongresie w Madrycie w 1980 roku przyjęto 6 nowych partii - Partię Rewolucji Lutowej (Paragwaj), Partię Lewicy Demokratycznej (Ekwador), Front Postępowy (Górna Wolta, obecne Burkina Faso), Gwatemalską Partię Socjaldemokratyczną, Ruch „New Jewel” (Grenada) oraz Partię Postępowych Socjalistów (Liban). W czasie XV Kongresu statu partii doradczych uzyskały partie tj. Ludowy Ruch Wyborczy Aruby, Ruch Nobo (Antyle) i Zjednoczona Partia Robotnicza Izraela.
Międzynarodówka stanowi centrum koordynacji informacyjnej a do pewnego stopnia ideologicznej światowego ruchu socjaldemokratycznego. Międzynarodówka nie stanowi jednak organu kierowniczego ruchu. Rezolucje Międzynarodówki nie mają mocy obowiązującej partie członkowskie organizacji. Partie skupione w grupie zajmują często odmienne stanowiska w kwestiach ideowych i międzynarodowych.
W 1969 roku partie skupione w MS liczyły 15 milionów członków (w tym 83% z Europy), w latach 80. na partie skupione w MS głosowało 78,5 milionów wyborców (z czego 56 milionów w Europie a więc 31% wszystkich Europejczyków oddawało głos na socjaldemokratów - dla porównania na chadeków zagłosowało 19,5% głosujących, na komunistów 11% a na liberałów 10,7%.
Najbardziej wpływowymi partiami MS były m.in. Szwedzka Socjaldemokratyczna Partia Robotnicza sprawująca władzę przez niemal 50 lat czy Norweska Partia Pracy rządząca nieprzerwanie przez 30 lat. W latach 1945-1970 sześć największych partii MS w Europie zachodniej (UK, Norwegia, RFN, Austria, Dania i Szwecja) łącznie 47-krotnie wzięło udział w wyborach parlamentarnych, w tym w 43 przypadkach partie te zdobył więcej niż 33%, 36 razy przekroczyły barierę 40%.
22 maja 2013 roku, Socjaldemokratyczna Partia Niemiec wraz z kilkoma innymi partiami socjaldemokratycznymi założyła Sojusz Postępowy, nową organizację międzynarodową mającą mieć charakter uzupełniający w stosunku do Międzynarodówki Socjalistycznej.
Aktywność międzynarodowa MS.
Kraje Trzeciego Świata.
Od lat 70. MS prowadzi ożywioną politykę w krajach Trzeciego Świata. W marcu 1970 roku w Welington utworzono Biuro Koordynacyjne Partii Socjaldemokratycznych Krajów Azji, Australii i Oceanii. Biuro zyskało status autonomicznej organizacji regionalnej Międzynarodówki. Siedzibą biura wybrano Singapur. W 1980 i 1981 roku w Dakarze odbyły się posiedzenia Komitetu Konstytucyjnego Afrykańskiej Międzynarodówki Socjalistycznej, w posiedzeniu udział wzięło sześć partii.
Poszczególne partie międzynarodówki był aktywne w różnych regionach świata, np. partia włoska i austriacka była aktywna głównie na terenie Maghrebu czy Bliskiego Wschodu, partia brytyjska i szwedzka zajmowała się południem Afryki, powiązana z SPD Fundacja F. Elberta działała na terenie Ameryki Łacińskiej a partie australijska i izraelska zajmowała się Azją.
Na XIII Kongresie MS w Genewie w listopadzie 1976 roku podjęto decyzję o zwiększeniu roli Biura Międzynarodówki. Pierwsze posiedzenia zreformowanego Biura odbyło się w Oslo w marcu 1977 roku. Na posiedzeniu w Oslo najwięcej czasu poświęcono na omówienie problemów polityki gospodarczej a głównie polityki zatrudnienia. W kwietniu szefowie rządów wraz z liderami partii centrolewicowych spotkali się w Amsterdamie gdzie przed belgradzkim spotkaniem KBWE, omówiono kwestie polityki odprężeniowej. W czerwcu 1977 roku Biuro obradowało w Rzymie, na posiedzeniu poruszono głównie kwestię rozbrojenia. W październiku Biuro spotkało się w Madrycie, w czasie trwania spotkania wysłuchano sprawozdań przewodniczących Misji Sondażowych Międzynarodowych - na Bliski Wschód (Bruno Kreisky) i Afryki południowej (Olof Palme). Sekretarz generalny Berndt Carlsson zrelacjonował przebieg konferencji specjalnej poświęconej sytuacji w Chile która odbyła się w holenderskim Rotterdamie w sierpniu 1977 roku.
Pod koniec 1977 roku odbyły się dwie konferencje MS - jedna poświęcona problemowi energetycznemu (odbyła się w Marsylii) oraz bezrobociu wśród młodych (w Zurychu). W grudniu 1977 roku odbyła się konferencja przywódców partyjnych w Tokio. Narada w Tokio była pierwszym takim spotkaniem MS poza Europą. W konferencji tokijskiej udział wzięło 77 delegatów z 21 partii socjalistycznych z 20 krajów świata. Celem konferencji było ustalenie kontaktów partii MS z partiami regionu Oceanu Spokojnego i Azji.
Działalność rozbrojeniowa.
W 1970 roku MS zwołało w Helsinkach konferencję poświęconą sprawom rozbrojenia. W rozmowach udział wzięli przedstawiciele rządów USA i ZSRR. Propozycje MS zyskały poparcie niechętnym socjaldemokratom przedstawicielom ZSRR. Sekretarz Komitetu Centralnego Komunistycznej Partii Związku Radzieckiego Boris Ponomariow stwierdził, że "w podejściu do walki o rozbrojenie komuniści i socjaldemokraci zajęli w ostatnich czasach bardzo zbliżone stanowisko[...] różnice ideologiczne nie mogą stanowić przeszkody w takiej współpracy".
W maju 1970 roku Biuro Międzynarodówki utworzyło grupę roboczą ds. rozbrojenia. Do grupy weszli przedstawiciele 11 partii i sekretarz generalny. Na czele grupy stanął przedstawiciel Socjaldemokratycznej Partii Finlandii Kalevi Sorsa. W maju 1979 roku grupa ta spotkała się w Waszyngtonie z prezydentem USA Jimmym Carterem oraz spotkała się z przedstawicielami demokratów i republikanów. W sierpniu 1979 roku grupa odwiedziła Sri Lankę gdzie spotkała się z przewodniczącym Ruchu Państw Niezaangażowanych Ranasinghe Premadasą. We wrześniu 1979 roku przedstawiciele grupy spotkali się w Nowym Jorku z Kurtem Waldheimem i innymi przedstawicielami Organizacji Narodów Zjednoczonych. Grupa zaplanowała też rozmowy z przedstawicielami Chin jednak rząd tego kraju odmówił przeprowadzenia takowych rozmów. Na jesieni 1979 roku delegacja MS złożyła wizytę z ZSRR gdzie spotkała się z Leonidem Breżniewem, spotkanie było pierwszym nawiązaniem kontaktu na linii MS-KPZR.
Sprawozdanie ze spotkań grupy roboczej ds. rozbrojenia było tematem XV Kongresu MS w Madrycie w lutym 1980 roku. W spotkaniu uczestniczyli przedstawiciele 30 partii. Grupa została rozwiązana a w jej miejsce powołano grupę doradczą MS ds. rozbrojenia i kontroli zbrojeń.
9-10 lutego 1978 roku w Hamburgu odbyło się posiedzenie Biura MS. Spotkaniu przewodził Willy Brandt. Na zakończenie spotkania opublikowano oświadczenie na temat metod walki z terroryzmem oraz uchwałę o rozpoczęciu prac nad nowym programem MS. Nowy program miał dostosować założenia „socjalizmu demokratycznego” do zarówno państw wysoko uprzemysłowionych jak i ruchów socjalistycznych z Afryki, Azji i Ameryki Łacińskiej.
12 lutego 1978 roku w Wiedniu odbyła się konferencja MS z udziałem 21 partii socjalistycznych Europy, obu Ameryk, Afryki oraz Azji. Na konferencji dyskutowano nt. sprawozdania Kesiskiego z „podróży informacyjnej” na Bliskim Wschodzie.
Struktury.
Władzę MS stanowi - Sekretariat, Biuro i Rada oraz Kongres. Kongres stanowi organ najwyższy grupy. Kongres zgodnie ze statutem powinien być zwoływany co dwa lata. Konferencja przywódców partii MS powinna być zwoływana raz w roku natomiast posiedzenia Biura i Komisji Finansowo-Administracyjnej co najmniej dwa razy w roku. W czasie pomiędzy kongresami zwoływana jest Rada Międzynarodówki do której należą partie członkowskie (dawniej też Unia Socjalistyczna Europy Środkowo-Wschodniej).
Sekretariat MS znajduje się w Londynie. W przeszłości Sekretariatem kierowali m.in. Julius Braunthal, Albert Carthy, Hans Janitschek czy Berndt Carlsson. Przewodniczącymi grupy byli m.in. Morgan Philips, Alsing Andersen, Brutno Pittermann, Willy Brandt. Innymi zasłużonymi działaczami socjaldemokracji sprawującymi funkcje w MS byli m.in. Olof Palme (odpowiadał za problemy krajów trzeciego świata), Bruno Kreisky (sprawy Bliskiego Wschodu), Francois Mitterand (działalność ogólna Międzynarodówki). Sekretariat MS odpowiedzialny jest za zwoływanie narad eksperckich, konferencji socjaldemokratycznych czy seminarium międzynarodowych. W Londynie najczęściej raz w roku zbiera się Biuro Międzynarodówki.
Początkowo do Biura MS należały partie z Austrii, RFN, Belgii, Francji, Izraela, Holandii, Kanady, Japonii, Skandynawii (partie z poszczególnych państw na zasadzie rotacji), Włoch, Wielkiej Brytanii a jedno miejsce należało do reprezentacji Azji. Na XXI Kongresie z 1972 roku liczbę członków Biura zwiększono do 18. XIII Kongres wprowadził kolejną zmianę na mocy której w Biurze reprezentowane są wszystkie partie członkowskie.
Do 1976 roku istniały trzy kategoria członkostwa w MS: członkostwo pełnoprawne, członkostwo afiliowane (partie takie brały udział w posiedzeniach kierownictwa MS jednak nie mogły głosować) i status obserwatora (partie te mogły uczestniczyć w posiedzeniach kierownictwa za zgodą prezydium MS). Na XIII Kongresie MS z listopada 1976 roku zmodyfikowano statut organizacji, ustanowiono wówczas nowe kategoria członkostwa w grupie - partie członkowskie (mogą one brać udział w głosowaniach i muszą płacić składki członkowskie), organizacje bratnie (mogą one zabierać głos lecz nie płacą składek członkowskich, są to organizacje tj. Międzynarodowa Rada Kobiet Socjaldemokratek, Międzynarodowy Ruch Sokolski, Międzynarodowy Związek Młodzieży Socjalistycznej), partie z głosem doradczym (mogą one wyłącznie zabierać głos) i organizacje stowarzyszone (mogą one zabierać głos, mają charakter regionalny bądź też międzynarodowy).
Organem prasowym Międzynarodówki jest kwartalnik „Socialist Affairs” (do 1970 roku pod nazwą „The Socialist International Information”). Ośrodkiem koordynacyjnym prasy socjalistycznej jest utworzona w 1953 roku Międzynarodowa Federacja Prasy Socjalistycznej i Demokratycznej.
Budżet MS pochodzi ze składek członkowskich partii.
Przy Międzynarodówce działają afiliowane organizacje takie jak Międzynarodowa Rada Kobiet Socjaldemokratek (centrala w Londynie) i Międzynarodowy Związek Młodzieży Socjalistycznej (centrala w Wiedniu). Rada Kobiet organizuje własne kongresy regionalne na obszarze Afryki i Azji. Organizacja prowadzi działalność edukacyjną - przyznaje kobietom z biednych państw stypendia w Europie i USA. Na obszarze Afryki i Azji ale też Ameryki łacińskiej działalność prowadzi też Związek Młodzieży. Związek organizuje tam seminaria, przyznaje stypendia, organizuje obozy międzynarodowe czy organizuje wycieczki do krajów Europy. W pracach MS jako organizacja brata udział bierze Międzynarodowy Związek Nauczycieli Socjaldemokratów, organizacja ta założona została w 1951 roku.
Z MS związana jest Międzynarodowa Konfederacja Wolnych Związków Zawodowych do której należą głównie związki znajdujące się w zasięgu wpływów socjaldemokracji. Wiele partii członkowskich MS sprawje władzę polityczną nad związkami zawodowymi (poprzez m.in. uczestniczenie w ich kierownictwie liderów socjaldemokracji). Partie z Wielkiej Brytanii i Nowej Zelandii tworzą ze związkami swoiste federacje oparte na zasadzie tzw. członkostwa zbiorowego. Dają one przez to centralą związkowym prawo do głosowania na forum partyjnym.
Ideologia.
Według partii założycieli Międzynarodówki, organizacja dąży do zastąpienia kapitalizmu, socjalizmem demokratycznym. W deklaracji odcięto się od idei rewolucyjnych, deklarując ewolucyjno-parlamentarną drogę reform, ma do tego dojść bez walki klasowej.
Od czasu powstania w 1951 roku, Międzynarodówka zakazywała współpracy swoich członków z komunistami. Do liberalizacji stanowiska antykomunistycznego doszło w latach 70. na skutek dyskusji pomiędzy poszczególnymi partiami. Partie z Francji, Hiszpanii, Belgii, Japonii, Włoch i Finlandii opowiedziały się za możliwą współpracą z ruchem komunistycznym natomiast przeciwko takowej współpracy opowiedziały się m.in. partie z RFN, Austrii i Wielkiej Brytanii. W kwietniu 1972 roku na skutek decyzji Biura Międzynarodówki Socjalistycznej w Amsterdamie przyznano partiom członkowskim swobodę współpracy z innymi partiami politycznymi a więc i komunistami.
Zgodnie z tezami stawianymi przez partie skupione w Międzynarodówce. od połowy lat 50. do końca lat 60. rewolucja naukowo-techniczna w krajach kapitalistycznych spowodowała wyeliminowanie przesłanek walki klasowej. Partie skupione w organizacji opowiadają się za więc za bezkonfliktowym przerastaniem kapitalizmu w państwo opiekuńcze.
Członkowie SI.
Do SI należy ponad 160 partii politycznych i organizacji społecznych, m.in.:
Symbol.
Symbolem organizacji jest czerwona róża i ręka zaciśnięta w pięść, która ją trzyma, dwa symbole socjalizmu i ruchu robotniczego.

</doc>
<doc id="12851" url="https://pl.wikipedia.org/wiki?curid=12851" title="Międzynarodówka Liberalna">
Międzynarodówka Liberalna

Międzynarodówka Liberalna (, LI) – międzynarodówka skupiająca partie liberalne.
Rys historyczny.
Partie liberalne tradycje współpracy ponadnarodowej wywodzą od spotkania grupy liberałów, które odbyło się we Francji w 1823 roku. To na tym spotkaniu uczestnicy przygotowali dokument („Plan liberałów na rzecz wzmocnienia rewolucji”) w którym to zawarli postulaty nawiązania intensywnych stosunków pomiędzy liberałami z innych krajów. Na podstawie tego dokumentu od 1910 r. rozpoczęła się seria regularnych spotkań liberałów z kilkunastu krajów europejskich (najbardziej znanie to: Haga – 1913 r., Genewa – 1924 r.). Na spotkaniu w Genewie z 1924 r. powołano do życia Międzynarodowe Porozumienie Partii Radykalnych i Podobnych Partii Demokratycznych, na czele którego stanął Francuz M.F. Buisson. W 1925 r. do organizacji należało 25 państw m.in. Polska. Spotkania Porozumienia odbywały się do 1934 r. Równolegle istniała Unia Radykalnej i Demokratycznej Młodzieży powstała w roku 1921. Wielu spośród tych, którzy działali w Unii, przystąpiło do Międzynarodówki Liberalnej, stając się jej aktywistami.
W okresie II wojny światowej Międzynarodówka Liberalna nie spotykała się. Idea przywrócenia jej do życia narodziła się w 1946 r. w Brukseli, podczas obchodów 100. rocznicy powstania Belgijskiej Partii Liberalnej – najstarszej partii liberalnej na świecie. 
W dniach 10–14 kwietnia 1947 r., w Oksfordzie w Wadham College odbył się kongres założycielski Międzynarodówki Liberalnej. Wzięli w nim udział członkowie partii liberalnych z 19 krajów. Na kongresie tym został przyjęty podstawowy dokument określający ramy przyszłej współpracy, „Manifest liberalny”.
Do Międzynarodówki Liberalnej należy ok. 70 partii, m.in.:
Siedzibą Międzynarodówki Liberalnej jest Londyn.

</doc>
<doc id="12852" url="https://pl.wikipedia.org/wiki?curid=12852" title="Forma Wszechświata">
Forma Wszechświata



</doc>
<doc id="12853" url="https://pl.wikipedia.org/wiki?curid=12853" title="Najcięższy karabin maszynowy">
Najcięższy karabin maszynowy



</doc>
<doc id="12854" url="https://pl.wikipedia.org/wiki?curid=12854" title="Międzynarodówka Chrześcijańsko-Demokratyczna">
Międzynarodówka Chrześcijańsko-Demokratyczna



</doc>
<doc id="12856" url="https://pl.wikipedia.org/wiki?curid=12856" title="George Campbell Scott">
George Campbell Scott



</doc>
<doc id="12857" url="https://pl.wikipedia.org/wiki?curid=12857" title="Partia Pracy (Wielka Brytania)">
Partia Pracy (Wielka Brytania)

Partia Pracy (ang. "Labour Party", LP), potocznie laburzyści (czyt.: lejburzyści) – brytyjska socjaldemokratyczna partia polityczna powstała w lutym 1900 r. ze zjednoczenia Niezależnej Partii Pracy, Towarzystwa Fabiańskiego i Federacji Socjaldemokratycznej; do 1906 roku pod nazwą Komitet Przedstawicielstwa Robotniczego ("Labour Representation Comittee").
Ideologia.
Partia Pracy została utworzona jako polityczna, parlamentarna reprezentacja związków zawodowych. Oficjalnie miano „socjalistycznej” zyskała na mocy klauzuli partii z 1918 roku (Klauzula IV). Według klauzuli socjalizm postrzegany był jako zobowiązanie do „własności wspólnej” i nacjonalizacji „środków produkcji, dystrybucji i wymiany”. Gdy po II wojnie światowej blisko jedna trzecia brytyjskiego przemysłu znajdowała się w rękach państwa (aż do lat 80.), partia do końca lat 50. odrzuciła postulat uspołecznienia, do zrewidowania programu doszło w dużej mierze dzięki pracy "The Future of Socialism" (1956) Anthony’ego Croslanda – w swojej pracy przedstawił on reformistyczną drogę, którą jego zdaniem powinna obrać Partia Pracy. Jako pierwszy Klauzulę IV usunąć chciał Hugh Gaitskell, jednak jego próba z 1959 roku nie powiodła się, ostatecznie klauzulę usunął Tony Blair w latach 90. XX wieku.
Historycznie zauważalny był duży wpływ ekonomii keynesowskiej, partia domagała się redystrybucji bogactw i zwiększenia interwencjonizmu gospodarczego. W manifeście wyborczym z października 1974 roku model opodatkowania postrzegany był jako środek do realizacji redystrybucji bogactw. Następnie partia zwróciła się w stronę budowy państwa opiekuńczego z rozbudowanym systemem ochrony zdrowia i praw pracowniczych.
Od późnych lat 80. partia przyjęła politykę wolnorynkową, przez co wielu obserwatorów opisuje obecną Partię Pracy jako socjaldemokratyczną lub partię trzeciej drogi (dawniej partia opisywana była jako demokratyczno-socjalistyczna). Według jeszcze innych komentatorów zmiany w Partii Pracy zaszły tak daleko, że niemożliwe jest opisanie jej jako partii socjaldemokratycznej.
Partyjne manifesty wyborcze od 1992 roku nie zawierają terminu "socjalizm". Nowa wersja klauzuli IV w dalszym ciągu potwierdza przynależność Partii Pracy do ruchu socjalizmu demokratycznego. W miejsce publicznej własności przemysłu laburzyści domagają się modelu konkurencyjnego i rynkowego.
Laburyzm nigdy nie kierował się jak inne ruchy socjaldemokratyczne poprzez rewizję marksizmu, jest to związane z odrębnym rodowodem linii laburzystowskiej; jak twierdził Harold Wilson: laburyzm „czerpie daleko więcej z nauk Kościoła metodycznego aniżeli marksizmu”.
Według A.W. Benna „marksizm był od najwcześniejszego okresu otwarcie akceptowany przez Partię Pracy jako jedno z wielu źródeł inspiracji dla ruchu robotniczego, akceptowany wespół, choć w dużo mniejszym stopniu – z chrześcijańskim socjalizmem, owenizmem, tradeunionizmem czy nawet radykalnym liberalizmem”.
Antykomunizm.
Złożonym stanowiskiem przez cały okres zimnej wojny był stosunek Partii Pracy do ruchu komunistycznego, stosunek ten charakteryzowała swoista dwoistość. Z jednej strony partyjni teoretycy odcinają się od marksizmu w sferze ideologicznej, a z drugiej podkreślają odrębność stanowiska antykomunistycznego od pozycji zajmowanych przez ideologów prawicy. O ile w większości partii socjaldemokratycznych Europy Zachodniej stosunek do lokalnej partii komunistycznej zajmuje naczelne miejsce w problematyce wewnątrzpartyjnej, w Wielkiej Brytanii zjawisko to nie istnieje; o ile w Europie Zachodniej zarówno partie socjalistycznie i komunistyczne cieszą się dużym poparciem społecznym, to Brytyjska Partia Komunistyczna i jej komunistyczne następczynie nie cieszyły się dużym poparciem, aż w końcu zostały zmarginalizowane.
Zdaniem Janusza W. Gołębiowskiego model stosunku Partii Pracy do komunistów jest prawicowo-antykomunistyczny. Partia komunistyczna już od 1920 roku starała się o przyjęcie jej w skład członków Partii Pracy, ale za każdym razem prośby o sojusz lub akces do partii były przez laburzystów odrzucane. Już w 1925 roku kierownictwo laburzystów zakazało terenowym oddziałom Partii Pracy na powierzanie członkom partii komunistycznej funkcji w związkach zawodowych czy stowarzyszeniach robotników, co było na tyle istotne, że w latach 70. zarysował się udział komunistów w ruchu związkowym, co dość mocno umożliwiło uchylenie w 1972 roku przez Radę Generalną TUC dotychczasowego zakazu wybierania członków partii komunistycznej na delegatów zjazdów związków zawodowych.
W międzynarodowym ruchu socjalistycznym Partia Pracy należy do grupy najbardziej negatywnie odnoszących się do rodzimych partii komunistycznych. Przy tym partia nie kwestionuje współpracy innych partii socjalistycznych z komunistami z własnych krajów.
Antykomunistyczne stanowisko zajmuje większość prawicy jak i lewicy partii. Bardziej elastyczne stanowisko partia zajmowała na płaszczyźnie międzynarodowej, na której w okresie zimnej wojny deklarowała gotowość do nawiązania stosunków z partiami komunistycznymi i państwami bloku wschodniego w okresie nasilenia tendencji eurokomunizmu, uważając to za element procesów odprężeniowych między blokami zimnej wojny.
Historia.
Geneza.
Do ukształtowania się w brytyjskim ruchu robotniczym nurtu laburzystowskiego doszło na przełomie lat wieku XIX i XX.
Początki Partii Pracy sięgają końca XIX wieku, co związane było z potrzebą budowy partii politycznej reprezentującej interesy proletariatu miejskiego, który gwałtownie przybrał na liczebności. Wielu członków związków zawodowych było zainteresowanych działalnością stricte polityczną, a po wyborach w 1867 i 1885 do parlamentu dostało się kilku kandydatów robotniczych popieranych przez Partię Liberalną. Kandydaci tacy określani byli jako Lib-Lab (Liberal Labour). Pierwszym z takich kandydatów, którzy dostali się do parlamentu, był George Odger, który dostał się do Izby Gmin z okręgu Southwark w wyborach w 1870 roku. W tym czasie powstało kilka małych grup o profilu socjalistycznym, wśród których narodziły się pomysły zjednoczeniowe. Grupami takimi były: Niezależna Partia Pracy (założona w 1893 roku), Towarzystwo Fabiańskie (1884), marksistowska Federacja Socjaldemokratyczna (1881) i Szkocka Partia Pracy. Towarzystwo Fabiańskie skupiało intelektualistów, laburzystowskich działaczy politycznych, literatów etc. Filozofia Towarzystwa zakładała zmienianie stosunków społecznych na drodze pokojowej i reformistycznej. Nazwa Towarzystwa sugerowała przejęcie taktyki rzymskiego dowódcy Fabiusza Kunktatora.
W wyborach powszechnych w 1895 roku Niezależna Partia Pracy wystawiła 28 kandydatów, partia uzyskała tylko 44.325 głosów. Lider partii Keir Hardie uważał, że aby osiągnąć sukces w wyborach parlamentarnych, konieczne będzie połączenie się z innymi grupami lewicowymi. Hardie zyskał sławę jako świecki kaznodzieja, stąd też w 1950 roku Sekretarz Generalny partii Morgan Phillips stwierdził, że „socjalizm w Wielkiej Brytanii zawdzięcza więcej metodyzmowi niż Marksowi”.
Brytyjski socjalizm zaczął robić postępy w samorządzie lokalnym. W 1892 roku Frederick William Jowett (członek Niezależnej Partii Pracy) został pierwszym socjalistą wybranym do Bradford City Council. Kilka miesięcy później Jowett założył oddział Niezależnej Partii Pracy w tym mieście. Jako członek rady Bradford, Jowett przeprowadził kilka reform, które zaczęły naśladować inne samorządy. Na przykład w 1904 roku Bradford jako pierwszy samorząd lokalny w Wielkiej Brytanii zapewnił w szkołach darmowe posiłki i przeprowadził kampanię na rzecz zastępowania slumsów nowymi domami.
W 1898 roku rada w West Ham stała się pierwszą laburzystowską radą w Wielkiej Brytanii. Administracja laburzystów realizowała program mający objąć proletariat ochroną publiczną, rada zapewniła pracownikom wypłatę pensji, godne warunki i poprawę bezpieczeństwa w pracy. W West Ham wprowadzono ośmiogodzinny dzień pracy, płacę minimalną i dwutygodniowy urlop przypadający raz w roku. Laburzystowska rada utraciła większość po dwóch latach, jednak jej działania pokazały możliwość skutecznego działania laburzystów w samorządzie.
W 1899 roku postępowe partie liberalne oraz partie wywodzące się z Towarzystwa Fabianów przejęły władzę w London County Council. Po raz pierwszy rada miejska Londynu znalazła się pod wpływami socjalistów. Składająca się z socjalistów rada doprowadziła do realizacji programu komunalizacji, z jej inicjatywy powstały pierwsze mieszkania socjalne w historii Anglii, zwiększono także wydatki publiczne na usługi takie jak straż pożarna. W tym czasie wzrosła liczba łaźni publicznych, parków, poprawiono system ścieków, poszerzono i utwardzono drogi, a w 1897 roku otwarty został Blackwall Tunnel łączący Isle of Dogs z Greenwich. Kobieca Liga Pracownicza przed wybuchem I wojny światowej otworzyła w Kensington klinikę dziecięcą.
Początki działalności.
Komitet Reprezentacji Pracujących.
W 1899 roku Thomas R. Steels, członek Zjednoczonego Towarzystwa Pracowników Kolejowych z Doncaster, zaproponował w swoim oddziale związkowym organizację specjalnej konferencji Trade Union Congress (federacji związków Anglii i Walii powstałej w 1868 roku), na której połączone zostaną różne grupy i organizacje lewicowe, tak, aby utworzyły one jeden organ, który sponsorować będzie udział kandydatów robotniczych w wyborach parlamentarnych. Wniosek Steelsa przekazany został do kierownictwa TUC, a zaproponowana przez niego konferencja odbyła się w Farrigdon Memorial Hall w dniu 26 i 27 lutego 1900 roku. W spotkaniu udział wzięło szerokie spektrum organizacji robotniczych i lewicowych - reprezentanci związków stanowili około jedną trzecią delegatów.
Po debacie 129 delegatów skupionych wokół Keira Hardie z Niezależnej Partii Pracy powołało Komitet Reprezentacji Pracujących. Nowa organizacja miała za zadanie wspierać kandydatów wystawianych przez związki zawodowe i reprezentujących przedstawicieli klasy robotniczej. Sekretarzem nowego ugrupowania wybrany został członek Niezależnej Partii Pracy, Ramsay MacDonald. W październiku 1900 roku odbyły się pierwsze wybory z udziałem Komitetu Reprezentacji Pracujących. Wydatki na wybory wyniosły jedynie 33 funty, za te pieniądze sponsorowano kampanię 15 kandydatów, z czego dwóch z nich dostało się do parlamentu - byli to Keir Hardie z Merthyr Tydfil i Richard Bell z Derby.
Poparcie dla Komitetu wzmocnił konflikt między strajkującymi kolejarzami a spółką kolejową, mający miejsce w 1901 roku. Spór skończył się nakazem zapłaty 23000 funtów odszkodowania za straty z okresu strajku, karę tę w całości opłacić mieli związkowcy. Decyzja podjęta została za zgodą konserwatywnego premiera Arthura Balfoura, który niespodziewanie stanął po stronie przemysłowców (dotychczas przemysłowcy stanowili tradycyjnego sojusznika Partii Liberalnej). Decyzja Balfoura w oczach wielu robotników objawiła się jako brak troski o pracowników i ich problemy.
W wyborach w 1906 roku Komitet zdobył 29 miejsc - na korzyść laburzystów wpłynął pakt pomiędzy Ramsayem MacDonaldem a liderem liberałów, 1. wicehrabią Gladstone Herbertem Gladstonem. Tajny pakt liberałów i socjalistów miał na celu uniknięcie rozbicia głosów pomiędzy laburzystów a Partię Liberalną i wspólne odsunięcie od władzy konserwatystów.
Wczesna działalność Partii Pracy.
W czasie pierwszego kongresu po wyborach 1906 roku Komitet oficjalnie zmienił nazwę na „Partia Pracy”. Przewodniczącym frakcji parlamentarnej partii został Keir Hardie (w praktyce lider partii). Hardie po kilku głosowaniach wygrał jednym głosem z kontrkandydatem, Davidem Shackletonem. Jednym z pierwszych działań nowego rządu liberałów, wspieranego przez laburzystów, było cofnięcie wyroku z 1901 roku (w sprawie konfliktu strajkujących kolejarzy z przemysłowcami). W 1906 roku Partia Pracy odnotowała pierwszy sukces legislacyjny – socjalistom udało się przeforsować projekt posła Freda Jowetta o dostarczaniu posiłków w szkołach.
Laburzystowscy parlamentarzyści przeforsowali też ustawy wprowadzające odszkodowania robotnicze (1906), ośmiogodzinny dzień pracy, emerytury i obowiązkowe kontrole lekarskie w szkołach państwowych (1908).
Przeprowadzenie reform socjalnych było wynikiem nieformalnego sojuszu laburzystowsko-liberalnego z 1906 roku. Sojusz kontynuowano po wyborach z 1910 roku, w których laburzyści zdobyli 42 mandaty w Izbie Gmin. W 1911 roku wprowadzono ubezpieczenia zdrowotne.
Partia Pracy od początku działała w ścisłej współpracy ze związkami zawodowymi. W 1909 roku uchwalono prawo, na mocy którego związki zawodowe nie mogły finansować partii politycznych, prawo to jednak uchylono w 1913 roku na skutek protestów ze strony największych związków. Statut przewiduje członkostwo indywidualne i zbiorowe (do 1918 roku wyłączne). Członkostwo indywidualne posiada ok. 300 000 osób, a na zasadzie członkostwa zbiorowego do partii należy ok. 5,3 mln osób. Do Partii Pracy należy większość ze związków zawodowych zrzeszonych w Kongresie Związków Zawodowych (TUC), a także wiele innych stowarzyszeń i ugrupowań.
W 1918 roku Sidney Webb opracował program "Praca i nowy porządek społeczny". Zamieścił w nim postulaty budowy socjalizmu, współzarządzania ziemią, kopalniami węgla, energetyką i koleją. Socjalne stanowisko przyjęte w dokumencie oznaczało koniec sojuszu z liberałami. Tendencja ta związana była z falą rewolucyjną ogarniającą ówczesny świat.
W samorządzie lokalnym.
W 1914 roku w radach miejskich różnego rodzaju (nie wliczając kilku radnych w wiejskich obszarach górniczych, członków rad dzielnicowych i parafialnych) zasiadło około 420 przedstawicieli laburzystów. Głównymi problemami poruszanymi przez laburzystów była polityka edukacyjna, żywieniowa, medyczna, szczególną wagę w samorządach przywiązywano do wprowadzenia ośmiogodzinnego dnia pracy, polepszenia warunków pracowników komunalnych i świadczeń dla bezrobotnych.
W niektórych regionach (szczególnie Birmingham i Glasgow) laburzystowskie samorządy działały na rzecz budowy mieszkań komunalnych, przebudowy dzielnic slumsów oraz poprawy sytuacji niższych klas społecznych, osób niepełnosprawnych i starszych. Czołowym przedsięwzięciem lewicowego samorządu było tworzenie obiektów łączących cechy przedsiębiorstw i budynków publicznej służby zdrowia w obecnym wydaniu.
W okresie międzywojennym.
W okresie międzywojennym Partia Pracy zaczęła przejmować pozycję Partii Liberalnej jako jednej z dwóch głównych partii. Już w wyborach w 1922 roku partia zajęła drugie miejsce, a w 1924, a następnie w latach 1929-1935, tworzyła rząd pod przewodnictwem Jamesa Ramsaya MacDonalda – początkowo mniejszościowy z poparciem liberałów. Po krachu na giełdzie amerykańskiej w 1929 roku świat ogarnął Wielki Kryzys. MacDonald i jego zwolennicy uzgodnili utworzenie rządu narodowego z liberałami i konserwatystami. Większa część laburzystów uznała to za zdradę, odchodząc z partii. Założyli oni ugrupowanie pod nazwą Narodowa Organizacja Pracy.
Po 1945 roku.
Po wybuchu II wojny światowej Partia Pracy wspierała uczestnictwo Wielkiej Brytanii w koalicji. Laburzyści dołączyli do rządu jedności narodowej z Partią Konserwatywną i Liberalną oraz zgodzili się na niekonkurowanie ze sobą w wyborach. W 1945 roku laburzyści po raz pierwszy sformowali jednopartyjny rząd większościowy pod przewodnictwem Clementa Attleego, który wprowadził radykalne reformy gospodarcze, nacjonalizując wiele gałęzi przemysłu, reorganizując system podatkowy, ubezpieczeń społecznych i służbę zdrowia. Partia Pracy pomimo zwycięstwa w wyborach straciła władzę w 1951 roku. W 1955 roku nowym liderem partii wybrany został przedstawiciel prawicowego skrzydła partii Hugh Gaitskell, pokonując w głosowaniu Aneurina Bevana. Konflikt między zwolennikami Gaitskella i Bevana był bardziej konfliktem na tle osobowości niż ideologii, tarcia zostały zażegnane, gdy przewodniczącym wybrany został Harold Wilson, zwolennik Bevana.
W latach 60. ówczesny przywódca Partii Pracy – Hugh Gaitskell – zreformował partię, rezygnując z radykalnych haseł socjalistycznych ("rethinking socialism") i ograniczając rolę związków zawodowych. Laburzyści tworzyli jeszcze rząd w latach 1964–1970 i 1974–1976 (premier Harold Wilson) oraz 1976–1979 (James Callaghan), po czym pozostawali w opozycji przez 18 lat. Partia nie potrafiła podczas tego okresu sformułować odpowiednio atrakcyjnego programu alternatywnego wobec taczeryzmu. Po klęsce w 1979 roku lider partii James Callaghan utrzymywał równowagę między lewą (Tony Benn) i prawą (Roy Jenkins) frakcją partii. W 1980 roku Callaghan został zastąpiony przez Michaela Foota, przedstawiciela lewicowego skrzydła partii, dystansującego się co prawda od radykalnego Tony’ego Benna. W 1981 roku doszło do rozłamu w Partii Pracy, w wyniku którego prawicowe skrzydło partii założyło Partię Socjaldemokratyczną, która w 1988 roku wraz z Partią Liberalną weszła w skład socjalliberalnej partii Liberalni Demokraci.
Lata 80. i 90..
Wybory w 1983 roku okazały się najgorszymi od 1918 roku wyborami dla laburzystów. W tym okresie kierownictwo partii lawirowało między umiarkowaną frakcją skupioną wokół magazynu Tribune i frakcją radykalną związaną z Tonym Bennem i parlamentarnym klubem "Socialist Campaign Group". W roku 1982 laburzystom udało się zdobyć kontrolę nad Liverpool City Council i prowadzić tam politykę przeciwstawną wobec rządowych cięć budżetowych; podobną politykę prowadził Ken Livingstone z Londynu. W tym okresie powstał termin „komunalny socjalizm”, opisujący działania laburzystowskich władz lokalnych, stanowiących kontrast wobec panujących w kraju neoliberalnych reform. W wyborach wewnątrzpartyjnych zwycięstwo odniósł Neil Kinnock, który postanowił położyć kres podziałom w partii, osłabiając wpływy frakcji lewicowych.
Partia Pracy powróciła do władzy dopiero w 1997 roku pod przewodnictwem Tony’ego Blaira, który dokonał zdecydowanej modernizacji partii w kierunku tzw. trzeciej drogi. Laburzyści w pełni zaakceptowali zasady wolnorynkowe, zmniejszyli uzależnienie od związków zawodowych, zapowiadali reformy ustrojowe (autonomia dla Szkocji i Walii – zrealizowana od 1997 roku, zlikwidowanie dziedziczności w Izbie Lordów – od 1999 roku).
XXI wiek.
W 2001 roku Partia Pracy ponownie wygrała wybory, uzyskując 40,7% głosów, w 2005 zwyciężyła, uzyskując 36% głosów
W wyborach w 2010 roku przegrała z Partia Konserwatywną, uzyskując 29% głosów (2. wynik) i 258 mandatów w Izbie Gmin. Ugrupowanie wygrało wybory lokalne w 2012, na łączną liczbę 128 brytyjskich hrabstw laburzyści zdobyli przewagę w radach 75 hrabstw.
W 2015 roku, po kolejnych przegranych wyborach, kierownictwo nad partią przejął radykalnie lewicowy Jeremy Corbyn.
Partia Pracy jest członkiem Partii Europejskich Socjalistów oraz Międzynarodówki Socjalistycznej.
W 2019 roku Partia pracy zaproponowała 4 dniowy tydzień pracy (32 godzin pracy w tygodniu traktowane jako cały etat).
Polityka międzynarodowa.
Polityka zagraniczna Partii Pracy na ogół mieściła się w głównym nurcie doktryny zagranicznej Wielkiej Brytanii. Różnice między konserwatystami a laburzystami polegają na metodach realizacji polityki zagranicznej.
W latach 50. partia promowała koncepcję „trzeciej siły” w układzie międzynarodowym. Koncepcja ta polegała na osiągnięciu niezależności międzynarodowej brytyjskiej dyplomacji, korzystając przy tym z czołowej roli Partii Pracy w ruchu robotniczym. Jak twierdzili laburzyści: „Jedynym możliwym do zaakceptowania rodzajem trzeciej siły jest światowy braterski związek socjalistów, tych, którzy sprawują władzę, i tych, którzy jej nie sprawują, zjednoczonych w ideologicznej opozycji zarówno wobec komunizmu, jak i stosunku do kapitalizmu”. Elementy koncepcji mieściły się do lat 70. w brytyjskiej doktrynie polityki zagranicznej w formule „trzech koncentrycznych kręgów.
Do polityki trzeciej siły nawiązywała polityka Partii Pracy z lat 60. Opierała się ona na współdziałaniu z krajami Wspólnoty Narodów, „stosunkach specjalnych” z USA, współpracy w ramach NATO i rozwijaniu powiązań z krajami Europy. Rząd Harolda Wilsona rozwijał tę koncepcję według interpretacji zgodnych z ideą pokojowego współistnienia.
Rozpad imperium kolonialnego w latach 60. doprowadził do przetasowań w polityce zagranicznej UK. Już w 1964 roku laburzyści akcentowali ściślejszą więź z Europą, lecz w dalszym zakresie priorytet widzieli w kontrolowanej przez Brytyjczyków Wspólnocie Narodów. W 1966 roku laburzyści deklarowali gotowość przystąpienia UK do Europejskiej Wspólnoty Gospodarczej pod warunkiem zabezpieczenia przez Wspólnotę interesów Wspólnoty Narodów i UK. W 1968 roku Harold Wilson ogłosił plan wycofania się UK z polityki na wschód od Suezu i stopniową eliminację brytyjskiej obecności wojskowej w krajach Zatoki Perskiej i na Dalekim Wschodzie.
Laburzystowska UK wyprzedziła inne kraje Europy Zachodniej w dziedzinie rozwoju kontaktów z blokiem wschodnim. W latach 60. laburzyści deklarowali wolę uczestnictwa w odprężeniu stosunków zimnowojennych i deklarowali utrzymanie pozycji UK jako pierwszego partnera handlowego i gospodarczego państw demokracji ludowej, pod koniec dekady kurs ten uległ osłabieniu.
W latach 70. przeważała orientacja europejska, w manifeście europejskim z 1970 roku laburzyści zapowiedzieli dążenie do zmniejszania napięcia między Zachodem a Wschodem i odpowiedzialną rolę UK w sprawach światowych i europejskich.
W trakcie trwającej wiele lat dyskusji poprzedzającej referendum na temat członkostwa UK we Wspólnocie Europejskiej z 1975 roku w Partii Pracy rozrysowały się głębokie rozbieżności - pojawiło się nawet widmo oderwania się od partii skrzydła proeuropejskiej prawicy na czele z Royem Jenkinsem.
W czasie rządów z okresu 1974-1979 doszło do kolejnych przetasowań. Program został zmodyfikowany w myśl formuły kojarzenia zjawiska „europeizmu” z „atlantyzmem” i „specjalnymi stosunkami” ze Stanami Zjednoczonymi. Partia Pracy opowiedziała się za umocnieniem NATO, która miała określać stosunki na linii Wschód-Zachód. Laburzyści mimo mocnego poparcia dla „atlantyzmu” i NATO przejawili więcej inicjatywy w rozwoju kontaktów z krajami socjalistycznymi niż poprzednie rządy konserwatywne. Polityka premierów Wilsona i Jamesa Callaghana przyczyniła się do hamowania tempa zbrojeń militarnych UK.
W sprawie członkostwa w EWG Partia Pracy zajęła stanowisko kompromisowe, w manifeście wyborczym z 1979 roku Callaghan stwierdził, że partia gotowa jest do współpracy nad umocnieniem relacji UK z Europą, lecz zaznaczył jednocześnie, że niektóre aspekty Wspólnego Rynku wskazują na brak zdrowego rozsądku. Ponadto w manifeście znalazły się akcenty rozbrojeniowe na rzecz odprężenia i poprawy relacji z blokiem wschodnim.
Po przejściu do opozycji na wiosnę 1979 odżyły spory partyjne dotyczące obecności UK w Europie. Radykałowie z lewego skrzydła partii opowiedzieli się za wystąpieniem Wielkiej Brytanii z EWG i powrotem do koncepcji trzeciej siły. Według przedstawiciela partyjnej lewicy, Benna, Partia Pracy musi utrzymywać dobre relacje z USA i ZSRR, a jednocześnie nie może pozwolić na kontrolę ze strony żadnego z tych mocarstw. Prawe skrzydło partii opowiedziało się natomiast za członkostwem w EWG. Zdaniem Shirley Williiams (która jeszcze na początku lat 80. zajmowała stanowisko partyjnej prawicy) EWG stanowi jedyną formację, która jest na tyle silna, by skłonić supermocarstwa do skutecznego i wielostronnego procesu rozbrojenia.
Rozbieżności w sprawach europejskich i polityce zagranicznej stanowiły jeden z czynników, które doprowadziły do rozłamu w Partii Pracy.
Struktury.
Członkostwo.
Do Partii Pracy oprócz członków indywidualnych należą organizacje afiliowane, czyli m.in. związki zawodowe, organizacje zawodowe, stowarzyszenia socjalistyczne, towarzystwa społeczne etc. Dominującą część członków stanowią związkowcy. Przykładowo na konferencji partii w Blackpool w latach 80. z 7206 tysięcy członków reprezentowanych na konferencji aż 6450 należało do partii według zasady członkostwa pośredniego poprzez jeden z 52 afiliowanych związków zawodowych.
Do czasu przyjęcia przez laburzystów elementów programu neoliberalnego silne związki łączyły partię ze związkami zawodowymi. Liczba członków afiliowanych związków zawodowych wzrosła z 2 510 w 1945 do 6 450 w 1980. W tym samym czasie do organizacji stowarzyszonych w 1945 należało 41 tysięcy, a w 1980 było to już 67 tysięcy. W przeciągu tego okresu liczba członków wyniosła kolejno 487 i 588 tysięcy członków. Największy okres rozwoju partii przypadł na czasy Clementa Atlee, gdy partia liczyła aż 908 tysięcy działaczy.
Partia wyróżnia dwa gatunki członkostwa - indywidualne (działające od 1918) i zbiorowe (w tym drugim przewiduje się członkostwo pośrednie). W przypadku członkostwa zbiorowego członkostwo w partii zgłaszają w imieniu członków członkowie zbiorowi. Tak więc do Partii Pracy należy każdy członek związku zawodowego związanego z partią, jeśli tylko nie złożył oświadczenia o braku chęci wstąpienia do partii. Przynależność ta w wielu przypadkach ma charakter czysto mechaniczny i formalny. W okresie walki z Partią Pracy w 1927 roku wprowadzono system odwrotny, który nakazywał członkom związków pragnącym wstąpić do partii złożenie deklaracji w sprawie przynależności. W wyniku tej ustawy liczba członków partii spadła o jedną trzecią (jeden milion działaczy), przywrócenie tegoż systemu w 1946 roku ponownie zwiększyło liczbę członków o jedną trzecią (1,7 miliona).
Na koniec 2018 Partia Pracy miała 518 659 członków i była największą partią polityczną w Wielkiej Brytanii.
Organizacje partyjne.
Od innych partii (w tym socjalistycznych) laburzystów odróżnia struktura wewnątrzpartyjna porównywalna do federacji ugrupowań czy koalicji. Struktura obejmuje formalnie dwa układy: pierwszy z nich to frakcja parlamentarna (PLP), na czele frakcji stoi wybierana corocznie egzekutywa czyli Komitet Parlamentarny. Do komitetu z miejsca wchodzi lider partii, jego zastępca i rzecznik dyscyplinarny frakcji. PLP odgrywa decydującą rolę w określaniu programu i linii politycznej ugrupowania. PLP uznawana jest niekiedy za niezależny od reszty partii organ. Obecnie skład społeczny PLP jest dość zróżnicowany, niegdyś niemal 40% członków frakcji stanowili deputowani wywodzący się z klasy robotniczej. W 1945 roku było to 43%, liczba ta spadła jednak do 1970 roku do 27%, a jednocześnie wzrosła liczba parlamentarzystów wywodzących się z klas wyższych i średniej.
Drugim z układów jest pozaparlamentarny aparat partii. Centralne miejsce w tymże układzie zajmuje Krajowy Komitet Wykonawczy - kieruje on ogółem działań Partii Pracy w sferze pozaparlamentarnej. Komitet Wykonawczy liczy 28 członków, z miejsca wchodzą do niego lider partii, jego zastępca i skarbnik. Szczeble terenowe tworzone są poprzez okręgu wyborcze czyli CLP. Do CLP należą szeregowi działacze partii i organizacji afiliowanych. Na czele okręgu wyborczego partii stoi egzekutywa składająca się z najbardziej wpływowych działaczy w regionie i kierowników największych organizacji afiliowanych. Aparat lokalny podporządkowany jest wymogom wyborczym i kampaniom, w czasie których aktywizuje swoje działanie.
Reprezentację członków partii stanowi wedle statutu Doroczna Konferencja Partii Pracy. W teorii steruje ona działaniami PL, tworzy programy polityczne, kieruje aparatem wykonawczym i podejmuje uchwały obejmujące ogół partii. W Konferencjach udział biorą delegaci wybrani przez okręgi wyborcze i organizacje afiliowane, a z miejsca zasiadają w nich działacze Krajowego KW, parlamentarzyści, kandydaci na parlamentarzystów, członkowie młodzieżówki i sekretarz generalny partii. Konferencja jest niekiedy uznawana za „parlament ruchu laburzystowskiego”.
Lider Partii Pracy jednocześnie sprawuje funkcję prezesa rady ministrów. Dzięki temu pozostaje w dużej mierze niezależny od frakcji parlamentarnej własnej partii.
Niegdyś dochodziło do pewnych zgrzytów między Konferencją a KW, podłoże tego konfliktu związane było z konfliktem między robotniczą większością partii a kierownictwem, zdominowanym przez członków reprezentujących klasy średnie. Zarówno na forum KW jak i Konferencji większość mieli bowiem reprezentanci związków zawodowych.
Wyborcy i członkowie.
Jeszcze w latach 80. partia skupiała ponad 50% elektoratu robotniczego, a w ogóle wyborców Partii Pracy robotnicy stanowili 80%. Jedną czwartą lub jedną trzecią według różnych źródeł stanowią reprezentanci klas średnich.
Do niedawna 50% członków partii stanowili robotnicy, więc ze względu na skład członkowski partię z pewnością zaklasyfikować można było jako partię robotniczą. Od lat istnieje w partii proces spadku udziału parlamentarzystów i ministrów z kręgów robotniczych przy jednoczesnym wzroście tych wywodzących się z klas średnich. Sytuacja ta nie pozostała bez wpływu na przyjęcie przez partię typowego kursu reformistycznego. Jeszcze w latach 40. i przez pewien okres 50. więcej niż połowę laburzystowskich ministrów stanowili robotnicy; w kolejnej dekadzie było to już tylko 35% ogółu, natomiast granicę 60% przekroczyli przedstawiciele klasy średniej, niezmienna pozostała stosunkowo mała liczba ministrów socjalistycznych wywodzących się z arystokracji.
Pochodzenie działaczy związane jest też z ich poglądami - działacze wywodzący się z klasy średniej zazwyczaj są zwolennikami kursu prawicowo-reformistycznego, natomiast ci pochodzący z klasy robotniczej należą do lewicy partyjnej.
Frakcje.
Prawica partyjna opowiadała się zawsze za utrzymaniem kapitalizmu i przekształceniami w stylu „współpracy klasowej”, z kolei lewica często łączyła elementy ocen klasowych z romantycznym radykalizmem pochodzącym z tradycji fabiańskich, niemniej jednak zawsze reprezentowała ona radykalny reformizm więc centrowy, prawicowy nurt w ruchu robotniczym.
Jednym z przejawów podziałów na tle ideologiczno-politycznym w partii jest występowanie w ramach ugrupowania frakcji. Frakcje do pewnego stopnia odznaczają się autonomią - mają własnych przywódców czy organy prasowe. Jak wykazała historia partii, większe tendencje do frakcyjności wykazuje lewica partii. Do współczesnych frakcji należą:
Historyczną poprzedniczką Grupy „Tribune” są: działająca od 1947 roku Grupa „Równać w lewo” (Keep Left Group), z A. Bevanem, przedstawicielem partyjnej lewicy, na czele. W latach 50. grupę określano jako bevanistów. Od 1950 do 1963 działała Grupa „O zwycięstwo socjalizmu” z K. Zillacusem, I. Mikardo i S. Silvermannem na czele. W 1951 roku prawica partii powołała Związek Socjalistyczny, działający jako stowarzyszenie teoretyków.
Podział na partyjną lewicę i prawicę odzwierciedlają też odrębne organy prasowe. Laburzystowską lewicę popiera tygodnik „Tribune”, miesięcznik „New Left Review” oraz dwumiesięcznik „New Socialist”; poparcie dla prawicy z kolei wyraża miesięcznik „Socialist Commentary” oraz kwartalnik „The Political Quarterly”.
Rozłam z 1981.
Na ogół w partii nie dochodziło do większych rozłamów, wyjątkiem była sytuacja po wyborach z wiosny 1979 roku, gdy spór między skrzydłami partii doprowadził do rozbicia jedności laburzystów. Konflikt uwidocznił się na konferencji z 25 stycznia 1981 roku, a do secesji doszło 26 marca. Z inicjatywy Davida Owena, Roya Jenkinsa, Shirley Williams i Williama Rodgersa utworzono odrębną partię pod nazwą Partia Socjaldemokratyczna.
Do rozłamu doprowadził spór między lewicą a prawicą partii, kontrowersje w sprawie rozwiązania problemów organizacyjnych partii oraz konflikty na tle kierunków polityki międzynarodowej. Szczególnie ostry konflikt wywiązał się wokół zmian trybu wyboru przewodniczącego, a konkretniej przekazania kompetencji frakcji parlamentarnej w ręce kolegium elektorskiego, oraz zwiększenia wpływów organizacji okręgowych na nominacje kandydatów na parlamentarzystów. Zmiany te zaproponowane zostały przez lewicę partyjną, a ich realizacja mogła osłabić frakcję parlamentarną wewnątrz partii, na co nie chciała zgodzić się prawica. Ostatecznie lewica przeforsowała zmiany w kierunku demokratyzacji życia wewnątrzpartyjnego, w wyniku których lider partii wybierany był przez kolegium elektorskie z udziałem 40% reprezentantów związków zawodowych, 30% parlamentarzystów i 30% delegatów organizacji okręgowych.
Rozłam nie oznaczał, że partia została podzielona na dwie mniej więcej równe części, odeszło „niewielkie, choć wpływowe odgałęzienie”. Jak się okazało wkrótce, Partia Socjaldemokratyczna miała zostać wchłonięta przez partię liberalną.

</doc>
<doc id="12858" url="https://pl.wikipedia.org/wiki?curid=12858" title="Partia Konserwatywna (Wielka Brytania)">
Partia Konserwatywna (Wielka Brytania)

Partia Konserwatywna (, CP, oficjalna nazwa: Partia Konserwatywno-Unionistyczna, ), potocznie torysi () – brytyjska partia polityczna powstała w 1832 roku w wyniku przekształcenia ugrupowania torysów, popularnie nazywana w dalszym ciągu torysami. Jedna z dwóch (obok Partii Pracy) głównych partii w Wielkiej Brytanii.
Historia.
Pierwsza deklaracja programowa Partii Konserwatywnej (manifest z Tamworth) została opracowana przez Roberta Peela i ogłoszona w 1834 roku. Manifest eksponował tradycyjne konserwatywne wartości, w szczególności elitaryzm. Reformy Benjamina Disraelego (początkowo liberała) z lat 1868–1874 spowodowały otwarcie się partii na szersze grono wyborców.
W XIX w. konflikt z opierającymi się na burżuazji przemysłowej liberałami doprowadził do wytworzenia się nurtu tzw. „konserwatyzmu jednego narodu”. Na początku XX w. w Partii Konserwatywnej, m.in. pod wpływem rosnącego znaczenia Partii Pracy, zaczął dominować nurt paternalistyczny, dopuszczający interwencjonizm państwowy (m.in. Joseph Chamberlain). Tendencje interwencjonistyczne zostały jeszcze bardziej wzmocnione po II wojnie światowej ("Karta przemysłowa" z 1947 roku).
Znaczący zwrot w programie partii nastąpił w 1976 roku wraz z objęciem przywództwa przez Margaret Thatcher. Od 1979 roku Thatcher na stanowisku premiera konsekwentnie realizowała politykę taczeryzmu, opierającą się na liberalizmie ekonomicznym, monetaryzmie, prywatyzacji wielu gałęzi przemysłu, niechęci do pogłębiania integracji europejskiej i centralizacji państwa. Po ustąpieniu Thatcher w 1990 roku polityka ta została nieco złagodzona przez nowego lidera partii i premiera Johna Majora, co umożliwiło m.in. przystąpienie Wielkiej Brytanii do Traktatu z Maastricht.
Konserwatyści oddali władzę dopiero w 1997, kiedy zdecydowanie przegrali wybory. Nowym liderem wybrany został William Hague, przeciwnik bliższej integracji europejskiej. Po kolejnych przegranych wyborach w 2001 roku Hague’a zastąpił Iain Duncan Smith, jeszcze bardziej eurosceptyczny. Zmiana przywództwa nie poprawiała notowań partii, które były najgorsze od wielu lat; poprawiły się na skutek sprzeciwu większości społeczeństwa wobec popierania przez premiera Blaira amerykańskiej polityki w stosunku do Iraku. W latach 2003–2005 liderem partii był Michael Howard, w latach 2005–2016 David Cameron, a 2016–2019 Theresa May. 23 lipca 2019 została zastąpiona na tym stanowisku przez Borisa Johnsona. Pod jego przywództwem partia wygrała wybory w 2019 roku, formułując rząd większościowy.

</doc>
<doc id="12860" url="https://pl.wikipedia.org/wiki?curid=12860" title="Liberalni Demokraci">
Liberalni Demokraci

Liberalni Demokraci (ang. "Liberal Democrats", LD, LDEM, pot. "Lib Dems"; oficj. "Social and Liberal Democrats") – brytyjska socjalliberalna partia polityczna. Powstała w 1988 w wyniku połączenia Partii Liberalnej i Partii Socjaldemokratycznej.
Partia jest członkiem Partii Europejskich Liberałów, Demokratów i Reformatorów oraz Międzynarodówki Liberalnej. Jest najbardziej przychylna Unii Europejskiej spośród głównych partii brytyjskich.
Do 2015 r. byli trzecią co do wielkości brytyjską partią polityczną, do 2010 nigdy nie uczestniczyli w sprawowaniu rządów. LD za przyczynę uznaje obowiązujący w Wielkiej Brytanii system większościowy i postuluje jego zmianę na proporcjonalny. W wyborach do Izby Gmin w 2005 partia zdobyła 22,1% głosów, co dało jej 62 (9,6%) mandaty. W wyborach w 2010 roku uzyskała 23% głosów, co jednak przełożyło się na mniejszą liczbę mandatów – 57. Współtworzyła wówczas rząd z Partią Konserwatywną, na czele którego stanął David Cameron.
Po wyborach parlamentarnych w 2015, w których Liberalni Demokraci zdobyli jedynie 8 miejsc w Izbie Gmin, Nick Clegg ustąpił z funkcji lidera partii.
Liderzy liberalnych demokratów.
Liderzy Liberalnych Demokratów
Liderzy Liberalnych Demokratów w Izbie Lordów

</doc>
<doc id="12862" url="https://pl.wikipedia.org/wiki?curid=12862" title="Pompa wirowa">
Pompa wirowa

Pompa wirowa – pompa, w której łopatkowy wirnik zwiększa moment pędu (kręt) cieczy powodując efekt ssania we wlocie i nadwyżkę ciśnienia po stronie tłocznej pompy.
Pompy wirowe dzielą się na:
W pompach wirowych nie jest potrzebne uszczelnienie oddzielające obszar ssawny od tłocznego (w przeciwieństwie do pomp wyporowych).
Zalety pomp wirowych:
Wady pomp wirowych:

</doc>
<doc id="12865" url="https://pl.wikipedia.org/wiki?curid=12865" title="Pompa wirowa krętna">
Pompa wirowa krętna

Pompa wirowa krętna – typ pompy wirowej, w której obrotowy ruch wirnika powoduje wzrost momentu pędu (krętu) cieczy.
Wirniki pomp wirowych mają różne konstrukcje, co decyduje o charakterystyce pompy. Konstrukcję wirnika pompy z parametrami pracy (prędkość obrotowa wirnika formula_1 wydajność formula_2 i wysokość podnoszenia formula_3) wiąże współczynnik szybkobieżności pompy wirowej. Kinematyczny współczynnik szybkobieżności pompy jest określony wzorem:
Zasada działania.
Łopatkowy wirnik zwiększa moment pędu cieczy przepływającej przez pompę, powodując efekt ssania we wlocie i nadwyżkę ciśnienia po stronie tłocznej pompy.
Typy pomp wirowych.
Typy pomp wirowych zostały przedstawione w poniższej tabeli:

</doc>
<doc id="12866" url="https://pl.wikipedia.org/wiki?curid=12866" title="Rok przestępny">
Rok przestępny

Rok przestępny – rok kalendarzowy, którego długość (366 dni) – w celu dopasowania roku kalendarzowego do roku zwrotnikowego – jest zwiększona w stosunku do lat nieprzestępnych (365 dni). Występuje wyłącznie w kalendarzach o rachubie opartej na obiegu Ziemi dookoła Słońca lub o rachubie kombinowanej (Księżyc i Słońce). Przykłady lat przestępnych: 2016, 2020, 2024, 2028 czy 2032.
W kalendarzu gregoriańskim (obowiązującym m.in. w Polsce), rok przestępny jest dłuższy o jeden dzień występujący w lutym, który ma wtedy 29 dni zamiast 28 dni. Dodatkowym dniem w kalendarzu liturgicznym tradycyjnie nie jest jednak 29 lutego, ale dzień dodawany między 23 a 24 lutego. Dodanie tego dnia powoduje przesunięcie obchodzonych w Kościele katolickim wspomnień świętych w okresie 24–28 lutego na następny dzień. Wiąże się to z praktyką starożytnego Rzymu, gdzie od czasów Cezara dzień przestępny wprowadzano przez powtórzenie 24 lutego (tzw. "bissextilis"). Nazwa "bissextilis" wzięła się stąd, że 24 lutego w kalendarzu rzymskim nosi nazwę "sextus Kalendas", a w roku przestępnym występuje dwa razy (łac. "bis").
W kalendarzu żydowskim rokiem przestępnym jest rok, który ma dodatkowy, trzynasty miesiąc, dodawany co 3 (rzadziej co 2) lata w celu zrównania cyklu słonecznego z księżycowym.
Historia.
Lata przestępne zostały pierwszy raz wprowadzone już w 238 roku p.n.e., kiedy to w Egipcie zaczęto uwzględniać dodatkowy dzień co cztery lata (zob. datowanie sotisowe). W roku 45 p.n.e. dekretem Juliusza Cezara wprowadzono taką samą rachubę w Rzymie (stąd określenie kalendarz juliański). Dodatkowy dzień zyskał najkrótszy miesiąc – luty – który w tym czasie był też ostatnim miesiącem roku. Błąd tej rachuby wynosi ok. 1 dobę na 128 lat, ponieważ rok zwrotnikowy jest nieco krótszy niż 365,25 dnia. Do dziś ten system jest stosowany w różnych kalendarzach kościołów prawosławnych (w niektórych w 1923 r. wprowadzono tzw. kalendarz nowojuliański). Również w astronomii używa się roku juliańskiego jako jednostki czasu.
Obecnie powszechnie stosuje się rachubę zgodną z kalendarzem gregoriańskim, wprowadzonym w 1582 roku bullą papieża Grzegorza XIII („Inter gravissimas”), w której wprowadzono następującą modyfikację kalendarza juliańskiego: nie uznaje się lat przestępnych wypadających na koniec wieku, z wyjątkiem tych, w których liczba stuleci jest podzielna przez 4. Inaczej mówiąc w myśl tej reguły latami przestępnymi są te, których numeracja:
Dotychczas według tej reguły lata 1600 i 2000 były przestępnymi, a lata 1700, 1800, 1900 nie. W przyszłości rok 2100 nie będzie rokiem przestępnym.
Modyfikacja kasuje 15 lat przestępnych na każde 2000 lat co zmniejsza błąd kalendarza juliańskiego o 1 dobę na 133 lata, dlatego błąd tej rachuby wynosi 1 dobę na nieco ponad 3322 lata.
Oprócz tego w celu dopasowania początku kalendarzowej wiosny do rzeczywistego momentu równonocy wiosennej (w 1582 roku różnica wynosiła już 10 dni) postanowiono, że bezpośrednio po dniu 4 października 1582 nastąpi dzień 15 października 1582 (z zachowaniem ciągłości dni tygodnia).
Wprowadzenie kalendarza gregoriańskiego na świecie.
Kalendarz gregoriański najszybciej został przyjęty w krajach katolickich. We Włoszech, Hiszpanii, Polsce i Portugalii nastąpiło to już w 1582. W krajach protestanckich przyjęto go później, np. w Wielkiej Brytanii i w krajach Imperium Brytyjskiego dopiero w 1750 roku (na mocy tzw. „aktu Chesterfielda”).
W prawosławnej Rosji kalendarzem juliańskim posługiwano się jeszcze na początku XX wieku, a w cerkwi prawosławnej jest on używany do dziś.
Przesilenie zimowe.
Niedokładność kalendarza juliańskiego spowodowała, że w IV w. przesilenie zimowe przesunęło się z 25 na 22 grudnia, a w XVI w. już na 12 grudnia. W wyniku wprowadzenia kalendarza gregoriańskiego w 1582 i pominięcia wówczas 10 dni, termin przesilenia wypada stale w okolicach 22 grudnia.
Bieżący błąd kalendarza gregoriańskiego.
Liczba lat przestępnych w ciągu 400 lat wynosi:
Jest ona równa liczbie lat podzielnych przez 4 z tym, że wypadają lata 100, 200 i 300, a nie wypada rok 400.
Biorąc pod uwagę, że rok zwrotnikowy ma 365,242199 dni, bieżący błąd obliczania daty wynosi:
Jest to około 26 sekund na rok (chociaż nie jest to błąd stały – ze względu na konieczność skokowego wprowadzania poprawek). W ciągu 3322 lat jest to niecały jeden dzień.

</doc>
<doc id="12867" url="https://pl.wikipedia.org/wiki?curid=12867" title="Kręt">
Kręt



</doc>
<doc id="12870" url="https://pl.wikipedia.org/wiki?curid=12870" title="Autoconf">
Autoconf

GNU Autoconf – zestaw narzędzi oraz makr M4 stworzonych w ramach projektu GNU, które służą do generowania skryptów powłoki mających zająć się procesem kompilacji programów komputerowych rozprowadzanych w formie kodu źródłowego. 
Autoconf jest w stanie dostosować się do specyfiki wielu systemów operacyjnych bez angażowania użytkownika.
Kompilacja z użyciem autoconf.
Podstawowym plikiem dla Autoconfa jest configure.ac (w starszych wersjach używano configure.in, które wprowadzało w pomyłki poprzez podobiznę do Makefile.in, teraz narzędzia wyświetlają ostrzeżenie w przypadku używania starej nazwy). Na podstawie tego pliku program autoconf generuje skrypt configure w katalogu głównym pakietu z oprogramowaniem. Skrypt ten, który jest uruchamiany przez użytkownika końcowego, sprawdza obecność programów, bibliotek, nagłówków i spełnienia innych warunków określonych przez programistę. W zależności od zastosowanej konfiguracji, Autoconf zmienia tworzone przez siebie pliki Makefile, które to bezpośrednio odpowiadają za kompilację programu. Następnie użytkownik, uzyskawszy już pliki Makefile, wywołuje polecenie make, aby skompilować program.
Oto uproszczony schemat działania:
(narzędzia aclocal i automake są częściami pakietu Automake, ale rozważa się przeniesienie aclocal do Autoconf).
Przykład.
Oto przykładowy plik configure.in, dla programu "Pustak":
dnl Komentarz, ignorowany przez program
AC_INIT([Pustak], [0.1], [pustak-bugreport@example.org], [pustak], )
AC_CONFIG_HEADERS([config.h])
AC_CONFIG_SRCDIR([src/pustak.c])
dnl Jeśli używamy Automake:
AC_CONFIG_AUX_DIR([build-aux]) dnl W folderze build-aux automake umieści skrypty pomocnicze
AC_CONFIG_MACRO_DIR([m4]) dnl W folderze m4 Libtool, Gnulib i Gettext umieszczą repozytorium makr
AM_INIT_AUTOMAKE
dnl Jeśli używamy Libtool:
LT_INIT
dnl Jeśli używamy języka C:
AC_PROG_CC
dnl Jeśli używamy Gnulib:
gl_EARLY
dnl Jeśli C++:
AC_PROG_CXX
dnl Jeśli Objective C:
AC_PROG_OBJC
dnl Jeśli Objective C++:
AC_PROG_OBJCXX
dnl Parę użytecznych programów:
AC_PROG_SED
AC_PROG_AWK
AC_PROG_GREP
AC_PROG_EGREP
AC_PROG_FGREP
AC_PROG_LEX
AC_PROG_YACC
dnl Jeśli używamy Gnulib:
gl_INIT
dnl Sprawdza, czy w bibliotece `-lselinux' jest symbol getfilecon
AC_CHECK_LIB([selinux], [getfilecon])
dnl Sprawdza, czy w systemie jest nagłówek errno.h i/lub err.h i/lub errx.h
AC_CHECK_HEADERS([errno.h err.h errx.h])
dnl Sprawdza, czy w standardowo włączanych nagłówkach ($ac_includes_default) jest funkcja fork i/lub vfork
AC_CHECK_FUNCS([fork vfork])
dnl Szuka typu bezznakowego 16-bitowego
AC_TYPE_UINT16_T
AC_CONFIG_FILES([Makefile src/Makefile doc/Makefile m4/Makefile])
AC_OUTPUT
Pierwsze wiersze, do AM_INIT_AUTOMAKE, to typowy początek pliku. Argumentem w trzeciej linii jest względna ścieżka do pliku źródłowego programu (w celu sprawdzenia, czy źródła są poprawnie rozpakowane), w pierwszej nazwa (użytkownika), wersja, adres zgłaszania błędów, nazwa (pliku) i strona domowa. Autoconf ma bardzo dużo makr. Aby zobaczyć je wszystkie, należy przeczytać dokumentację.

</doc>
<doc id="12871" url="https://pl.wikipedia.org/wiki?curid=12871" title="Zasada kosmologiczna">
Zasada kosmologiczna

Zasada kosmologiczna – postulat w kosmologii teoretycznej i obserwacyjnej używany w co najmniej dwóch znaczeniach:
W obydwu wypadkach zasada kosmologiczna bywa też nazywana zasadą kopernikańską – mimo że ten termin ma również inne znaczenie, a Kopernik nie postulował zasady kosmologicznej.
Postulat ten ma przesłanki filozoficzne (brzytwa Ockhama), a także obserwacyjne. Obserwacje te dotyczą zarówno izotropowości kosmicznego promieniowania tła, jak również rozkładu galaktyk w skali setek megaparseków.
Zasada kosmologiczna w różnych modelach Wszechświata.
Większość modeli kosmologicznych była i jest konstruowana zgodnie z tą zasadą:
Rozważa się też modele łamiące zasadę kosmologiczną – zwykle po jednym z jej elementów.
Doskonała zasada kosmologiczna.
Dawniej rozważano również możliwość obowiązywania doskonałej zasady kosmologicznej, według której obraz Wszechświata nie zależy nie tylko od miejsca, ale i czasu obserwacji, zatem średnia gęstość materii pozostawałaby stała w czasie (model stanu stacjonarnego). Zasada niezakładająca niezmienności czasowej nazywana była słabą zasadą kosmologiczną.
Postulat ten dawał się pogodzić nawet z obserwowanym faktem ucieczki galaktyk, ponieważ wymagał kompensującej kreacji materii na niemierzalnym poziomie, tj. dwa atomy na km³ na rok. Doskonała zasada kosmologiczna została zarzucona po odkryciu mikrofalowego promieniowania tła, którego istnienie i właściwości świadczą o tym, że Wszechświat był w przeszłości znacznie gęstszy i gorętszy.
Inne teorie.
Prawdziwość zasady kosmologicznej jest kwestionowana przez niektóre dane obserwacyjne takie jak ciemny przepływ i Huge-LQG, które sugerują, że we Wszechświecie istnieją struktury zbudowane na bardzo dużą skalę, w przypadku Huge-LQG o rozmiarach sięgających jednej dwudziestej widzialnego Wszechświata.

</doc>
<doc id="12872" url="https://pl.wikipedia.org/wiki?curid=12872" title="Musical">
Musical

Musical – forma teatralna, łącząca muzykę, piosenki, dialogi i taniec. Ładunek emocjonalny dzieła – humor, patos, miłość, gniew – podobnie jak sama opowieść, jest wyrażany poprzez słowa, muzykę, ruch i aspekty techniczne przedstawienia, tworząc jedną, spójną całość. Od początków XX wieku produkcje teatru muzycznego są nazywane po prostu „musicalami”. Wcześniejszą podobną do musicalu formą widowiska była extravaganza.
Musicale są wykonywane na całym świecie. Mogą być wystawiane na wielkich scenach, jak wysokobudżetowe produkcje teatrów na West Endzie w Londynie czy Broadwayu w Nowym Jorku lub w mniejszych teatrach awangardowych, na Off-Broadwayu lub jako produkcje lokalne, wyjazdowe, w amatorskich grupach szkolnych, teatrach i innych przestrzeniach wykonawczych. Oprócz Wielkiej Brytanii i Ameryki Północnej istnieją inne dobrze działające sceny musicalowe w wielu krajach Europy, Ameryki Łacińskiej, Australii i Azji.
Definicja.
Współczesny musical jest formą eklektyczną i wielotworzywową. Korzysta z różnych gatunków muzycznych (od hard rocka przez jazz, calypso, rap aż do muzyki poważnej) i różnych rodzajów tańca (od baletu klasycznego po taniec współczesny i stepowanie). W produkcjach musicalowych na porządku dziennym jest użycie efektownych i monumentalnych dekoracji, technik multimedialnych i pełnego nagłośnienia akustycznego. W musicalach występują różnorodne typy orkiestr – od niewielkich "combo" (np. "Grease", "Chicago", "Rent"), aż po duże orkiestry musicalowe (np. "Miss Saigon", "Taniec wampirów", "Upiór w operze").
Musicale mają różny czas trwania. Wahają się od krótkich, jednoaktowych przedstawień, do wielu aktów i kilku godzin trwania (lub nawet przedstawień wielospektaklowych); jednakże większość musicali trwa od półtorej do 3 godzin. Musicale są zazwyczaj przedstawiane w dwóch aktach z jednym, 10-20-minutowym antraktem. Pierwszy akt jest najczęściej dłuższy od drugiego, wprowadza wszystkie główne postaci i większość warstwy muzycznej, często kończy się wstępem do konfliktu dramatycznego czy komplikacji fabuły. Drugi akt może wprowadzać kilka piosenek, jednak zazwyczaj tylko przywołuje ważne tematy muzyczne i rozwiązuje konflikty dramatyczne. Musical fabularny (ang. "book musical") jest na ogół konstruowany na podstawie 4 do 6 głównych tematów muzycznych, które powracają w późniejszych etapach spektaklu, choć czasem może zawierać zbiór piosenek niezwiązanych ze sobą muzycznie w sposób bezpośredni. Dialogi mówione generalnie występują pomiędzy utworami muzycznymi, choć może mieć zastosowanie „dialog śpiewany”, bądź recytatyw, zwłaszcza w musicalach śpiewanych w całości, jak "Jesus Christ Superstar", "Les Misérables" i "Evita". W ostatnich dekadach na Broadwayu i West Endzie wystawiono kilka krótszych musicali jednoaktowych.
Fabuła musicalu może być pomysłem własnym jednoaktowych autora lub adaptacją powieści ("Wicked" i "Man of La Mancha"), sztuki teatralnej ("Hello, Dolly!"), klasycznej legendy ("Camelot"), wydarzenia historycznego ("Evita"), czy też filmu ("The Producers" i "Hairspray"). Z drugiej strony wiele spośród popularnych teatralnych produkcji musicalowych zostało zaadaptowanych na film muzyczny, jak na przykład "The Sound of Music", "West Side Story", "My Fair Lady", czy "Chicago".
Musical fabularny.
Musical XX wieku – musical fabularny (ang. "book musical") definiuje się jako spektakl muzyczny, w którym piosenki i taniec są w pełni zintegrowane, tworząc dobrze napisaną historię z poważną dramaturgią, który jest zdolny do wywołania nie tylko śmiechu, ale i innych prawdziwych emocji.
Trzy główne składniki musicalu fabularnego to muzyka, teksty piosenek i scenariusz (ang. book). Pojęcie "scenariusz" odnosi się w musicalu do historii, rozwoju postaci, struktury dramatycznej wraz z dialogami mówionymi. "Scenariusz" może się jednak odnosić do dialogów i tekstów piosenek jednocześnie, używa się wówczas (na wzór opery) określenia "libretto" (wł. „mała książka”). "Muzyka" i "teksty piosenek" tworzą "partyturę" musicalu. Interpretacja musicalu przez kierownictwo artystyczne poszczególnych produkcji silnie wpływa na sposób jego prezentowania. W jego skład wchodzą: reżyser, kierownik muzyczny/dyrektor artystyczny, zwykle choreograf, a czasem także i orkiestrator. Musical kształtowany jest także przez techniczne jego aspekty, jak scenografia, kostiumy, rekwizyty, oświetlenie sceniczne i dźwięk, które zwykle ulegają zmianom w kolejnych produkcjach. Niektóre słynne elementy produkcji mogą jednak zostać zachowane z oryginału, jak na przykład choreografia Boba Fosse’a w musicalu Chicago.
W musicalu fabularnym najbardziej dramatyczne momenty wyraża się poprzez śpiew. Funkcjonuje zasada: „gdy emocje stają się zbyt silne, by je wypowiedzieć, zaśpiewaj; kiedy są zbyt silne, by je wyśpiewać, zatańcz.” W musicalu fabularnym piosenka jest skrojona dla danej postaci i jej pozycji dramaturgicznej; były jednakże okresy w historii musicalu (np. od 1890 do 1920 roku), kiedy integracja opowieści z muzyką była osłabiona. Krytyk "New York Times", Ben Brantley określił ideał piosenki musicalowej recenzując wznowienie musicalu "Gypsy" z 2008 roku: „Piosenki są idealnie scalone z postaciami, zdarza się to w tych rzadkich momentach, kiedy musicalom udaje się sięgnąć celów, dla których w ogóle istnieją”. Zwykle znacznie mniej słów wyśpiewuje się w trakcie 5-minutowej piosenki, niż pada ich w 5-minutowym dialogu. Jako że musical generalnie poświęca więcej czasu muzyce, niż dialogom, jest mniej czasu na rozwój dramatu w musicalu, niż w zwykłej sztuce o podobnym czasie trwania. Pisarze są więc zmuszeni dokonać trudnej sztuki rozwoju postaci i fabuły wewnątrz skompresowanej natury musicalu.
Opera – różnice i podobieństwa.
Musical jest powiązany z inną formą teatralną, operą. Obie formy zwykle odróżnia się na podstawie kilku czynników. W musicalu kładzie się większy nacisk na dialogi mówione (choć niektóre z musicali są w całości akompaniowane, bądź śpiewane); z drugiej strony, niektóre opery, jak np. „Czarodziejski flet” i większość operetek zawiera dialogi bez akompaniamentu; na taniec (wykonywany zarówno przez wiodących wykonawców, jak i chór); na użycie różnych gatunków muzyki popularnej (lub chociażby popularnych stylów śpiewania); unikanie użycia typowych konwencji operowych.
Musical jest prawie zawsze wykonywany w języku ojczystym jego odbiorców. Musicale wyprodukowane w Londynie i Nowym Jorku, są zawsze śpiewane po angielsku, nawet jeśli oryginalnie zapisano je w innym języku („Les Misérables”, stworzony w oryginale po francusku światową karierę zrobił w wersji anglojęzycznej). Podobnie sytuacja wygląda w polskiej praktyce musicalowej, gdzie wszystkie musicale wystawiane na scenach polskich tłumaczy się na język polski.
Podczas gdy śpiewak operowy jest przede wszystkim śpiewakiem, i dopiero w drugiej kolejności aktorem (i rzadko kiedy musi tańczyć), wykonawca musicalowy jest często przede wszystkim aktorem, a dopiero później śpiewakiem i tancerzem. Osobę, która doskonale opanowała te 3 umiejętności nazywa się w krajach anglojęzycznych „triple threat”. Kompozytorzy muzyki musicalowej ustalając wokalne uwarunkowania ról zwykle biorą pod uwagę wykonawców. Współcześnie teatry wystawiające musicale stosują skale głosu aktorów w sposób, który w kontekście opery byłby dezaprobowany, czy nawet niedopuszczalny.
Aspekt ekonomiczny.
Produkcja musicalu, w szczególności na Broadwayu i West Endzie to złożone przedsięwzięcie finansowe. Przypomina strukturę przedsiębiorstwa, które zakładane jest w celu wyprodukowania musicalu, zatrudniającego wiele dziesiątek pracowników. Przystępując do produkcji w USA producent zobowiązany jest zawrzeć umowy z organizacjami zrzeszającymi dramatopisarzy, aktorów, reżyserów, choreografów, dekoratorów, oświetlaczy, dźwiękowców i garderobianych. Właściciel sceny, na której wystawiany będzie spektakl musi podpisać umowy ze związkami pracowników technicznych sceny (IATSE), kasjerów, woźnych i sprzątaczy, operatorów ciężkiego sprzętu, odźwiernych i bileterów.
Producent najczęściej jest jedynie organizatorem – fundusze pozyskuje od inwestorów, a w razie odniesienia przez spektakl sukcesu ma swój udział w zyskach. Przedstawienia na Broadwayu są finansowane zwykle więcej niż przez jednego inwestora, na zasadach spółki z o.o. (limited partnership). W przeszłości, gdy koszty produkcji spektaklu muzycznego były znacznie niższe, w teatr inwestowali przeciętni obywatele – na zasadach lokaty czasem przynoszącej zysk, a zawsze dającej dreszcz emocji. W drugiej połowie lat 70. wystawienie musicalu kosztowało przeciętnie między 750 a 1 mln dolarów, na początku lat 80. koło 1,5 mln dolarów aż do ustanowienia rekordu przez musical Cats (5 mln dolarów).
Rzadko zdarza się, aby produkcja została sfinansowana w całości przez jednego inwestora. My Fair Lady został w całości sfinansowany przez stację CBS (400 tys. dolarów); w Annie (kosztującym 800 tys. dolarów) wniosła 100-tysięczny wkład wytwórnia filmowa Columbia.
Historia.
Musical jest jedyną rdzennie amerykańską formą teatralną, która dzięki Stanom Zjednoczonym stała się popularna na całym świecie. U źródeł musicalu leżą przede wszystkim gatunki takie jak: wodewil, rewia, burleska i minstrel show. W latach 20. XX wieku teatr amerykański zyskuje swoją odrębną tożsamość (kształtuje się dramat amerykański). Po tym, jak w 1924 pojawił się pierwszy utwór George’a Gershwina „Lady Be Good”, w 1943 powstał pierwszy musical fabularny (badacze określają go jako pierwszy prawdziwy musical) "Oklahoma!" Rodgersa i Hammersteina.
Musical filmowy.
Musical filmowy to odmiana filmu muzycznego, w której „muzyka, piosenka i taniec stanowią dominantę dramaturgiczną dzieła”.

</doc>
<doc id="12873" url="https://pl.wikipedia.org/wiki?curid=12873" title="Final Fantasy">
Final Fantasy

 – japońska seria gier, filmów i mangi z gatunku fantasy, stworzona przez Hironobu Sakaguchiego i produkowana przez firmę Square Enix (przed 2003 przez Square). Seria skupia się głównie na grach, które łączą w sobie gatunki fantasy i fantastykę naukową, a w kwestii rozgrywki cechują je rozbudowane elementy charakterystyczne dla japońskich gier fabularnych. Pierwsza gra, wydana w 1987 roku na platformę NES, została pomyślana jako ostatni tytuł niemającego wcześniej sukcesów Square. Tytuł ten jednak okazał się na tyle udany, że uratował firmę od bankructwa i dał jej możliwość stworzenia kolejnych sequeli i różnych spin-offów nieklasyfikujących się już do gatunku jRPG, a np. do taktycznych gier fabularnych, fabularnych gier akcji, MMORPG, wyścigowych, bijatyk czy rytmicznych.
Pomimo iż akcja każdej gry z serii głównej toczy się w innym świecie i przedstawia historie różnych bohaterów, gry mają wiele wspólnych elementów, jak na przykład mechaniki gry, imiona postaci czy podobne elementy fabuły, która często przedstawia grupę bohaterów stawiających opór złu skupiając się jednocześnie na relacjach łączących członków grupy. Imiona postaci, nazwy stworzeń i obiektów często zapożyczane są z historii i różnych mitologii oraz języków.
Seria stała się ogromnym sukcesem na całym świecie, sprzedając się w milionowych nakładach i otrzymując bardzo wysokie oceny od recenzentów. Jest ona najlepiej sprzedającą się serią gier od Square Enix i jedną z najlepiej sprzedających się serii gier w historii, pojawiła się również siedmiokrotnie w Księdze Rekordów Guinnessa w wydaniu z 2008 roku. W czerwcu 2011 roku Square Enix poinformowało, że wszystkie gry z serii sprzedały się w ilości ponad 100 milionów egzemplarzy.
Elementy serii.
Gry.
Seria główna.
Trzy pierwsze części serii wydano na Nintendo Entertainment System. "Final Fantasy" zostało wydane w Japonii w roku 1987, w Ameryce Północnej w 1990, a w Europie oryginalna wersja (jak i pozostałe pięć gier głównych na platformy Nintendo) nie została wydana. Gra ta była kilkukrotnie odnawiana na różnych platformach. "Final Fantasy II" wydano w Japonii w 1988 roku. Pierwsze wydanie w języku angielskim to remake z roku 2003 na konsolę Sony PlayStation. Grę "Final Fantasy III" wydano w 1990 roku, zachodniego wydania doczekała się dopiero w 2006 roku pod postacią remake’u na konsolę Nintendo DS.
Trzy kolejne części wydano na następcę NESa, Super Nintendo Entertainment System. "Final Fantasy IV" wydano w 1991 roku. Poza Japonią Nintendo dystrybuowało oryginalne wydanie jako Final Fantasy II, co wzięło się z niewydania na Zachodzie części drugiej i trzeciej. Wszystkie późniejsze wydania na inne konsole nosiły już oryginalny numer. W tej grze po raz pierwszy pojawił się system Active Time Battle. "Final Fantasy V", wydane w roku 1992 to pierwsza część której wydarzenia kontynuowano w sequelu – anime o tytule "". Pierwsze wydanie po angielsku to remake wydany w 1999 (2002 w Europie) na Sony PlayStation. "Final Fantasy VI" wydano w 1994 roku. Oryginalne wydania zachodnie używały nazwy Final Fantasy III, podobnie jak to było w przypadku Final Fantasy IV.
Na konsolę Sony PlayStation wydano trzy następne części główne, z których dwie pierwsze po kilku miesiącach od wydania konsolę Sony opublikowano na komputery osobiste. Części te wyróżniała zmiana grafiki z dwuwymiarowej na trójwymiarową, która opierała się na wyświetlaniu modeli postaci na prerenderowanych tłach. "Final Fantasy VII" z roku 1997 odróżnia się od części poprzednich cyberpunkowym klimatem. Jest to pierwsza gra z serii wydana w Europie. "Final Fantasy VIII" wydane w roku 1999 odróżnia się zastosowaniem postaci o realistycznych proporcjach, w odróżnieniu od poprzednich gier gdzie często stosowano styl super deformed. Jest to też pierwsza część, w której część muzyki jest śpiewana. "Final Fantasy IX" (2000) powraca do korzeni serii jako dziejące się w świecie bliższym grom I-VI zamiast w świecie dużo bardziej nowoczesnym ukazanym w częściach VII i VIII.
Następca PlayStation, konsola Sony PlayStation 2, doczekała się trzech części głównych, w tym jednej gry MMORPG. Tytuł z roku 2001, "Final Fantasy X" to pierwsza gra w serii w której zastosowano pełny dubbing oraz pomieszczenia i inne obszary w pełnym 3D. Jest to też pierwsza gra, która doczekała się grywalnego sequela ("Final Fantasy X-2"). Pierwsza gra MMORPG z serii, "Final Fantasy XI" została wydana w roku 2002 na PS2 i PC, a później też na Xbox 360. Dwunastą część opublikowano w roku 2006 i jest to pierwsza gra z serii głównej, w którym wykorzystano świat z innej gry – świat Ivalice, w którym dzieje się akcja także serii "Final Fantasy Tactics", gry "Vagrant Story" oraz sequelu „dwunastki” – "".
Sequele i serie poboczne.
"Final Fantasy" dało początek wielu spin-offom, z których niektóre rozwinęły się w rozbudowane serie.
Część gier, aby wykorzystać popularność serii w Ameryce Północnej zostało tam przemianowane ze swych oryginalnych tytułów na zawierające w nazwie Final Fantasy. Do tych gier należy seria SaGa, której trzy pierwsze części wydano jako "The Final Fantasy Legend", "Final Fantasy Legend II" oraz "Final Fantasy Legend III". Pierwsza gra z serii "Mana", o oryginalnym tytule "Seiken Densetsu" została wydana w Ameryce Północnej jako "Final Fantasy Adventure", a w Europie jako "Mystic Quest".
"Final Fantasy Mystic Quest" zostało zaprojektowane z myślą o północnoamerykańskiej widowni (co znajdowało odbicie w tytule japońskim – "Final Fantasy USA: Mystic Quest") jako gra o uproszczonych mechanikach i obniżonym poziomie trudności. W Europie tytuł ten nosił nazwę "Mystic Quest Legend" i, wraz z Mystic Quest, jest to pierwsza gra powiązana z serią "Final Fantasy" wydana w Europie.
"Final Fantasy Tactics" jest serią poboczną taktycznych gier fabularnych zawierającą dużo elementów pochodzących z serii głównej i odniesień do niej. Ivalice, świat, w którym dzieje się akcja tej serii został wykorzystany później w grze "Final Fantasy XII". Pozostałe serie poboczne, jak np. Chocobo (większość tytułów nie wydano poza Japonią) czy "Final Fantasy Crystal Chronicles" także korzystają z wielu elementów serii głównej. Świat przedstawiony "Final Fantasy" pojawił się też w grach serii "Kingdom Hearts".
Pierwszy bezpośredni, grywalny sequel gry z serii głównej to "Final Fantasy X-2" z roku 2003. "Final Fantasy XIII" pierwotnie miał stanowić jedną całość, jednak Square Enix postanowiło rozwinąć uniwersum tej gry, w wyniku czego powstały dwa sequele – "Final Fantasy XIII-2" oraz ", które razem stworzyły pierwszą w historii serii głównej trylogię.
Odbiór.
Seria rozumiana jako całość odniosła komercyjny sukces, choć każda z części w dość różnym stopniu partycypowała w tym sukcesie. Według Square Enix do sierpnia 2003 sprzedano 45 mln kopii gier, do grudnia 2005 63 mln, a do lipca 2008 85 mln. W czerwcu 2011 poinformowano o stumilionowej sprzedanej kopii.
Kilka gier zostało bestsellerami. Ogłoszono, że pod koniec 2007 roku "Final Fantasy VII", "Final Fantasy VIII" oraz "Final Fantasy X" były kolejno siódmą, ósmą i dziewiątą grą RPG pod względem ilości sprzedanych kopii.
Oceny.
Serię chwalono często za muzykę i stronę wizualną. Wielokrotnie seria i poszczególne gry zajmowały wysokie miejsca w różnorakich konkursach, ankietach i listach najlepszych gier. W 2006 roku w konkursie na najlepszą serię gier w dziejach zorganizowanym przez GameFAQs "Final Fantasy" zajęło drugie miejsce za serią The Legend of Zelda. Wiele gier z serii znalazło miejsce na kilku takich listach autorstwa IGN. Na liście Famitsu „100 ulubionych gier wszech czasów” znalazło się 11 gier z serii, z których 4 umieszczono w pierwszej dziesiątce, a "Final Fantasy X" i "Final Fantasy VII" na odpowiednio pierwszym i drugim miejscu. 7 rekordów w księdze rekordów Guinnessa z 2008 należy do serii, m.in. „najwięcej części serii gier RPG” (13 części głównych, 7 bezpośrednio powiązanych z częściami głównymi i 32 spin-offy), „najdłuższy okres produkcji” ("Final Fantasy XII" produkowane przez 5 lat) czy „najwięcej sprzedanych kopii konsolowej gry RPG w ciągu jednego dnia” ("Final Fantasy X").
Niektóre mechaniki stosowane w serii jednak krytykowano. W ocenie IGN skomplikowany system menu odrzuca wielu graczy. Autorzy piszący na tej stronie krytykowali także stosowany system losowych walk w trakcie eksploracji. Wypomniano też serii nieudane podejścia do przeniesienia jej w świat filmu i animacji. W 2007 Edge skrytykował serię za dużą liczbę spin-offów niedorastających poziomem do gier z głównej serii.

</doc>
<doc id="12874" url="https://pl.wikipedia.org/wiki?curid=12874" title="Maskarada">
Maskarada



</doc>
<doc id="12875" url="https://pl.wikipedia.org/wiki?curid=12875" title="Procesja">
Procesja

Procesja ma dwa znaczenia:

</doc>
<doc id="12876" url="https://pl.wikipedia.org/wiki?curid=12876" title="Hispania (Antioquia)">
Hispania (Antioquia)

Hispania – miasto w Kolumbii, w departamencie Antioquia.

</doc>
<doc id="12877" url="https://pl.wikipedia.org/wiki?curid=12877" title="Maska">
Maska

Maska – przykrycie twarzy lub jej części, z otworami na oczy, początkowo używane w celach magicznych lub obrzędowych.
Maska jest przedmiotem noszonym zazwyczaj na twarzy, zwyczajowo dla ochrony, rozrywki, służącym przebraniu bądź wykorzystywanym podczas występów. Maski były używane od starożytności zarówno do obrzędów, jak i do celów praktycznych. Zazwyczaj noszone na twarzy, chociaż mogą także być umieszczone gdziekolwiek indziej na ciele.
W niektórych częściach Australii gigantyczne totemiczne maski zakrywały całe ciało. Inuitki zaś używały masek zakładanych na palce w trakcie opowiadań i tańców.
Maski mogą mieć różne kształty, czasami przedstawiają emocje, innym razem zwierzę, demona lub potwora.
Maski występują w różnych kulturach i obszarach geograficznych. W Europie znane w starożytnym teatrze greckim, od średniowiecza używane w czasie zabaw karnawałowych zwanych maskaradami. Od XVI w. wprowadzone do teatru dworskiego, później do "commedii dell’arte".
Etymologia.
Polskie słowo „maska” (podobnie jak angielskie "mask", które pojawiło się w języku angielskim w latach 30. XVI wieku) pochodzi z francuskiego oznaczającego „nakrywanie w celu schowania lub ochrony twarzy”, które z kolei wywodzi się z włoskiego słowa "machera", a to ze średniowiecznej łaciny, w której oznaczało „maskę, zjawę, koszmar”. Wyraz ten ma niepewne pochodzenie, przypuszczalnie z arabskiego "mascharah" , czyli „błazen”, pochodzącego ze słowa "sachira", czyli „ośmieszać”. Jednakże słowo może również pochodzić od prowansalskiego , czyli „zaczerniający (twarz)” (lub powiązanego z katalońskim lub starofrancuskim "mascurer"). To ma również niepewne pochodzenie – może mieć niemiecki źródłosłów pokrewny z angielskim , ale może to być również "mask"- „czarny”, zapożyczone z języka preindoeuropejskiego. Natomiast wg Markusa Kupferbluma słowo ma korzenie arabsko-hiszpańskie, gdzie arabskie „mascharat” oznacza psotę, wybryk, a hiszpańskie ma znaczenie ogólniejsze i głębsze – „więcej niż twarz”. Stąd powstało „máscara”, czyli maska. Inne powiązane formy to arabska "maschara" = „ośmieszony, wykpiony”, "masacha" =„odmieniony”.
Historia.
Stosowanie masek w rytuałach lub ceremoniach jest bardzo starą ludzką praktyką na całym świecie, chociaż maski mogą być również noszone dla ochrony, dla sportu, na polowaniach, na ucztach lub na wojnach – lub po prostu użyte jako ornamentyka. Niektóre maski ceremonialne lub dekoracyjne nie były przeznaczone do noszenia. Chociaż użycie religijne masek zmalało, maski bywają stosowane w terapii teatralnej lub psychoterapii.
Antyczna maska.
Jednym z wyzwań w antropologii jest znalezienie dokładnego pochodzenia ludzkiej kultury i wczesnych działalności, z inwencją i użyciem maski stanowiącej tylko jeden obszar nierozwiązanego dochodzenia. Użycie masek datuje się na kilka tysięcy lat. Przypuszcza się, że pierwsze maski mogły być powszechnie używane przez prymitywnych ludzi, żeby połączyć posiadacza ze swego rodzaju bezspornym autorytetem, taki jak bogowie lub skądinąd nadać wiarygodność osobie o danej roli społecznej. Najstarsze maski, które były odkryte, mają 9000 lat i są przechowywane w Muzeum „Bible et Terre Sainte” (Paryż) i Muzeum Izraela (Jerozolima). Najprawdopodobniej praktyka wykonywania masek jest starsza – najwcześniejsze znane antropomorficzne dzieła sztuki mają 30000–40000 lat. Maski szamańskie uważane są za najstarsze, na przykład maski z Malakoff sprzed 27 tysięcy lat p.n.e. Warto również zwrócić uwagę na malowidła paleolityczne w niektórych jaskiniach, które to przedstawiają tańczące postaci w maskach przypominających głowy zwierząt takich jak dziki, bizony, niedźwiedzie, kozice czy jelenie.
Wykonanie.
W antyku maski tworzone były przede wszystkim z płótna, korka czy drewna. Odznaczały się silną ekspresją, ich zadaniem było ukazać jednoznacznie określone emocje lecz mimo to zachowywały naturalne proporcje. Wyjątek stanowiły maski, które przedstawiać miały postacie nie z tego świata. W Afryce maski wykonywano z drewna, kości słoniowej, metalu, kamieni, roślin. Charakterystyczną ich cechą jest dramatyczny i silny ekspresjonizm, brak przywiązywania wagi do naturalizmu oraz proporcji, ostre i kanciaste formy, mocne wyczucie plastyczne. Popularny rodzaj masek stanowią maski karnawałowe, które najczęściej wykonywane są z papieru czy plastiku. Maski karnawałowe nakłada się, by ukryć swoją tożsamość dla czystej zabawy. Słowo „maska” bywa używane nie w znaczeniu nakrycia twarzy, lecz na określenie części ubrania zakrywającego twarz, takiego jak welon, frędzle lub zasłona, czy ozdoby twarzy o charakterze jej repliki. Zdarza się, iż oznacza się w ten sposób podobizny, rzeźby, twarze malowane na budynkach czy łodziach nie zależnie od ich wielkości, pomalowanie twarzy, ciała, make up lub tatuaże. W takim zakresie pojęciowym słowo „maska” staje się mało użyteczne. Według Asa Boholma główną funkcją maski nie jest pospolite zakrywanie twarzy. Maską staje się cały kostium osoby przebranej jak na przykład ozdoby, nakrycie głowy, różnorodne konstrukcje architektoniczne czego przykładem są sławne szczudła afrykańskiego plemienia Dogonów, ekrany, platformy oraz inne urządzenia posiadające znaczenie rytualne. Innymi popularnymi rodzajami masek są maski przedstawiające rożnego rodzaju istoty nadprzyrodzone, przodków, zmarłych, potwory, które starano się obłaskawić, maski wymierzające sprawiedliwość, maski wojenne, komiczne. Unikano tworzenia masek demonów, których lękano się nieprzeciętnie, na przykład demonów chorób nieuleczalnych.
Funkcje.
Maski ważną rolę odgrywały w obrzędach religijnych, szczególnie podczas obrzędów przejścia. Przedmiot ten ma służyć ukryciu, ochronie jednostkowej jaźni, porozumieniu, scaleniu które w systemach totemicznych doprowadzić może do reprezentowania określonego klanu bądź też służyć mogła odseparowaniu jednostki od grupy. Posługiwanie się maską przez dawne kultury związane było z różnego rodzaju stanami liminalności, zmianą statusu czy ról społecznych. Ważną rolę pełniły również w ceremoniach związanych z kultem przodków. Miały one bowiem za zadanie wizualizować istoty, które według tubylców należą już do świata transcendentnego, przy jednoczesnej wspólnej potrzebie uczucia aktualizacji obecności i mocy zmarłych. Dzięki masce dokonywało się wkroczenie ze sfery "sacrum" w sferę "profanum". Maski oraz przebrania używane w celach rytualnych umożliwiały człowiekowi stawanie się osobnikiem przybyłym z zaświatów. Człowiek w kostiumie nie objawiał już cech ludzkich. Symboliczny związek istniejący pomiędzy przebraniem a jego żywym odpowiednikiem umożliwiał zyskanie wymiaru sakralnego. Dlatego też człowiek, który przebrany był za groźne zwierzę, wykazywać miał cechy tegoż osobnika. 
Funkcje maski w różnych plemionach.
Sycylia
Nowa Gwinea
Nowa Brytania
Maska w performansie.
Na całym świecie maski są używane z powodu swojej siły ekspresji jako cecha charakterystyczna występów z użyciem masek – zarówno rytualnych, jak i teatralnych. Rytualne i teatralne definicje używania maski nierzadko częściowo łączą się, jednakże ciągle zapewniają użyteczne podstawy klasyfikacji. Obrazy zestawienia komediowych i dramatycznych masek są powszechnie używane do prezentowania sztuk scenicznych, a szczególnie dramatów. Dzięki maskom, kilku zaledwie aktorów mogło odgrywać wiele ról. W starożytnym Rzymie, słowo „persona” (osoba) ma znaczenie „maska”, odpowiada również osobie, która miała pełne obywatelstwo rzymskie. Obywatel mógł demonstrować swoje pochodzenie poprzez wyobrażenia pośmiertnych masek przodków.
Były one odlewane z wosku i przechowywane w larariu, czyli w rodzinnej kapliczce. Podczas ceremonii przejścia, czyli inicjacji młodych członków rodziny, czy pogrzebów, maski były przenoszone z kapliczek pod nadzorem rodowych obywateli. Na pogrzebach profesjonalni aktorzy nosili maski by przedstawiać czyny z życia przodków, łącząc w ten sposób role maski jako obiektu rytualnego oraz teatralnego. Maski są znanymi i żywymi elementami wielu kultur, tradycyjnych występów, ceremonii, rytuałów i festiwali oraz często mają starożytne pochodzenie. Maska jest przeważnie częścią kostiumu, który zdobi całe ciało i uosabia ważne tradycje wspólnoty religijnej lub społecznej, zarówno całej, jak i poszczególnych grup. Maski są używane niemal uniwersalnie zachowując przy tym swoją moc i tajemnice zachowane dla ich użytkowników oraz odbiorców. Popularnym przykładem są maski pojawiające się na karnawałach, a także na imprezach dla dzieci oraz festiwalach – na przykład Halloween. W dzisiejszych czasach plastikowe maski są zazwyczaj produkowane masowo. Często bywają związane z postaciami popularnymi w telewizji bądź bohaterami bajkowymi. Są one jednakże przypomnieniem o trwałej grze pozorów oraz ich sile i uroku. Maska sama w sobie pełni podwójną rolę – skrywania i odsłaniania zarazem. Jest jednocześnie wyrazem sekretu jak i zaproszeniem do jego odkrycia.
Maska pośmiertna.
Maska pośmiertna według archaicznych tradycji, osoba nakładająca maskę reprezentowała zmarłych. Dzięki masce umarli przemieniali się w żywych, zaś żywi w zmarłych, a granica między życiem i śmiercią zacierała się. Jednak maska utożsamiana ze śmiercią miała nie tylko straszyć. Przykłady na to znajdujemy w starogreckiej komedii, gdzie maski wywoływały efekt śmieszności, który wyzwalał przed przykrą koniecznością śmierci.
Maskowanie się myśliwych.
Ludzie paleolitu byli myśliwymi i zbieraczami, nie rolnikami. Dla kobiet przywiązanych do obozowisk z powodu nadanych im funkcji fizjologicznych takich jak ciąża, zajmowanie się dzieckiem przeznaczona była przyroda jako obiekt poznania, dla mężczyzn zaś była wrogiem. Kobiety, jako zbieraczki w poszukiwaniu pożywiania nie potrzebowały planu czy specjalistycznych taktyk, w przeciwieństwie do polowania, którym zajmowali się mężczyźni. Zwodzenie, oszustwo i pozór stosowane przez mężczyzn miało na celu zdobyć pożywienie w postaci zwierzyny. W pierwotnych kulturach polowanie stanowiło rodzaj pracy, zapewniającej przetrwanie całemu plemieniu, pracy która dała początek zachowaniu kolektywnemu. Ukrywanie prawdziwego ja myśliwych pod maską stanowi cząstkę działania socjalnego i socjalizującego zarazem. W skład tego typu maskowania wchodzi nie tyle co sam wygląd w postaci na przykład zwierzęcych skór, ale również zachowanie, ruchy oraz głos. By polowanie się powiodło, myśliwi wykorzystywali tusz z upolowanych zwierząt, by ukrywając swoją tożsamość upodobnić się do ofiary lub też smarowali ciała specjalnie przygotowanymi maściami, dzięki którym niwelowali własny zapach.

</doc>
<doc id="12878" url="https://pl.wikipedia.org/wiki?curid=12878" title="Karnawał">
Karnawał

Karnawał, zapusty – okres zimowych balów, maskarad, pochodów i zabaw. Rozpoczyna się najczęściej w dniu Trzech Króli, a kończy we wtorek przed Środą Popielcową, która oznacza początek wielkiego postu i oczekiwania na Wielkanoc.
Geneza karnawału.
Nazwa pochodzi od włoskiego "carnevale", z łaciny: "carnem levāre" ("mięso usuwać") bądź "caro, vale" ("żegnaj mięso"). Pokrewne nazwy to starowłoskie "carasciale" z łaciny "carnem" "laxāre", rumuńskie "cârneleagă" z "carnem" "ligat", oraz hiszpańskie "carnestolendas" z "caro" "tollenda". Wszystkie oznaczały pożegnanie mięsa przed rozpoczynającym się wielkim postem. Inna etymologia tej nazwy, każe szukać jej źródeł w łac. "carrus navalis" wóz w kształcie okrętu, który uczestniczył w procesji świątecznej ku czci bogini Izydy a później Dionizosa w starożytnym Rzymie.
Karnawał wywodzi się z kultów płodności i z kultów agrarnych. Od głębokiej przeszłości utrzymywało się przekonanie, że im wyższe będą skoki, tym wyżej będzie rodziło zboże. Między innymi dlatego Karnawał jest tak ściśle związany z tańcami. W wielu krajach europejskich, zwłaszcza na wsiach praktykowano także tańce dookoła ogniska, najczęściej w formie koła.
Zapusty w polskiej kulturze ludowej.
Zapusty na Kaszubach.
Zarówno zapusty jak i inne zwyczaje Kaszubów mają swoje źródło w dawnej przeszłości i tworzą ich kulturę. Zapusty to czas zabaw i tańców. W tym czasie często spożywa się też duże ilości alkoholu. Panny wystrojone w piękne suknie brały udział w balach, by znaleźć mężów. Okres ten kończy się w ostatki.
Dawniej w zapusty jedzono dużo tłustych dań, bardzo popularne były placki ziemniaczane. Jedzono wiele, jakby chciano zaspokoić głód przed zbliżającym się postem. Ludzie bardzo biedni starali się w tym dniu zjeść choć trochę mięsa wierząc w to, że kto w zapusty nie je mięsa, tego komary przez lato zjedzą. W tym czasie smażono też pączki, faworki i bliny. Taniec, zabawa, śpiewy, to nieodzowne elementy zapustne. Do dzisiaj zachował się tam zwyczaj chodzenia w zapusty przebierańców. Spotkać można wśród nich postacie z kolędowania, niedźwiedzia, konia, bociana, cygana czy żandarma.
Wraz z wybiciem północy kończy się zabawa i rozpoczyna się czas wielkiego postu. Zgodnie ze zwyczajem, we wtorek zapustny piecze się wyjątkowe ciasto, tzw. "popielnik". Ciasto to piecze się z reszty ciasta po pùrclach zôpùstnëch. Na Kaszubach bardzo przestrzega się dni postnych, dlatego też we wtorek zapustny dokładnie myje się wszystkie patelnie i garnki, w których było przygotowywane na zapusty mięso. Dawniej na czas postu patelnie wieszano na płocie lub na kominie. Głównym pożywieniem Kaszubów w czasie postu były krëpe, bùlwe i slëdze. Śledzie były stosunkowo tanie, więc gospodarze mogli sobie pozwolić na zakup całej beczki śledzi, które spożywano w czasie postu.
Zapusty, to czas, w którym na Kaszubach odwiedzało się dalekich krewnych. Rodziny zbierały się i w kilka sań wyruszano na wspólne odwiedziny bliskich. Kaszubskie zwyczaje karnawałowe są bardzo urozmaicone, a wiele z nich przetrwało do dziś.
Karnawał na świecie.
Widowiskowe karnawały odbywają się w Rio de Janeiro, w Wenecji oraz na Wyspach Kanaryjskich i w Niemczech. Największym po karnawale w Rio pod względem liczby odwiedzających go turystów jest Notting Hill Carnival w Londynie. Co roku w ciągu dwóch dni przyciąga ponad 1,5 mln turystów.
Karnawał wenecki.
Jednym ze zwyczajów jest Lot Anioła. W 2007 aniołem była włoska pływaczka Federica Pellegrini, natomiast w 2008 amerykański raper Coolio.
Karnawał w Londynie.
Coroczny festiwal w Londynie trwa dwa dni (niedziela i poniedziałek, tzw. Bank Holiday Monday) w sierpniu w dzielnicy Notting Hill.
Karnawał w krajach niemieckojęzycznych.
Centrum niemieckiego karnawału (Karneval) jest północna Nadrenia-Westfalia, gdzie co roku 11 listopada o godz. 11.11 rozpoczyna się tzw. piąta pora roku (tak nazywa się karnawał w Kolonii). Przez kolejne miesiące (w czasie adwentu nie wszędzie) odbywają się posiedzenia karnawałowe, sowicie podlewane alkoholem i intensywne przygotowania stowarzyszeń karnawałowych do karnawałowej parady końcem karnawału. Święto Trzech Króli rozpoczyna powszechny karnawał. W ostatni czwartek karnawału (Weiberfastnacht) w Nadrenii i Westfalii kobiety uzbrojone w nożyce obcinają mężczyznom krawaty, oprócz tego odbywają się też kobiece szturmy na ratusze. Co roku w Weiberfastnacht, punktualnie o godzinie 11.11 kilkadziesiąt tysięcy przebranych w barwne kostiumy kobiet wdziera się do ratuszy w Düsseldorfie, Bonn, Kolonii, Moguncji i innych niemieckich miastach, by obciąć krawaty urzędnikom i otrzymać symboliczny klucz do bram miasta, przejmując na ten dzień symbolicznie władzę. W ostatni poniedziałek (Rosenmontag) odbywają się duże karnawałowe parady, z muzyką, wozami pełnymi przebierańców zrzeszonych w towarzystwach karnawałowych, rzucających słodycze w tłum. Poszczególne regiony mają swoje zawołania (Narrenruf), np. Kölle Alaaf w Kolonii.
Poza powyższym obszarem istnieje zwyczaj świętowania karnawału pod nazwą Fasching, Fastnacht, Fastelabend lub Fasnacht – także poza Niemcami. Np. w Moguncji używa się nazw "Mainzer Fastnacht", "Määnzer Fassenacht" lub "Meenzer Fassenacht".
Karnawał w Danii.
W Danii obchodzone jest święto karnawałowe "Fastelavn" siedem tygodni przed Niedzielą Wielkanocną.
Karnawał w Nowym Orleanie.
Karnawał w Nowym Orleanie jest znany jako "Mardi Gras", dosłownie "Tłusty wtorek" (Ostatki) – w rzeczywistości chodzi o cały okres karnawału.
Carnaval Sztukmistrzów.
Karnawał w Mieście Lublin znany jest tu jako "Carnaval", i jest festiwalem sztuki nowego cyrku i teatru, który odbywa się zazwyczaj w ostatnim weekendzie lipca. Nazwa tego wydarzenia nawiązuje do postaci Sztukmistrza z Lublina, bohatera książki noblisty Izaaka Bashevisa Singera. Patronem jest więc Jasza Mazur, iluzjonista i akrobata z powieści Singera, który przypominać ma o wielokulturowości i wieloreligijnej tradycji miasta. Carnaval Sztukmistrzów z roku na rok przyciąga coraz szersze rzesze artystów, mieszkańców i turystów. Szacuje się, że w edycji z 2019 roku wzięło udział już ponad 200 tysięcy widzów.

</doc>
<doc id="12880" url="https://pl.wikipedia.org/wiki?curid=12880" title="Triumf">
Triumf

Triumf (z łac. "triumphus") – w antycznym Rzymie najwyższe wyróżnienie jakie otrzymywał wódz za swe zwycięstwa na polu walki. Początkowo miał charakter religijny, związany z oczyszczeniem żołnierzy biorących udział w walce. Z czasem ewoluował w kierunku okazałego widowiska mającego na celu uczczenie zwycięskiego wodza i jego żołnierzy.
Rozróżniano dwa rodzaje triumfów: "triumphus curulis" (tzw. wielki triumf), podczas którego triumfator jechał na rydwanie, i "ovatio", gdy wódz jechał konno.
Warunki przyznania prawa do triumfu.
Triumf mógł zostać przyznany wbrew woli Senatu, z woli jedynie ludu (Rzymian); z woli tak Senatu, jak i ludu; czasami także bez zezwolenia Senatu czy ludu. Uzyskanie prawa do triumfu wiązało się z koniecznością spełnienia kilku warunków:
Zdarzały się wyjątki, gdy triumf odbył się bez działań wojennych lub bez udziału wojska, gdy imperator sam jeden wjechał do miasta.
Przebieg triumfu.
Wojska stawały przed granicami stolicy, wódz wkraczał samotnie do Rzymu i składał dokładne sprawozdanie przed Senatem. Na tej podstawie Senat podejmował decyzję o przyznaniu prawa do przeprowadzenia triumfu oraz nadaniu przydomków pochodzących od podbitych krain i ludów, a wódz miał prawo przedstawić bitwy na obrazach. Triumf mógł się odbyć bez przeprowadzenia działań wojennych
Jeżeli prawo zostało przyznane, wódz wkraczał do miasta na czele swoich wojsk. Triumf trwał trzy dni. Uroczysty pochód podążał ustaloną trasą w stronę świątyni Jowisza, położonej na Kapitolu. Na początku szli członkowie senatu i dostojnicy państwowi, następnie muzykanci. Wszyscy przybrani byli w wieńce. W dalszej kolejności niesiono zdobycze i wyobrażenia zdobytych krajów w formie obrazów lub wież oraz malowidła niektórych wydarzeń bitewnych. Niesiono wieńce dla wodza. Po nich prowadzono zwierzęta ofiarne, następnie królów i wodzów zdobytych krajów i jeńców wojennych. Bezpośrednio przed wodzem kroczyli liktorzy ubrani w purpurę, a także muzykanci oraz gromada ludzi z kadzielnicami. 
Imperator jechał na specjalnym rydwanie, zwanym currus, zaprzężonym w 4 białe konie, z którego zwisał fallus, jako amulet. Ubrany był na wzór dawnych królów rzymsko-etruskich, a więc: szata Jowisza Najlepszego Największego wzięta z Kapitolu, haftowana purpurowa toga z wyszytymi złotymi gwiazdami ("tunica palmata, toga picta"), na głowie wieniec ("corona laurea" lub "corona Etrusca"), na palcu żelazny pierścień. Twarz na podobieństwo boga miał ubarwioną czerwienią. W rydwanie mogły mu towarzyszyć żona i dzieci. W rękach zwycięzca trzymał berło z kości słoniowej i wawrzyn. Na jego piersi wisiał złoty medalion odwracający wszelki zły urok ("bulla aurea"). Zgodnie z tradycją na rydwanie za wodzem stał niewolnik, trzymał nad jego głową złoty laur i cały czas mu powtarzał: "Hominem te memento!" ("Pamiętaj, że jesteś tylko człowiekiem") tzn. że nie jest bogiem. 
Po bokach rydwanu na koniach jechali krewni. Za nim podążali żołnierze straży przybocznej z okrzykiem "io triumphe"; następnie pisarze i służący. Za nimi wojsko według centurii i kohort, wszyscy w wieńcach, najdzielniejsi nieśli nagrody zwycięstwa. W trakcie triumfu obowiązywała wolność słowa, co umożliwiało wyrażanie opinii o wodzach poprzez szydzenie z nich lub chwalenie. Z Forum wozy kierowano na Kapitol, gdzie zwycięzca oddawał Jowiszowi wawrzyn, składał ofiary dziękczynne, następnie całą uroczystość zakańczał sakralną ucztą. W tym czasie pojmanych wodzów odprowadzano do więzienia i uśmiercano.
Juliusz Cezar po zwycięstwie nad Pontem kazał nieść przed sobą słynny napis: "veni, vidi, vici" („przybyłem, zobaczyłem, zwyciężyłem”. Wśród dekoracji niesiono wyobrażenia miast, a także rzek: Renu i Rodanu. Ocean przedstawiono w postaci młodego chłopca pomalowanego na złoto.
Triumf w czasach nowożytnych.
W czasach nowożytnych triumfy zostały wskrzeszone w renesansowych Włoszech, we Florencji. Odbywały się one w czasie karnawału, brały w nich udział specjalnie przystrojone wozy przyozdobione kwiatami, dekoracjami i postaciami mitologicznymi, towarzyszył im tłum przebierańców w maskach i kostiumach, śpiewający satyryczne pieśni, często o zabarwieniu erotycznym.
Jednym z najsłynniejszych triumfów nowożytnych był "Triumf Bachusa", dedykowany Wawrzyńcowi Wspaniałemu. Innym znanym adresatem triumfu był Petrarka, którego lud Florencji uczcił jako swego wielkiego poetę. Dość precyzyjnie triumfy opisał włoski architekt Giorgio Vasari w swym dziele "Le vite".

</doc>
<doc id="12883" url="https://pl.wikipedia.org/wiki?curid=12883" title="Salii">
Salii



</doc>
<doc id="12885" url="https://pl.wikipedia.org/wiki?curid=12885" title="Saliowie">
Saliowie

Saliowie (łac. "Salii", od "salio" – tańczę) – członkowie jednego z najstarszych kolegium kapłanów w Rzymie antycznym, kapłani Marsa.
Początkowo istniało jedno kolegium, zorganizowane przez Numę Pompiliusza na Palatynie – tak zwani "Salii Palatini", które później rozpadło się na dwa. Drugą grupę miał zorganizować Tullus Hostiliusz na Kwirynale w pobliżu Porta Collina; zwano ich "Salii Collini" lub "Agonales".
Saliów było 24 (12 z Kapitolu i 12 z Kwirynału) i byli wybierani wyłącznie z patrycjuszów. Przewodził kolegium "magister", ważną rolę odgrywali też "praesul" (prowadzący taniec) i "vates" (prowadzący chór). Dwa razy w roku: w marcu i październiku, w formie procesji, wykonywali oni na ulicach miasta staroitalskie tańce i pieśni kultowe, ze spiżowymi tarczami, zwanymi ancilia, przyodziani w (już wtedy uznawane za antyczne) staroitalskie stroje składające się z tuniki, pancerza, togi ("toga praetexta") i szpiczastej czapki ("apex"). W swych pieśniach ("Carmen saliare") wzywali Marsa. Była to tak stara tradycja, że Marek Terencjusz Warron (116-27 p.n.e.) dokonywał przekładu tekstów tych pieśni na bardziej współczesną łacinę.

</doc>
<doc id="12886" url="https://pl.wikipedia.org/wiki?curid=12886" title="Patrylokalność">
Patrylokalność

Patrylokalność, patrylokalizm – zasada wynikająca ze zwyczaju obecnego w pewnych kręgach kulturowych, według którego para po zawarciu związku małżeńskiego zamieszkuje w miejscu lub w pobliżu miejsca zamieszkania rodziny męża. Patrylokalność (w odniesieniu do łączenia się w pary, a nie do samego małżeństwa) występowała prawdopodobnie także wśród Neandertalczyków oraz przedstawicieli "Australopithecus" i "Paranthropus robustus". Nie było to jednak uniwersalne zjawisko – matrylokalność przejawiali m.in. przodkowie rdzennych mieszkańców Oceanii. Możliwe, że patrylokalność jest jedną z przyczyn, dla których niektórzy rodzice na Bliskim Wschodzie decydują się na aborcję selektywną ze względu na płeć, w wyniku której w społeczeństwie jest znacznie więcej mężczyzn niż kobiet.

</doc>
<doc id="12887" url="https://pl.wikipedia.org/wiki?curid=12887" title="Matrylokalność">
Matrylokalność

Matrylokalność, matrylokalizm – zasada wynikająca ze zwyczaju
obecnego w pewnych kręgach kulturowych, według którego para po zawarciu związku
małżeńskiego zamieszkuje w miejscu lub w pobliżu miejsca zamieszkania rodziny żony. Występuje ona np. w Laosie. 
Rodzina matrylokalna to młode małżeństwo osiadłe w domu rodziców panny młodej.

</doc>
<doc id="12888" url="https://pl.wikipedia.org/wiki?curid=12888" title="Lokalizacja małżeństwa">
Lokalizacja małżeństwa

Lokalizacja małżeństwa – zwyczaje społeczne wyznaczające miejsce zamieszkania
współmałżonków po zawarciu związku małżeńskiego.
Antropologowie, by opisać te sytuacje, mówią o lokalizacji małżeństwa, małżeńskim lokalizmie albo jeszcze inaczej o rezydencji i wyróżniają wiele znaczących przypadków; nie są to przypadki wykluczające się nawzajem. Wyraz „współmałżonkowie” może się odnosić do małżeństw poligamicznych, np. w przypadkach poliandrii w Tybecie.
Najczęściej wspominane w literaturze przypadki to:
Inne przypadki:

</doc>
<doc id="12889" url="https://pl.wikipedia.org/wiki?curid=12889" title="Wyraz">
Wyraz

Wyraz – pewna wyróżniona fonetycznie, czy też graficznie, część wypowiedzi, składająca się z jednego lub więcej morfemów.
„Wyraz” nie jest tworem w pełni obiektywnym i co jest wyrazem, a co nim nie jest, zależy w sporym stopniu od tradycji językoznawczej danego języka. W językach analitycznych „wyraz” to to samo co „słowo”, w językach fleksyjnych pojęcie wyrazu wydaje się mniej jasne – wyrazem jest morfem bazowy z dołączonymi do niego aktualnie użytymi morfemami odmiany. W praktyce przyjmuje się kryterium graficzne: w ramach tekstu pisanego (zapisanego w alfabetach zachodnich: greckim, łacińskim, cyrylickim, ormiańskim, gruzińskim, a także w hebrajskim) traktuje się jako ciąg liter pomiędzy dwiema spacjami. To kryterium nie ma zastosowania w przypadku wielu innych systemów pisma (np. arabskiego, gdzie pseudo-spacje pojawiają się wewnątrz wyrazów; chińskiego, japońskiego, czy wielu pism Azji południowo-wschodniej, gdzie w ogóle nie stosuje się spacji; tybetańskiego, gdzie spację zapisuje się po każdej sylabie, bez względu na długość wyrazu/słowa; podobnie zresztą jak w tekstach wietnamskich zapisywanych z użyciem alfabetu łacińskiego. Szczególnie trudne jest do stosowania w przypadku analizy wypowiedzi ustnych (czy języków nie posiadających w ogóle pisma).
Wyraz w polskiej tradycji językoznawczej.
W przypadku języka polskiego przyjmuje się kryterium morfologiczno-graficzne, w połączeniu z fonetycznym (granicę wyrazu wyznacza stały akcent na drugiej sylabie od końca).
Jednak nawet tutaj jest wiele niejasności, na przykład:
Wyraz a słowo.
Niektórzy strukturaliści proponują następujące rozróżnienie pomiędzy "wyrazem" a "słowem":
Wyrazy samodzielne i niesamodzielne.
Wyrazy samodzielne – wyrazy, które mogą same pełnić funkcję części wypowiedzenia. Są to czasowniki, rzeczowniki, przymiotniki, liczebniki, przysłówki i zaimki. Wyrazy niesamodzielne to zaś wyrazy, które nie mogą same pełnić funkcji wypowiedzenia: partykuły, spójniki, przyimki.
Wyrazy odmienne i nieodmienne.
Wyrazy odmienne, występujące w wypowiedzeniach w różnych formach, to czasowniki, rzeczowniki, przymiotniki oraz większość zaimków. Wyrazy nieodmienne zaś nie zmieniają swoich form. Do tej grupy należą przysłówki, zaimki przysłowne, przyimki, spójniki, wykrzykniki, partykuły.
Wyrazy określane i określające.
Wyrazy określane – wyrazy, które w związku wyrazowym pełnią rolę wyrazów nadrzędnych np. w związku wyrazowym "ładny kot" wyraz "kot" jest wyrazem nadrzędnym (określanym) w stosunku do wyrazu dopełniającego go treścią, podrzędnego - "czarny" kot: jaki? – czarny. Wyrazy określające to zaś wyrazy, które w związku wyrazowym pełnią rolę wyrazów podrzędnych.

</doc>
<doc id="12891" url="https://pl.wikipedia.org/wiki?curid=12891" title="Rzeczownik określający">
Rzeczownik określający

Rzeczownik określający – nazwa części mowy mającej funkcję określającą dla rzeczowników, a jednocześnie właściwości gramatyczne charakterystyczne dla przymiotnika.
Występuje m.in. w języku japońskim obok właściwych przymiotników.

</doc>
<doc id="12892" url="https://pl.wikipedia.org/wiki?curid=12892" title="Czasownik">
Czasownik

Czasownik – część mowy służąca do przedstawiania dziejących się czynności oraz zachodzących stanów. W zdaniu tworzy orzeczenie. Czasowniki są nazwami czynności, jakie wykonują w danym czasie istoty żywe, narzędzia lub maszyny, oraz nazwami stanów, w jakich te istoty albo przedmioty się znajdują. 
Nie w każdym języku da się wyróżnić jasną klasę czasowników (na przykład w języku japońskim przymiotniki mają wiele właściwości charakterystycznych dla czasowników). 
Podział czasowników.
Czasowniki można podzielić na:
W ostatniej grupie czasowników wyróżnia się:
Czasownik w języku polskim.
Odmiana.
W języku polskim czasownik odmienia się przez:
Nieosobowe formy.
W języku polskim czasowniki tworzą formy nieosobowe, w których nie można określić osoby (podmiotu):
Aspekt.
Aspekt w języku polskim sygnalizuje, czy czynność została wykonana, czy się ją nadal wykonuje. W czasie przyszłym zawiera informację, czy podmiot będzie miał zamiar ją skończyć, czy tylko zacząć.
Wyróżnia się czasowniki w formie aspektowej:
Iteratywność.
W systemach gramatycznych niektórych języków (w tym m.in. języka polskiego) wyróżnia się ponadto czasowniki jednokrotne, np. "chodzić", "czytać", "spać", oraz wielokrotne (tzw. iterativa), np. "chadzać", "czytywać", "sypiać".
Imiesłowy.
W wielu językach indoeuropejskich niektóre formy czasowników (imiesłów, rzeczownik odczasownikowy) przybierają pewne cechy uznawane za typowe dla innych części mowy. Dla przykładu polskie formy imiesłowu przymiotnikowego czynnego, ("mieszkający", "czytający" itp.) uważane są za formy czasownikowe, jednak odmieniają się przez przypadki jak przymiotniki ("mieszkającego", "czytającemu" itp.). Podobnie formy imiesłowu przymiotnikowego biernego ("zbudowany", "robiony" itp.) mają cechy przymiotników i także odmieniają się przez przypadki. Analogiczna sytuacja występuje także w innych językach, na przykład angielskie "building" (budowla, budujący), niemieckie "Essen" (jedzenie) i "essen" (jeść).

</doc>
<doc id="12893" url="https://pl.wikipedia.org/wiki?curid=12893" title="18. ceremonia wręczenia Oscarów">
18. ceremonia wręczenia Oscarów

18. ceremonia rozdania Oscarów odbyła się 7 marca 1946 roku w Grauman’s Chinese Theater w Los Angeles.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii, napisano ich pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).

</doc>
<doc id="12894" url="https://pl.wikipedia.org/wiki?curid=12894" title="Rzeczownik">
Rzeczownik

Rzeczownik – samodzielna składniowo i semantycznie odmienna część mowy nazywająca rzeczy, obiekty, miejsca, osoby, czynności, organizmy, zjawiska i pojęcia abstrakcyjne. Rzeczownik w języku polskim pełni funkcję głównie podmiotu w zdaniu; może też pełnić funkcję dopełnienia, okolicznika, przydawki lub orzecznika. Może odmieniać się przez liczby i przypadki, występuje w rodzajach. Odmianę rzeczowników przez przypadki określa się mianem deklinacji. Istnieje także grupa rzeczowników całkowicie nieodmiennych (np. "atelier, kiwi, bikini, taxi, kakadu, kamikaze" itp.). Rzeczownik tworzy związki składniowe i semantyczne z rzeczownikami (zaimkami rzeczownymi), przymiotnikami (zaimkami przymiotnymi), liczebnikami (zaimkami liczebnymi) i czasownikami lub (rzadko) przysłówkami (zaimkami przysłówkowymi). 
W większości języków istnieje jakiś system klasyfikacji rzeczowników. Systemy te to zwykle system rodzajów (niewielka zamknięta liczba kategorii mająca duży wpływ na inne konstrukcje języka) lub system liczników (duża otwarta liczba kategorii mająca ograniczony wpływ na inne konstrukcje, np. przy liczeniu) albo klasy. Większość języków indoeuropejskich ma system rodzajów – od 2 (włoski, francuski, hiszpański), przez 3 (łacina, niemiecki) do nawet 5 (polski). Języki japoński oraz chiński są przykładami języków z systemem liczników.
Język polski.
Podział rzeczowników.
W języku polskim rzeczowniki według kategorii desygnatów przyjęło się dzielić na:
Przynależność rzeczowników do grupy żywotnych lub nieżywotnych, osobowych i nieosobowych wpływa na ich odmianę.
Rzeczowniki można podzielić także na:
Liczba rzeczownika.
Rzeczownik w języku polskim odmienia się współcześnie przez liczby: pojedynczą i mnogą. Dawna liczba podwójna wyszła z użycia, jej ślady zachowały się w języku w formie szczątkowej.
Nie zawsze liczba gramatyczna rzeczownika zgadza się z liczbą opisywanych jednostek. Rzeczowniki zbiorowe, choć występują w liczbie pojedynczej, opisują większą liczbę przedmiotów, np.: "zboże, młodzież, brzezina". Rzeczowniki jednostkowe odwołują się w liczbie pojedynczej do jednego desygnatu: "człowiek, książka". Niektóre rzeczowniki posiadają jednocześnie znaczenie zbiorowe i jednostkowe, np.: "ziarno" może być rozumiane jako pojedyncze nasiono, ale też jako cały zapas ziarna.
W wyjątkowych przypadkach zdarza się, że znaczenie rzeczownika zależnie jest od liczby: "srebro" w liczbie pojedynczej to metal szlachetny, w liczbie mnogiej ("srebra") to wyroby ze srebra, srebrna zastawa stołowa.
Przeważająca większość rzeczowników posiada zarówno liczbę pojedynczą, jak i mnogą. Jednak niektóre z nich występują tylko w liczbie mnogiej (pluralia tantum), np.: "chrzciny, sanie", inne tylko pojedynczej (singularia tantum), np.: "miłość" (rozumiana jako uczucie).
Rodzaj gramatyczny.
Rzeczownik w liczbie pojedynczej występuje w rodzaju męskim, żeńskim lub nijakim.
W liczbie mnogiej rzeczownik można przyporządkować do jednego z dwóch rodzajów gramatycznych:
Zazwyczaj wyznacznikiem rodzaju jest jego forma (końcówka kojarzona z określonym rodzajem). Rzeczowniki żywotne często mają rodzaj naturalny: mężczyźni i samce określa się przy użyciu rodzaju męskiego (np.: "Adam, sprzątacz, baran, koń, jeleń"), kobiety i samice – żeńskiego (np.: "Ewa, sprzątaczka, owca, klacz, łania"). Rodzaj nijaki bywa stosowany przy nazywaniu młodych osobników (np.: "dziecko, źrebię, szczenię").
Można też spotkać rzeczowniki, które występują jednocześnie w więcej niż jednym rodzaju gramatycznym. Wyróżnia się tu dwie grupy:
Niektóre rzeczowniki w procesie ewolucji języka zmieniały swój rodzaj np.: dzisiaj – "ta kometa", w XIX wieku – "ten kometa"; dzisiaj "ten album", w XIX wieku – "to album".
Esperanto.
W esperanto rzeczownik w liczbie pojedynczej zawsze przyjmuje końcówkę -o. Odmienia się przez przypadki (mianownik i biernik) i liczby (pojedyncza zakończona -o i mnoga na -oj).

</doc>
<doc id="12895" url="https://pl.wikipedia.org/wiki?curid=12895" title="Rzeczownik odczasownikowy">
Rzeczownik odczasownikowy

Rzeczownik odczasownikowy, rzeczownik odsłowny, gerundium, odsłownik – rzeczownik utworzony od czasownika, zwykle będący nazwą czynności lub stanu.
Przykłady.
W języku polskim rzeczownik odczasownikowy odmienia się przez przypadki, jak większość rzeczowników. Najczęściej tworzy się go za pomocą przyrostka "-nie" lub "-cie", na przykład "pływanie" (od "pływać") albo "mycie" (od "myć"). Często taką samą formę przyjmują nazwy wytworów lub obiektów, na których czynność się odbywa, na przykład "jedzenie" (od "jeść"). Należy odróżnić użycie tego słowa w funkcji gerundialnej (zazwyczaj jest to wówczas rzeczownik abstrakcyjny) od użycia go w funkcji zwykłego rzeczownika, często konkretnego (rzeczownik odsłowny: „"Jedzenie" kapusty może powodować wzdęcia”, „"Mieszkanie" na poddaszu nie trwało długo, bo wkrótce otrzymali lepszy lokal”; rzeczownik konkretny: „Kapusta to moje ulubione "jedzenie"”, „Kupili nowe "mieszkanie"”). "Nie" z rzeczownikami odczasownikowymi pisze się łącznie, na przykład: "niedotrzymanie terminu", "niepalenie papierosów", "nieuświadomienie pacjentów", "nieprzestrzeganie reguł", "niezatrzymanie się", "niewykonanie polecenia".
W języku angielskim formę gerundialną ("gerund") tworzy się za pomocą przyrostka "-ing", na przykład "waiting" („czekanie”). Uwaga: w ten sam sposób tworzy się w języku angielskim imiesłów przysłówkowy współczesny oraz imiesłów przymiotnikowy czynny, czyli "waiting" może znaczyć „czekający/-a/-e” albo „czekając” (w zależności od funkcji w zdaniu lub kontekstu).
W języku niemieckim forma gerundialna ("Gerundium") ma taką samą postać jak bezokolicznik, jest rodzaju nijakiego i pisana wielką literą, jak wszystkie niemieckie rzeczowniki, na przykład "das Essen" (od "essen"). Występuje w funkcji rzeczownika będącego nazwą czynności.
W języku hiszpańskim forma gerundialna ("gerundio") ma przyrostek "-ando" lub "-iendo" ("-yendo") w zależności od rodzaju koniugacji, na przykład "caminando" (od "caminar"), "leyendo" (od "leer"). Występuje wyłącznie w funkcji imiesłowowej.
W języku włoskim forma gerundialna ("gerundio") ma przyrostek "-ando" lub "-endo", zależnie od sposobu odmiany, na przykład "parlando" (od "parlare"), "leggendo" (od "leggere"), "finendo" (od "finire").
W języku węgierskim formę gerundialną ("gerundium") tworzy się poprzez dodanie przyrostka "-ás" albo "-és" do tematu czasownika, w zależności od jego harmonii wokalicznej, na przykład "elrejtés" (od. elrejt), "úszás" (od. "úszik").
W języku łacińskim "gerundium" występuje w funkcji rzeczownikowej prawie wyłącznie w przypadkach zależnych, na przykład "facultas dicendi" („zdolność mówienia”).
Sposoby wyrażania teraźniejszości.
W niektórych językach istnieją gerundialne konstrukcje gramatyczne służące do wyrażania czynności odbywającej się w chwili mówienia.
Język hiszpański.
W języku hiszpańskim istnieje konstrukcja estar + gerundio, składająca się z odmienionego czasownika "estar" ("być" odnoszące się do stanu przejściowego, w odróżnieniu od "ser" – "być" używane przy określaniu cechy stałej) oraz formy gerundium.
Przykłady:
Język włoski.
W języku włoskim istnieje konstrukcja stare + gerundio, składająca się z odmienionego czasownika "stare" ("czuć się, przebywać, być", „zwykłe” "być" to po włosku "essere") oraz formy gerundium.
Przykłady:

</doc>
<doc id="12896" url="https://pl.wikipedia.org/wiki?curid=12896" title="Model (logika)">
Model (logika)



</doc>
<doc id="12897" url="https://pl.wikipedia.org/wiki?curid=12897" title="Kniejówka (broń)">
Kniejówka (broń)

Kniejówka – skrócona broń myśliwska o dwóch lufach: gładkiej i gwintowanej.
Kniejówka pozwala na polowanie zarówno na zwierzynę drobną, jak i grubą podczas jednego polowania. Najczęściej spotykane kalibry śrutowe w kniejówkach to: 12/70, 12/76, 16/70, 20/70, 20/76. Lufa gwintowana w kniejówce to najczęściej kalibry: .22 Hornet, 5,6x50R, .222Rem, 5,6x52R, 7x57R, 7x65R, .308Win, 30-06, 8x57IRS, 9,3x74R .
Kniejówkę cechuje krótsza długość całej broni niż w przypadku sztucera i dubeltówki. Ma to na celu wygodniejsze poruszanie się w lesie, stąd nazwa odnosząca się do "poruszania się w kniei". Zasadniczo kniejówka nie służy do polowania "z zasiadki" tylko do polowania "z podchodu".

</doc>
<doc id="12898" url="https://pl.wikipedia.org/wiki?curid=12898" title="Via Appia">
Via Appia

Via Appia (właśc. "Via Appia Antica"), Droga Appijska – najstarsza droga rzymska, przebiegająca przez Italię w południowej części Półwyspu Apenińskiego.
Przebieg.
Zasadniczą jej rolą było połączenie Wiecznego Miasta z Kampanią i zaopatrzenie go w tamtejsze produkty rolne. Początek miała przy rzymskim "Forum Romanum" i przez Bramę Kapuańską ("Porta Capena") prowadziła na południe w okolice Kapui pod Neapolem, gdzie skręcała na wschód i ciągnęła się aż do Brindisi na wybrzeżu Adriatyku, zbiegając się tam z Via Traiana (współcześnie z Via Adriatica). Połowę szlaku wytyczała miejscowość Forum Appii (Forum Appiusza, dzisiejsze Torre del Mercato), znana z tego, że chrześcijanie wyszli tam na spotkanie św. Pawła (Dz 28,15). Na odcinku od Velitrae do Norba szlak biegł po dawnej drodze żwirowej "Via Norbana". Był drogą państwową, przebiegał po gruncie należącym do Rzymu. Przez wieki był starannie utrzymywany, przebudowywany i naprawiany.
Obecnie na przedmieściach Rzymu droga przebiega przez "Parco dell'Appia Antica", w którym znajdują się ruiny starożytnych willi, a także antyczne katakumby. W Rzymie równolegle do starożytnej drogi w odległości kilku kilometrów biegnie też współczesna Via Appia Nuova. Chociaż sama nie stanowi atrakcji, to jednak dostęp do niektórych zabytków "Parco dell'Appia Antica" (jak Villa dei Quintili) możliwy jest tylko z jej strony.
Historia.
Zgodnie ze świadectwem Liwiusza budowę drogi rozpoczął cenzor Appiusz Klaudiusz w 312 p.n.e. Początkowo była ona gościńcem prowadzącym od Porta Capena w Rzymie do Formiae i przedłużonym do Kapui; ukończenie tej części miało nastąpić w 293 p.n.e. Po zakończeniu ostatecznej rozbudowy (270-225 p.n.e.) łączyła Rzym z portowym Brundisium, zapewniającym morskie połączenia z Grecją i rzymskimi posiadłościami na Wschodzie przez Terracinę, Kapuę, Beneventum i Tarent. Jej zamorskie przedłużenie stanowiła Via Egnatia. Przez odgałęzienia miała połączenia z innymi drogami Italii (np. z Via Popillia – w Calatia; także z Via Latina, Via Traiana). Najstarszy kamień milowy znaleziony w okolicy Mesa (staroż. Ad Meidias, dosł. Przy Połowie) datuje się z czasów pierwszej wojny punickiej. Za latyńską kolonią Minturnae stał setny kamień milowy, utrwalony w nazwie obecnej miejscowości Masseria Centore.
Kolejni władcy mieli swój udział w jej rozbudowie i upiększaniu: Cezar, August, Klaudiusz, Domicjan, Trajan, Hadrian i Septymiusz Sewer. Podczas przebudów został m.in. w roku 289 p.n.e. poszerzony jej najstarszy odcinek. Za Trajana nastąpiło położenie bruku na długości 19 mil (tj. 28 km). Kontynuował on prace podjęte przez Nerwę, doprowadzając je w 100 r. n.e. aż do 48 kamienia milowego od Forum Appii.
W XIX wieku odrestaurowano stary szlak i przywrócono jego świetność na odcinku pierwszych 11 mil; dziś jest jedną z atrakcji turystycznych „Wiecznego Miasta”. Odnowiony odcinek drogi ciągnie się do Ciampino pod Rzymem.
Konstrukcja.
Droga początkowo nie była prawdopodobnie brukowana (wiadomo jedynie, że do 293 p.n.e. położono bruk aż do Bowilli) i ostateczną postać uzyskała dopiero w późniejszym okresie, gdy zyskała miano „królowej dróg”. Opisywana niejednokrotnie Via Appia wywoływała zachwyt świadków, m.in. dokładnym zespoleniem swej kamiennej nawierzchni. Bizantyjski historyk Prokop z Cezarei w 536 r. zanotował, że jej szerokość umożliwiała wyminięcie się dwóch pojazdów, a nawierzchnię stanowiły duże kamienie, podobne do młyńskich, tak ściśle połączone, że stwarzały wrażenie jednej płyty kamiennej. Mimo wielowiekowego już wówczas funkcjonowania nie nosiła jednak śladów istotnych uszkodzeń.
Dla zwiększenia trwałości tego traktu zastosowano 4 warstwy tzw. korpusu drogowego:
a) podłoże z kamienia tłuczonego (brekcja) grubości 20 cm;
b) warstwę kamienia na zaprawie wapiennej (20 cm);
c) warstwę drobnego tłucznia kamiennego (7,5 cm);
d) nawierzchnię z bloków kamiennych (silex) bądź nieregularnych bloków z kamienia wulkanicznego.
Odcinek przebiegający przez Bagna Pontyjskie ("Pontinae paludes") zbudowany był na nasypie o długości 28 km, wysokości 3-4 metrów i szerokości 20-23 metrów. Na niektórych odcinkach mury oporowe zabezpieczały trakt przed osuwaniem się gruntu – np. w okolicach Aricii mur o wysokości 43 metrów. Dla utworzenia przejść usuwano ostrogi skalne – np. w Terracina szlak biegnie wzdłuż ściany wyciętej do wysokości 36 m (co poświadczają liczby wyryte na stoku). Koło Casilinum (dzisiejsza Kapua) drogę przecinał most w Narnii (Umbria), z którego zachowały się filary i łuk lewobrzeżny; miał on długość ponad 120 metrów przy rozpiętości 16-32 m czterech przęseł, wznoszących się na wysokość powyżej 30 metrów.
Znaczenie.
Z informacji Liwiusza wynika, że Via Appia miała stanowić punkt wyjścia dla wszystkich dróg prowadzących w kierunku Wielkiej Grecji, zarazem będąc pierwszym odcinkiem gęstej sieci dróg Cesarstwa o imponującej do dziś rozpiętości. Na decyzji o jej budowie niewątpliwie musiały zaważyć względy polityczno-wojskowe. Przeszła jednak do historii nie tylko jako ważna arteria komunikacyjna, ale też dzięki zainicjowaniu udoskonalonej technicznie budowy dróg rzymskich.
Rola strategiczna.
Od początku miała doniosłe znaczenie strategiczne, łącząc stolicę imperium z ważnym portem nad Adriatykiem, zapewniającym komunikację ze wschodnimi prowincjami państwa rzymskiego. Zwana przez Rzymian "regina viarum" (królową dróg), była odtąd ściśle związana z wielowiekową historią Rzymu. Tędy wyruszały legiony rzymskie na wschód i powracały stamtąd wojska, przemierzali ją kupcy, podróżni i posłańcy cesarscy. Była świadkiem najazdów będących przyczyną ostatecznego upadku imperium i jego stolicy. Według historycznej relacji na ok. 200-kilometrowym odcinku z Rzymu do Kapui w r. 71 p.n.e. ukrzyżowano 6 tysięcy niewolników z pokonanych oddziałów Spartakusa. Historia kościoła wiąże jeszcze Via Appia z zakończonym męczeńską śmiercią powrotem św. Piotra do Rzymu (ok. 64 r. n.e.), co upamiętnia wystawiony niedaleko Bramy św. Sebastiana kościół Santa Maria in Palmis, który zainspirował Henryka Sienkiewicza do napisania "Quo vadis".
Miejsce pochówków.
Ponadto droga uchodziła za jedno z ulubionych miejsc przechadzek i spotkań mieszkańców Wiecznego Miasta. Była też główną aleją cmentarną: wzdłuż niej wznosiły się setki pomników grobowych, kolumbariów i monumentalnych grobowców najważniejszych rodów rzymskich, jak np. grobowiec Scypionów, grobowce Horacjuszów i Kuriacjuszów czy Waleriusza Romulusa, syna cesarza Maksencjusza; niektóre (grobowiec Cecylii Metelli) zachowały się dotychczas. Tradycje grzebalne w tej okolicy przejęli chrześcijanie, choć ich cmentarze były podziemne; katakumby św. Sebastiana oraz św. Kaliksta zaliczane są do najstarszych i najpiękniejszych.

</doc>
<doc id="12900" url="https://pl.wikipedia.org/wiki?curid=12900" title="Dionizje">
Dionizje

Dionizje – attyckie święta w starożytnej Grecji na cześć Dionizosa, boga wina (Bachusa)
Początki Dionizji odnajduje się w ostatniej dekadzie szóstego wieku p.n.e., tuż po powstaniu demokracji ateńskiej, nazwa dionizyjskiej osady mogła więc wzbudzać wówczas uzasadniony entuzjazm, bowiem eleutheria oznacza po grecku „wolność”. Podczas eisagoge rzeźba boga była dekorowana laurami i ubierana w odświętne szaty. Dionizje właściwe rozpoczynały się od pompe – wielkiej procesji ofiarnej, urozmaicanej tańcami i śpiewem, której trasa znajdowała finał w świątyni Dionizosa. Tam składano bogu thysia, przeważnie był to byk.
Dionizje Wielkie.
Dionizje Wielkie. Święto obchodzone w Atenach początkowo przez pięć, potem sześć dni pod koniec marca i na początku kwietnia. Wielkie Dionizje rozpoczynały się od pokazów przedpremierowych (proagon). Podczas proagon uczestnicy konkursów przedstawiali się publiczności poprzez demonstrowanie iogus- treści swoich sztuk. Następnie miała miejsce procesja – nocną porą efebowie uroczyście wnosili (eisagoge) posąg Dionizosa, boga wina, do teatru, by symbolicznie odtworzyć mityczne przybycie boga do Aten z Eleuterai. Pierwszy dzień poświęcony był składaniu Dionizosowi ofiary z kozła, czemu towarzyszył śpiew chłopięcego chóru. Posąg boga przenoszono ze świątyni do gaju Akademosa. W gaju odbywało się nabożeństwo i uczta. Po zachodzie słońca posąg przenoszono w blasku pochodni do Aten. Drugiego dnia miała miejsce prezentacja chórów chłopięcych i męskich. Kolejny dzień był przeznaczony na komedie polityczne. Czwartego, piątego i szóstego dnia trzech autorów prezentowało swoje tragedie (każdy miał jeden dzień na prezentację). Święta dionizyjskie były świętem ruchomym, więc nie figurują pod dokładną datą w attyckim kalendarzu liturgicznym. Ogólnodostępne źródła podają, że Dionizje Wielkie, czyli miejskie, obchodzono w miesiącu zwanym Elafebolion (przełom marca i kwietnia). W Atenach, mniej więcej wówczas, gdy w Delfach rozpoczynał się zimowy okres dionizyjski, „rozpoczynano (...) najnaturalniejsze pod słońcem, niezwiązane z żadnym określonym dniem, obrzędy świąteczne” .
Dionizje Małe.
Dionizje wiejskie, obchodzono w "Posejdonie" (na przełomie grudnia i stycznia), wówczas bowiem nadchodził czas, kiedy młode wino było już wystarczająco dojrzałe, by otwierać pierwsze jego amfory, świętować, organizować zabawy ludowe i procesje taneczne. Współczesne dość dokładne wyobrażenie na temat przebiegu tegoż święta zawdzięczamy ateńskiemu historykowi, Fanodemosowi. Ateńczycy, zebrani w pobliżu stojącej na moczarach ("en limnais") świątyni śpiewali sławiące Dionizosa pieśni, tańczyli i „przyzywali boga imionami Euanthes, Dithyrambos, Bakcheutas i Bromios”. Uczestnicy obrzędu przynosili ze sobą do sanktuarium gleukos – młode, słodkie wino – które właśnie podczas owych ceremonii po raz pierwszy w „nowym winnym roku” mieszano z wodą i pito. Historycy podają, że owa bagienna świątynia, jedna z najstarszych w mieście, umiejscowiona była na południe od Akropolu. Informacje takie znaleźć można u Tukidydesa, również sam Fanodemos, wspominając o mieszaniu gleukos z wodą źródlaną, zdaje się potwierdzać tę wersję.
Oschoforia.
Nieco odmienny charakter miały "Oschoforia", obchodzone na cześć Dionizosa w miesiącu "Pyanepsion" (październik-listopad), kiedy to obchodzono najwięcej świąt w roku. Procesję z Aten do Faleronu prowadzili dwaj chłopcy w kobiecych szatach, trzymając w rękach gałęzie winorośli z pełnymi gronami. W Faleronie składano ofiary i − wśród okrzyków − wylewano bogu wino. Święto kończyło się na nadbrzeżnych łąkach, gdzie "dejpnoforoj" rozdawały posiłki, świętujący tańczyli, a atleci brali udział w biegach. Aż do nocy trwały śpiewy i opowiadanie mitów.

</doc>
<doc id="12901" url="https://pl.wikipedia.org/wiki?curid=12901" title="Terpsychora (muza)">
Terpsychora (muza)

Terpsychora (także Terpsichore, „Kochająca taniec”, „Radująca się tańcem”; gr. Terpsichórē, łac. Terpsychore) – w mitologii greckiej muza tańca (radości z tańca) i pieśni chóralnej.
Uchodziła za córkę boga Zeusa i tytanidy Mnemosyne oraz za siostrę: Erato, Euterpe, Kalliope, Klio, Melpomene, Polihymnii, Talii i Uranii, a także za matkę Linosa i syren.
Była jedną spośród dziewięciu muz olimpijskich (przebywały na Olimpie), które należały do orszaku boga Apollina (Apollon Musagetes), ich przewodnika. Wraz ze swoimi siostrami uświetniała śpiewem biesiady bosko-ludzkie (m.in. zaślubiny Tetydy i Peleusa oraz Harmonii i Kadmosa), a także uczty olimpijskie samych bogów.
W sztuce przedstawiana jest zwykle jako kobieta, w tanecznej pozie, z lirą i plektronem – atrybutami symbolizującymi dziedzinę sztuki, której patronowała.
Imieniem muzy została nazwana jedna z planetoid – (81) Terpsichore.

</doc>
<doc id="12911" url="https://pl.wikipedia.org/wiki?curid=12911" title="19. ceremonia wręczenia Oscarów">
19. ceremonia wręczenia Oscarów

19. ceremonia rozdania Oscarów odbyła się 13 marca 1947 roku w Shrine Auditorium w Los Angeles.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii, napisano ich pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).

</doc>
<doc id="12912" url="https://pl.wikipedia.org/wiki?curid=12912" title="Karabinek AK">
Karabinek AK

Karabinek AK (także: AK-47, , pot. "Kałasznikow") – radziecki karabinek automatyczny opracowany tuż po II wojnie światowej przez Michaiła Kałasznikowa. Zastąpiony pod koniec lat 50 przez karabinek AKM (będący jego zmodernizowaną wersją). Szerokie rozpowszechnienie broni opartej na systemie AK, czynią tę konstrukcję jedną z najpopularniejszych wśród karabinków automatycznych XX i XXI w.
Historia.
Powstanie.
W ZSRR prace nad bronią strzelającą nabojem pośrednim rozpoczęły się już w latach 30. XX wieku, kiedy konstruktorzy radzieccy, w ramach przyjacielskiej współpracy technicznej, zapoznali się z niemieckimi osiągnięciami w tej dziedzinie. Pracowano równocześnie nad amunicją i bronią kalibru 7,62 mm oraz 5,5 mm. Działania te zostały zaniechane w momencie wybuchu wojny. Zajęto się bieżącymi potrzebami frontu. Zainteresowanie bronią na nabój pośredni powróciło po zdobyciu pierwszych egzemplarzy niemieckich karabinków StG44 oraz pojawieniu się, dostarczanych z USA, karabinków M1 posiadających większy zasięg i celność od pistoletów maszynowych PPSz i PPS.
We wrześniu 1943 r., w OKB-44 kierowanym przez inż. Jelizarowa, zakończono prace nad nabojem pośrednim 7,62 × 39 mm. Został on przyjęty do uzbrojenia jako Nabój wz. 43. Od marca 1944 r. rozpoczęto jego eksperymentalną produkcję w fabryce nr 543 w Uljanowsku.
W listopadzie 1943 r. ogłoszono pierwszy konkurs na całą rodzinę broni. Miała się ona stać podstawą uzbrojenia strzeleckiego Armii Radzieckiej. Miał to być: karabin samopowtarzalny, karabinek automatyczny (według radzieckiej nomenklatury – automat) strzelający nabojem pośrednim i ręczny karabin maszynowy. Nowy typ karabinka automatycznego, według założeń, miał być bronią wsparcia. Miał zwiększać siłę ognia drużyny piechoty w ataku i obronie. Nie miał być podstawową bronią piechoty, a jedynie następcą pistoletu maszynowego. Jego masa miała wynosić do 5 kg, a z dwoma pełnymi magazynkami nie przekraczać 9 kg. Broń nie mogła być dłuższa niż 1000 mm, a lufa nie krótsza niż 500 mm. Magazynek miał mieć pojemność co najmniej 30 naboi.
W efekcie powstało 15 prototypowych karabinków automatycznych konstrukcji m.in. Tokariewa, Diegtiariowa, Korowina, Baryszewa, Konstantinowa, Stieczkina, Korobowa (TKB-408) i Sudajewa (AS-44). Wszystkie konstrukcje, po próbach, odrzucono. Najbardziej udany okazał się AS-44, który, jako jedyny, przeszedł pełny program prób. Skoncentrowano się więc na jego doskonaleniu. Do pomocy choremu na białaczkę konstruktorowi przydzielono asystenta – M. T. Kałasznikowa. W wyniku dalszych prac udało się zmniejszyć masę broni do 4,8 kg. Inne parametry były jednak dalej niezadowalające. Z tego powodu komisja wojskowa odrzuciła także ten projekt.
W maju 1945 r. rozpisano nowy konkurs. Tym razem zakładano przezbrojenie całej piechoty w broń na naboje pośrednie. W konkursie wzięło udział kilkunastu młodych konstruktorów. Najbardziej znanym z nich był Sudajew. I tym razem za najlepszy uznano karabinek AS-44. Nie został on jednak skierowany do produkcji. Prace nad bronią zakończyła śmierć konstruktora w 1946 r.
W 1946 r. rozpisano trzeci konkurs. Tym razem wymagana była długość broni poniżej 900 mm. Karabinki miały występować w dwóch odmianach. Z drewnianą kolbą stałą dla piechoty oraz z kolbą składaną dla młodszych oficerów i wojsk powietrznodesantowych. Zakładano, że głównie ogień będzie prowadzony krótkimi seriami. Wymagano jednak też, by broń była wyposażona w przełącznik rodzaju ognia, który pozwalał prowadzić ogień pojedynczy.
Do konkursu zgłoszono 16 projektów. W sierpniu 1946 r. sześć z nich odrzucono jako nieperspektywiczne. Dziesięć pozostałych skierowano do dalszych prac, które zakończyły się w październiku. Wśród nich był karabinek konstrukcji M. T. Kałasznikowa, zgłoszony do konkursu pod godłem „Michtim”. Do fazy badań prototypów zakwalifikowano sześć konstrukcji. Pierwszej nagrody nie przyznano. Drugą otrzymał Rukawisznikow, a trzecią Korobow. Wyróżnienie otrzymał m.in. Kałasznikow. Równocześnie został on skierowany do fabryki nr 2 w Kowrowie. Mógł tam korzystać z nowoczesnego parku maszynowego, a także z pomocy doświadczonego biura konstrukcyjnego. Kałasznikow stanął tam na czele zespołu roboczego, który zajął się wyłącznie dopracowywaniem jego karabinka. Najbliższym jego współpracownikiem stał się młody inżynier Aleksander A. Zajcew. Broń otrzymała oficjalną nazwę Automat Kałasznikowa wz. 1946 nr 1 (AK-46 nr 1). Pracowano jednocześnie nad dwiema odmianami karabinu: z frezowaną komorą zamkową (znany jako AK-1) i z komorą tłoczoną (AK-2). Broń z komorą tłoczoną (prace nad nią były mniej zaawansowane) miała być konstrukcją docelową. AK-1 miał wziąć udział w próbach poligonowych.
Ostatecznie w wyznaczonym terminie dostarczono 5 prototypów:
Jako broń porównawcza zostały użyte: pistolet maszynowy PPSz, karabinek Sudajewa – AS-44 oraz zdobyczny niemiecki karabinek StG44.
Już na początku odpadł, z powodu nagminnych zacięć, karabinek Rukawisznikowa. Odpadł też karabinek Korobowa, w którym nie wytrzymał zamek i komora zamkowa.
Program prób zakończył się w czerwcu 1947 r. Uznano, że żaden karabinek nie spełnia wymagań.
Dla Kałasznikowa próby zakończyły się niepowodzeniem. Planowano nawet jego konstrukcję wykluczyć z dalszych etapów konkursu. Pomogła interwencja kolegów z Naukowo-Badawczego Poligonu Broni Strzeleckiej, którzy uznali użyty sposób ryglowania broni za najbardziej perspektywiczny. W rezultacie zalecono mu dokonanie poprawek w konstrukcji komory zamkowej i mechanizmu spustowego, poprawę funkcjonowania spustu w trybie samoczynnym. Zlecono też przeniesienie rękojeści napinania, bezpiecznika i przełącznika rodzaju ognia na prawą stronę broni.
Widząc zbliżającą się porażkę, Zajcew postanowił uciec się do podstępu, który był ewidentnym złamaniem warunków konkursu. Namówił do tego Kałasznikowa. W rezultacie do następnego etapu przedstawiono broń o całkowicie zmienionej konstrukcji. Praktycznie był to zupełnie nowy karabinek. Otrzymał on oznaczenie AK-47 nr 1. Po próbach fabrycznych i wprowadzeniu szeregu zmian, nadano mu oznaczenie fabryczne KB-P-580. Powstały trzy prototypy: AK-47 nr 2 i 3 z kolbą stałą, oraz AK-47 nr 4 z kolbą składaną. Mimo napiętych terminów, udało się dostarczyć prototypy na próby, które miały się odbyć w listopadzie 1947 r.
Równocześnie nastąpiły zmiany w konstrukcji naboju pośredniego wz. 43. Od 1945 r. prowadzono z nim nieprzerwane testy. Wykazały one szereg wad amunicji, prowadzących do zrywania kryz i pękania łusek. W wyniku prac prowadzonych w zakładach w Uljanowsku, okazało się, że konieczna jest zmiana długości łuski i szerokości kryzy. Tak powstał nowy nabój 7,62 × 39 mm wz. 43, który latem 1947 r. zastąpił stary nabój 7,62 mm × 41 wz. 43.
Przed rozpoczęciem zaplanowanych prób ogłoszono, że startujące w nich karabinki muszą strzelać nową amunicją. Ostatecznie próby rozpoczęto 16 grudnia 1947 r. Okazało się, że korzystając ze zmiany naboju inni uczestnicy także przebudowali swoje karabinki. Nie były to jednak tak głębokie zmiany jak w broni Kałasznikowa i Zajcewa.
Testy trwały do 11 stycznia 1948 r. Karabinek KB-P-580 wygrał w nich bezdyskusyjnie. Pobił konkurencję w próbach żywotności i niezawodności. Wyróżniał się także prostotą konstrukcji. Mimo oficjalnego protestu pozostałych uczestników konkursu, zapewniło mu to pierwszą lokatę w ogólnej ocenie konstrukcji. Został jednocześnie rekomendowany do przyjęcia na uzbrojenie Armii Radzieckiej.
21 stycznia 1948 r. minister uzbrojenia D. Ustinow, wydał rozkaz zakończenia do 1 czerwca prac nad rodziną broni strzelających nabojem pośrednim. Nakazał też rozpoczęcie przygotowań do jej masowej produkcji. Produkcja karabinków automatycznych Kałasznikowa miała się odbywać w Iżewskich Zakładach Samochodowych. W przygotowaniach brał początkowo udział konstruktor z zespołem. Później zadanie to przejął główny konstruktor fabryki Dawid Winkorjoz.
W lipcu 1948 r. zamówiono partię karabinków AK-47 przeznaczoną do prób w jednostkach wojskowych. Miały się one odbywać w wybranych pododdziałach moskiewskiego, leningradzkiego i środkowoazjatyckiego okręgu wojskowego.
Po próbnej eksploatacji i wprowadzeniu poprawek, powstał kolejny wariant przedseryjny. Nosił on oznaczenie AK-48. Występował w dwóch wariantach: AK-48 nr 1 – z kolbą stałą i AK-48 nr 2 – z kolbą składaną.
Nie osiągnięto w nim spodziewanej poprawy celności. Dowództwo Armii Radzieckiej zrezygnowało w końcu z tego wymogu. Zakładano, że w nowe karabinki będzie uzbrojonych sześciu żołnierzy w każdej drużynie piechoty. Mieli oni stanowić jej główną siłę ognia, prowadzonego krótkimi seriami, na niewielkich dystansach. Nadzwyczajna celność nie była więc potrzebna. Precyzyjny ogień mieli prowadzić pozostali żołnierze, uzbrojeni w karabinki SKS. Nie chciano też zbytniego przedłużania przygotowań do produkcji. Chodziło o jak najszybsze zastąpienie karabinów Mosina, oraz pistoletów maszynowych PPSz i PPS.
Na początku 1949 r. zostały więc, trochę pośpiesznie, przyjęte na uzbrojenie Armii Radzieckiej:
W nagrodę M. T. Kałasznikow został odznaczony Nagrodą Stalinowską I stopnia.
Produkcja.
W sierpniu 1949 r. podjęto decyzję o całkowitym przezbrojeniu Armii Radzieckiej w nowe karabinki. Zaplanowano dostarczenie w latach 1951–1955 2,5 mln karabinków AK oraz 1,5 mln karabinów AKS.
Pierwszym producentem AK były zakłady nr 74 w Iżewsku. Fabryka miała duże kłopoty z uruchomieniem produkcji nowej broni. Okazało się, że konieczne jest dokonanie ponad 450 poprawek w dokumentacji technicznej. Karabinki te są określane jako "AK typu I". Posiadały one komory zamkowe wykonane metodą głębokiego tłoczenia. Okazało się, że fabryka ma kłopoty z wdrożeniem tej technologii. Opracowano nową komorę zamkową wykonywaną poprzez frezowanie z odkuwki. Komora zamkowa typu II była uniwersalna i stosowano ją zarówno w karabinkach AK, jak i AKS. Montaż kolby stałej był możliwy dzięki zastosowaniu obsady łączącej komorę zamkową z kolbą. Ponieważ element ten osłabiał mocowanie kolby, od 1953 roku rozpoczęto produkcję AK z ponownie przekonstruowaną komorą zamkową. Jest ona znana jako typ III. Była ona wykonywana identyczną technologią jak komora zamkowa typu II, ale była produkowana w dwóch wersjach (dla karabinków AK i AKS) różniących się sposobem montażu kolby, dzięki czemu wyeliminowano obsadę kolby stałej. Wersja z 1953 r. stała się ostateczną i jest najbardziej rozpowszechnionym modelem AK.
Od 1956 r. ZSRR rozpoczął sprzedaż licencji na produkcję AK do sojuszniczych państw bloku wschodniego (w tym m.in. do Polski gdzie wyprodukowano 44 060 szt. AK typu III oraz 328 850 szt. AKS). AK produkowany był w wielu państwach świata (w tym bezlicencyjnie), a na jego bazie opracowywano również wersje regionalne jak np. MPi-K (w NRD), Typ 56 (w Chinach), Valmet M62 (w Finlandii) czy AR-M1 (w Bułgarii).
Modernizacja i rozwój.
Jeszcze w 1956 r. w ZSRR karabinek poddano modernizacji wprowadzając w nim szereg drobnych usprawnień (np. opóźniacz kurka zmniejszający rozrzut przy ogniu ciągłym), oraz lepiej przystosowując go do produkcji masowej. Tak zmodernizowana wersja w 1958 r. została przyjęta na wyposażenie Armii Radzieckiej jako AKM, a od lat 60 XX w. rozpoczęto sprzedaż licencji na jej produkcję również do innych państw. Z czasem AKM stał się najbardziej rozpowszechnioną pochodną wersją AK.
Na tym jednak nie zakończył się jego rozwój. W latach 70 XX w. w ZSRR opracowano jego kolejną wersję rozwojową – AK-74 (przystosowaną do nowoczesnej małokalibrowej amunicji 5,45 × 39 mm), która w zmodernizowanej wersji (AK-74M) stanowi obecnie podstawowy karabinek Sił Zbrojnych Federacji Rosyjskiej. Konstrukcja jest nadal rozwijana czego przykładem mogą być prace prowadzone nad karabinkiem AK-12 (docelowo mającym zastąpić AK-74 w armii rosyjskiej).
Opracowany pod koniec lat 40 XX w. karabinek AK okazał się konstrukcją ponadczasową i stał się podstawą do powstania opartej na nim całej rodziny broni palnej włączając w to pistolety maszynowe (np. PP-19 Bizon), strzelby (np. Sajga-12), subkarabinki (np. AKS-74U), karabinki (np. kbs wz. 96 Beryl), ręczne karabiny maszynowe (np. RPK), a nawet karabiny wyborowe (np. PSL). Karabinki z rodziny AK nadal cieszą się ogromną popularnością i stanowią podstawowe uzbrojenie strzeleckie wielu armii świata (w tym m.in. Polski).
Konstrukcja.
Opis techniczny.
Karabinek automatyczny AK jest bronią samoczynno-samopowtarzalną, działającą na zasadzie odprowadzenia gazów przez boczny otwór w lufie do komory gazowej, umieszczonej nad lufą. Elementem łączącym zespoły i mechanizmy karabinka jest komora zamkowa, wykonana ze stali metodą obróbki wiórowej. Wewnątrz niej znajdują się: mechanizm powrotny, opory ryglowe, mechanizm spustowo-uderzeniowy, wyrzutnik łusek oraz zespół odrzutowy. Do komory w sposób trwały jest przyłączona lufa (za pomocą gwintu), kolba stała (AK) lub składana (AKS), rękojeść typu pistoletowego i kabłąk języka spustowego z zatrzaskiem magazynka, natomiast w sposób rozłączny – magazynek i pokrywa komory zamkowej.
Lufa karabinka ma przewód z bruzdowaną częścią prowadzącą (4 bruzdy prawoskrętne) i komorą nabojową. Na jej zewnętrznej części wylotowej jest nacięty gwint lewoskrętny, służący do nakręcania odrzutnika (do strzelania 7,62 mm nabojami ślepymi wz. 1943) lub tłumika dźwięku i płomieni PBS-1.
Na lufie za pomocą kołków są zamocowane: podstawa muszki, komora gazowa z gniazdem tłoka gazowego, pierścień oporowy do zamocowania łoża i podstawa celownika. Między komorą gazową i podstawą celownika jest zamontowana rura gazowa z nakładką ochronną, zabezpieczona przed wypadnięciem łącznikiem obrotowym. Zespół odrzutowy karabinka stanowi suwadło (tworzące z tłoczyskiem i tłokiem gazowym jedną całość) oraz prowadzony przez nie zamek. Suwadło wodzi się w prowadnicach komory zamkowej. Jest ono podparte sprężyną powrotną nałożoną współosiowo na żerdź, która jest połączona teleskopowo z prowadnicą sprężyny. Stopka prowadnicy jest oparta o tylec komory zamkowej i ma ząb stanowiący zatrzask pokrywy zamkowej. Suwadło wymusza zaryglowanie i odryglowanie zamka, napina kurek oraz stanowi prowadnicę cylindrycznej części zamka. Zamek w przedniej części ma dwa rygle, występ prowadzący – do współpracy ze skosem ryglującym i odryglowującym suwadła. Występ dosyłający nabój do komory nabojowej, czółko do pomieszczenia dna łuski oraz wyciąg łusek zaopatrzony w pazur i sprężynę. Ryglowanie przewodu lufy następuje przez obrót zamka w prawo w wyniku przesunięcia rygli zamka za opory ryglowe komory gazowej. W karabinku zastosowano mechanizm spustowo-uderzeniowy działający na zasadzie przechwytywania kurka, zawierający spust obrotowy w formie dźwigni dwuramiennej. Samoczynny bezpiecznik (uniemożliwiający odpalenie przy niezaryglowanym zamku), zaczep do prowadzenia ognia pojedynczego (spełniający funkcję przerywacza), kurek ze sprężyną spustowo-uderzeniową. Iglicę umieszczoną w zamku i przełącznik rodzaju ognia, spełniający jednocześnie funkcję bezpiecznika przed przypadkowym wystrzałem. Przełącznik uruchamiany ramieniem nastawczym umieszczonym na prawej ściance komory zamkowej może zajmować trzy położenia: dolne (P) – umożliwiające prowadzenie ognia pojedynczego, środkowe (C) – ognia ciągłego oraz górne – powodujące zabezpieczenie broni. Karabinek można zabezpieczyć zarówno podczas przerwy w strzelaniu (z kurkiem napiętym i wprowadzonym nabojem do komory nabojowej), jak i po jego zakończeniu (po rozładowaniu broni i zwolnieniu kurka). W położeniu zabezpieczonym dźwignia przełącznika unieruchamia spust uniemożliwiając zwolnienie kurka, a ramię przełącznika blokuje zespół odrzutowy w przednim położeniu.
Zasilanie broni odbywa się z dwurzędowego magazynka łukowego o pojemności 30 nabojów wykonanego z blachy stalowej metodą tłoczenia. W karabinie zastosowano muszkę typu słupkowego oraz celownik krzywkowy wyposażony w odchylane ramię z otwartą szczerbinką prostokątną i naniesioną podziałką odległości. Żądaną nastawę celownika w zakresie od 100 do 800 m (co 100 m) ustawia się suwakiem ramienia celownika, którego zatrzask wchodzi w nacięcia prawej krawędzi ramienia.
Ocena konstrukcji.
Karabinki z rodziny AK oceniane są jako broń bardzo trwała, niezawodna oraz bardzo odporna na zanieczyszczenia i zaniedbania eksploatacyjne. Są również proste w obsłudze i tanie w produkcji. Cechy te sprawiają, że karabinki wywodzące się od AK świetnie nadają się do masowej produkcji i mogą być sprawnie wykorzystywane nawet przez słabo wyszkolone oddziały.
Do wad karabinków AK zalicza się między innymi bardzo niską (jak na współczesne standardy) ergonomię oraz niską celność na dystansach powyżej 300 m. Wziąwszy jednak pod uwagę fakt, że w 85% przypadków z broni tego typu strzela się na odległości poniżej 300 metrów, wada ta nie ma większego znaczenia. Problematyczny jest również sposób montażu na karabinkach celowników optycznych i kolimatorowych (pod koniec lat 40 XX w. nie przewidywano takiej opcji), ze względu na sposób rozkładania broni (zamykana blaszaną klapą komora zamkowa). Istotną wadą jest również ułożenie kolby względem lufy (nie są ułożone w jednej osi) co generuje dość znaczny podrzut broni.
Wyposażenie dodatkowe.
W skład wyposażenia dodatkowego karabinka AK wchodził:
Kontrowersje.
Kwestia nazwy.
Wobec karabinka AK powszechnie stosowana jest również nazwa AK-47, jednak wzbudza ona wiele kontrowersji i zazwyczaj uznawana jest za niepoprawną. Wiąże się to z faktem, iż Armia Radziecka w okresie użytkowania tego karabinka co do zasady nie stosowała oznaczeń rocznikowych wobec broni strzeleckiej, a nazwy pokroju „AK-46”, „AK-47” i „AK-48” odnosiły się do konstrukcji prototypowych. Mimo to nazwa „AK-47” pojawia się w instrukcji obsługi karabinka wydanej w 1949 r., a więc pierwszym roku produkcji seryjnej, jednak w instrukcji wydanej w 1958 r. oznaczenie rocznikowe już nie występuje i stosowana jest nazwa „AK”. Ponadto „AK-47” pojawiała się również w instrukcjach obsługi czołgów T-55, T-62, T-64 oraz transportera opancerzonego BTR-60. Nie jest zatem do końca jasne czy „AK-47” było pierwotną nazwą karabinka Kałasznikowa, którą później zastąpiono przez „AK” (rezygnując z oznaczenia rocznikowego), czy też był to wynik pewnego bałaganu w systemie nazewnictwa i obu nazw używano przez pewien czas zamiennie. Nie zmienia to jednak faktu, iż pomimo uznawania nazwy „AK” za podstawową dla tego karabinka, to nazwa „AK-47” również pojawiała się w oficjalnych dokumentach Armii Radzieckiej. Poza tym karabinek Kałasznikowa funkcjonował również pod oznaczeniami kodowymi jako: „wyrób 56-A-212” (dla AK), oraz „wyrób 56-A-212M” (dla AKS).
Wobec karabinka Kałasznikowa w Polsce występował ponadto problem z jego klasyfikacją, ponieważ broń tego typu nie występowała nigdy wcześniej na wyposażeniu Wojska Polskiego. Z tego powodu aż do lat 60 XX w. AK określany był w Polsce jako „pistolet maszynowy” ("7,62 mm pmK – 7,62 mm pistolet maszynowy Kałasznikowa"), a dopiero potem zaczęto klasyfikować go jako karabinek ("7,62 mm kbk AK – 7,62 mm karabinek AK").
AK a StG44.
W odniesieniu do karabinka AK często powtarzana jest teoria spiskowa, jakoby był on kopią lub modyfikacją niemieckiego karabinka StG44. Teoria opiera się na pewnym podobieństwie wizualnym obu karabinków, jest jednak bezpodstawna, gdyż pod względem technicznym obie konstrukcje nie są ze sobą powiązane.
Dość powierzchowne podobieństwo karabinków, oprócz ogólnego układu ich elementów jak umieszczenie komory gazowej nad lufą i magazynka przed kabłąkiem spustu (co jest powszechnym układem w tego typu broni), przejawia się w zasadzie jedynie w przyrządach celowniczych i łukowych magazynkach (których kształt wymuszony był kształtem nabojów). Oba są karabinkami automatycznymi zasilanymi amunicją pośrednią, których automatyka oparta jest na odprowadzeniu gazów prochowych przez boczny otwór w lufie (rozwiązanie to było jednak powszechnie znane i stosowane już na przełomie XIX i XX w. a Rosjanie z powodzeniem zastosowali je w karabinach DP, AWS-36 i SWT-38/SWT-40, a więc na lata przed opracowaniem StG44 i jego protoplasty – MKb 42). Szczegółowe rozwiązania techniczne obu karabinków również są odmienne. Przede wszystkim różnią się zasadniczo konstrukcją i sposobem ryglowania zamka – w StG44 odbywa się ono przez przekoszenie zamka, a w AK przez jego obrót. Pociąga to za sobą dalsze różnice w konstrukcji obu broni. Rozwiązanie zamka zastosowane w AK jest przy tym lepsze z punktu widzenia technicznego. Istotną różnicą jest krótsza komora zamkowa AK. Dzięki innemu zamocowaniu sprężyny powrotnej, umożliwia ona zastosowanie składanej kolby, podczas gdy StG44 musiał mieć kolbę stałą, bo mieściła się w niej część tej sprężyny. Inny jest wreszcie sposób rozkładania i podział technologiczny obu karabinków. AK jest także nieco mniejszy i znacząco lżejszy.
Wizualne podobieństwo obu karabinków doprowadziło również do kuriozalnej pomyłki podczas budowy pomnika Michaiła Kałasznikowa w Moskwie. Odsłonięty w 2017 r. monument, którego projekt zaakceptował prezydent Federacji Rosyjskiej Władimir Putin, a w odsłonięciu brał udział minister kultury Władimir Miedinski, przedstawia postać konstruktora stojącą na postumencie, na którym umieszczono płaskorzeźbę z wizerunkami broni palnej projektowanej przez Kałasznikowa. Na płaskorzeźbie znalazł się również rysunek techniczny mający przedstawiać budowę karabinka AK, jednak po kilku dniach zauważono, że w rzeczywistości przedstawiono na nim karabinek StG44. Po wykryciu błędu, płaskorzeźbę niezwłocznie zdemontowano w celu jej poprawienia.
Wpływ kulturowy.
Ze względu na swoją popularność, karabinek Kałasznikowa stał się z czasem ikoną popkultury. Pojawia się w licznych filmach oraz grach komputerowych, a jego motyw jest wykorzystywany również przez artystów tworzących murale, grafiki i utwory muzyczne. Za przykład obecności karabinka AK w kulturze mogą posłużyć niektóre prace Banksy’ego (np. "Mona Lisa z AK47"), utwór "Kałasznikow" skomponowany przez Gorana Bregovicia do filmu "Underground" Emira Kusturicy, czy fakt przybrania pseudonimu artystycznego "AK-47" przez polskiego rapera Adama Kubiaka. Ponadto wizerunek tej broni jest często wykorzystywany do produkcji różnego rodzaju gadżetów (np. breloków, koszulek czy butelek na alkohol).
Karabinek ten urósł także do rangi ważnego symbolu pojawiając się m.in. na godle i fladze Mozambiku, godle Burkina Faso (lata 1984–1997), Timoru Wschodniego oraz fladze Hezbollahu.

</doc>
<doc id="12913" url="https://pl.wikipedia.org/wiki?curid=12913" title="Amunicja pośrednia">
Amunicja pośrednia

Amunicja pośrednia – rodzaj amunicji zespolonej, zapewniającej uzyskanie energii początkowej pocisku w przedziale ok. 1300 – 2300 J, co plasuje jej osiągi powyżej amunicji pistoletowej, ale poniżej amunicji karabinowej, stanowiąc rozwiązanie pośrednie (stąd nazwa). Amunicja pośrednia wykorzystywana jest głównie do zasilania: subkarabinków i karabinków automatycznych, oraz karabinków maszynowych.
Historia.
Za dalekiego przodka amunicji pośredniej można niejako uznać stosowanie w XIX wieku amunicji rewolerowej w broni długolufowej – karabinach i karabinkach, które to rozwiązanie zapewniało osiągi pośrednie pomiędzy pociskiem wystrzelonym z rewolweru, a karabinem zasilanym normalną amunicją karabinową.
Poszczególne armie prowadziły badania nad amunicją pośrednią jeszcze na długo przed wybuchem II wojny światowej, jednak konserwatyzm wojskowych nie sprzyjał pracom w tym kierunku. Badania zostały zintensyfikowane dopiero w trakcie trwania tego konfliktu, kiedy to w wyniku wojennych doświadczeń zauważono, że większość walk pomiędzy piechotą toczyła się na dystansach nie przekraczających 400 m. Wyciągnięto z tego faktu prosty wniosek, iż dotychczas użytkowane karabiny powtarzalne zasilane silną amunicją karabinową (teoretycznie mogące razić przeciwnika nawet powyżej 1000 m), zapewniają osiągi przekraczające praktyczne zapotrzebowanie. Zastosowanie w to miejsce słabszej i lżejszej amunicji pozwoliłoby na oszczędności finansowe i materiałowe, a także umożliwiłoby żołnierzom przenoszenie jej większego zapasu. Co istotne, broń zasilana taką amunicją mogłaby być mniejsza, lżejsza a dzięki zmniejszeniu odrzutu również – automatyczna. Bronią pozornie spełniającą te warunki wydawać by się mogły pistolety maszynowe, wykorzystywane jako uzupełnienie karabinów już od końca I wojny światowej. Mimo iż ta automatyczna broń świetnie sprawdzała się w walce na krótkich dystansach, to na odległościach przekraczających 100–200 m stawała się już zupełnie bezużyteczna, ponieważ słaba amunicja pistoletowa nie zapewniała dostatecznego zasięgu i celności.
W związku z tym zrodziła się potrzeba zaprojektowania amunicji, będącej rozwiązaniem pośrednim pomiędzy nabojem karabinowym a pistoletowym, oraz mogącej strzelać nią broni. Najbardziej zaawansowane prace w tym kierunku toczyły się równolegle w Stanach Zjednoczonych oraz III Rzeszy, efektem czego było wprowadzenie naboju .30 Carbine i zasilanego nim karabinka samopowtarzalnego M1 w armii amerykańskiej (1941 r.), oraz naboju 7,92 × 33 mm Kurz i zasilanego nim karabinka automatycznego MKb 42 w armii niemieckiej (1942 r.) Niedługo potem dołączył do nich ZSRR z nabojem 7,62 × 39 mm wz. 43 oraz zasilanym nim karabinkiem samopowtarzalnym SKS (1944 r.)
Rola amunicji pośredniej zaczęła gwałtownie rosnąć po II wojnie światowej, głównie za sprawą karabinków automatycznych z rodziny AK w bloku wschodnim zasilanych amunicją 7,62 × 39 mm (która stała się podstawową amunicją pośrednią Układu Warszawskiego), oraz powstałych w odpowiedzi amerykańskich karabinków automatycznych M16 na amunicję 5,56 × 45 mm (którą z czasem standaryzowano na podstawową amunicję pośrednią NATO).
Współcześnie karabinki automatyczne zasilane amunicją pośrednią stanowią podstawową broń strzelecką większości armii świata, marginalizując w tej roli amunicję karabinową. Do najpopularniejszych typów amunicji pośredniej należą: 7,62 × 39 mm i 5,45 × 39 mm (Rosja), 5,56 × 45 mm (NATO) oraz 5,8 × 42 mm (Chiny).

</doc>
<doc id="12915" url="https://pl.wikipedia.org/wiki?curid=12915" title="William Henry Harrison">
William Henry Harrison

William Henry Harrison (ur. 9 lutego 1773 w hrabstwie Charles City, zm. 4 kwietnia 1841 w Waszyngtonie) – dziewiąty prezydent USA.
Młodość i edukacja.
William Henry Harrison urodził się w 9 lutego 1773 w hrabstwie Charles City w kolonii Wirginii, jako najmłodsze z siedmiorga dzieci, zamożnego plantatora Benjamina Harrisona i jego żony Elizabeth. Po śmierci ojca w 1791, William trafił pod opiekę kupca Roberta Morrisa.
Ponieważ pochodził z bogatej rodziny, do 1787 roku naukę pobierał w domu. Następnie wstąpił do Sidney College, a w 1791 rozpoczął studia medyczne na University of Pennsylvania. Po niespełna 4 miesiącach porzucił naukę i zaciągnął się do wojska.
Kariera wojskowa.
Już po niecałym roku służby uzyskał awans na podporucznika i uczestniczył głównie w potyczkach z Indianami m.in. w bitwie pod Miami Rapids 20 sierpnia 1794 roku. 15 maja 1797 uzyskał stopień kapitana i komendanta Fort Washington, jednak 1 czerwca 1798 odszedł ze służby.
W tym samym roku został powołany na sekretarza Terytoriów Północno-Zachodnich, przez prezydenta Johna Adamsa. Po roku sprawowania urzędu ustąpił, ponieważ został przedstawicielem Terytoriów w Izbie Reprezentantów. Doprowadził wówczas do uchwalenia ustawy o podziale Terytoriów Północno-Zachodnich na Ohio i Terytorium Indiańskie. W 1801 roku Harrison został powołany na stanowisko gubernatora Indiany i naczelnika ds. indiańskich. Zajmował się głównie negocjacjami lub walką z Indianami, których wypierał coraz bardziej na zachód, realizując politykę ekspansjonizmu.
W 1805 roku, Szaunisi, pod wodzą braci Tecumseha i Tenskwatawy zorganizowali swoje plemiona, by powstrzymać Amerykanów. Z tego powodu, Harrison nie mógł zawrzeć żadnego układu handlowego z Indianami w latach 1806–1809 i uciekał się do bardziej drastycznych metod. 30 września 1809 roku podpisano pokojowy traktat z Fort Wayne, którego jednak Tecumseh nie uznał. Po nieudanych rokowaniach, 22 sierpnia 1811 prezydent Madison wydał zezwolenie Harrisonowi na użycie siły. Podczas gdy gubernator usiłował jeszcze bezskutecznych negocjacji, 7 listopada oddziały indiańskie zaatakowały obóz amerykański nad rzeką Tippecanoe. Dzień później wojska Harrisona odniosły zwycięstwo, jednak Indianie postanowili zawrzeć sojusz z Anglią. Harrison został awansowany na generała brygady i dowódcę wojsk całego Terytorium Północno-Zachodniego. Podczas wojny amerykańsko-brytyjskiej Harrison zajął Detroit 29 września 1813, a następnie pokonał Anglików pod Thames 5 października (w bitwie tej zginął m.in. przywódca Indian – Tecumseh). 31 maja 1814 Harrison podał się do dymisji.
Kariera polityczna.
Po dwóch latach spędzonych na swojej farmie, Harrison został wybrany członkiem Izby Reprezentantów (1816-1818). Kiedy prezydentem został James Monroe Harrison zabiegał o stanowisko sekretarza wojny, a następnie – ministra pełnomocnego w Rosji. W obu wypadkach nie uzyskał nominacji. Od 1819 do 1821 roku pełnił funkcję senatora Senatu Ohio. Wybory w 1821 roku przegrał podobnie jak wybory do Izby Reprezentantów w 1822. Dwa lata później uzyskał mandat do Senatu USA i zasiadał w nim do 1828. Mając ambicje na wyższe stanowiska, liczył na nominację na placówkę dyplomatyczną w Meksyku, jednak został mianowany posłem w Kolumbii, którym był w latach 1828–1829.
Kiedy w wyborach prezydenckich w 1828 zdecydowane zwycięstwo odniósł kandydat Partii Demokratycznej Andrew Jackson, Harrison wraz z Henrym Clayem i Danielem Websterem zaczęli organizować partię przeciwników polityki Jacksona i Van Burena, która została nazwana Partią Wigów. Harrison został kandydatem wigów na prezydenta w 1836 r., jednak przegrał wyraźnie z van Burenem. Od 4 do 7 grudnia 1839 trwała konwencja wyborcza wigów, która wyłoniła swoich kandydatów w zbliżających się wyborach William Henry Harrison został kandydatem na prezydenta, natomiast John Tyler – na wiceprezydenta. W czasie kampanii wyborczej zwolennicy Harrisona, oskarżali Van Burena o rozrzutność i nadmierny luksus, natomiast jego przeciwnicy przedstawiali Harrisona jako agresora i „bohatera 40 klęsk”.
Prezydentura i śmierć.
W głosowaniu powszechnym Harrison uzyskał 52% głosów, a w głosowaniu Kolegium Elektorskiego – 234 głosy (niemal 80%), wobec 60 głosów dla urzędującego prezydenta Van Burena (nieco ponad 20%). Wiceprezydentem został John Tyler, natomiast Daniel Webster – sekretarzem stanu. W swoim przemówieniu inauguracyjnym Harrison zapowiedział kontynuację dotychczasowej polityki wobec Indian i przywrócenie przyjaznych stosunków z innymi państwami. Dwugodzinne przemówienie wygłaszał w deszczowy dzień bez kapelusza oraz płaszcza, by udowodnić, że jest pełen energii.
Trzy tygodnie po zaprzysiężeniu prezydent zachorował na zapalenie płuc. Po początkowej poprawie, 3 kwietnia nastąpił nawrót zapalenia płuc. Harrison zmarł dzień później w Waszyngtonie i został pochowany w North Bend.
Życie prywatne.
William Henry Harrison poznał swoją przyszłą żonę, Annę Tuthil Symmes, w 1795 roku w Ohio. Ślub pary odbył się 25 listopada 1795 i doczekali się oni dziesięciorga dzieci.

</doc>
<doc id="12916" url="https://pl.wikipedia.org/wiki?curid=12916" title="Lukusta">
Lukusta

Lukusta, Lokusta (zm. 69) – rzymska zawodowa trucicielka; postać opisana w "Rocznikach" Tacyta.
Życiorys.
Pochodziła z Galii. Mieszkała w Rzymie niedaleko wzgórza Awentyn, gdzie cieszyła się poprawną opinią wśród sąsiadów. Dwa dni w tygodniu przyjmowała u siebie kochanka - wysokiej rangi urzędnika odpowiedzialnego w Rzymie za rejestr zgonów. Została wdową po tym, gdy otruła znęcającego się nad nią brutalnie męża alkoholika. W swym trucicielskim procederze czerpała ogromne zyski od najzamożniejszych osób, jednocześnie rozdając za darmo swoje preparaty klientom nie posiadającym żadnych pieniędzy. Również i mikstury przygotowywała w różnorodnych wersjach, od szybko do bardzo wolno działających, jedne zdolne do zatrucia organizmu na bardzo długi, więcej niż kilkuletni okres, inne zaś wywoływały uczucie wielkiego bólu. Wyrabiała specyfiki duszące ofiarę i deformujące jej twarz, przyprawiające o ślepotę albo powodujące patologiczne działanie w umyśle ofiary, która zaczynała pod wpływem substancji poruszać się na czworakach i szczekać.
Z jej usług korzystały m.in. kobiety w celu likwidowania swoich rywalek w miłosnych utarczkach, z czasem jednak zyskała znaczącą sławę i wpływy polityczne, gdy rozpoczęła współpracę z rzymskimi kręgami dworskimi. Messalina (pierwsza żona cesarza Klaudiusza) zaopatrzyła się u niej w truciznę przeznaczoną dla naprzykrzającego się jej byłego kochanka, następnie wynajęta przez Agrypinę Młodszą otruła samego Klaudiusza. Szczyt swej przestępczej kariery Lokusta osiągnęła wykonując zlecenia jego następcy - cesarza Nerona. Wówczas na jego zlecenie podała truciznę Brytanikowi. Pierwsza próba tego morderstwa nie powiodła się, za co Neron własnoręcznie wymierzył jej karę chłosty, lecz po podaniu kolejnej mikstury Brytanik zginął, a Lukusta powróciła do łask cesarza. Neron nagrodził ją posiadłością ziemską i zezwolił na prowadzenie swoistej szkółki trucicielskiej, czyli na przekazywanie wiedzy o swoim "fachu" chętnym uczniom. Usiłowała również przy użyciu trucizny zamordować samego Nerona.
W 68 roku Neron obalony przez wojskowy zamach stanu kierowany przez Galbę, uciekając popełnił samobójstwo. Kiedy Galba jako jego następca przystąpił do rozprawy z otoczeniem usuniętego cesarza, ofiarą tej czystki padła też Lukusta, którą stracono.

</doc>
<doc id="12917" url="https://pl.wikipedia.org/wiki?curid=12917" title="Ancile">
Ancile

Ancile (l.mn. "ancilia") – mityczna tarcza owalna, stanowiąca dla Rzymian pradawny obiekt kultowy. 
Według tradycyjnego przekazu miała spaść z nieba jako symbol ochrony miasta podczas zarazy, jaka wybuchła za panowania króla Numy Pompiliusza. Według Warrona nazwa ta pochodzi od "ancisu" (wykrojony, wycięty), co określa szczególny kształt tarczy. 
Pojawienie jej łączyło się z przepowiednią, że od dalszego jej istnienia uzależnione będzie trwanie i potęga państwa rzymskiego. Za radą wieszczki Egerii, dla uniemożliwienia kradzieży lub rozpoznania oryginału, Numa polecił wykonać 11 dokładnych kopii tej tarczy. W przypadku zagrożenia miały one samoczynnie wprawiać się w ruch.
Miejscem ich przechowywania była początkowo Regia, później znajdowały się w świątyni Marsa pod opieką jego kapłanów zwanych saliami. Co roku w marcu i październiku nieśli je oni w uroczystych procesjach organizowanych ku czci boga Marsa i w pełnym uzbrojeniu wykonywali prastary taniec wojenny, z tarczą na lewym ramieniu. 

</doc>
<doc id="12918" url="https://pl.wikipedia.org/wiki?curid=12918" title="Homer">
Homer

Homer (, "Hómēros", ) (VIII wiek p.n.e.) – grecki pieśniarz wędrowny ("aojda"), epik, śpiewak i recytator ("rapsod"). Uważa się go za ojca poezji epickiej. Najstarszy znany z imienia europejski poeta, który zapewne przejął dziedzictwo długiej i bogatej tradycji ustnej poezji heroicznej. Do jego dzieł zalicza się eposy: "Iliadę" i "Odyseję". Grecka tradycja widziała w nim również autora zbioru hymnów, tzw. hymnów homeryckich, oraz kilku poematów heroikomicznych - "Margites" ("Głuptak"), Kerkopes ("Kerkopowie"), Epikichlides ("Chichotki"), "Batrachomyomachia" ("Wojna mysio-żabia"). Żaden poeta grecki nie przewyższył sławą Homera. Na wyspach Ios i Chios wzniesiono poświęcone mu świątynie, a w Olimpii i Delfach postawiono jego posągi. Pizystrat wprowadził recytacje homeryckich poematów na Panatenajach.
Życie i legendy.
W starożytności istniał pogląd, iż Homer pierwotnie nazywał się Melesigenes; miał być synem boga rzeki Meles płynącej koło Smyrny i nimfy Kreteis. Świadczy to o randze Homera w świecie greckim, gdyż zawsze wybitnym ludziom przypisywano tam boskie lub półboskie pochodzenie.
Nie zachowały się żadne wiarygodne wiadomości o jego życiu i, jak pisał badacz John Myres, "żadne zdanie dotyczące Homera nie jest bezsporne". Niemniej, antyczni Grecy długo nie wątpili w jego istnienie. Prawdopodobnie urodził się w Smyrnie lub na wyspie Chios w Jonii – krainie w Azji Mniejszej, jednak wiele miast greckich ubiegało się o ten honorowy zaszczyt. W sporze o pochodzenie Homera brało udział siedem miast: Argos, Ateny, Chios, Itaka, Kolofon, Pylos, Smyrna.Według legendy Homer był ślepcem. Tezę tę mogą wspierać dwa epizody umieszczone w homeryckich epopejach. W "Odysei" niewidomy bard "Demodokos" opiewa bohaterskie czyny, a autor, prawdopodobnie Homer, w "Hymnie homeryckim" pisze do Apollina: "Pozdrawiam was wszystkie. A o mnie pamiętajcie, gdy przyjdzie jakiś człowiek obcy, co świata doświadczył, i zapyta: Dziewczęta, który jest wam najmilszy z aojdów, co tu przychodzą? Wtedy wszystkie razem odpowiecie: Ślepiec, który mieszka na skalistym Chios – jego pieśni będą zawsze najpiękniejsze (...)". Martin P. Nilsson w pracy "Homer and Mycenae" podaje, że w wielu regionach w rytualny sposób bardów pozbawiano wzroku, co miało stymulować pamięć. Poza tym imię Homera w niektórych dialektach starożytnej Grecji oznaczało właśnie ślepca.
Focjusz I Wielki przypisywał Homerowi autorstwo Cyprii, zaginionego greckiego eposu traktującego o wojnie trojańskiej. Miałby napisać ją z okazji zaślubin swojej córki ze Stasinusem.
"Iliada" i "Odyseja".
Autorstwo "Iliady" i "Odysei" wzbudza do dziś wątpliwości, a problem ten nazwano kwestią homerycką. Z braku wiarygodnych danych o życiu Homera niektórzy badacze wysuwali hipotezę, że Homer nigdy nie istniał. Już w III w. p.n.e. aleksandryjscy krytycy (tzw. "chorizontes", czyli „rozdzielacze”) uważali, że oba dzieła miały dwóch różnych autorów. W czasach nowożytnych niemiecki filolog F.A. Wolf w wydanej w 1795 r. książce "Prolegomena ad Homerum" ogłosił koncepcję zwaną teorią pluralistyczną, według której epopeje te są w istocie zlepkiem pieśni z różnych czasów, połączonych w Atenach w VI w. p.n.e. Po około stu pięćdziesięciu latach dyskusji i sporów zwyciężyła teoria unitarystyczna, zgodnie z którą Homer istniał i był autorem obu poematów, a jego zasługą jest stworzenie wybitnych dzieł w oparciu o wielowiekową tradycję pieśni heroicznych, istniejącą w starożytnej Grecji.
Homer w swych eposach posługiwał się charakterystycznym stylem. Styl homerycki cechuje się obecnością stałych epitetów, porównań homeryckich, wzniosłością (występuje patos), a także występowaniem rozbudowanych realistycznych opisów, powodujących retardację, czyli spowolnienie akcji utworu.
Imię.
Imię Homera w antycznej grece oznaczało "zakładnika", "człowieka towarzyszącego", "zmuszonego do podążania", w niektórych dialektach "ślepca".
Przekłady.
Utwory tradycyjnie uważane za dzieła Homera były wielokrotnie przekładane na język polski. Fragmenty "Iliady" ("Monomachia Parisowa z Menelausem") przełożył Jan Kochanowski. Przekładu obu eposów podjął się Jacek Idzi Przybylski. "Odyseję" przetłumaczył Lucjan Siemieński. Współcześnie tłumaczenie eposu o wojnie trojańskiej wydała Kazimiera Jeżewska.
Bilingwiczną edycję (tekst oryginalny i polskie tłumaczenie) "Wojny mysio-żabiej" wydał Włodzimierz Appel w 1993 roku, a hymnów homeryckich w 2001. Sześć lat później, w ramach serii Biblioteka Antyczna, autor ten opublikował w ramach jednego tomu zbiór dziewięciu antycznych żywotów Homera oraz tłumaczenia: hymnów homeryckich, "Głuptaka", "Kerkopów", "Chichotek", "Wojny mysio-łasiczej" ("Galeomyomachia") i "Wojny mysio-żabiej".

</doc>
<doc id="12922" url="https://pl.wikipedia.org/wiki?curid=12922" title="Pompa odśrodkowa">
Pompa odśrodkowa

Pompa odśrodkowa – pompa wirowa krętna o wirniku odśrodkowym i o pojedynczej lub przestrzennej krzywiźnie łopatek.
Wirnik (1), o poziomej lub pionowej osi obrotu, umieszczony jest w spiralnym korpusie (2). Dopływ cieczy (3) jest osiowy, zaś odpływ (4) promieniowy w przypadku pompy z poziomą osią obrotu. Przepływ cieczy przez wirnik jest promieniowy. W pompie z pionową osią obrotu zwykle dopływ i przepływ cieczy jest pionowy. Większość pomp paliwa czy pomp płynu spryskiwaczy szyb w pojazdach mechanicznych jest pompami z pionową osią obrotu. Pompy z poziomą osią obrotu są najczęściej stosowane w dużych instalacjach przemysłowych.
Pompy odśrodkowe są najczęściej używanymi pompami. Ich wysokość podnoszenia wynosi do 150 m, a wydajność – w zależności od wielkości wirnika – od kilku centymetrów sześciennych na minutę (dla urządzeń miniaturowych) do kilkunastu tysięcy metrów sześciennych na godzinę (w instalacjach przemysłowych). Za pomocą pomp wielostopniowych można uzyskać wysokość podnoszenia do kilku kilometrów, co pozwala na stosowanie ich w instalacjach odwadniających kopalnie lub do tłoczenia ropy naftowej (z dna odwiertów lub w rurociągach dalekobieżnych). 
Konstrukcja wirnika oraz materiał, z jakiego jest wykonany, mogą być różne. Niewielkie pompki wykonywane są w całości z plastiku; pompy do zawiesin, szlamów lub cieczy agresywnych wyposażone są zwykle w wirniki gumowe.
Sprawność energetyczna pomp odśrodkowych leży w zakresie od η = 0,65 (małe) do η = 0,89 (duże). Dla danej konstrukcji sprawność można obliczyć jako iloczyn natężenia przepływu i wytwarzanego ciśnienia podzielony przez zapotrzebowanie na moc.

</doc>
<doc id="12923" url="https://pl.wikipedia.org/wiki?curid=12923" title="Muzy">
Muzy

Muzy (lm gr. Moûsai, łac. Musae, lp. gr. Moúsa, łac. Musa) – w mitologii greckiej boginie sztuki i nauki. Ośrodkami kultu muz były Delfy, Parnas i Helikon w Beocji.
W zależności od autora różniły się składem, imionami i rodowodem.
Muzy olimpijskie.
Hezjod, Apollodoros i inni autorzy wymieniają dziewięć tzw. muz olimpijskich (gr. Moûsai Olympiádes), będących córkami Zeusa i Mnemosyne. Każda muza opiekowała się konkretną dziedziną poezji, sztuki czy nauki i miała przydzielony atrybut:
Wszystkie muzy miały zdolność wieszczenia i występowały w orszaku Apollina, nazywanego przodownikiem muz (gr. "Mousēgétēs").
Inne muzy.
Początkowo była jedna muza – opiekunka aojdów, muza pamięci, później trzy:
Zwane były muzami helikońskimi (gr. Helikōniádes Moûsai), ponieważ czczono je na Helikonie, bądź muzami tytanidami (gr. Moûsai Titanídes), jako że wedle Pauzaniasza były córkami Uranosa.
W "O naturze bogów" Cyceron z kolei wymienia cztery muzy – córki Uranosa:
Zgodnie z przekazem Plutarcha w Delfach znano trzy muzy apollonidy (gr. Moûsai Apollōnídes), które są również nazwami trzech antycznych muzycznych strun liry:
U Eumelosa pojawiają się inne córki Apollina:
Odwołania w nowożytności.
Film lub twórczość filmową określa się mianem „dziesiątej muzy”, telewizję – „jedenastej muzy”, internet i gry zaś- „dwunastej muzy”.

</doc>
<doc id="12925" url="https://pl.wikipedia.org/wiki?curid=12925" title="Ciało zbiorów">
Ciało zbiorów

Ciało zbiorów, algebra zbiorów – rodzina formula_1 podzbiorów pewnego niepustego zbioru formula_2 spełniająca warunki:
Czasami, by podkreślić, że formula_1 jest rodziną podzbiorów konkretnego zbioru formula_9 pisze się "ciało zbiorów na" formula_10
Ciała zbiorów bada się w teorii mnogości i teorii algebr Boole’a, w mniejszym stopniu w teorii miary, probabilistyce, topologii i kombinatoryce.
Podstawowe przykłady.
Niech formula_2 będzie niepustym zbiorem.
Następujące rodziny podzbiorów formula_2 są ciałami na formula_13
Jeśli formula_20 jest przestrzenią topologiczną, to rodzina otwarto-domkniętych podzbiorów formula_2 tworzy ciało. (Ciała tego typu są rozważane głównie dla przestrzeni zerowymiarowych).
Niech formula_22 będzie porządkiem liniowym w którym istnieje element najmniejszy. Dla formula_23 niech formula_24 (Element formula_25 jest traktowany jako element większy niż wszystkie punkty z formula_10) Niech formula_1 będzie rodziną złożoną ze zbioru pustego oraz tych podzbiorów formula_2 które mogą być przedstawione jako formula_29 dla pewnych elementów formula_30 spełniających nierówności formula_31 formula_32 Wówczas formula_1 jest ciałem podzbiorów formula_34 jest to ciało generowane przez przedziały formula_35 dla formula_36

</doc>
<doc id="12928" url="https://pl.wikipedia.org/wiki?curid=12928" title="Pompa helikoidalna">
Pompa helikoidalna

Pompa helikoidalna – pompa wirowa krętna o wirniku helikoidalnym.
Wirnik (1) (zwykle o poziomej osi obrotu), umieszczony jest w spiralnym korpusie (2). Dopływ cieczy (3) jest osiowy, zaś odpływ (4) promieniowy. Przepływ cieczy przez wirnik jest ukośny.
Pompy helikoidalne osiągają wysokości podnoszenia z zakresu 5 do 60 m oraz wysokie wydajności dochodzące do 14 000 m³/h. Pompy helikoidalne stosowane są zwykle w instalacjach przemysłowych lub odwadniających do pompowania cieczy czystych lub lekko zanieczyszczonych.
Sprawność energetyczna pompy helikoidalnej leży w zakresie od η=0,75 do η=0,88.

</doc>
<doc id="12929" url="https://pl.wikipedia.org/wiki?curid=12929" title="Pompa śmigłowa">
Pompa śmigłowa

Pompa śmigłowa – pompa wirowa krętna o wirniku śmigłowym.
Śmigłowy wirnik (1) (niekiedy z łopatkami o regulowanym nachyleniu) umieszczony jest w osiowym korpusie (2). Dopływ (3), odpływ (4) oraz przepływ cieczy przez wirnik jest osiowy. Ciecz opuszczająca wirnik trafia do kierownicy łopatkowej (5) gdzie jej moment pędu zamieniany jest w energię ciśnienia. Pompy śmigłowe pracują niemal wyłącznie w położeniu pionowym.
Pompy śmigłowe osiągają niewielką wysokości podnoszenia – przeważnie poniżej 12 m oraz bardzo wysokie wydajności dochodzące do 40 000 m³/h. Pompy śmigłowe stosowane są w instalacjach przemysłowych I energetycznych.
Sprawność energetyczna pompy śmigłowej leży w zakresie od η=0,8 do η=0,9.

</doc>
<doc id="12930" url="https://pl.wikipedia.org/wiki?curid=12930" title="Pompa diagonalna">
Pompa diagonalna

Pompa diagonalna – pompa wirowa krętna o wirniku diagonalnym.
Wirnik (1) umieszczony w osiowym korpusie (2). Dopływ (3) i odpływ (4) cieczy jest osiowy. Przepływ cieczy przez wirnik jest ukośny. Kierunek cieczy z ukośnego na osiowy zmieniany jest w kierownicy łopatkowej (5). Także w kierownicy część energii momentu pędu cieczy zamieniana jest na energię ciśnienia. Pompy diagonalne niemal wyłącznie pracują w pozycji pionowej.
Pojedyncze pompy diagonalne osiągają wysokości podnoszenia do 60 m oraz wysokie wydajności dochodzące do 40000 m³/h. Pompy diagonalne często stosuje się w układach wielostopniowych. Jako że korpus pompy diagonalnej swymi zewnętrznymi wymiarami niewiele przekracza średnicę rurociągu, pompy tego typu często stosowane są w pionowych instalacjach odwadniających.
Sprawność energetyczna (η) pompy diagonalnej leży w zakresie 0,75–0,88.

</doc>
<doc id="12933" url="https://pl.wikipedia.org/wiki?curid=12933" title="Rajmonda (balet)">
Rajmonda (balet)

Rajmonda – balet w 3 aktach z apoteozą. 
Prapremiera: Petersburg 7 stycznia 1898, Teatr Maryjski.
Premiera polska: Wrocław 17 grudnia 1955, Państwowa Opera.
Osoby:

</doc>
<doc id="12934" url="https://pl.wikipedia.org/wiki?curid=12934" title="Trójkątny kapelusz">
Trójkątny kapelusz

Trójkątny kapelusz lub Trójgraniasty kapelusz (hiszp. "El sombrero de tres picos, Le Tricorne") – balet komiczny w jednym akcie.
Prapremiera: Londyn 22 lipca 1919, Alhambre Theatre, Balety Rosyjskie Diagilewa.
Premiera polska: Warszawa 1 października 1962, Państwowa Opera.

</doc>
<doc id="12935" url="https://pl.wikipedia.org/wiki?curid=12935" title="Urania (muza)">
Urania (muza)

Urania („Niebiańska”; gr. Ouranía, łac. Urania, ‘Niebiańska’ od gr. "ouranós" ‘niebo’) – muza astronomii (łącznie z astrologią).
Uchodziła za córkę boga Zeusa i tytanidy Mnemosyne oraz za siostrę: Erato, Euterpe, Kalliope, Klio, Melpomene, Polihymnii, Talii, Terpsychory. Według niektórych źródeł miała synów Linosa (z Amfimarosem) i Hymena.
Była jedną spośród dziewięciu muz olimpijskich (przebywały na Olimpie), które należały do orszaku boga Apollina (Apollon Musagetes), ich przewodnika. Wraz ze swoimi siostrami uświetniała śpiewem biesiady bosko-ludzkie (m.in. zaślubiny Tetydy i Peleusa oraz Harmonii i Kadmosa), a także uczty olimpijskie samych bogów.
W sztuce przedstawiana jest zwykle jako kobieta z cyrklem, kulą nieba (gwiezdnym globusem) i wskaźnikiem (pałeczką służącą do wskazywania czegoś na globusie) – atrybutami symbolizującymi dziedzinę nauki, której patronowała (jej dziełem było gwiaździarstwo).
Imieniem muzy nazwano jedną z planetoid – (30) Urania, niektóre obserwatoria astronomiczne (m.in. w Antwerpii, Berlinie, Wiedniu, Zurychu) oraz czasopismo poświęcone upowszechnianiu wiedzy astronomicznej – „Urania – Postępy Astronomii”, a także nocny pociąg TLK Urania, w sezonie letnim 2016, kursujący między Krakowem a Kołobrzegiem i Krakowem a Ustką.

</doc>
<doc id="12936" url="https://pl.wikipedia.org/wiki?curid=12936" title="Szach-mat (balet)">
Szach-mat (balet)

Szach-mat "(Checkmate)" - balet w jednym akcie z prologiem.
Prapremiera: Paryż 15 czerwca 1937, Théâtre des Champs-Elysée, Vic-Wells Ballet.
Premiera polska: Wrocław 8 lutego 1964, Państwowa Opera.

</doc>
<doc id="12937" url="https://pl.wikipedia.org/wiki?curid=12937" title="Focus (holenderski zespół muzyczny)">
Focus (holenderski zespół muzyczny)

Focus – holenderska progresywna grupa rockowa istniejąca w latach 1968-1978. Reaktywowana w 2002 roku. Formacja nagrywała głównie muzykę instrumentalną, charakteryzującą się bogatym brzmieniem opartym na dźwiękach instrumentów klawiszowych, pasażach fletu, gitarowych riffach i skomplikowanych rytmach. W jej muzyce wyraźnie daje się zauważyć wpływy muzyki klasycznej, która stanowi podstawę stylu zespołu, oraz elementy jazzu. Najbardziej znanym utworem grupy Focus jest groteskowy „Hocus Pocus”, w którym wykorzystano jodłowanie. Trzon zespołu do marca 1976 roku stanowiła para liderów: Thijs van Leer (flet, głos, organy i inne instrumenty klawiszowe) i Jan Akkerman (gitary, lutnia).
Historia.
Zespół powstał w 1968 roku w Amsterdamie z inicjatywy Thijsa van Leera, wówczas studenta tamtejszego Konserwatorium, oraz studentów tej samej uczelni, czyli Martina Dresdena (gitara basowa) i Hansa Cleuvera (perkusja). T. van Leer poznał ich podczas sesji nagraniowej do audycji radiowej "Jazz i poezja". Muzycy pod nazwą "Thijs van Leer Trio", początkowo specjalizowali się w wykonywaniu utworów popularnej w tamtym czasie grupy Traffic, Boba Dylana i in., grali także własne kompozycje.
Siedzibą zespołu był wówczas teatr "Felix Merrites". Z powodów finansowych formacja akompaniowała na żywo takim wykonawcom jak: Ramses Shaffy (Focus pomógł mu nagrać w 1970 roku singla, pt. „The Shrine of God”), czy Jurriaan Andriessen, a także wzięła udział w holenderskiej inscenizacji i rejestracji musicalu "Hair". Wówczas członkiem grupy był już wybitny gitarzysta Jan Akkerman (ex- Brainbox), który po raz pierwszy zagrał z nią pod koniec 1968 roku podczas jam session w związku studentów "Mags".
Już pod nową nazwą "Focus", grupa nagrała w Londynie swój pierwszy album, wydany w 1970 w Holandii pod nazwą "Focus Plays Focus", zaś w Wielkiej Brytanii pod nazwą "In and Out of Focus". Sponsorem płyty był dział wydawniczy Radia Luxembourg, którego dyrektorem był Hubert Terheggen. Nagranie nie spodobało się wytwórni i jej wydanie wstrzymano. Zespół wrócił do studia i na własny koszt nagrał singiel, pt. „House of the King”, który słuchacze w Europie Zachodniej odebrali jako kolejną propozycję grupy Jethro Tull.
Dopiero na fali jego powodzenia ukazał się debiutancki krążek zespołu, który główne centra rockowego życia, czyli Wielka Brytania i Stany Zjednoczone przyjęły z umiarkowanym entuzjazmem. Po tym eksperymencie formacja przestała tworzyć piosenki (ze względu na złą wymowę w języku angielskim) i zmieniła styl.
Z inicjatywy Akkermana, Cluevera zastąpił perkusista Pierre van der Linden, dołączył także Cyril Havermans (gitara basowa, śpiew). W dniach 13 kwietnia – 14 maja 1971 roku zespół nagrywał pod okiem doświadczonego producenta Mike’a Vernona (współpracował m.in. z: The Artwoods, Fleetwood Mac, Ten Years After, Johnem Mayallem, Erikiem Claptonem, Davidem Bowie) swój drugi album, "Focus II", poza Holandią znany jako "Moving Waves". We wrześniu odchodzi Havermans, zaś nowym basistą grupy zostaje Bert Ruiter, z którym Focus podbija Wielką Brytanię (1972) i bierze udział w programie telewizyjnym "Old Grey Whistle Test". Wówczas zespół pozostawał w trasie przez co najmniej osiem miesięcy.
Podsumowaniem tego okresu był występ na "Redding Rock Festival" w sierpniu 1972 roku. Focus był tam jedną z głównych atrakcji imprezy, pomimo silnej konkurencji, którą stanowiły grupy takie jak: Emerson, Lake and Palmer, Wishbone Ash czy Genesis. Płyta ukazała się w październiku, z miejsca zdobywając uznanie krytyków i słuchaczy. Wydarzenie to było ewenementem, ponieważ album był niemal całkowicie instrumentalny (z wyjątkiem tytułowego „Moving Waves”). Singiel „Hocus Pocus” był obecny na większości List Przebojów w Europie, a wiosną 1973 roku doszedł do 9 miejsca "Hot 100" tygodnika Billboard. W tym samym roku Akkerman został uznany przez tygodnik "Melody Maker" gitarzystą roku na świecie, wyprzedzając m.in. Erica Claptona i Jeffa Becka.
Na fali popularności "Moving Waves" muzycy nagrali dwupłytowy album "Focus 3" (1972), który okazał się znacznie trudniejszy w odbiorze, lecz dotarł do jeszcze szerszego grona odbiorców, a przyczynił się do tego sukces singla pt. „Sylvia”. Płyta staje się hitem w Holandii i w Wielkiej Brytanii. W 1973 roku Focus wyrusza na zwieńczone sukcesem tournée po Stanach Zjednoczonych, gdzie występuje obok takich wykonawców jak: Santana, Joe Cocker, Joe Walsh czy Little Feat, zaś wytwórnia dyskontuje popularność grupy poprzez wydanie płyty koncertowej "At the Rainbow".
W październiku odchodzi van der Linden, którego zastąpił były muzyk Stone the Crows – Collin Allen ("Hamburger Concerto", 1974). Powraca do zespołu na krótko w połowie 1975 roku, ale szybko jego miejsce zajmuje David Kamper ("Mother Focus", 1975 – Allen zagrał w utworze „I Need a Bathroom”). Kolejne dwa wydawnictwa zespołu znacznie różnią się od siebie. Longplay pt. "Hamburger Concerto" nie wzbogacał artystycznego wizerunku grupy, choć zauważalny jest większy wpływ muzyki dawnej, zaś "Mother Focus" to radykalna zmiana stylu i flirt z muzyką taneczną.
W marcu 1976 roku, przed kolejną brytyjską trasą koncertową odchodzi pragnący poświęcić się w pełni karierze solowej Akkerman. Sytuacji nie ratuje ani przyjęcie do grupy nowego gitarzysty Philipa Catherine, ani wydanie albumu "Focus Con Proby", nagranego z drugim gitarzystą i kompozytorem Eefem Albersem i perkusistą Steve'em Smithem. W kilku utworach zaśpiewał P.J. Proby (wybór wokalisty był przypadkowy – zaważyły na nim osobiste kontakty menedżera zespołu z fan clubem Proby'ego w Holandii). Kolejnym perkusistą grupy został Richard James. Focus zostaje rozwiązany w 1978 roku, ostatni koncert dając w Terneuzen.
W roku 1985 dwóch liderów zespołu nagrało wspólną płytę sygnowaną Focus. Było to jednorazowe wydarzenie, po którym nie odbyła się trasa, ani nie nastąpiła reaktywacja zespołu. W latach 1990 (na potrzeby programu telewizyjnego "The Gold Of Old") i 1999 dochodziło do pojedynczych występów oryginalnego składu zespołu. W 1993 roku van Leer i Akkerman występowali wspólnie na festiwalach jazzowych, lecz nie pod szyldem "Focus".
W roku 2002 Thijs van Leer reaktywował zespół (bez udziału Akkermana). Od tego momentu zespół nagrał cztery albumy (ostatni, jak dotąd, w 2016 pod szyldem "Focus and Friends featuring Marvio Ciribelli") i regularnie koncertuje.
Pierwszy koncert zespołu w Polsce odbył się 16 czerwca 2007 w katowickim klubie Mega Club. Kolejne to: 6 września 2008 w Inowrocławiu oraz 7 września 2008 w Poznaniu. 4 września 2016 roku i 15 września 2018 roku zespół zagrał koncert podczas finału Festiwalu Kielce Rockują w Kielcach.

</doc>
<doc id="12938" url="https://pl.wikipedia.org/wiki?curid=12938" title="Melpomene (mitologia)">
Melpomene (mitologia)

Melpomene (także Melpomena, „Śpiewająca”; gr. Melpoménē, łac. Melpomene, ‘Śpiewaczka’; od gr. "mélpein" ‘śpiewać’) – w mitologii greckiej muza tragedii.
Uchodziła za córkę boga Zeusa i tytanidy Mnemosyne oraz za siostrę: Erato, Euterpe, Kalliope, Klio, Polihymnii, Talii, Terpsychory i Uranii. Według jednej z wersji miała z bogiem Acheloosem córki – syreny.
Była jedną spośród dziewięciu muz olimpijskich (przebywały na Olimpie), które należały do orszaku boga Apollina ("Apollon Musagetes"), ich przewodnika. Wraz ze swoimi siostrami uświetniała śpiewem biesiady bosko-ludzkie (m.in. zaślubiny Tetydy i Peleusa oraz Harmonii i Kadmosa), a także uczty olimpijskie samych bogów.
W sztuce przedstawiana jest zwykle jako kobieta oparta o skałę lub maczugę, z maską tragiczną w ręce i wieńcem z winorośli na głowie – atrybutami symbolizującymi dziedzinę sztuki, której patronowała.
Imieniem muzy została nazwana jedna z planetoid – (18) Melpomene.

</doc>
<doc id="12939" url="https://pl.wikipedia.org/wiki?curid=12939" title="Klio (muza)">
Klio (muza)

Klio („Głosząca sławę”, „Sławiąca”; gr. Kleiṓ, od gr. "kléos" ‘sława’, "kleíein" ‘wsławiać’, łac. Clio) – w mitologii greckiej muza historii.
Uchodziła za córkę boga Zeusa i tytanidy Mnemosyne oraz za siostrę: Erato, Euterpe, Kalliope, Melpomene, Polihymnii, Talii, Terpsychory i Uranii. Według niektórych źródeł miała synów Hiacynta (z Pierosem) i Hymena.
Była jedną spośród dziewięciu muz olimpijskich (przebywały na Olimpie), które należały do orszaku Apollina (Apollon Musagetes), ich przewodnika. Wraz ze swoimi siostrami uświetniała śpiewem biesiady bosko-ludzkie (m.in. zaślubiny Tetydy i Peleusa oraz Harmonii i Kadmosa), a także uczty olimpijskie samych bogów.
W sztuce przedstawiana jest zwykle jako kobieta ze zwojem papirusu (lub pergaminu) – atrybutem symbolizującym dziedzinę nauki, której patronowała.
Imieniem muzy nazwano jedną z planetoid – (84) Klio oraz nagrodę udzielaną każdego roku polskim autorom popularyzującym historię.

</doc>
<doc id="12941" url="https://pl.wikipedia.org/wiki?curid=12941" title="Mnemosyne (mitologia)">
Mnemosyne (mitologia)

Mnemosyne (także Mnemozyna, Mnemosyna, Pamięć; Mnēmosýnē ‘pamięć’, ) – w mitologii greckiej tytanida, bogini i uosobienie pamięci.
Należała do pierwszego pokolenia tytanów i tytanid. Uchodziła za córkę Uranosa i Gai. Była siostrą tytanów (Hyperiona, Japeta, Kojosa, Kriosa, Kronosa, Okeanosa) i tytanid (Fojbe, Rei, Tei, Temidy, Tetydy) oraz cyklopów niebiańskich (Argesa, Brontesa, Steropesa) i hekatonchejrów (Ajgajona, Gygesa, Kottosa). Z bogiem Zeusem (połączył się z nią w Pierii w ciągu kolejnych dziewięciu nocy) miała córki (Erato, Euterpe, Kalliope, Klio, Melpomene, Polihymnię, Talię, Terpsychorę i Uranię), które były muzami olimpijskimi.
Przed wyrocznią Trofoniosa w Lebadei w Beocji istniało Źródło Pamięci (Mnemosyne).
Imieniem tytanidy nazwano jedną z planetoid – (57) Mnemosyne oraz motyla z rodziny paziowatych – niepylak mnemozyna ("Parnassius mnemosyne").

</doc>
<doc id="12946" url="https://pl.wikipedia.org/wiki?curid=12946" title="Allegro">
Allegro



</doc>
<doc id="12948" url="https://pl.wikipedia.org/wiki?curid=12948" title="Efekt Coriolisa">
Efekt Coriolisa

Efekt Coriolisa, zwyczajowo siła Coriolisa – zjawisko występujące, gdy ciało porusza się w obracającym się układzie odniesienia.
Opis.
Załóżmy, że obserwator nieruchomy względem inercjalnego układu odniesienia obserwuje ciało, na które nie działa żadna siła. Zgodnie z I zasadą dynamiki, ciało to poruszać się będzie ruchem jednostajnym i prostoliniowym – jednak obserwator nieruchomy względem obracającego się nieinercjalnego układu odniesienia będzie widział zakrzywienie toru ruchu ciała. Zakrzywienie to zdaje się być wywołane jakąś siłą, nazwaną siłą Coriolisa. Jest to więc siła pozorna i działa jedynie na ciała poruszające się względem obracającego się nieinercjalnego układu odniesienia.
Badaniem tego zjawiska zajmował się francuski inżynier i matematyk Gaspard-Gustave Coriolis. Efektownym potwierdzeniem siły Coriolisa dla Ziemi jest zmiana płaszczyzny wahania wahadła Foucaulta. Samo zjawisko znali już w XVII wieku włoscy uczeni G.B. Riccioli i F.M. Grimaldi. Równanie je opisujące wyprowadził szwajcarski uczony Leonhard Euler w 1749 roku.
Siła Coriolisa wyrażona jest wzorem:
Z siłą tą wiąże się przyspieszenie Coriolisa:
gdzie:
Przyczyny i skutki.
Siła Coriolisa powoduje odchylenie od linii prostej toru ruchu ciała, poruszającego się w układzie obracającym się (np. Ziemi lub płaskiej tarczy). Ponieważ Ziemia obraca się z zachodu na wschód, zatem siła Coriolisa powoduje odchylenie w kierunku zachodnim toru ciała poruszającego się po powierzchni Ziemi ku równikowi na półkuli północnej, a w kierunku wschodnim, gdy ciało porusza się w stronę biegua, czyli ku miejscu przechodzenia osi obrotu Ziemi. Na półkuli południowej kierunki odchyleń będą odwrotne, odpowiednio na wschód i zachód.
W drugim szczególnym przypadku na Ziemi siła Coriolisa powoduje odchylenie swobodnie spadających ciał w kierunku wschodnim. Dzieje się tak, gdyż ciało, przybliżając się do osi obrotu, zachowuje swoją dotychczasową prędkość liniową (która jest większa niż dla punktów położonych niżej, obracających się z tą samą prędkością kątową). Jeśli na równiku postawić wysoką wieżę i puścić z jej szczytu swobodnie kamień, to – przyciągany siłą grawitacji – będzie się on zbliżał do powierzchni, która porusza się z mniejszą prędkością liniową niż wierzchołek wieży; zatem spadający kamień „wyprzedzi” powierzchnię Ziemi. Ciała swobodnie spadające odchylają się na wschód wszędzie poza biegunami Ziemi.
Siła Coriolisa nie oddziałuje na ciała pozostające w spoczynku, jak również na ciała poruszające się równolegle do osi obrotu Ziemi (wówczas iloczyn wektorowy prędkości ciała i prędkości kątowej Ziemi równy jest 0).
Efekt na Ziemi.
Ziemia obraca się wokół swojej osi i dlatego dla ciał poruszających się po powierzchni Ziemi, w jej wodach lub atmosferze występuje efekt Coriolisa. Na północ od równika powoduje on zakrzywienie toru ruchu poruszających się obiektów w prawo (z punktu widzenia poruszającego się obiektu), a na południe – w lewo.
Efekt ten nie jest zazwyczaj odczuwalny, objawia się jedynie przy długotrwałych procesach lub w przypadku ciał poruszających się swobodnie na dużym obszarze (pasaty, prądy morskie). A oto przykłady jego wpływu (z punktu widzenia obserwatora poruszającego się wraz z obiektem – wiatrem, rzeką...):
Jeśli z określonego miejsca na półkuli północnej zacznie przemieszczać się ku biegunowi masa powietrza, to napływa ona nad obszary o malejącej prędkości liniowej i będzie w stosunku do nich napływać nie z południa, lecz z południowego zachodu. Z punktu widzenia obserwatora na Ziemi wygląda to, jakby na powietrze działała siła skierowana z zachodu na wschód. Tą pozorną siłą jest właśnie siła Coriolisa.
Efekt Coriolisa musi być także brany pod uwagę przez artylerzystów, osoby sterujące lotem samolotów, rakiet itp.

</doc>
<doc id="12949" url="https://pl.wikipedia.org/wiki?curid=12949" title="Siły Coriolisa">
Siły Coriolisa



</doc>
<doc id="12951" url="https://pl.wikipedia.org/wiki?curid=12951" title="Mnemozyne">
Mnemozyne



</doc>
<doc id="12952" url="https://pl.wikipedia.org/wiki?curid=12952" title="Teoria modeli">
Teoria modeli

Teoria modeli (nazywana też semantyką logiczną) – dział logiki matematycznej zajmujący się badaniem własności modeli teorii aksjomatycznych i zależności między nimi. Dziedzina ta jest w znacznym stopniu powiązana z algebrą i teorią mnogości, ale ma też mocno rozbudowany własny aparat pojęciowy i w swojej współczesnej postaci jest w pełni samodzielną dziedziną wiedzy.
Początki teorii modeli.
Początki teorii modeli sięgają lat trzydziestych XX wieku (chociaż pewne rozważania o teoriomodelowym charakterze były przeprowadzane znacznie wcześniej), kiedy osiągnięto wiele ważnych wyników, które stworzyły fundament dla dalszego bujnego rozwoju tej dziedziny. Największe osiągnięcia tego okresu wiąże się zazwyczaj z nazwiskami Gödla i Tarskiego, którzy przez współczesnych są zaliczani do grona najwybitniejszych logików wszech czasów.
Alfred Tarski, polski logik i matematyk, jest powszechnie uważany za twórcę teorii modeli. W swojej słynnej pracy "Pojęcie prawdy w językach nauk dedukcyjnych" z 1933 roku rozważał między innymi pojęcie zdania prawdziwego i jego różne możliwe definicje. Wykazał on w szczególności, że można podać definicję prawdy dla dowolnego języka skończonego rzędu, zaś dla języków nieskończonego rzędu już nie. Tarski zdefiniował pojęcie spełniania (funkcji zdaniowej przez ciąg elementów oraz zdania przez model), które jest kluczowe dla całej teorii modeli i w nieznacznie zmienionej formie używane do dzisiaj. Opracował też między innymi pewną metodę badania czy dany model stanowi elementarną podstrukturę innego (test Tarskiego-Vaughta). Badania Tarskiego nad związkami między syntaktyką i semantyką logiczną wpłynęły na ugruntowanie podstaw teorii modeli.
Austriak Kurt Gödel (sławny dzięki osiągnięciom w dziedzinie logiki, również niezwiązanych z teorią modeli) udowodnił w 1931 roku twierdzenie o istnieniu modelu, które głosi, że każda niesprzeczna teoria pierwszego rzędu ma model. Natychmiastowym wnioskiem z tego twierdzenia jest inne, znane jako twierdzenie o pełności klasycznego rachunku logicznego. Orzeka ono, że teoria T dowodzi zdania X (tzn. istnieje dowód zdania X oparty na zdaniach należących do teorii T oraz aksjomatach i regułach dowodzenia klasycznego rachunku logicznego) wtedy i tylko wtedy, gdy każdy model teorii T spełnia zdanie X.
Prowadzi to do ważnego wniosku, że pojęcia konsekwencji syntaktycznej i semantycznej są równoważne i można ich używać wymiennie, w zależności od tego, które się łatwiej daje zastosować w danym przypadku. Warto przy tym zwrócić uwagę, że zgodnie z wynikami Tarskiego w teorii muszą istnieć jednocześnie zdania prawdziwe których teoria nie dowodzi i że pojęcie prawdziwości i konsekwencji syntaktycznej (dowodliwości) są różne. Sam Tarski w swojej pracy naukowej konsekwentnie unikał czysto formalnego operowania symbolami i prezentował pogląd, w ramach którego ważne jest znaczenie badanych zdań teorii, a nie jedynie ich syntaktyczne związki z innymi zdaniami. Zatem równoważność konsekwencji syntaktycznej i semantycznej należy rozumieć jako równoważność wewnętrzną teorii, a nie jako orzeczenie o prawdziwości zdania jako cechy wynikającej z jego syntaktycznych związków. Znane są bowiem zdania, o których wiadomo, że są prawdziwymi zdaniami pewnych teorii (i jest na to dowód), nie są one jednak w danej teorii dowiedlne (dowód wymaga środków wykraczających poza daną teorię). Przykładów takich zdań dostarcza np. dowód twierdzenia Gödla. W konsekwencji zdania dowiedlne w danej teorii (czyli we wszystkich jej modelach) stanowią podzbiór właściwy zdań prawdziwych danej teorii. Tym samym twierdzenie o równoważności syntaktyki i semantyki może dotyczyć wyłącznie części wspólnej tych zbiorów, nie zaś pełnego zbioru zdań prawdziwych danej teorii czy zbioru zdań prawdziwych w ogóle.
Wyodrębnienie jako dział logiki.
Ważnym etapem w rozwoju teorii modeli były lata sześćdziesiąte XX wieku, kiedy wyraźnie wyodrębniła się ona jako jeden z kilku działów logiki matematycznej. Matematycy i logicy uzyskali wtedy wiele istotnych rezultatów, znacznie rozbudowując przy okazji aparat pojęciowy teorii modeli i wyznaczając dla tej dziedziny zupełnie nowe kierunki rozwoju. Poniżej wymieniamy tylko niektóre ważniejsze wydarzenia z tego okresu.
Ze względu na dokonania Morleya i zastosowane przez niego nowe metody (między innymi w dowodzie wyżej wspomnianego twierdzenia dotyczącego kategoryczności teorii, które ktoś nazwał "pierwszym głębokim twierdzeniem teorii modeli") rok 1964 jest przez niektórych uznawany za symboliczną datę wyodrębnienia się teorii modeli z logiki jako samodzielnej dziedziny.
Rozwój teorii modeli.
W latach siedemdziesiątych XX wieku szczególnie duże zasługi dla rozwoju teorii modeli położył izraelski matematyk Saharon Szelach. Próbował on klasyfikować teorie ze względu na liczbę oraz stopień komplikacji ich modeli. Rozważał pewne kombinatoryczne własności modeli, dzięki których użyciu mógł dokonać podziału teorii na łatwo dające się opisać klasy. Szczególnie interesowały go te teorie, które mają stosunkowo mało modeli w każdej mocy – uważał je za prostsze od innych i lepiej nadające się do klasyfikowania. Shelah stworzył hierarchię stabilności, która zawiera kolejne klasy coraz bardziej niestabilnych teorii (teorie z ostatniej klasy noszą właśnie nazwę niestabilnych). Metoda, którą Shelah specjalnie wymyślił i stosował w swoich badaniach, to forking (czyli rozwidlanie); jest ona dziś jednym z podstawowych narzędzi używanych w rozważaniach teoriomodelowych.
W tym samym czasie co Shelah teorię modeli rozwijało wielu innych matematyków. W swoich ówczesnych badaniach próbowali oni odpowiedzieć na pytanie, jak różne pojęcia logiczne wyglądają w konkretnych strukturach algebraicznych (czyli na przykład w grupach, pierścieniach, ciałach czy modułach). Zresztą teoria modeli od początku swego istnienia była rozwijana z zamiarem zastosowania jej metod w algebrze, zaś struktury algebraiczne są najbardziej naturalnymi przykładami modeli.
Z biegiem lat specjaliści z teorii modeli obejmowali swym zainteresowaniem coraz szersze obszary matematyki. Od lat osiemdziesiątych XX wieku teorię modeli stosuje się w geometrii algebraicznej, a nawet w analizie (teoria struktur o-minimalnych). Jest to dynamicznie rozwijający się dział logiki matematycznej, w którym wciąż można spodziewać się ważnych i ciekawych wyników.
Struktury w teorii modeli.
Struktura matematyczna, model, system semantyczny, model semantyczny, dziedzina, struktura pierwszego rzędu to zbiór obiektów matematycznych połączonych w pewien system.
Na strukturę matematyczną formula_1 składają się "uniwersum" (czyli pewien zbiór lub szerzej klasa) oraz "interpretacja symboli" pewnego "języka" formula_2 w skład którego mogą (lecz nie muszą) wchodzić "symbole funkcji", "relacji" i "stałych" ("interpretacje symboli" stałych w modelu to "elementy wyróżnione"; zob. symbol funkcyjny). Dlatego każdą strukturę formula_1 należy rozpatrywać w kontekście ustalonego języka formula_2 mówi się wtedy, że formula_1 jest modelem (strukturą) dla języka formula_6
Niekiedy rozróżnia się znaczenia terminów „model” i „struktura matematyczna” („system semantyczny”). Słowo „model” oznacza wtedy tylko "uniwersum".
Własności i zastosowania.
Każdemu modelowi można przyporządkować zbiór tych wszystkich zdań logicznych wyrażonych w języku tego modelu, które są w nim prawdziwe – jest to tzw. teoria tego modelu. Można też rozważać modele, które spełniają dany niesprzeczny zbiór zdań. Twierdzenie o istnieniu modelu udowodnione w 1931 roku przez Kurta Gödla mówi, że dla każdego takiego zbioru zdań istnieje model, który spełnia je wszystkie (spełnia w sensie definicji spełniania Tarskiego).
Struktura matematyczna jest na tyle ogólnym pojęciem, że badanie własności modeli i pewnych klas ich przekształceń (na przykład izomorfizmów, elementarnych równoważności) pozwala na wyciąganie pewnych generalnych wniosków dotyczących rzeczywistości matematycznej. Badaniami takimi zajmuje się teoria modeli, jeden z działów logiki matematycznej.
Modele języków pierwszego rzędu.
Niech formula_7 będzie alfabetem pewnego języka pierwszego rzędu formula_8
Interpretacją lub modelem języka formula_9 nazywa się dowolną parę uporządkowaną formula_10 gdzie U jest niepustym zbiorem, natomiast formula_11 jest funkcją określona na zbiorze wszystkich stałych pozalogicznych rozważanego języka, spełniającą następujące warunki:

</doc>
<doc id="12956" url="https://pl.wikipedia.org/wiki?curid=12956" title="Pompa wirowa krążeniowa">
Pompa wirowa krążeniowa

Pompa wirowa krążeniowa – rodzaj pompy wirowej, w której proces konwersji energii od mechanicznej do hydraulicznej odbywa się na drodze wymiany ilości ruchu (pędu) między cieczą pozostającą w spoczynku a poruszającą się w obszarze wirnika. Ciecz wielokrotnie przepływa przez wirniki, doznając za każdym razem impulsowego przyrostu energii, dzięki czemu osiągane są niskie wartości wyróżnika szybkobieżności nq. 
Jednostki te często mają geometrię przepływową zapewniającą samozasysanie, to znaczy zdolność rozruchu bez konieczności zalania rurociągu ssawnego. Pompy te, ze względu na możliwe do uzyskania niskie wartości podciśnienia, stosowane są jako pompy próżniowe. Należą do nich pompy krążeniowe z bocznymi kanałami pierścieniowymi, pompy peryferalne, pompy z wirującym pierścieniem wodnym (pompy o pierścieniu wodnym) i wiele innych.
Pompy samozasysające stosuje się tam, gdzie istnieje konieczność rozruchu bez wstępnego zalania, na przykład w pompach strażackich lub jako pompy rozruchowe (zalewające) w układach pompowych.

</doc>
<doc id="12957" url="https://pl.wikipedia.org/wiki?curid=12957" title="Narrator">
Narrator

Narrator – termin z teorii literatury. Podmiot narracji, osoba opowiadająca o wydarzeniach przedstawionych w książce. Narrator jest ośrodkiem sytuacji narracyjnej, w obrębie której sytuuje się wobec świata przedstawionego i wobec adresata narracji. Głos narratora nie musi być identyczny z głosem autora dzieła. 
Narrator występuje w utworach epickich, może także pojawiać się w epickich formach poetyckich, jak również w dramacie (np. w dramatach Jana Augusta Kisielewskiego – postać narratora, jako jeden z elementów tzw. epizacji dramatu).
Rodzaje.
Istnieje kilka rodzajów narratora:
W powieściach bardzo często zdarza się, że narracja zmienia się w różnych ich częściach. Np. powieść zaczyna się od wprowadzenia narratora świadka, który następnie subtelnie przechodzi na pozycję narratora wszechwiedzącego, który czasami „oddaje głos" narratorom bezpośrednim.

</doc>
<doc id="12959" url="https://pl.wikipedia.org/wiki?curid=12959" title="20. ceremonia wręczenia Oscarów">
20. ceremonia wręczenia Oscarów

20. ceremonia rozdania Oscarów odbyła się 20 marca 1948 roku w Shrine Auditorium w Los Angeles.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii, napisano ich pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).

</doc>
<doc id="12967" url="https://pl.wikipedia.org/wiki?curid=12967" title="21. ceremonia wręczenia Oscarów">
21. ceremonia wręczenia Oscarów

21. ceremonia rozdania Oscarów odbyła się 24 marca 1949 roku w The Academy Theatre w Los Angeles.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii napisano ich nazwiska pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).

</doc>
<doc id="12968" url="https://pl.wikipedia.org/wiki?curid=12968" title="Amadeusz (imię)">
Amadeusz (imię)

Amadeusz lub Amedeusz – imię męskie pochodzące od łacińskiego imienia "Amadeus", powstałego w kręgach zakonnych. Wywodzi się od słów "amo, are" (kochać), oraz "Deus" (Bóg), co oznacza „kochający Boga”.
Żeńskim odpowiednikiem jest Amadea.
Podobne znaczenie w języku polskim posiada imię Bogumił, a z języka greckiego pochodzi znaczeniowo podobny Teofil.
Imię jest popularne w Sabaudii.
Amadeusz imieniny obchodzi 28 stycznia, 30 marca, 10 sierpnia, 12 września i 27 września.
Święci i błogosławieni o tym imieniu:
Inne osoby noszące imię Amadeusz:

</doc>
<doc id="12969" url="https://pl.wikipedia.org/wiki?curid=12969" title="Amadea">
Amadea

Amadea – żeński odpowiednik łacińskiego imienia Amadeusz, powstałego w kręgach zakonnych w średniowieczu. 
Oznacza „kochającą Boga”. Podobne znaczenie ma imię Teofila. 
Amadea imieniny obchodzi:
Znane osoby noszące imię Amadea:

</doc>
<doc id="12970" url="https://pl.wikipedia.org/wiki?curid=12970" title="Amedeusz">
Amedeusz



</doc>
<doc id="12972" url="https://pl.wikipedia.org/wiki?curid=12972" title="Amata">
Amata



</doc>
<doc id="12973" url="https://pl.wikipedia.org/wiki?curid=12973" title="Amato">
Amato



</doc>
<doc id="12975" url="https://pl.wikipedia.org/wiki?curid=12975" title="Wojciech Jaruzelski">
Wojciech Jaruzelski

 (ur. 6 lipca 1923 w Kurowie, zm. 25 maja 2014 w Warszawie) – polski polityk komunistyczny i dowódca wojskowy, generał armii ludowego Wojska Polskiego. Prezes Rady Ministrów (1981–1985), przewodniczący Rady Państwa (1985–1989), pierwszy i ostatni prezydent Polskiej Rzeczypospolitej Ludowej (1989) i pierwszy prezydent III Rzeczypospolitej Polskiej (1989–1990).
Szef Głównego Zarządu Politycznego Wojska Polskiego (1960–1965), szef Sztabu Generalnego Wojska Polskiego (1965–1968), minister obrony narodowej (1968–1983), przewodniczący Wojskowej Rady Ocalenia Narodowego (1981–1983), I sekretarz Komitetu Centralnego Polskiej Zjednoczonej Partii Robotniczej (1981–1989). Członek Biura Politycznego KC PZPR (1971–1989), poseł na Sejm PRL III, IV, V, VI, VII, VIII i IX kadencji (1961–1989), członek prezydium Ogólnopolskiego Komitetu Frontu Jedności Narodu w latach 1981–1983. Przewodniczący Komitetu Obrony Kraju – zwierzchnik Sił Zbrojnych, współtwórca Patriotycznego Ruchu Odrodzenia Narodowego.
W nocy 12/13 grudnia 1981 stanął na czele Wojskowej Rady Ocalenia Narodowego, która wprowadziła stan wojenny (1981–1983) i sprawowała faktyczną władzę w Polsce podczas jego trwania. Określany z tej racji jako dyktator wojskowy.
Życiorys.
Dzieciństwo i młodość.
Wywodził się z rodziny szlacheckiej i ziemiańskiej herbu Ślepowron. Ród wywodzi się z pogranicza Mazowsza i Podlasia. Korzeniami sięga przełomu XV i XVI wieku. Gniazdem rodowym przodków był majątek Jaruzele, a później m.in. Ruś Stara – Sokoły wraz z przyległościami.
Dziadek Wojciecha, również Wojciech, brał udział w powstaniu styczniowym, za co został zesłany na Syberię na 8 lat. Po powrocie do Polski, poślubił Helenę z domu Filipkowską, która wniosła mu duży posag. Dzięki temu małżeństwo mogło kształcić liczne potomstwo. Ojciec Wojciecha, Władysław, był siódmym z ośmiorga dzieci Wojciecha i Heleny. Ukończył Akademię Rolniczą w czeskim Taborze. Wziął udział w wojnie polsko-bolszewickiej w 1920. Mimo że należała mu się część dóbr rodzinnych, pracował jako administrator majątków ziemiańskich. Ciesząc się opinią dobrego fachowca, trafił do Kurowa, położonego 17 km na wschód od Puław, gdzie poznał Wandę z Zarembów z pobliskiej Dąbrowy Wielkiej, absolwentkę Szkoły Gospodarstwa Wiejskiego w Puławach. Ich ślub miał miejsce 19 września 1922. Wojciech urodził się 6 lipca 1923 o godz. 21 w Kurowie. Pierwsze imię otrzymał po dziadku – powstańcu. W 1928 małżeństwu urodziła się jeszcze córka Teresa.
7 października 1923 został ochrzczony w kościele Narodzenia Najświętszej Maryi Panny i św. Michała Archanioła w Kurowie. Rodzina była głęboko religijna i patriotyczna. W 1925 rodzina Jaruzelskich opuściła Kurów i zamieszkała w majątku Trzeciny nad rzeką Brok.
Nie uczęszczał do szkoły powszechnej. Już po pierwszym dniu edukacji poprosił rodziców o kontynuowanie nauki w domu. Wkrótce potem został zatrudniony dla niego prywatny nauczyciel. Od 1933 Wojciech Jaruzelski uczęszczał do gimnazjum prowadzonego przez zakon marianów na warszawskich Bielanach, a jego edukacja była sporym obciążeniem dla budżetu domowego. Na etapie wyboru rozpatrywane były także gimnazjum jezuickie w Chyrowie koło Lwowa i gimnazjum w Rydzynie. Szkoła uczyła w duchu endeckim oraz zasad katolickich i poszanowania polskiej tradycji. We wczesnej młodości był bardzo religijnym i dobrze zapowiadającym się uczniem. Dostrzeżono w nim talent do przedmiotów humanistycznych. W klasie przyjaźnił się z Tadeuszem Gajcym. Miał dobry styl pisania i formułowania myśli. W latach 1937–1939 należał do Związku Harcerstwa Polskiego, należał do drużyny im. Stanisława Żółkiewskiego. W tym czasie opublikował artykuł "Służba Polsce" do szkolnej „Jednodniówki”. Odwoływał się tam do tradycji Orląt Lwowskich i harcerzy, którzy polegli w 1920, walcząc z bolszewikami. W 1939 ukończył IV klasę gimnazjum, uzyskując tzw. „małą maturę” w gimnazjum marianów.
Po wybuchu II wojny światowej rodzina uciekała w kierunku wschodnim. W momencie agresji ZSRR na Polskę, rodzina Jaruzelskich przebywała w jednym z majątków w powiecie lidzkim (województwo nowogrodzkie). Wobec ataku ze wschodu postanowili wrócić do Trzecin. Ostatecznie kierując się w kierunku Litwy, w nocy z 22 na 23 września przekroczyli w okolicach Kopciowa granicę z Litwą. Tam mieszkali w różnych miejscowościach w majątkach polskich rodzin. Po okupacji Litwy przez Armie Czerwoną i aneksji przez ZSRR, rodzina Jaruzelskich postanowiła wrócić na tereny okupacji niemieckiej. Ostatecznie matka, obawiając się, że przy przekroczeniu granicy może dojść do rozdzielenia rodziny, zdecydowała o pozostaniu na Litwie. 14 czerwca 1941 rodzina została deportowana na Syberię. Wojciech zamieszkał wraz z matką i siostrą w osadzie leśnej Turoczaku, gdzie w Górach Ałtajskich (ok. 300 km od Bijska) pracował w tajdze przy wyrębie lasów. Nabawił się tam choroby oczu, ślepoty śnieżnej, która trwale uszkodziła mu wzrok. Ciemne okulary ochronne stały się jego znakiem rozpoznawczym. Był także urzędnikiem w Rajpotriebsojuzie (Rejonowy Związek Spożywców). Ojciec został zesłany do łagrów w Kraju Krasnojarskim. Po podpisaniu umowy Sikorski-Majski, jesienią 1941 Władysław został zwolniony z łagru i udał się do Bijska, gdzie znajdowała się polska delegatura. Według siostry Wojciecha, ojciec zapisał go na ochotnika do formującego się wojska Andersa, lecz Wojciech z rodziną dopiero w styczniu 1942 przybył do Bijska. W międzyczasie w październiku 1941 Wojciech został wezwany przez miejscowe NKWD i poinformowany, że dostał pracę na stanowisku pomocnika magazyniera przy jedynym sklepie w osadzie, oraz większe mieszkanie i większy przydział chleba. W styczniu 1942, bez wiedzy miejscowego NKWD, podjął decyzję o opuszczeniu Turoczaka wraz z matką i siostrą, i udaniu się do Bijska celem dołączenia do ojca. Po przybyciu z matką i siostrą w styczniu 1942 do Bijska, spotkał się z – wówczas już ciężko chorym – ojcem. Jaruzelscy zamieszkali przy ulicy Gorkiego 51. Wojciech podjął pracę przy wyrębie lasu, a potem jako tragarz w piekarni. Aresztowany na 3 tygodnie przez NKWD za odmowę przyjęcia radzieckiego tymczasowego zaświadczenia tożsamości.
Ojciec Wojciecha Jaruzelskiego dostał posadę wozaka w miejscowym przedsiębiorstwie rybnym. Władysław Jaruzelski zmarł 4 czerwca 1942 w Bijsku i został pochowany na miejscowym cmentarzu. 19-letni Wojciech stał się jedynym opiekunem rodziny.
Kariera wojskowa.
II wojna światowa.
W maju 1943 został wezwany przez radziecką Wojskową Komendę Uzupełnień w Bijsku. Dostrzeżono w nim kandydata na oficera i nakazano czekać. Ponownie został wezwany 19 lipca tegoż roku. Dostał skierowanie do Szkoły Oficerskiej 1 Korpusu Sił Zbrojnych w Riazaniu. Nie był to zaciąg ochotniczy, lecz radziecki pobór do wojska. Został skierowany do I Batalionu Piechoty, dowodzonego przez kapitana nazwiskiem Kostriuko. Przydzielony do karabinów maszynowych (CKM typu Maxim). Nie przejawiał większego zainteresowania przedmiotami wojskowymi. Uzyskiwał przeciętne wyniki. Przysięga wojskowa miała miejsce w dniu 11 listopada, odbierał ją gen. bryg. Zygmunt Berling w obecności m.in. Wandy Wasilewskiej i Gieorgija Żukowa. Promocja miała miejsce 16 grudnia 1943. Promował gen. Berling. Jaruzelski na 296 promowanych zajął miejsce około 100. Według generała Zygmunta Huszczy prymusi (m.in. Florian Siwicki) byli mianowani na stopień podporucznika, a większość została, w tym Jaruzelski, mianowana na stopień chorążego. Po uzyskaniu promocji został skierowany na stanowisko dowódcy plutonu piechoty w składzie 8 Kompanii, III Batalionu, 5 Pułku, 2 Dywizji Piechoty im. Henryka Dąbrowskiego. Od 1943 do 1944 był dowódcą plutonu strzelców, w maju 1944 został przeniesiony do zwiadu, gdzie został dowódcą plutonu zwiadu konnego (dwunastoosobowa drużyna).
Wraz z pułkiem przeszedł szlak bojowy 1 Armii Wojska Polskiego. Udział w walkach rozpoczął w końcu lipca 1944, kilkanaście kilometrów od rodzinnego Kurowa, przy forsowaniu Wisły. Potem brał udział w walkach na przyczółku magnuszewskim i akcjach pomocy powstańczej Warszawie (w październiku 1944 został lekko ranny). 11 listopada 1944 został awansowany do stopnia podporucznika (Rozkaz Naczelnego Dowództwa WP nr 59) w korpusie kawalerii. We wniosku awansowym napisano: „(...) jeden ze zdolniejszych i śmielszych oficerów. (...) w okresie bojów wykazał żelazną dyscyplinę, wykonując szybko i dokładnie wydawane mu rozkazy. (...) Zachowanie wzorowe. Cieszy się autorytetem swych zwierzchników i podwładnych.”.
Do Warszawy oddział zwiadu na czele z Jaruzelskim wkraczał od strony Bielan, gdzie znajdowało się przedwojenne gimnazjum Jaruzelskiego. 19 stycznia 1945 wziął udział w defiladzie w gruzach zniszczonej Warszawy. Po zdobyciu Warszawy, 2 Dywizja Piechoty otrzymała nazwę Warszawska, a Jaruzelski otrzymał Srebrny Medal „Zasłużonym na Polu Chwały” (w uzasadnieniu wniosku o nadanie stwierdzono: „(...) doskonale wyszkolony i zdyscyplinowany, a także odważny zwiadowca. Niejednokrotnie kontrolując i kierując (...) akcjami zwiadowczymi batalionów wykazywał zimną krew i odwagę, osobiście wysuwając się w najbardziej niebezpieczne punkty obserwacyjne, dając przykład żołnierzom”). Od końca stycznia 1945 dowodził całością zwiadu pułku.
W lutym 1945 wraz z pułkiem walczył o przełamanie Wału Pomorskiego. Był kilkakrotnie wymieniany w rozkazach dowódcy dywizji jako zasłużony w walkach. Za likwidację granatami stanowiska niemieckiego ckm podczas akcji wywiadowczej w okolicach Borujska, został ponownie odznaczony Srebrnym Medalem „Zasłużonym na Polu Chwały”. Po raz trzeci został odznaczony tym medalem za marcowe walki pod Dziwnówkiem nad Morzem Bałtyckim. 15 marca brał udział w uroczystości zaślubin z morzem mających symbolizować przyłączenie tych terenów do państwa polskiego.
W połowie kwietnia 5 pp uczestniczył w forsowaniu Odry (14 kwietnia żołnierze pułku wbili słupy graniczne na Odrze). 22 kwietnia pułk dotarł do obozu koncentracyjnego w Sachsenhausen. 24 kwietnia 1945 Jaruzelski został mianowany rozkazem ND WP nr 217 na stopień porucznika w korpusie oficerów piechoty. We wniosku awansowym napisano: „(...) odważny i zdecydowany. Dzięki jego organizacji niejednokrotnie zwiady dawały pozytywne wyniki. Dobrze wyszkolony, inteligentny. Prezentuje się dobrze. W plutonach zwiadowczych, nad którymi utrzymuje kontrolę, panuje wysoka dyscyplina, której on osobiście też bacznie przestrzega”. 3 maja wraz z pułkiem dociera nad Łabę. Za walki na terenie Niemiec Jaruzelski został odznaczony Krzyżem Walecznych oraz Orderem Krzyża Grunwaldu III klasy (nadano 2 września 1945 za to, że „na czele grup zwiadowczych osobiście udawał się na wypady, w nocnych zwiadach sam kierował akcjami (...) W walkach pod Alt-Reetz i Wustrow pierwszy wpadł do okopów wroga i jeszcze przed nadejściem głównych sił zajął mocny i silnie broniony plac Darm [sic!]. Stale i wszędzie podczas bojów na swym stanowisku, nie zwracał uwagi na zmęczenie, gdy cały pułk odpoczywał, on szukał dalszych dróg, rozpoznawał teren.”).
Kapitulacja III Rzeszy zastała Jaruzelskiego wraz z 5 pp na północny wschód od miasta Nauen. Pułkowi nadano miano „Kołobrzeskiego” w uznaniu zasług w walkach na Pomorzu Zachodnim. W czerwcu Jaruzelski przebywał w zdobytym Berlinie. W drugiej połowie czerwca jego pułk został rozmieszczony w stolicy Łużyc – Chociebużu. 1 lipca przekroczył Nysę Łużycką, wracając do Polski.
Polska Ludowa.
Po przybyciu do Polski w związku z groźbą polsko-czechosłowackiego zatargu zbrojnego o granicę pułk, w którym służył Jaruzelski, otrzymał w dniu 5 lipca 1945 rozkaz bronienia 107-kilometrowego odcinka granicy polsko-czechosłowackiej od Raciborza do Racławic Śląskich (powiaty raciborski, głubczycki i prudnicki). Pułk stacjonował w Głubczycach. 3 sierpnia Wojciech Jaruzelski został komendantem wojskowym miasta. W dniu 9 września pułk po przekazaniu terenu nowo sformowanej 13 Dywizji Piechoty został skierowany do Częstochowy. W nowym miejscu 5 pp miał przede wszystkim prowadzić szkolenie bojowe. Jaruzelski miał odpowiadać za utrzymanie gotowości bojowej wyznaczonych pododdziałów alarmowych oraz organizację stałych patroli na szczeblu garnizonu.
Na przełomie października i listopada 1945 zapadła decyzja o wysłaniu 5 pp, w którym służył Jaruzelski, na teren powiatu hrubieszowskiego, by tam walczyć z Ukraińską Armią Powstańczą. Pułk dotarł na miejsce w dniu 14 listopada. W dniu 22 stycznia 1946 Jaruzelski został skierowany do Wyższej Szkoły Oficerskiej w Rembertowie, jednakże szef pułku zwrócił się o pozostawienie Jaruzelskiego na dotychczasowym stanowisku jako niezbędnego dla funkcjonowania pułku. Do zadań Jaruzelskiego należało przygotowywanie opracowań dotyczących działań UPA (przesłuchiwał jeńców ukraińskich) i podziemia antykomunistycznego oraz raportów o działaniach pułku przeciwko nim. Oddziały zwiadowcze pod dowództwem Jaruzelskiego brały również udział w akcji wysiedlania ludności ukraińskiej zamieszkującej powiat hrubieszowski na teren Ukrainy radzieckiej. 16 kwietnia 1946 Jaruzelski został wyznaczony na stanowisko przewodniczącego Wewnętrznej Komisji Kontroli w 5 pp. W dniu 2 maja tego samego roku został zatwierdzony na stanowisku II pomocnika szefa sztabu 5 pp ds. zwiadu. Został drugim zastępcą szefa sztabu pułku. 28 maja 1946 na czele grupy zwiadowczej 5 pp udał się do Hrubieszowa, gdzie poprzedniej nocy połączone siły Wolności i Niezawisłości oraz UPA zdobyły budynki starostwa oraz Urzędu Bezpieczeństwa i Polskiej Partii Robotniczej, a także rozstrzeliwały działaczy PPR. Za walki z „ukraińskimi bandami” Jaruzelski otrzymał Srebrny Krzyż Zasługi (został odznaczony podczas uroczystości państwowych 22 lipca 1946). W okresie czerwca 1946 oddziały podległe Jaruzelskiemu miały za zadanie ochraniać obwodowe komisje wyborcze powołane do celu przeprowadzenia referendum ludowego. 14 czerwca 1946 wyszedł z pułku wniosek o awans dla Jaruzelskiego na stopień kapitana (awansowany 22 lipca 1946).
10 lipca 1946 5 pp został skierowany do Piotrkowa Trybunalskiego. W lipcu 1946 został mianowany wojskowym komendantem miasta Piotrków Trybunalski. We wrześniu na odprawie oficerów pułku został wybrany na przewodniczącego Sądu Honorowego dla młodszych oficerów pułku. W swoich sprawozdaniach opisywał walki jednostek pułku z "bandami WiN", akcje represyjne i przeciwdziałające wpływom "reakcyjnego PSL" wśród ludności. W styczniu 1947 kpt. Jaruzelski został zastępcą przewodniczącego komisji wyborczej w wyborach sejmowych.
Według dokumentów znajdujących się w archiwach Instytutu Pamięci Narodowej współpracował od 23 marca 1946 jako agent informator z Informacją Wojskową pod pseudonimem „Wolski”. Współpraca została zakończona najprawdopodobniej w 1954, a na pewno przed 1955. Odmienną interpretację wydarzeń przedstawia Wojciech Jaruzelski: "(...) nie byłem w informacji wojskowej (...) natomiast ja zostałem posądzony o to, że byłem tajnym współpracownikiem, którego pozyskano do tej współpracy 23 marca ’46 r. Byłem wtedy chyba jeszcze kapitanem, czy porucznikiem nawet, było to w Hrubieszowie w czasie walk z podziemiem ukraińskim, krwawych walk. Ja byłem szefem zwiadu pułku i współpracowałem rzeczywiście i to było absolutnie zrozumiałe i konieczne z szefem kontrwywiadu pułku. I nie wiem skąd przeniesiono potem dalej tę formułę, bez żadnych podstaw..."
W 1947 Jaruzelski (w skierowaniu wpisano "Jarozelski") został wysłany w celu uzupełnienia edukacji wojskowej na kurs szefów sztabu dużych jednostek do Centrum Wyszkolenia Piechoty w Rembertowie, które ukończył z wynikiem bardzo dobrym. 30 listopada 1947 został skierowany do cyklu taktyki piechoty i służby sztabów na etat wykładowcy taktyki w Centrum Wyszkolenia Taktyki. Od 1 maja 1948 był wykładowcą taktyki i służby sztabów. Otrzymał etat podpułkownika. Szybko dał się poznać jako dobry wykładowca. W grudniu 1947 został wyróżniony premią 3000 zł za dobre przygotowanie i „zabezpieczenie materiałowe” ćwiczeń na kursach dowódców dywizji i pułków. Wybierany do licznych komisji w uczelni. Trafił np. do składu zarządu klubu oficerskiego, wybrany na kierownika działu pomocy społecznej. Powierzono mu opiekę nad zebraniem młodszych oficerów, które miało dokonać wyboru sądu polubownego.
10 lipca 1948 zarządzeniem prezydenta RP Bolesława Bieruta mianowany majorem, a już 25 stycznia 1949 podpułkownikiem.
21 lutego 1949 został przeniesiony do Dowództwa Wojsk Lądowych. Został wyznaczony przez szefa Dowództwa gen. Popławskiego na stanowisko szefa Wydziału Szkół i Kursów Oficerów Rezerwy Oddziału Szkół i Kursów Sztabu Wojsk Lądowych. Wydziałowi, którym kierował Jaruzelski, podlegały 2 wyższe szkoły oficerskie, 12 szkół oficerskich, 25 szkolnych kompanii oficerów rezerwy i 5 fakultetów wojskowych na uczelniach cywilnych. Na nowym stanowisku miał się zająć bezpośrednio pionem rezerw oficerskich. W dniu 11 października 1949 awansował na stanowisko szefa Wydziału Szkół Oficerskich i Podoficerskich Zawodowych oraz został pierwszym zastępcą szefa oddziału. Z pozycji nowego stanowiska współdecydował między innymi, jaka kategoria Polaków może ubiegać się o dostęp do uczelni wojskowych. O wysokiej randze Jaruzelskiego świadczy fakt, że dwukrotnie powierzono mu kierownictwo Dowództwem, gdy wyjeżdżał szef gen. Wiktor Sienicki. Jednego razu nawet mimo tego, że byli obecni szefowie działów. Gen. Popławski powierzył mu także wyszkolenie 30-osobowej grupy seminaryjnej szefów wydziałów z DWL. W związku ze zmianami w Wojsku Polskim przeprowadzonymi przez marszałka Konstantego Rokossowskiego, w dniu 1 marca 1950 Dowództwo Wojsk Lądowych przekształcono w Główny Zarząd Wyszkolenia Bojowego. Jaruzelski został wówczas mianowany szefem Wydziału Szkół i Kursów Oficerów Zawodowych. Wraz z płk. Pawluczenkowem objeżdżał garnizony wojskowe z inspekcjami. W tychże inspekcjach był zastępcą przewodniczącego komisji, na czele której stał wspominany Pawluczenko. Po raz pierwszy stanął samodzielnie na czele 20-osobowej komisji w dniach 12–17 marca 1951, kiedy przeprowadzał inspekcję Oficerskiej Szkoły Łączności Przewodowej w Sieradzu. W okresie od 1 października 1952 do 3 października 1953, jak wynika z informacji zawartych w personalnej teczce Jaruzelskiego, odbył kurs doskonalenia dowódców w Akademii Sztabu Generalnego (brak nazwiska na zachowanych listach słuchaczy kursów w ASG), który ukończył z wynikiem bardzo dobrym. W 1953 otrzymał propozycję objęcia stanowiska szefa sztabu korpusu lub starszego wykładowcy taktyki ogólnej i służby sztabów w Akademii Sztabu Generalnego. Z niewiadomych przyczyn nie przyjął propozycji. W dniu 3 października 1953 ponownie awansował, tym razem na stanowisko szefa Oddziału Akademii Wojskowych w Głównym Zarządzie Wyszkolenia Bojowego. Często brał udział w komisjach egzaminacyjnych w szkołach wojskowych.
31 grudnia 1953 mianowany na stopień pułkownika.
W marcu 1954 przewodniczył komisji mającej na celu przeprowadzenie kontroli pracy Akademii Sztabu Generalnego. W lipcu 1955 jako ekstern ukończył z wynikiem bardzo dobrym studia w Akademii Sztabu Generalnego. Było to zgodne z nauką radziecką, która dopuszczała, by szef instytucji nadrzędnej studiował eksternistycznie w podległej sobie uczelni. 14 listopada 1955 awansował na stanowisko szefa Zarządu Akademii Wojskowych, Szkół i Kursów Oficerskich.
14 lipca 1956 został mianowany na stopień generała brygady.
Nie wiadomo, jak zachowywał się Jaruzelski w czerwcu i październiku 1956. Jako jedyny polski generał opowiedział się za pozostaniem marszałka Konstantego Rokossowskiego w Wojsku Polskim.
7 marca 1957 został zastępcą szefa Głównego Zarządu Wyszkolenia Bojowego.
8 października 1957 objął stanowisko dowódcy 12 Dywizji Piechoty (od 24 listopada 1958 Dywizja Zmechanizowana) w Szczecinie. Zastąpił na tym miejscu płka Aleksandra Majtka. 6 listopada 1957 gen. Zygmunt Huszcza wyznaczył Jaruzelskiego na dowódcę garnizonu szczecińskiego. Tym samym Jaruzelski został w Szczecinie najwyższym i najważniejszym dowódcą. W 1958 gen. Huszcza polecił Jaruzelskiemu napisanie artykułu pt. "Organizacja marszu w przewidywaniu boju w spotkaniu z dywizją pancerną". Jaruzelski, wykręcając się nawałem pracy, polecił napisanie tego artykułu płk. Kwiatkowskiemu. Wynika z tego, że Jaruzelski nigdy nie czuł się dobrze jako teoretyk sztuki wojskowej i trudno znaleźć jakiś jego tekst z zagadnień myśli wojskowej. W maju 1959 po raz pierwszy w roli dowódcy dywizji wziął udział w ćwiczeniach wojskowych, współdziałając z 8 Dywizją Zmechanizowaną i 20 Dywizją Pancerną. W tym samym miesiącu odwiedzili dowodzoną przez Jaruzelskiego dywizję delegaci Chińskiej Armii Ludowo-Wyzwoleńczej. Wiedział o tej wizycie już dwa miesiące wcześniej i już w marcu wydał odpowiednie zarządzenia, dzięki czemu można było dopracować wszystkie szczegóły, łącznie z propagandą obrazującą przyjaźń polsko-chińską i proletariackie braterstwo broni. Zatem pomyślny przebieg wizyty wystawił dobre świadectwo Jaruzelskiemu, o którym dowiedziało się szybko Ministerstwo Obrony Narodowej i najwyższe kierownictwo partyjne. Na początku 1960 dywizja Jaruzelskiego została uznana za najlepszy związek taktyczny w WP. Jednakże surowa dyscyplina nie była możliwa do utrzymania na dłuższą metę. Już w pierwszym kwartale 1960 roku wskaźniki wykroczeń dyscyplinarnych pogorszyły się.
Rozkazem nr 06 z 12 stycznia 1960 ustanowił „Dyplom Honorowy Związku Taktycznego im. Armii Ludowej”, którym mieli być wynagradzani oficerowie i podoficerowie dywizji, którzy służyli w niej minimum 10 lat, prezentowali wysoki poziom moralny i przejawiali aktywność społeczno-ekonomiczną. Preferencje były jednoznaczne – postawa polityczna przed umiejętnościami.
13 lipca 1960 został awansowany na stopień generała dywizji.
Od 6 lutego 1965 do 11 kwietnia 1968 pełnił funkcję szefa Sztabu Generalnego WP. W latach 60. należał do grupy zaledwie 12 osób w Polsce, które posiadały wiedzę na temat przechowywania na terenie kraju sowieckiej broni atomowej (zadanie specjalne „Wisła”).
Od czerwca 1962 do kwietnia 1968 pełnił funkcję wiceministra obrony narodowej.
Od 11 kwietnia 1968 do 21 listopada 1983 był ministrem obrony narodowej.
22 listopada 1983 Rada Państwa mianowała go Naczelnym Dowódcą Sił Zbrojnych PRL na czas wojny.
Zawodową służbę wojskową zakończył 31 stycznia 1991.
Kariera polityczna w PRL.
Do Polskiej Partii Robotniczej wstąpił w czerwcu 1947. Od 15 grudnia 1948 członek Polskiej Zjednoczonej Partii Robotniczej. W latach 1950–1952 brał udział w zajęciach dwuletniego Wieczorowego Uniwersytetu Marksizmu-Leninizmu, który ukończył z oceną bardzo dobrą. Od 1 czerwca 1960 do lutego 1965 był szefem Głównego Zarządu Politycznego WP. Stanowisko to zaproponował gen. Jaruzelskiemu marsz. Marian Spychalski, odmawiając wyrażonej listownie przez gen. Jaruzelskiego prośbie o niepowoływanie go na to stanowisko ("... jestem szczerze zmartwiony ewentualnością odejścia z pionu liniowego w którym służę z wielkim zamiłowaniem od 17-stu lat. Nawet traktując takie odejście jako czasowe, muszę liczyć się z faktem, iż wyłączy mnie ono z właściwego rytmu problematyki bojowej, stwarzając tym samym poważne luki i zaległości)." Na nowym stanowisku został bezpośrednio podporządkowany sekretarzowi Komitetu Centralnego PZPR Ryszardowi Strzeleckiemu. Z racji pełnionej funkcji zasiadał w Zespole MON i Radzie Wojskowej MON. W wyborach z 1961 został z klucza partyjnego mianowany na posła z ziemi szczecińskiej, gdyż wcześniej dowodził dywizją w Szczecinie.
Od 15 czerwca 1964 do 19 lipca 1989 był członkiem KC PZPR. Od grudnia 1970 do grudnia 1971 był zastępcą członka, a od 11 grudnia 1971 do 19 lipca 1989 członkiem Biura Politycznego KC PZPR. Na IV Plenum KC PZPR 18 października 1981 został wybrany na I sekretarza KC PZPR (pełnił tę funkcję do 29 lipca 1989).
Marzec 1968.
W okresie 1967–1968 jako członek ścisłego kierownictwa resortu obrony aktywnie włączył się w organizację czystek "syjonistycznych" w wojsku (usunięcie z armii i degradacja oficerów pochodzenia żydowskiego, co było częścią antysemickich działań władz państwowych, których kulminacją były tzw. wydarzenia marcowe). Generał Jaruzelski twierdził, że akcję przeprowadzał Główny Zarząd Polityczny WP, a wśród oficerów zwolnionych z wojska „ani jeden (...) nie był pracownikiem Sztabu Generalnego, której to instytucji ja wówczas byłem szefem”. Pomimo tego żałował tego co się wtedy stało, albowiem to „ciemna, brudna karta najnowszej historii”. „Tamten czas ma jednak wiele płaszczyzn i uwarunkowań (...). Na różnych etapach różne były moje – i miejsce, i możliwości. Nie uchylam się jednak od krytycznej oceny tego na co mogłem mieć realny wpływ. Ubolewam z powodu symptomów i faktów, jakie „pełzały” w drugiej połowie lat pięćdziesiątych i w latach sześćdziesiątych. Rok 1967 to było w Wojsku wybuchowe apogeum. Po tzw. wojnie czerwcowej pojawił się w naszych siłach zbrojnych (...) szokujący sygnał strategiczno-profesjonalny. W warunkach antagonistycznie podzielonego wówczas świata nastąpiło obsesyjne wręcz uwrażliwienie na ochronę tajemnicy, problem lojalności oraz zagrożenia zaskakującą napaścią zwłaszcza z powietrza. (...) Powstała w skali kraju swoista psychoza, słynne określenie „piąta kolumna”, pożywka dla podejrzeń, inspiracja i pretekst do oskarżeń oraz różnych, niewątpliwie także preparowanych informacji, wreszcie polityczno-personalnych rozgrywek (...).” – stwierdził Jaruzelski.
Podległe mu jednostki WP brały udział w tłumieniu Praskiej Wiosny przez siły Układu Warszawskiego w ramach operacji „Dunaj”. W lutym 1969 z inicjatywy Jaruzelskiego odbyło się w Sztabie Generalnym WP sympozjum naukowe poświęcone interwencji w Czechosłowacji. W tym samym roku odznaczony najwyższym odznaczeniem PRL „Orderem Budowniczych Polski Ludowej”. Został wezwany na 2. miesięczny kurs strategiczno-operacyjny w Moskwie w Akademii Wojskowej im. Klimienta Woroszyłowa. Wraz z nim wyjechali m.in. generałowie: Tadeusz Tuczapski, Florian Siwicki i Wojciech Barański.
Grudzień 1970.
Wojciech Jaruzelski nadzorował także tłumienie wystąpień robotników w czasie wydarzeń grudnia 1970 na Wybrzeżu, piastował wówczas stanowisko ministra obrony narodowej. Z tego powodu zarzucano mu współodpowiedzialność za krwawe wydarzenia, do których wtedy doszło. Jaruzelski twierdził, iż rozkaz strzelania do robotników zapadł w najwyższym kierownictwie PZPR, do którego, jako zastępca członka Biura Politycznego KC PZPR, on wtedy nie należał i nie ponosi odpowiedzialności karnej za to, co się stało.
Nie protestował przeciwko decyzji o użyciu broni wobec demonstrantów, która zapadła na posiedzeniu Biura Politycznego KC PZPR 15 grudnia w Warszawie (był na nim obecny). Zdaniem krytyków gen. Jaruzelskiego, brak jego sprzeciwu i jednomyślność decyzyjna innych członków narady wskazują, iż w rzeczywistości decyzja o użyciu broni zapadła kolegialnie, zatem gen. Jaruzelski ponosi za tę decyzję współodpowiedzialność.
Uczestniczył także w przygotowaniach do pacyfikacji strajków na Wybrzeżu, wydając jako minister obrony narodowej liczne decyzje – 8 grudnia 1970 gen. Jaruzelski wydał rozkaz (rozkaz MON nr 8884/Oper.) "(...) w sprawie zasad współdziałania wojska i resortu spraw wewnętrznych w zakresie zwalczania wrogiej działalności (...)", który stanowił podstawę do kooperacji MON i Ministerstwa Spraw Wewnętrznych w tłumieniu robotniczych protestów w czasie wydarzeń grudnia 1970 i był jedną z przyczyn późniejszej masakry.
Także 14 grudnia 1970 o godz. 23:40 z polecenia gen. Jaruzelskiego szef Sztabu Generalnego WP wydał tajny szyfrogram nakazujący dowódcom okręgów wojskowych przeprowadzających akcję pacyfikacyjną na Wybrzeżu podjęcie działań w przypadku ewentualnego użycia wojsk do zadań specjalnych i faktycznie włączający siły zbrojne do konfliktu.
Jaruzelski po wydarzeniach grudniowych został wynagrodzony stanowiskiem zastępcy członka Biura Politycznego KC, a już w grudniu 1971 dotarł na szczyt hierarchii partyjnej na stanowisko członka Biura Politycznego KC.
W latach 70. Wojciechowi Jaruzelskiemu planowano nadać stopień marszałka Polski. Zamierzenia takie przewijały się na szczycie władz partyjno-państwowych. Z różnych względów oraz z racji niechęci do tego samego Wojciecha Jaruzelskiego, zamierzenia te nie zostały zrealizowane.
Działalność polityczna w latach 1980–1981. Stan wojenny.
Po rozpoczęciu strajków w lipcu i sierpniu 1980 Wojciech Jaruzelski jako członek BP wszedł w skład specjalnej kilkuosobowej komisji wewnątrzpartyjnej, która miała zaproponować zmiany w składzie władz partii, co świadczyło o jego rosnącym znaczeniu politycznym. W połowie sierpnia Edward Gierek zaproponował jego kandydaturę (jako jedną z trzech obok Stefana Olszowskiego i Stanisława Kani) jako odpowiednią na swojego następcę na stanowisku I sekretarza KC PZPR. Generał odmówił, argumentując, że w czasie, gdy społeczeństwo oczekuje zmian w kierunku demokratyzacji, wybór wojskowego na tę funkcję mógłby zostać odczytany jako symbol zanegowania tej tendencji. Jego kandydatura na funkcję I sekretarza została ponownie wysunięta (przez Stanisława Kanię) po odejściu ze stanowiska Edwarda Gierka we wrześniu 1980. Generał ponownie odmówił. Jednocześnie poparł kandydaturę Stanisława Kani. Kania w tym okresie konsultował z generałem wszystkie wystąpienia publiczne i posunięcia kadrowe.
Już od sierpnia 1980 rozpoczął prace studyjne nad wprowadzeniem stanu wojennego w Polsce, prowadzone w ramach Komitetu Obrony Kraju i Sztabu Generalnego Wojska Polskiego. 12 listopada 1980, dwa dni po oficjalnej rejestracji Niezależnego Samorządnego Związku Zawodowego „Solidarność”, ujawnił na posiedzeniu KOK-u, że przygotowany został "zestaw niezbędnych aktów prawnych dotyczących stanu wojennego". 1 grudnia władze Związku Radzieckiego przekazały polskim wojskowym plany wkroczenia wojsk radzieckich do Polski w ramach ćwiczeń "Sojuz 81". Gotowość operacyjną do przekroczenia granicy wyznaczono na 8 grudnia.
11 lutego 1981 gen. Jaruzelski objął stanowisko Prezesa Rady Ministrów. Nominacja ta nastąpiła pod osobistym naciskiem ze strony ówczesnego I sekretarza PZPR Stanisława Kani przy niechęci gen. Jaruzelskiego. Na IV plenum KC PZPR obradującym w dniach 16–18 października, po ustąpieniu Stanisława Kani, Wojciech Jaruzelski został I sekretarzem KC PZPR. Otrzymał, w głosowaniu tajnym, 180 głosów za i 4 przeciw. Od października 1981 do końca lat 80. dziennikarz Wiesław Górnicki był ghostwriterem Jaruzelskiego: napisał wystąpienia ogłaszające stan wojenny, redagował przemówienia i dostarczał notatki, jak komentować wydarzenia.
5 grudnia na szczycie państw Układu Warszawskiego w Moskwie gen. Wojciech Jaruzelski przedstawił koncepcję samodzielnego zlikwidowania „Solidarności” i opozycji, gdy tylko wystąpią pierwsze oznaki wyczerpania społeczeństwa. 13 grudnia 1981 wprowadził w Polsce stan wojenny i stanął na czele Wojskowej Rady Ocalenia Narodowego (WRON) i pozostawał na tym stanowisku do 21 lipca 1983.
Wzmocnienie pozycji politycznej gen. Jaruzelskiego w wyniku stanu wojennego posłużyło mu do wprowadzenia polityki kadrowej „cięcia po skrzydłach”, polegającej na odsuwaniu od władzy w PZPR przedstawicieli skrajnych frakcji: liberalnej i dogmatycznej (już na początku stycznia 1982 usunięto z funkcji partyjnych I sekretarzy PZPR w Gdańsku i Katowicach: Tadeusza Fiszbacha i Andrzeja Żabińskiego). Jednocześnie rozpoczął się stopniowy proces utraty wpływów przez działaczy inspirowanych przez czynniki radzieckie.
W stanie wojennym rząd gen. Jaruzelskiego zrealizował wiele reform instytucjonalnych. Powołano wówczas Trybunał Stanu, uchwalono nową ustawę o szkolnictwie wyższym rozszerzającą samodzielność wyższych uczelni, wprowadzono samorząd radców prawnych (ustawa z 6 lipca 1982), a także wprowadzono w życie nową ustawę o radach narodowych i samorządzie terytorialnym, przywracając pojęcie samorządu terytorialnego mimo sprzeciwów zwolenników teorii jednolitości władzy państwowej.
Nie zdecydował się na realizację koncepcji jednego ze swoich najbliższych współpracowników Mieczysława Rakowskiego – rozwiązania PZPR lub jej zawieszenia na czas trwania stanu wojennego. Na początku lutego 1982 zwołał posiedzenie KC PZPR, gdzie rzucił hasło: „Partia ta sama, ale nie taka sama”.
W lutym 1992 Sejm przeważającą liczbą głosów podjął uchwałę, w której uznał decyzję o wprowadzeniu stanu wojennego za sprzeczną z konstytucją PRL. Powołano specjalną komisję do przesłuchania ówczesnych członków Rady Państwa, po roku parlament został jednak rozwiązany, a przejmujące wówczas władzę Sojusz Lewicy Demokratycznej i Polskie Stronnictwo Ludowe zrezygnowały z kontynuacji śledztwa parlamentarnego. Jaruzelskiego doceniono, zapraszając go na pierwsze posiedzenie Sejmu II kadencji. W 1996 Komisja Odpowiedzialności Konstytucyjnej, gromadząca dokumenty dotyczące stanu wojennego, uznała, że wprowadzenie stanu wojennego było „wyższą koniecznością”, sejm umorzył postępowanie wobec Jaruzelskiego, podzielając opinię tej komisji.
Jedna z osób represjonowanych w okresie stanu wojennego, działacz chłopski Stanisław Helski, uderzył Jaruzelskiego kamieniem w twarz podczas spotkania 11 października 1994, na którym promował on swą książkę w księgarni na placu Legionów we Wrocławiu.
Od 1993, w rocznicę ogłoszenia stanu wojennego, przed domem Wojciecha Jaruzelskiego (przy ul. Ikara na warszawskim Mokotowie) odbywały się demonstracje przeciwników wprowadzenia stanu wojennego. 13 grudnia 2003 po raz pierwszy uczestniczyli w manifestacji również zwolennicy Jaruzelskiego, którzy podziękowali mu za decyzję o wprowadzeniu stanu wojennego. Po raz pierwszy Jaruzelski wyszedł do demonstrujących, dziękując im za wyrazy poparcia i zagrzewając do dalszej walki „na froncie ideologicznym i edukacyjnym”. Podkreślił, iż „gdyby nie stan wojenny z 13 grudnia 1981, nie byłoby 13 grudnia w Kopenhadze i w Brukseli”.
Działalność polityczna w latach 1982–1989.
W latach 1961–1989 był posłem na Sejm PRL III, IV, V, VI, VII, VIII i IX kadencji. Od 11 lutego 1981 do 6 listopada 1985 był prezesem Rady Ministrów. Współtworzył Patriotyczny Ruch Odrodzenia Narodowego, w 1982 był członkiem Prezydium Tymczasowej Rady Krajowej tej organizacji. 22 listopada 1983 został powołany przez Sejm na przewodniczącego Komitetu Obrony Kraju – zwierzchnika Sił Zbrojnych, a przez Radę Państwa mianowany naczelnym dowódcą Sił Zbrojnych na wypadek wojny. 2 września 1982 stanął na czele Komitetu Honorowego uroczystości żałobnych Władysława Gomułki.
W latach osiemdziesiątych inicjował reformy gospodarcze i instytucjonalne (np. powołanie Trybunału Stanu (1982), Rzecznika Praw Obywatelskich (1985) czy Naczelnego Sądu Administracyjnego). Był twórcą Rady Konsultacyjnej przy Przewodniczącym Rady Państwa, która rozpoczęła działalność w grudniu 1986. W skład Rady wchodzili m.in. przedstawiciele frakcji liberalnej we władzach, katolików świeckich, a także ludzie kultury. Uczestnictwo w Radzie zaproponowano też Lechowi Wałęsie. Już wtedy gen. Jaruzelski brał pod uwagę możliwość budowy koncesjonowanej opozycji w oparciu o środowiska katolików świeckich oraz wykorzystania hierarchii kościelnej jako gwaranta „niekonfrontacyjności” tego procesu.
Po amnestii we wrześniu 1986 ekipa gen. Jaruzelskiego rozpoczęła formułowanie koncepcji generalnej reformy państwa, w której było miejsce na pluralizm społeczny, ograniczony pluralizm polityczny, na rynkową reformę gospodarki i uczynienie z sektora prywatnego istotnego jej elementu.
Próby przemian gospodarczych spaliły na panewce (klęska w referendum z 1987).
Jako I sekretarz KC PZPR wprowadził regularne częste posiedzenia Biura Politycznego z wykorzystaniem wiedzy ekspertów, podczas których ściśle przestrzegano zasady swobody dyskusji. Według Komisji Odpowiedzialności Konstytucyjnej pracującej do 1994 Wojciech Jaruzelski wraz z Czesławem Kiszczakiem mieli w 1989 wydać polecenie zniszczenia stenogramów posiedzeń Biura Politycznego KC PZPR. Na początku lat 90. toczyło się w tej sprawie postępowanie. Później zostało umorzone ze względów formalnych.
W latach 80. następował powrót do tradycyjnych motywów historycznych w działaniach władz. W 1982 kompania honorowa zaczęła używać w umundurowaniu rogatywki wzoru z 1935 roku. Od tegoż 1982 roku uroczyście obchodzono kolejne rocznice 3 Maja. W 1987 oficjalne warty wojskowe pojawiły się na Cmentarzu Powązkowskim przed grobami poległych w 1920 i pomordowanych w Katyniu. Pod koniec czerwca 1988, na wniosek kilku wdów po zamordowanych oficerach, zgłoszony pod adresem ówczesnego I sekretarza KC PZPR gen. Wojciecha Jaruzelskiego, zorganizowano ich przyjazd do Katynia. Relacja z tej podróży ukazała się w gazecie „Rzeczpospolita” z 1 lipca 1988. Była to pierwsza organizowana przez władze polskie wizyta rodzin pomordowanych na miejscu zbrodni w Katyniu. W lipcu 1988 do Związku Radzieckiego, w związku z uroczystościami 45-lecia powstania ludowego Wojska Polskiego, udała się do Katynia grupa kapelanów WP, która złożyła wieńce na mogiłach pomordowanych i odprawiła tam mszę. W kwietniu 1989 delegacja Rady Ochrony Pamięci Walk i Męczeństwa pod przewodnictwem gen. Romana Paszkowskiego wraz z grupą rodzin ofiar zbrodni pobrała w Katyniu urnę z prochami, która potem została uroczyście złożona w Grobie Nieznanego Żołnierza w Warszawie oraz w Dolince Katyńskiej.
Przewodniczący Rady Państwa i prezydent PRL.
6 listopada 1985 został powołany przez Sejm na przewodniczącego Rady Państwa. Funkcję tę sprawował aż do czasu zastąpienia Rady Państwa urzędem Prezydenta Polskiej Rzeczypospolitej Ludowej 19 lipca 1989.
Był głównym animatorem Okrągłego Stołu, choć nie uczestniczył w jego obradach. Nie kandydował też w przegranych przez komunistów wyborach do Sejmu X kadencji. W czerwcu 1989 przebywał z wizytą w Wielkiej Brytanii, a w tym czasie Rada Narodowa Rzeczypospolitej Polskiej w rezolucji przyjętej 10 czerwca 1989 na posiedzeniu otwierającym VIII kadencję oświadczyła, że Wojciech Jaruzelski "nie ma żadnego prawa do reprezentowania narodu polskiego".
24 września 1985 Jaruzelski spotkał się z Davidem Rockefellerem w Nowym Jorku w obecności Zbigniewa Brzezińskiego. Omówione zostały inwestycja Rockefellera w rolnictwo i działalność Fundacji Rockefeller w Polsce.
III Rzeczpospolita.
Prezydent Rzeczypospolitej Polskiej.
3 lipca 1989 Adam Michnik opublikował na łamach „Gazety Wyborczej” artykuł zatytułowany "Wasz prezydent, nasz premier", gdzie pośrednio odniósł się do kontraktu zawartego przy Okrągłym Stole, gdy obie strony zgodziły się na ustanowienie urzędu prezydenta PRL.
Jeszcze 30 czerwca w obliczu demonstracji antykomunistycznej, jaka przeszła ulicami Warszawy pod hasłem "Jaruzelski-musisz odejść" (demonstracja ta została rozpędzona przez milicję), Wojciech Jaruzelski, przemawiając na XIII Plenum KC PZPR, oświadczył, że wycofuje swoją kandydaturę i zaproponował na najwyższy urząd w państwie Czesława Kiszczaka. Dopiero 18 lipca zgodził się ponownie kandydować na ten urząd, uzyskawszy poparcie NSZZ „Solidarność”.
6 lipca 1989 „Gazeta Wyborcza” przeprowadziła sondaż, w którym ankietowani typowali swoich najlepszych kandydatów na stanowisko prezesa Rady Ministrów i prezydenta PRL. Próba wynosiła ponad 1000 osób, w 31 miastach. Na urząd prezydenta PRL najwięcej osób typowało Wojciecha Jaruzelskiego, a następni byli kolejno: Lech Wałęsa, Bronisław Geremek, Czesław Kiszczak, Aleksander Gieysztor i Mieczysław Rakowski. 54% badanych nie miało zdania w tej kwestii. Na urząd premiera najwięcej osób wytypowało Mieczysława Rakowskiego, a następni byli kolejno: Bronisław Geremek, Witold Trzeciakowski, Ryszard Bugaj, Jacek Kuroń, Lech Wałęsa, Ireneusz Sekuła, Władysław Baka, Aleksander Kwaśniewski, Czesław Kiszczak i Adam Michnik. 61% nie miało zdania w tej kwestii.
W dniach 9–11 lipca 1989 przyjął goszczącego w Polsce z oficjalną wizytą prezydenta Stanów Zjednoczonych George’a H. Busha.
Od 3 aż do 19 lipca Konfederacja Polski Niepodległej zorganizowała pikietę pod gmachem parlamentu (tym razem interwencja Zmotoryzowanych Odwodów MO okazała się nieudolna) oraz mniejsze demonstracje m.in. w Krakowie, Katowicach, Lublinie, Białymstoku, Kielcach, Opolu, Radomiu i Toruniu, sprzeciwiając się wyborowi Jaruzelskiego na prezydenta.
19 lipca 1989 Jaruzelski został jednak prezydentem PRL (a od 31 grudnia 1989 prezydentem Rzeczypospolitej Polskiej), wybranym przez Zgromadzenie Narodowe przewagą dwóch głosów (wybór poparło 270 spośród 537 biorących udział w głosowaniu członków ZN; do wyboru była potrzebna większość bezwzględna, czyli 269 głosów) na 6-letnią kadencję. O jego wyborze zdecydowała postawa posłów i senatorów wybranych z list „Solidarności”. Popierał reformy rządu Tadeusza Mazowieckiego.
13 kwietnia 1990 podczas oficjalnej wizyty w Związku Radzieckim otrzymał od Michaiła Gorbaczowa kopie dokumentów dotyczących zbrodni katyńskiej z 1940.
19 września 1990 przesłał do marszałka Sejmu Mikołaja Kozakiewicza projekt ustawy konstytucyjnej skracający jego kadencję oraz wprowadzający do porządku konstytucyjnego wybory powszechne prezydenta RP.
Z chwilą objęcia urzędu przez nowo wybranego prezydenta elekta Lecha Wałęsy 22 grudnia 1990 na mocy art. 2 "Ustawy z dnia 27 września 1990 o zmianie Konstytucji Rzeczypospolitej Polskiej" wygasła kadencja prezydenta Wojciecha Jaruzelskiego.
Działalność po prezydenturze.
Po 1990 wycofał się z życia politycznego, choć brał udział w debatach społecznych i politycznych (wypowiadał się m.in. na temat członkostwa Polski w Unii Europejskiej).
Jako były prezydent RP, zgodnie z ustawą o uposażeniu byłych prezydentów z 1996, Jaruzelski objęty był dożywotnią ochroną osobistą Biura Ochrony Rządu. Z urzędu przysługiwała mu także emerytura prezydencka, jednak nie pobierał pensji byłego prezydenta, decydując się na pozostanie przy generalskiej. Przysługiwały mu również pieniądze na prowadzenie biura oraz prawo do korzystania z lecznic państwowych.
9 maja 2005 na zaproszenie prezydenta RP Aleksandra Kwaśniewskiego wziął udział w delegacji państwowej na uroczystości z okazji 60. rocznicy zakończenia II wojny światowej w Moskwie. Został tam odznaczony przez prezydenta Federacji Rosyjskiej Władimira Putina Medalem 60-lecia Zwycięstwa w Wielkiej Wojnie Ojczyźnianej. Ceremonia odbyła się podczas przyjęcia, wydanego na Kremlu przez rosyjskiego prezydenta. Przeciw odznaczeniu Jaruzelskiego tym medalem zaprotestował wówczas prezydent Czech Václav Klaus, przypominając rolę generała w trakcie interwencji w Czechosłowacji w 1968.
W czerwcu 2008 przyznano mu honorowe członkostwo w partii Racja Polskiej Lewicy (rozwiązanej w 2013). W latach 2001–2013 publikował w tygodniku „Przegląd”.
W 2010 przyjął zaproszenie rosyjskie na uroczystości z okazji 65. rocznicy zakończenia II wojny światowej w Moskwie. W związku z tym został zaproszony do składu delegacji polskiej przez prezydenta RP Lecha Kaczyńskiego, przy tym prezydencki minister Paweł Wypych podkreślił, że Lech Kaczyński bardzo negatywnie ocenia działalność gen. Jaruzelskiego w latach PRL, jednak był on kombatantem podczas wojny i demokratycznie wybranym prezydentem Polski, w związku z tym szacunek wydaje się być oczywisty. Po śmierci prezydenta Kaczyńskiego w katastrofie smoleńskiej, 9 maja 2010 Jaruzelski wziął udział w delegacji państwowej na uroczystości rocznicy zakończenia wojny na zaproszenie wykonującego obowiązki prezydenta RP Bronisława Komorowskiego. Spotkał się m.in. z prezydentem Federacji Rosyjskiej Dmitrijem Miedwiediewem oraz odwiedził miejsce katastrofy smoleńskiej i cmentarz w Katyniu.
24 listopada 2010, na zaproszenie prezydenta RP Bronisława Komorowskiego, wziął udział w Pałacu Prezydenckim w posiedzeniu Rady Bezpieczeństwa Narodowego.
W marcu 2011 u Wojciecha Jaruzelskiego zdiagnozowano chłoniaka (nowotwór złośliwy) po tym, jak dwa tygodnie wcześniej trafił do szpitala z powodu infekcji układu oddechowego i wysokiej gorączki. Pod koniec marca został ponownie przyjęty do szpitala, gdzie przeszedł tygodniowy zabieg chemioterapii. Ponieważ nowotwór w organizmie Jaruzelskiego bardzo szybko się rozwijał, jego stan zdrowia znacznie się pogorszył, mocno go osłabiając i odbierając nadzieję na wyzdrowienie.
11 maja 2014 gen. Wojciech Jaruzelski przeszedł rozległy udar mózgu, wskutek którego został częściowo sparaliżowany i utracił zdolność samodzielnego oddychania.
Zmarł 25 maja 2014 o godz. 15:24 w Warszawie, a krótko przed śmiercią wyspowiadał się oraz przyjął katolickie sakramenty, mimo deklarowania się przez większość życia jako ateista. Zwłoki zostały skremowane.
Pogrzeb.
Kancelaria Prezydenta RP zwróciła się do rodziny zmarłego z propozycją zorganizowania pogrzebu państwowego z honorami. Rodzina propozycję Kancelarii przyjęła. Prezydent Warszawy Hanna Gronkiewicz-Waltz zgodziła się na pochówek prochów generała na cmentarzu na Powązkach i w imieniu miasta nieodpłatnie przekazała kwaterę na ten cel.
Przeciwko organizacji państwowego pogrzebu i pochówku na Powązkach zaprotestował prezes Instytutu Pamięci Narodowej Łukasz Kamiński, który oświadczył, że "nie można pogodzić pamięci o ofiarach systemu totalitarnego z honorowaniem pogrzebem państwowym na Cmentarzu Wojskowym na Powązkach człowieka, który poświęcił większość swojego życia służbie reżimowi komunistycznemu". Sprzeciw wobec decyzji władz wyrazili również niektórzy działacze opozycji demokratycznej oraz rodziny ofiar stanu wojennego.
Pogrzeb odbył się 30 maja 2014. Mszę św. żałobną w katedrze polowej Wojska Polskiego w Warszawie odprawił bp polowy Wojska Polskiego ks. Józef Guzdek wraz z księżmi Adamem Bonieckim oraz Wojciechem Lemańskim i Wojciechem Drozdowiczem z Bielan. Urna z prochami zmarłego nie była obecna w świątyni. Oprócz najbliższej rodziny zmarłego żony Barbary i córki Moniki obecni byli m.in. prezydent RP Bronisław Komorowski, a także byli prezydenci Lech Wałęsa i Aleksander Kwaśniewski. W trakcie mszy pogrzebowej na placu przed katedrą demonstranci rozwinęli portrety i plakaty przypominające ofiary stanu wojennego.
Po nabożeństwie na Cmentarzu Wojskowym na Powązkach odbył się pogrzeb świecki z udziałem honorowej asysty wojskowej (kwatera C6-tuje-5). Przemarszowi konduktu pogrzebowego towarzyszyły okrzyki i gwizdy niektórych demonstrantów. Nad grobem przemówienie wygłosił Aleksander Kwaśniewski. Władze RP reprezentował minister w Kancelarii Prezydenta RP prof. Tomasz Nałęcz oraz minister obrony narodowej Tomasz Siemoniak. Na pogrzeb przybyli: część posłów Sojuszu Lewicy Demokratycznej, działacz polityczny Adam Michnik oraz najbliżsi współpracownicy Jaruzelskiego z lat 80.: były szef MSW Czesław Kiszczak oraz były rzecznik prasowy rządu Jerzy Urban, a także ambasador Rosji w Polsce Aleksandr Aleksiejew. Urnę z prochami złożono w kwaterze 1 Armii Wojska Polskiego. Grób był stale monitorowany i strzeżony przez policję.
Życie prywatne.
Żoną Wojciecha Jaruzelskiego była od 1960 Barbara Jaruzelska (ślub wzięli w Szczecinie), doktor filologii germańskiej Uniwersytetu Warszawskiego. Mieli córkę Monikę oraz wnuka Gustawa.
Tablice genealogiczne rodu Jaruzelskich herbu Ślepowron.
Procesy karne.
Wojciech Jaruzelski, jako stojący na czele utworzonej w nocy z 12 na 13 grudnia 1981 Wojskowej Rady Ocalenia Narodowego, został oskarżony o:
Postępowanie sądowe rozpoczęło się w marcu 2008. Akt oskarżenia nie został odczytany, gdyż sąd w maju 2008 nakazał prokuratorowi z IPN-u uzupełnienie materiału dowodowego m.in. o przesłuchanie świadków Margaret Thatcher i Michaiła Gorbaczowa.
Był również oskarżony w procesie o „sprawstwo kierownicze” masakry robotników Wybrzeża w grudniu 1970.
Ocena.
Według badania przeprowadzonego przez Centrum Badań Opinii Społecznej w 2014, już po śmierci Wojciecha Jaruzelskiego, 47% badanych przyznało, że generał dobrze zasłużył się Polsce.
Odznaczenia.
Polskie.
W sierpniu 1999 odznaczony medalem „Cztery Wieki Stołeczności Warszawy”. Wręczył go ówczesny wiceprezydent miasta Jacek Zdrojewski. 21 grudnia 1999 gen. Wojciech Jaruzelski zwrócił medal otrzymany w sierpniu po wiadomości prasowej informującej, że prezydent Warszawy Paweł Piskorski nie podtrzymałby tej decyzji, gdyby był o niej poinformowany. W liście do prezydenta miasta gen. Wojciech Jaruzelski napisał m.in.:
26 marca 2006 gen. Wojciech Jaruzelski został odznaczony przez prezydenta RP Lecha Kaczyńskiego Krzyżem Zesłańców Sybiru. Komentując ten fakt, stwierdził, że cieszy się, iż prezydent Kaczyński wzniósł się ponad historyczne podziały. Po ujawnieniu tego faktu przez TVN Kancelaria Prezydenta oświadczyła, że gen. Wojciech Jaruzelski został odznaczony przez pomyłkę, gdyż "Prezydent akceptował tylko postanowienia, nie zaś listy osób" i nie zdawał sobie sprawy, że na liście występuje Wojciech Jaruzelski. Po tym oświadczeniu gen. Wojciech Jaruzelski odesłał otrzymane odznaczenie prezydentowi Lechowi Kaczyńskiemu.
Wojciech Jaruzelski w filmie i teatrze.
Wojciechowi Jaruzelskiemu poświęcono filmy dokumentalne. W 2011 powstała sztuka teatralna pt. "Generał" autorstwa Jarosława Jakubowskiego.

</doc>
<doc id="12976" url="https://pl.wikipedia.org/wiki?curid=12976" title="Silnik spalinowy tłokowy">
Silnik spalinowy tłokowy

Silnik spalinowy tłokowy – silnik cieplny o spalaniu wewnętrznym, w którym energia uzyskana w wyniku spalania paliwa zamieniana jest w energię mechaniczną. Spalanie mieszanki odbywa się w komorze spalania. Skonstruowanie pierwszego spalinowego silnika tłokowego datuje się na 1860 rok, jego konstruktorem był Étienne Lenoir.
Klasyfikacja silników tłokowych.
Ze względu na sposób zapłonu, który także decyduje o rodzaju użytego paliwa, silniki spalinowe dzielą się na:
Ze względu na rodzaj ruchu organu roboczego silniki spalinowe dzielą się na:
Ze względu na układ cylindrów silniki spalinowe dzielą się na:
Ze względu na liczbę suwów w cyklu roboczym silniki spalinowe dzielą się na:
Parametry pracy i charakterystyki silników spalinowych tłokowych.
Parametry pracy.
Charakterystyki silnika spalinowego są graficznym przedstawieniem zależności niektórych parametrów pracy silnika w zależności od prędkości obrotowej wału w całym zakresie pracy silnika.
Parametry konstrukcyjne.
Do ważnych parametrów konstrukcyjnych silnika spalinowego wpływających zasadniczo na charakterystyki silnika są:
Średnia prędkość tłoka – decyduje o szybkobieżności silnika.
Współczynnik kształtu cylindra. Wyraża się jako stosunek skoku tłoka do średnicy cylindra. Silnik może być krótkoskokowy, jak i długoskokowy. Decyduje o średniej prędkości tłoka i (pośrednio) o liczbie zaworów, jakie można umieścić w jednym cylindrze.
Stopień sprężania. Jest to najistotniejszy parametr konstrukcyjny silnika. Wyraża się jako stosunek objętości komory roboczej w najwyższym i najniższym skrajnym położeniu tłoka. Im większy stopień sprężania, tym wyższa wydajność energetyczna silnika.
Do najważniejszych parametrów silnika spalinowego należą:

</doc>
<doc id="12977" url="https://pl.wikipedia.org/wiki?curid=12977" title="ORP Mazur">
ORP Mazur

ORP „Mazur” – nazwa noszona na przestrzeni dziejów przez okręty polskiej Marynarki Wojennej. Pochodzi od określenia ludności zamieszkującej Mazury:

</doc>
<doc id="12979" url="https://pl.wikipedia.org/wiki?curid=12979" title="Opera seria">
Opera seria

Opera seria, czyli opera poważna – jeden z dwóch podstawowych gatunków opery, obok opery komicznej. Jej powstanie jest związane z ośrodkiem szkoły neapolitańskiej. W operze seria muzyka dominuje nad słowem, zawiera ona liczne arie, pieśniowe cavatiny, ensemble, chóry.
Do czasów Mozarta opera seria miała ścisłe kanony budowy, takie jak zasada równomiernego rozmieszczania arii i forma owych arii, umieszczanie fragmentów baletowych, odpowiednio zbudowane wątki fabularne i postacie. W późniejszym okresie kompozytorzy zaczęli pozwalać sobie na większą swobodę, np. w operze "Don Giovanni" Mozart połączył kanony komiczne z poważnymi i sam umieścił to dzieło w katalogu oper buffa.
Poza operą seria i dramma giocoso formą pośrednią jest opera semiseria (opera półpoważna), której przykładem jest "Sroka złodziejka" Rossiniego.
Opera seria w muzyce polskiej.
Pierwszą znaną polską operą poważną są "Ruiny Babilonu" Karola Kurpińskiego, najbardziej znane to jednak "Halka" i "Straszny dwór" Stanisława Moniuszki. Za najwybitniejsze opery seria w Polsce uważa się dzieła Karola Szymanowskiego ("Król Roger") i Krzysztofa Pendereckiego ("Diabły z Loudun").

</doc>
<doc id="12981" url="https://pl.wikipedia.org/wiki?curid=12981" title="RPG (język programowania)">
RPG (język programowania)

RPG (ang.: "Report Program Generator") – jeden z kilku języków programowania pierwotnie używanych na komputerach wyposażonych w czytniki kart perforowanych, lecz wciąż pozostający w użyciu. RPG został zaprojektowany w IBM dla systemów klasy "mainframe", w szczególności dla słynnej rodziny maszyn System/390 (gdzie używano RPG2).
Kolejna wersja – RPG3 była używana na maszynach System/36, a na będących ich następcami maszynach AS/400 używany był RPG/400 ze znacznie poprawioną składnią oraz lepszą obsługą plików i baz danych. Język ten był podstawą programowania na AS/400 mimo bardzo prostego edytora liniowego.
RPG3 wyewoluował w RPG4, w którym usunięto składniowe pozostałości z epoki kart perforowanych.
RPG jest nadal użytkowany i rozwijany na kolejnych generacjach maszyn AS/400 (nazywanych obecnie iSeries) pod ich systemem OS/400 (nazywanym obecnie i5/OS).

</doc>
<doc id="12982" url="https://pl.wikipedia.org/wiki?curid=12982" title="Euterpe (mitologia)">
Euterpe (mitologia)

Euterpe („Radosna”; gr. Eutérpē ‘dobrze się ciesząca’, łac. Euterpe) – w mitologii greckiej muza poezji lirycznej i gry na aulosie.
Uchodziła za córkę boga Zeusa i tytanidy Mnemosyne oraz za siostrę: Erato, Kalliope, Klio, Melpomene, Polihymnii, Talii, Terpsychory i Uranii. Według jednej z wersji miała z bogiem Strymonem syna Resosa.
Była jedną spośród dziewięciu muz olimpijskich (przebywały na Olimpie), które należały do orszaku Apollina (Apollon Musagetes), ich przewodnika. Wraz ze swoimi siostrami uświetniała śpiewem biesiady bosko-ludzkie (m.in. zaślubiny Tetydy i Peleusa oraz Harmonii i Kadmosa), a także uczty olimpijskie samych bogów.
W sztuce przedstawiana jest zwykle jako kobieta z aulosem (lub fletem) – atrybutem symbolizującym dziedzinę sztuki, której patronowała.
Imieniem muzy nazwano jedną z planetoid – (27) Euterpe oraz rodzaj palm z rodziny arekowatych – euterpa ("Euterpe").

</doc>
<doc id="12983" url="https://pl.wikipedia.org/wiki?curid=12983" title="Erato (muza)">
Erato (muza)

Erato („Umiłowana”, „Ukochana”, gr. Eratṓ, łac. Erato ‘Pożądana’, ‘Namiętna’) – w mitologii greckiej muza poezji miłosnej.
Uchodziła za córkę boga Zeusa i tytanidy Mnemosyne oraz za siostrę: Euterpe, Kalliope, Klio, Melpomene, Polihymnii, Talii, Terpsychory i Uranii.
Była jedną spośród dziewięciu muz olimpijskich (przebywały na Olimpie), które należały do orszaku Apollina (Apollon Musagetes), ich przewodnika. Wraz ze swoimi siostrami uświetniała śpiewem biesiady bosko-ludzkie (m.in. zaślubiny Tetydy i Peleusa oraz Harmonii i Kadmosa), a także uczty olimpijskie samych bogów.
W sztuce przedstawiana jest zwykle jako kobieta z kitarą (lub cytrą) – atrybutem symbolizującym dziedzinę sztuki, której patronowała.
Imieniem muzy nazwano jedną z planetoid – (62) Erato oraz rodzaj roślin z rodziny astrowatych – "Erato".

</doc>
<doc id="12984" url="https://pl.wikipedia.org/wiki?curid=12984" title="Polihymnia">
Polihymnia

Polihymnia (także Polyhymnia, Polymnia, „Obfitująca w hymny”; gr. Polýmnia, łac. Polyhymnia ‘bogata w pieśni’, ‘wiele hymnów’) – w mitologii greckiej muza poezji sakralnej i hymnicznej oraz pantomimy.
Uchodziła za córkę boga Zeusa i tytanidy Mnemosyne oraz za siostrę: Erato, Euterpe, Kalliope, Klio, Melpomene, Talii, Terpsychory i Uranii. Niekiedy uważano ją za matkę Orfeusza.
Była jedną spośród dziewięciu muz olimpijskich (przebywały na Olimpie), które należały do orszaku Apollina (Apollon Musagetes), ich przewodnika. Wraz ze swoimi siostrami uświetniała śpiewem biesiady bosko-ludzkie (m.in. zaślubiny Tetydy i Peleusa oraz Harmonii i Kadmosa), a także uczty olimpijskie samych bogów.
W sztuce przedstawiana jest zwykle jako kobieta otulona himationem, w długiej uroczystej szacie (w głębokiej zasłonie, jakiej używało się przy obrzędach religijnych), w zamyślonej pozie, niekiedy z palcem na ustach (na ogół nie posiada atrybutu).
Imieniem muzy została nazwana jedna z planetoid – (33) Polyhymnia.

</doc>
<doc id="12985" url="https://pl.wikipedia.org/wiki?curid=12985" title="Talia (muza)">
Talia (muza)

Talia (także Taleja, „Rozkoszna”; gr. Tháleia ‘kwitnąca’, łac. Thalia, Thalea) – w mitologii greckiej muza komedii.
Uchodziła za córkę boga Zeusa i tytanidy Mnemosyne oraz za siostrę: Erato, Euterpe, Kalliope, Klio, Melpomene, Polihymnii, Terpsychory i Uranii, a także za matkę korybantów.
Była jedną spośród dziewięciu muz olimpijskich (przebywały na Olimpie), które należały do orszaku Apollina (Apollon Musagetes), ich przewodnika. Wraz ze swoimi siostrami uświetniała śpiewem biesiady bosko-ludzkie (m.in. zaślubiny Tetydy i Peleusa oraz Harmonii i Kadmosa), a także uczty olimpijskie samych bogów.
W sztuce przedstawiana jest zwykle jako kobieta z maską komiczną i wieńcem z bluszczu na głowie – atrybutami symbolizującymi dziedzinę sztuki, której patronowała.
Imieniem muzy nazwano jedną z planetoid – (23) Thalia oraz festiwal teatralny odbywający się każdego roku w Tarnowie – Ogólnopolski Festiwal Komedii „Talia”.

</doc>
<doc id="12986" url="https://pl.wikipedia.org/wiki?curid=12986" title="Magia">
Magia

Magia, czary – ogół wierzeń i praktyk opartych na przekonaniu o istnieniu sił nadprzyrodzonych, które można opanować za pomocą odpowiednich zaklęć i określonych czynności.
Osoba zajmująca się magią (mag, czarownik, szaman) stosuje różnorakie gesty, wypowiada zaklęcia (inkantacje) i wykonuje czynności o cechach rytuału mające dać mu władzę nad siłami nadprzyrodzonymi, i które w jego przekonaniu umożliwiają mu kształtowanie rzeczywistości.
Brak możliwości stwierdzenia powiązania między zastosowanym środkiem a ewentualnym efektem powoduje, że skuteczność działań magicznych i istnienie postulowanych przez nią sił nadprzyrodzonych pozostają w sferze wiary.
Etymologia.
Słowo „magia” pochodzi od Magów (staroperskie "maguš", gr. "μάγος"), astrologów-kapłanów zoroastryzmu z ludu Medów i jest pokrewne polskiemu „moc”, „mocarz”, greckiemu "μάγος" ("magos"), "μαγικός" ("magikos", łac. "magicus") typowo występujący w rodzaju żeńskim, na przykład w zwrocie "μαγική τέχνη" ("magike techne", łac. "ars magica," „sztuka magii”). Angielskie "magic" weszło w użytek pod koniec XIV wieku jako zapożyczenie ze starofrancuskiego "magique".
Biała a czarna magia.
Istnieje wiele rozbieżności w pojmowaniu różnicy pomiędzy białą a czarną magią. Większość współczesnych magów, szczególnie należących do zachodniego kręgu kulturowego, żadnemu rodzajowi magii nie przypisuje kolorów, twierdząc, że magia jest tylko narzędziem, a sposób jej wykorzystania zależy tylko od woli maga (to mag może być „czarny” lub „biały”, a nie jego narzędzie). Z drugiej strony na przykład na Syberii funkcjonuje ścisły podział pomiędzy „białych” a „czarnych” szamanów, który generalnie jest całkowicie zdeterminowany przez ich pochodzenie. O ile jednak w części średniowiecznej Europy podział ten był ścisły o tyle w innych jej częściach nie był on aż tak wyraźny. Ówczesny aspekt magii pojmowany np. jako sięganie do sił demonicznych (które pierwotnie w wierzeniach np. Greków lub Słowian miały charakter ambiwalentny) lub boskich, również wskazuje na różne podejście w kwestii jej klasyfikacji. Tym samym reprezentowanemu przez część współczesnych czarowników, magów lub szamanów braku rozróżniania rodzajów magii, nie można przypisać wyłącznie charakterowi współczesnej kultury zachodniej (ideom indywidualnej wolności, liberalizmu, demokracji).
W kulturze popularnej biała magia to zwykle magia, która wykorzystywana jest do dobrych celów i dobrymi sposobami, zaś czarna magia służy złu, wykorzystywana jest do niecnych zamiarów i zwykle wiąże się z wykonywaniem jej na mroczne sposoby. Podobnie podejście stosowane jest w religii Wicca, gdzie magia rozróżniana jest na białą i czarną według zasady „Czyń to, co chcesz, pod warunkiem, że Twoje czyny nie skrzywdzą nikogo” – czyny nie sprawiające nikomu krzywdy kwalifikują się tu jako magia biała, zaś ta wyrządzająca krzywdę to magia czarna. Według Alistera Crowleya magia biała to wszelkie działania maga wykonywane w zgodzie z jego Wolą (co nie jest równoznaczne robieniu co się chce, patrz: Thelema). Wszystkie inne działania magiczne sprzeciwiające się Woli uznawane były przez niego za magię czarną. Choć Crowley był orędownikiem (wszak jego własnej) filozofii Woli, w związku z czym nie powinien korzystać z magii innej niż biała, w swoim domu w Szkocji posiadał dwa oddzielne pomieszczania do magii białej i czarnej, którą również się posługiwał. Ze względu na nie zawsze dokładne granice wyznaczone przez te pojęcia, pojawiło się także pojęcie szarej magii, oznaczającej magię balansującą na granicy tych dwóch.
Modele funkcjonowania magii.
Pojęcie magii towarzyszy ludzkości od początków dziejów. Różne ludy usiłowały w różny sposób wyjaśnić zjawiska zachodzące w otaczającym je świecie i następnie wpłynąć na nie dla swojej korzyści. Dlatego znane obecnie praktyki magiczne są bardzo różnorodne – postulują znacząco odmienne zasady funkcjonowania rzeczywistości i metody wpływania na nią. Można jednak zgrupować je w kilka modeli funkcjonowania magii:
Model duchowy.
Jest to prawdopodobnie najstarszy model magii, występujący przede wszystkim w szamanizmie. Zakłada on istnienie Zaświatów zamieszkanych przez istoty duchowe, takie jak: duchy, demony, anioły itp. W zależności od konkretnego systemu magicznego mag albo wchodzi (zwykle jedynie umysłem – dzięki transowi lub ekstazie) do Zaświatów i podróżując przez nie podejmuje działania magiczne, albo też tworzy zamknięty obszar (np. krąg), w którym inwokuje świat duchowy lub jego mieszkańców. W tym drugim przypadku duch albo wykonuje powierzone zadania oddziałując na świat materialny z Zaświatów, albo też opętuje maga, który dzięki temu zyskuje dodatkowe możliwości działania.
Wszystkie działania magiczne wykonują tak naprawdę istoty duchowe, mag musi je do tego przekonać lub zmusić do posłuszeństwa swej woli. Odbywa się to przez modlitwy, obietnice posług, przyjmowanie na siebie określonych tabu, a nawet zastraszanie zaklęciami czy duchowymi „zwierzchnikami” danej istoty.
Przykładami systemów magicznych, które stosują ten model, są na przykład: szamanizm, teurgia i goetia. Z adwokatów tego modelu wymienić można np. Salomona, Johna Dee, a z bardziej współczesnych – Aleistera Crowleya.
Model energetyczny.
Model ten jest prawdopodobnie niewiele nowszy niż model duchowy. Zakłada on, że świat widzialny przeniknięty jest wszechobecną energią życiową, nazywaną różnie w różnych kulturach: "prana", "qi", "ki", "mana", "vril", a w Europie: "vis vitalis", fluid magnetyczny itd. Procesy zachodzące w świecie widzialnym są według tego modelu efektem działania owych energii subtelnych, zaś działania magiczne polegają na takim manipulowaniu obiegiem energii, by wytworzyć pożądany efekt w makroskali. Podobnie jak w poprzednim modelu, również tutaj znajduje zastosowanie magiczny trans wyciszający część umysłu posługującą się logiką, tak by mag postrzegał i działał wyłącznie intuicyjnie.
Model ten jest wykorzystywany przede wszystkim przez wschodnie systemy magiczne i okultystyczne: Hunę, większość odmian jogi, tradycyjną chińską medycynę i Feng shui, Reiki, a także sztuki walki, przede wszystkim Taijiquan i Qigong. W tradycji Zachodu model ten pojawia się po raz pierwszy u Mesmera w jego koncepcji magnetyzmu zwierzęcego, a następnie w teozofii Bławatskiej. Na szeroką skalę został spopularyzowany przez ruch New Age.
Model psychologiczny.
Model ten w zasadzie nie wyjaśnia, jak działa magia, a jedynie utrzymuje, że za działania magiczne jest odpowiedzialna podświadomość i może ona być programowana w celu osiągnięcia pożądanych zmian. Programowanie to następuje przez użycie symboli i autosugestię w stanie umysłu, który buddyści nazywają "samadhi", a chaoci – "gnozą".
Mag bazujący na tym modelu nie potrzebuje w praktyce magicznej istot duchowych czy energii subtelnych – wystarcza mu programowanie w psychice stanów mentalnych. W praktyce jednak często zdarza się, że magowie posługujący się tym modelem magii przyjmują istnienie duchów lub energii, co miałoby im pozwalać np. ładować sigile energią w celu wzmocnienia bądź przyspieszenia ich działania.
Najbardziej znanym magiem, który stosował magię tego modelu był Austin Osman Spare, którego magia sigili jest w zasadzie odwróceniem teorii kompleksów Freuda. Polega ona na tym, że mag skupia swoją intencję na sigilu, czyli stworzonym przez niego symbolu graficznym lub dźwiękowym, a następnie zapomina o nim (czyli usuwa ze świadomości). Sigil zostaje jednak w podświadomości, gdzie tworzy jakby sztuczny kompleks, który zaczyna wpływać na poczynania maga w sposób podobny jak zwykłe zepchnięte w podświadomość lęki.
Psychologiczny model magii stał się popularny najpierw w świecie anglojęzycznym, by w latach 70. zeszłego stulecia stać się dominującym paradygmatem magicznym w zachodnim kręgu kulturowym. Jego wyznawcami byli między innymi: Israel Regardie, Dion Fortune i Peter Carroll.
Model informacyjny.
Jest to najnowszy model magii, datujący się na schyłek lat 80. zeszłego stulecia. Bazuje na założeniu, że istnieje kosmiczna energia, którą można kształtować za pomocą informacji, oraz że informacja jest odrębna od masy i energii, ale może się z nimi wiązać. 
Magowie stosujący model informacyjny (nazywani czasem „cybermagami”) w swej praktyce nie posługują się magicznym transem, co odróżnia ich od pozostałych magów. Raczej w normalnym stanie umysłu posługują się centrami magazynowania i przetwarzania informacji (mózg i czakry wzdłuż kręgosłupa). Wierzą, że z ich pomocą nadają kierunek przepływowi informacji, która w pożądany sposób kształtuje kosmiczną energię. W odróżnieniu od innych systemów magii, tutaj informacja nie zużywa się, lecz jest kopiowana między systemami energetycznymi.
Tak więc mimo nowoczesnego wizerunku wydaje się, że model ten jest pochodną modelu energetycznego. Cybermag oprócz praktycznej wiedzy na temat programowania i administrowania systemami informatycznymi powinien być też biegły w medytacji i jakiejś technice rozwijającej system energetyczny, na przykład w Jodze.
Wiara ta jest szczególnie powszechna wśród Iluminatów Thanaterosa.
Podejście naukowe.
Współczesna antropologia rozpatruje magię w kategoriach myślenia mitycznego, a także w związku z zakorzenionym w danej kulturze postrzeganiem przyczynowości zachodzących zjawisk.
Bronisław Malinowski interpretował magię w zgodzie z paradygmatem antropologii funkcjonalnej:
W odróżnieniu od podejścia naukowego, w popularnym odczuciu części współczesnego społeczeństwa magia utożsamiana jest z zabobonem lub folklorem, a działania magiczne postrzegane są jako nieskuteczne lub wręcz oszukańcze. Mimo tak negatywnych konotacji, magia zakorzeniła się jednak w kulturze popularnej jako stały element w literaturze fantasy, bajkach dla dzieci oraz kampaniach marketingowych.
Magia a religia.
W obu tych formach ludzkiej aktywności jaką stanowi magia i religia, występuje wiara w istnienie świata pozazmysłowego, a więc nie weryfikowalnego drogą doświadczalną. W magii, podobnie jak w religii, może dojść do personifikacji sił nadprzyrodzonych (np. dżinny, demony itp.), niektórzy badacze uważają egzorcyzm za odmianę magii. Zgodnie z nauką większości kościołów, istnieje jednak zasadnicza różnica w kontaktach z tymi siłami pozwalająca odróżnić religię od magii: w magii nie dochodzi do złożonego kontaktu psychicznego między sprawującym obrzęd a duchem, do którego się on zwraca (niepowodzenie obrzędu zostanie przypisane brakom umiejętności maga, nie zaś, jak w religii, np. kaprysowi bóstwa). Istotną różnicą jest także to, że osoba kierująca się myśleniem magicznym, np. szaman, zakłada, że dzięki praktykom magicznym ma wpływ na bieg zdarzeń otaczającego ją świata, a jeżeli napotyka trudności, zakłada, że spotkał się z silniejszą magią, natomiast kierująca się myśleniem religijnym (kapłan) zakłada, że nie jest w stanie wywierać wpływu na istoty duchowe, lecz może je jedynie przebłagać poprzez np. modlitwę. Myślenie opierające się na magii zakłada więc siłę sprawczą człowieka, natomiast myślenie religijne zakłada, że bieg zdarzeń w świecie jest zależny od istot wyższych, bogów.
Istotną różnicą między magią a religią jest aspekt soteriologiczny, czyli istotą religii jest zogniskowanie wokół idei życia pozagrobowego. Ważnym wyróżnikiem religii jest więc zainteresowanie losami duszy po śmierci. Z magią natomiast mamy do czynienia także kiedy mowa o kontaktach ze sferą transcendencji, jednakże jest bardziej pragmatyczna niż religia. Według Malinowskiego magia istnieje dla osiągnięcia złożonych celów – w umysłach ludności społeczeństw pierwotnych istnieje od zawsze.
Wiara w magię jest rozpowszechniona w większości systemów wierzeń etnicznych – plemiennych społeczności Afryki i Oceanii, rdzennych Amerykanów oraz rodzimych wierzeń średniowiecznej Europy i części jej współczesnych kontynuatorów – wierzeń rodzimych. Do XVIII wieku w Europie była karana śmiercią (zazwyczaj spaleniem na stosie).
Według przedstawicieli niektórych wyznań (szczególnie monoteistycznych – jak np. chrześcijaństwo, islam i judaizm) jakiekolwiek stosowanie magii jest zakazane.
Magia według Biblii.
Biblia sprzeciwia się praktykom magicznym:
W przekonaniu biblistów praktyki magiczne wywodzą się z interakcji między wolą człowieka a strefą duchową tożsamą – wedle części interpretacji przekazów Biblijnych – ze sferą demoniczną (przed którą uchronić mogą np. praktyki egzorcystów). Cechą charakterystyczną tych interakcji jest wówczas interesowność sił ze strony demonicznej, przez co każda forma praktyk magicznych (w mniejszym lub większym stopniu) ostatecznie wpływa destrukcyjnie na osobową strukturę bytową człowieka. Według zwolenników tej koncepcji, skutki (pod postacią zniewolenia demonicznego, opętania, choroby fizycznej, jak i psychicznej, depresji lub myśli samobójczych) wynikłe ze stosowania tak rozumianych praktyk magicznych pojawiać się mogą w trakcie ich stosowania, jak i po tym czasie – gdy osoba (czarownik) zaprzestała już swoich praktyk.
Religie wobec magii.
Chrześcijaństwo.
Kościół Katolicki.
Stanowisko Kościoła katolickiego względem magii precyzuje Katechizm Kościoła Katolickiego: 
Świadkowie Jehowy.
Świadków Jehowy obowiązuje zakaz praktykowania jakichkolwiek form okultyzmu, wróżbiarstwa, spirytyzmu czy magii (Pwt 18:9-13; 1 Kor 10:21, 22; Gal 5:20, 21).
Islam.
Także w islamie praktykowanie magii i wróżbiarstwa jest surowo zakazane (Koran 5:3, 5:90-91). W krajach, gdzie rządzi radykalny islam, za praktykowanie magii grozi ścięcie mieczem.
Magia według praktyków.
Na świecie istnieje wiele organizacji, jak i indywidualnych osób wierzących w realną możliwość stosowania magii. Mag i okultysta, Aleister Crowley, nazwał ją „magiją” ("magick") i pisał o niej w jednym ze swoich dzieł tak: "MAGIJA jest nauką powodowania zmiany zgodnie ze swoją Wolą. (Objaśnienie: Jest moją Wolą poinformowanie świata o pewnych faktach dotyczących mojej wiedzy. Korzystam w tym celu z „magicznych broni”, pióra, tuszu, i papieru. Piszę „inkantacje” – te zdania – w języku magicznym, tj. w takim, który jest zrozumiały dla ludzi, których chcę poinstruować. Wzywam następnie „duchy”, a więc drukarzy, wydawców, księgarzy i im podobnych, których zmuszam do przekazania mojego przekazu tym ludziom. Układ książki i jej dystrybucja jest zatem aktem MAGIJI, dzięki któremu powoduję zajście zmian zgodnie z moją Wolą)."
Praktycy magii zakładają, że każde działanie odnoszące się do jakiejś konkretnej sfery bytu powinno dać efekt w postaci wywarcia wpływu na byty zależne od tego działania, pomimo pozornego braku związku przyczynowo-skutkowego między tym działaniem a jego spodziewanym efektem. Według tego typu myślenia każde podobne, analogiczne działanie powinno spowodować analogiczne skutki. Tak definiowana magia określona została przez Jamesa Frazera jako magia sympatyczna, w obrębie której wyróżniał też dwa sposoby praktykowania magii: magię homeopatyczną i magię przenośną.
W języku angielskim na określenie "prawdziwej" magii, a nie iluzjonistycznych sztuczek, Aleister Crowley wprowadził określenie „Magick” (dodał literę „k” do słowa „Magic”). W języku polskim zaś wciąż najpopularniejsze jest to pierwsze określenie („magia”) na określenie obydwu pojęć, tym niemniej jednak tłumaczenia na język polski używają równie często określenia „magija” bądź „magyia” (również wprowadzonego dla rozróżnienia).
Magia na co dzień.
Osoby wierzące w magię uznają, iż w każdym etapie naszego życia mamy z nią do czynienia, niejednokrotnie nie zdając sobie z tego sprawy. Widocznym elementem jest, według nich, potęga myśli. Choć niektóre aspekty tego zagadnienia zostały częściowo udowodnione przez psychologów, nadal wiele pozostaje uznawanych za typową magię przez ogół społeczeństwa. Magowie (choć nie ze wszystkich kręgów) uznają za prawdę fakt, że jeśli poświęcamy czemuś dużo uwagi, ma to większe szanse spełnienia, obojętnie czy to będzie obawa przed czymś, czy też pragnienie osiągnięcia czegoś. W podobny sposób działają przekonania, określające nasze doświadczanie. To znaczy, że jeśli nauczono nas, wpojono nam, bądź my sami uznaliśmy za prawdę fakt, że dany autobus często się spóźnia, to najprawdopodobniej jeśli następnym razem pójdziemy na przystanek, autobus także spóźni się. Ten pogląd jest m.in. często używany przez ezoteryków do osiągnięcia zdolności paranormalnych poprzez zmianę wpajanego im od dzieciństwa np. przez rodziców poglądu, że nadprzyrodzone zdolności są niemożliwe. Zasada jest podobna do efektu placebo.
Według badań CBOS w 2018 roku 45 procent polskich respondentów czytało horoskopy (głównie kobiety: 55%), 11 procent korzystało z wróżbitów (kobiety trzykrotnie częściej, także popularne wśród rozwodników), a 5% nosiło wtedy talizmany (popularne szczególnie wśród młodszych osób).

</doc>
<doc id="12988" url="https://pl.wikipedia.org/wiki?curid=12988" title="Czart">
Czart

Czart zwany także jako czort (czesk. "czert", rusk. "czort", ros. "чёрт") – w wierzeniach Słowian demon zła, znany głównie u plemion ruskich, zastąpił starosłowiańskiego biesa. W gwarze ludowej nazywany kusym, a w wierzeniach chrześcijańskich diabłem.
W wierzeniach ludowych czart wyobrażany jest jako chromy. Zamieszkuje bagna, lasy i zbiorniki wodne, objawia się także w wirach powietrznych, co dało podstawę do wysunięcia teorii, według której czart był upersonifikowaniem niszczycielskiej siły wiatru. Czart zsyłał na ludzi niepogodę i choroby, a także namawiał do samobójstwa. Mógł przyjmować postać węża, psa, świni lub czarnego kota. W mitologii słowiańskiej czart prowadził kiedyś walkę z którymś z bogów, w trakcie której został zraniony w nogę, lub też został zrzucony z nieba i spadając złamał nogę. Inna wersja tego mitu mówi o odgryzieniu czartowi ogona przez psa nasłanego przez boga.
Po chrystianizacji określenie czart stało się synonimem słowa diabeł, zaś pierwotne znaczenie i funkcje czarta uległy zatarciu i są obecnie rekonstruowane na podstawie folkloru.
Etymologię słowa wywodzono od określenia „czarny” lub „czary”, wskazywano też na podobieństwo do litewskiego "kyréti", „złościć się”. Inna możliwość to związek ze słowem „krótki”, „skrócony” (por.: ang. "short", niem. "kurz", łac. "curtis"), na co wskazuje też określenie „kusy” stosowane niekiedy wobec diabła. Imię pochodziłoby w tym wypadku od faktu, że czart miał jedną nogę krótszą.

</doc>
<doc id="12989" url="https://pl.wikipedia.org/wiki?curid=12989" title="Tecumseh">
Tecumseh

Tecumseh ("Tecumthe", "Tikamthe", "Tecumtha" - j.shawnee "Puma gotowa do skoku", "Skacząca Puma", ur. 1768, zm. 5 października 1813) – wódz północnoamerykańskiego plemienia indiańskiego Szaunisów (Szawanezów), przywódca wojskowy, mówca, polityk, generał brytyjski. Na początku XIX w. był zwolennikiem utworzenia szerokiej konfederacji plemion indiańskich na południe od Wielkich Jezior, której celem byłoby powstrzymanie inwazji białych.
Życiorys.
Wojny na przełomie XVIII i XIX w..
W latach 70. i 80. XVIII w. trwały walki o dolinę rzeki Ohio pomiędzy Indianami, Brytyjczykami a Amerykanami. Z czasem plemiona indiańskie coraz lepiej rozumiały, że zawiązywanie sojuszy może zwiększyć ich możliwości militarne i własne bezpieczeństwo. Jesienią 1787 na czele połączonych sił Szaunisów, kanadyjskich Irokezów, Wyandottów, Mingo, Ottawów, Czikamaugów, Miami, Kikapów, Delawarów, Odżibwejów, Potawatomich, Lisów, Sauków i Mascoutenów stanął wódz plemienia Miamisów Michikinikwa (Mały Żółw).
Konfederacja, dysponująca dwoma tysiącami wojowników, odniosła kilka znaczących zwycięstw. W 1791 w bitwie nad rzeką Wabash wojska amerykańskie doznały największej, pod względem liczby zabitych i rannych, klęski w historii swych wojen z Indianami. W starciu w zachodnim Ohio Indianie zabili wówczas 600 i zranili 400 żołnierzy.
W tym samym roku rząd w Waszyngtonie wysłał do walki generała „Mad Anthony’ego” Wayne’a. W sierpniu 1794 przeciwnicy spotkali się pod Fallen Timbers - rozegrała się wówczas Bitwa pod zaporą z pni. Opuszczeni przez Brytyjczyków Indianie ulegli przeważającej sile wroga. W bitwie tej po raz pierwszy spotkali się na polu walki Tecumseh (wtedy mało znaczący wódz) i William Henry Harrison (wówczas młody porucznik).
Początki konfederacji.
W 1795 rozpoczęły się negocjacje pokojowe, których celem miało być zaprzestanie walk i umożliwienie Amerykanom osiedlania się w dolinie Ohio. Przeciwny ustępstwom terytorialnym Tecumseh zbojkotował negocjacje, był jednak jeszcze mało znany i bojkot nie przyniósł rezultatów. Wódz Szaunisów uznał, że konfederacja indiańskich plemion doliny Ohio nie jest w stanie powstrzymać ekspansji białych. Postanowił stworzyć znacznie szerszą koalicję Indian. Od tej pory wiele podróżował po Ameryce Północnej, prowadząc rozmowy z licznymi plemionami.
Wraz z Tecumsehem działał jego młodszy o trzy lata brat, Tenskwatawa (Otwarte Drzwi), wśród Białych znany jako Prorok. W 1805 przeżył on duchowe przebudzenie i oświadczył, że posiada ponadnaturalne zdolności. Początkowo podchodzono do niego nieufnie, ale jego wpływy wzrosły, gdy przewidział zaćmienie słońca. Kombinacja politycznych zdolności Tecumseha i duchowego przywództwa jego brata zaczęła przynosić efekty. W 1808 nad Tippecanoe w zachodniej Indianie ustanowiono stolicę konfederacji Tecumseha.
Konflikt z Amerykanami.
Tecumseh wiele podróżował, namawiając kolejne plemiona do przyłączenia się do konfederacji. W tym czasie gubernatorem Terytorium Indiany był wspomniany już Harrison. Z niepokojem patrzył on na rozwój wypadków, gdyż coraz bardziej prawdopodobny wydawał się wybuch wojny pomiędzy USA i Wielką Brytanią a Harrison obawiał się, że Tecumseh wesprze w wojnie Brytyjczyków.
Gdy w 1809 Tecumseh był w kolejnej ze swych podróży, Harrison perswazją i podstępem przekonał wodzów Delawarów, Miami, Kaskaskiów i Potawatomich, i wbrew wcześniejszym umowom i zapowiedziom odkupił od nich duże połacie ziemi (traktat z Fortu Wayne). Wywołało to ostrą reakcję Tecumseha. Wysłał on do Harrisona list, w którym stwierdził, że biali nie mają prawa nabywać od Indian ziemi. Pomiędzy oboma przywódcami dochodziło do spotkań, które jednak nie prowadziły do rozwiązania problemów.
Porażki i śmierć.
W 1811 Tecumseh wyruszył na południe, by przyprowadzić wsparcie ze strony Czikasawów, Czoktawów, Krików i Seminoli. Dowództwo przejął jego brat. W tym czasie Harrison na czele wojsk podszedł pod Tippecanoe. Tenskwatawa nakazał atak na obóz Amerykanów, jednak zakończył się on klęską. Indianie musieli opuścić osadę, którą zajął i spalił Harisson. Tecumseh powrócił w styczniu 1812, jednak jego starania o pozyskanie wojowników z południa spełzły na niczym. Mimo to wciąż cieszył się znacznym poważaniem u wielu Indian. Szanowali go również Brytyjczycy - współpracował np. z generałem Izaakiem Brockiem aż do jego śmierci pod Queenston Heights.
Do sierpnia 1813 William Henry Harrison dostał pod swoje dowództwo 8000 żołnierzy. Gdy Oliver Hazard Perry pokonał brytyjską flotę na jeziorze Erie i Brytyjczycy oraz Indianie musieli opuścić Detroit, Harrison ruszył za nimi w pościg. Doszło do konfliktów wśród sojuszników - dowódca brytyjski, gen. Henry Proctor, lekceważył Indian, jednocześnie posyłając ich do osłony tyłów. 5 października 1813 doszło do konfrontacji nad kanadyjską rzeką Thames (bitwa pod Moraviantown). W jej trakcie Brytyjczycy wycofali się z pola bitwy. Osamotnieni Indianie ponieśli klęskę, a Tecumseh zginął w walce. W literaturze istnieje kilkadziesiąt różnych opisów okoliczności jego śmierci.
Literatura.
Historia Tecumseha stała się tematem wielu książek. Seria trzech powieści Longina Jana Okonia – "Tecumseh", "Czerwonoskóry generał" i "Śladami Tecumseha", opisuje ona fikcyjne przygody Ryszarda Kosa, towarzyszącego Tecumsehowi w jego walce przeciwko Amerykanom. W tej powieści Tecumseh urodził się w roku 1770 i był bratem bliźniakiem Tenskwatawy (Otwarte Drzwi).
Tecumseh (pod imieniem Ta-Kumsaw), i Tenskwatawa (Tenskwa-Tawa) pojawiają się w powieści fantasy Orsona Scotta Carda "Czerwony prorok", należącej do cyklu "Opowieści o Alvinie Stwórcy."

</doc>
<doc id="12990" url="https://pl.wikipedia.org/wiki?curid=12990" title="Współrzędne współporuszające się">
Współrzędne współporuszające się

Współrzędne współporuszające się (ang. "comoving coordinates") – pojęcie wprowadzone dla uproszczenia rozważań nad kształtem Wszechświata. Drugim pojęciem kluczowym dla zagadnienia jest czynnik skali.
Przyjmuje się, że we współrzędnych współporuszających się Wszechświat jest (pomijając ruchy własne) statyczny. Dzięki temu można skoncentrować się na kształcie przestrzeni (lub, mówiąc bardziej formalnie, na hiperpowierzchni przestrzennej, przy stałym czasie kosmicznym). Wybór takiego układu odniesienia często ułatwia obliczenia, może również pomóc lepiej poznać i zrozumieć niektóre zjawiska. Aby przejść ponownie do rozważań nad rozszerzającym się Wszechświatem, wystarczy pamiętać o czynniku skali.
Niektórzy autorzy używają symbolu χ dla współrzędnych współporuszających się.
Pojęcia pokrewne.
Posługując się pojęciem współrzędnych współporuszających się można zdefiniować czas kosmiczny. W uproszczeniu, dla obserwatora (tak zwanego obserwatora fundamentalnego) znajdującego się w ustalonym punkcie określonym przez współrzędne współporuszające się, jest on taki sam jak czas mierzony lokalnie.
"Odległość współporuszająca się" jest zatem dystansem jaki dzieli dwa punkty położone w układzie współrzędnych współporuszających się, przy takim samym czasie kosmicznym, mierzonym w obu tych punktach.
Znaczenie odległości współporuszającej się.
Odległości współporuszające się, podobnie jak czas kosmiczny, stanowią część składową modelu Wielkiego Wybuchu.
Czas kosmiczny i czas mierzony lokalnie przez obserwatora fundamentalnego są takie same. Jednak odległość współporuszająca się nie jest tożsama z odległością (rozumianą jako różnica położeń) przebytą przez cząstkę poruszającą się wolniej niż światło w próżni.
Wynika to z tego, że w rzeczywistości Wszechświat nie jest statyczny. W czasie kiedy cząstka będzie się przemieszczać, Wszechświat zmieni swoje rozmiary, więc cząstka przebędzie odpowiednio dłuższą (w przypadku rozszerzania się Wszechświata) lub krótszą (w przypadku kurczenia się Wszechświata) drogę, niż wynosi odległość współporuszająca się pomiędzy punktem, gdzie cząstka rozpoczęła podróż, a punktem, gdzie ją zakończyła, o ile poruszać się będzie po najkrótszej drodze (linii geodezyjnej), łączącej te dwa punkty w danej geometrii przestrzeni.
Jeżeli podzieli się odległość współporuszającą się przez obecny czas kosmiczny (wiek Wszechświata) i wynik tego działania nazwie się „prędkością”, wówczas z łatwością można otrzymać prędkości galaktyk położonych w pobliżu lub za horyzontem cząstek, które będą większe od prędkości światła w próżni. Na tej podstawie można by powiedzieć, że "Wszechświat rozszerza się szybciej, niż prędkość światła w próżni", takie stwierdzenie będzie paradoksem, jeśli nie zdefiniuje się poprawnie prędkości. Zatem należałoby powiedzieć:
"galaktyka w pobliżu lub za horyzontem cząstek może mieć prędkość względem obserwatora, zdefiniowaną jako iloraz odległości współporuszającej się i czasu kosmicznego mierzonego przez obserwatora, większą niż prędkość światła w próżni"
Jednak zanim zacznie się szukać na niebie galaktyk o prędkościach ucieczki większych od prędkości światła w próżni, musi się wziąć najpierw pod uwagę to, że:
Inne odległości używane w kosmologii.
Trzy ostatnie odległości połączone są prostym związkiem:
gdzie "z" jest mierzonym przesunięciem ku czerwieni.
Tylko wtedy, gdy krzywizna Wszechświata k=0, spełniony jest związek:
Gdy przestrzeń we Wszechświecie ma krzywiznę:
gdzie:
Praktyczna zależność formula_2 od redshift formula_15
i wtedy ma też formula_17
Odległości radialna i tangencjalna.
Inaczej mówiąc, formula_2 jest to radialna odległość współporuszająca się, a formula_5 jest to tangencjalna odległość współporuszająca się dla kąta jednego radiana.
Odległości użyteczne w małych skalach.
W małych, czyli rzędu rozmiaru galaktyki lub gromady galaktyk skalach przestrzennych i czasowych, można traktować Wszechświat tak, jakby był statyczny, wtedy odległość przebyta przez cząstkę będzie równa przebytej przez nią odległości współporuszającej się pomnożonej przez czynnik skali w danym czasie kosmicznym.

</doc>
<doc id="12991" url="https://pl.wikipedia.org/wiki?curid=12991" title="Czynnik skali">
Czynnik skali

Czynnik skali – wielkość zależna tylko od czasu kosmicznego, wiążąca odległość własną pomiędzy dwoma punktami z odległością we współrzędnych współporuszających się:
gdzie:
Czynnik skali może mieć wymiar odległości lub być bezwymiarowy (w zależności od przyjętej konwencji), wtedy odpowiednio odległość we współrzędnych współporuszających się jest bezwymiarowa lub ma wymiar odległości. Może być też różnie normalizowany – czasem przyjmuje się np. formula_7 gdzie "t"0 jest obecną wartością czasu kosmicznego (obecnym wiekiem Wszechświata).
W ogólności, gdy formula_8 mamy następującą zależność pomiędzy czynnikiem skali a przesunięciem ku czerwieni:
gdzie "z" jest przesunięciem.
Czynnik skali występuje w równaniach Friedmanna-Lemaître’a.
Zależność czynnika skali od czasu związana jest z dynamiką Wszechświata.
Z czynnikiem skali związany jest parametr Hubble’a, będący pochodną czynnika skali po czasie, dzieloną przez czynnik skali:
W modelu kosmologicznym z niezerową stałą kosmologiczną, wartość czasu kosmicznego dla przesunięcia ku czerwieni "z" (a więc odpowiadającego mu czynnika skali "a") wyraża się wzorem:
gdzie "H"0 jest stałą Hubble’a (obecną wartością parametru Hubble’a), formula_12 jest obecną gęstością materii nierelatywistycznej, wyrażoną w jednostkach gęstości krytycznej, zaś formula_13 jest obecną gęstością stałej kosmologicznej.

</doc>
<doc id="12992" url="https://pl.wikipedia.org/wiki?curid=12992" title="Hellada">
Hellada

Hellada (gr. , "Elláda", a także , "Ellás") – ogólna nazwa starożytnej Grecji. Pierwotnie tą nazwą określano ziemie na południu Tesalii, zamieszkane przez plemię Hellenów. Mianem Hellenów zaczęto określać w czasach pohomeryckich wszystkich Greków, a Helladą zasiedlane przez nich ziemie.
Określenie helleński bywa czasem stosowane w języku polskim także w odniesieniu do Grecji nowożytnej. Jest to możliwe w sytuacjach, gdy kontekst wskazuje na stylizację lub świadome kreowanie wizerunku poprzez nawiązanie do antycznych tradycji. W odniesieniu do współczesnej Grecji w języku polskim stosowana była dawniej także nazwa "Hellas".
W języku nowogreckim nazwa "Elláda" odnosi się głównie do współczesnego państwa greckiego. Dla odróżnienia czasów starożytnych w nowogreckim używa się określenia Αρχαία Ελλάδα (trb. "Archea Ellada" – „starożytna Grecja”). Przymiotnik „helleński” i określenie „hellenizm” w znaczeniach nowożytnych mogą być jednak też stosowane dla opisu zjawisk (w tym współczesnych nam), silnie związanych z grecką kulturą, tradycją lub narodowością, mimo braku ich związku z grecką państwowością lub historycznie greckim obszarem geograficznym. 
We współczesnej polszczyźnie spotykanym niekiedy nieporozumieniem jest stosowanie terminu „helleński” w odniesieniu do epoki hellenistycznej, gdyż wyznacza to dwie zupełnie różne cezury czasowe.

</doc>
<doc id="12995" url="https://pl.wikipedia.org/wiki?curid=12995" title="Jodłowanie">
Jodłowanie

Jodłowanie () – śpiew z częstymi zmianami skokowymi między rejestrami: piersiowym i głowowym, dominacją brzusznego toru oddychania i powiększeniem rezonatorów głosowych przez znaczne obniżenie krtani. Efektem jest specyficzna barwa głosu.
Jodłowanie jest charakterystyczne dla muzyki ludowej Tyrolu, ale nie jest ograniczone tylko do tego rejonu. Popularność jodłowania wśród alpejskich pasterzy wynika z praktycznego zastosowania tej techniki. Górale używali jej do nawoływania bydła pasącego się na górskich halach. Podobne techniki były niekiedy wykorzystywane przez Indian północnoamerykańskich w ich okrzykach bojowych.
Jodłowanie jest popularne w muzyce country. Wykorzystywane bywa także we współczesnej muzyce popularnej, np. Gwen Stefani jodłuje w singlu „Wind It Up”. Jodłowanie jest słyszalne w piosence Loituma – Ievan Polkka. Znanym austriackim zespołem w tej dziedzinie muzyki są Zillertaler Schürzenjäger. Jodłujący wokaliści używają najczęściej sylab pozbawionych znaczenia.

</doc>
<doc id="12996" url="https://pl.wikipedia.org/wiki?curid=12996" title="Historia Grecji">
Historia Grecji

Historia Grecji – obejmuje dzieje współczesnej Grecji, a także narodu greckiego oraz obszarów, które historycznie zamieszkiwał i nad którymi panował.
Grecja starożytna.
Dzieje starożytnej Grecji (Hellady) to historia kilku następujących po sobie wysokich kultur oddzielonych „ciemnymi wiekami” i wielkimi migracjami. O najstarszej z tych kultur (jeszcze przedhelleńskiej) zwanej od mitycznego króla Minosa kulturą minojską, która rozwinęła się w III tysiącleciu p.n.e. na Krecie, wiadomo stosunkowo najmniej. Jej świadectwem są ruiny wielkich pałaców odkryte w Knossos i Fajstos. Nie wiadomo, kim byli ich budowniczowie. Nie udało się dotąd odczytać dwóch starszych z trzech pozostawionych przez nich systemów pisma. Z badań archeologicznych wynika, że w 2 połowie III tysiąclecia p.n.e. na wyspie znajdowało się wiele niezależnych małych państw. Pod koniec tysiąclecia władcy z Knossos podporządkowali sobie sąsiadów. Korzystne położenie geograficzne pozwoliło Kreteńczykom uczestniczyć w wymianie handlowej między ośrodkami cywilizacji greckich a Bliskim Wschodem i Egiptem. Zyski z handlu zainwestowano w rozwój floty, co uczyniło z Krety w XIX-XVIII w. p.n.e. największe mocarstwo morskie. Około 1800 p.n.e. Kreteńczycy założyli pierwszą kolonię na Kyterze, a wkrótce potem następne na innych wyspach Morza Egejskiego. W XV w. p.n.e. kultura minojska załamała się, co wiązane jest z erupcją wulkanu na wyspie Thira i – prawdopodobnie – z następstwami tsunami powstałego w trakcie tego wybuchu.
Przedstawiciele kultury mykeńskiej (greccy Achajowie) ukształtowanej w XV w. p.n.e. na Peloponezie, zniszczyli pałace na Krecie i narzucili wyspie swoje zwierzchnictwo. Posługiwali się przejętym od Kreteńczyków alfabetem, tzw. pismem linearnym B (odczytanym). Śladami ich działalności budowlanej są ruiny twierdz w Mykenach i Tyrynsie, a aktywności politycznej – późniejszy, literacki opis wojny z Troją w Azji Mniejszej ("Iliada" Homera).
W XII w. p.n.e. kultura mykeńska upadła – miasta zostały zniszczone, pismo wyszło z użycia. Stało się tak za przyczyną napływu obcych ludów i, być może, trzęsień ziemi. Czas od XII do VIII w. p.n.e. nosi w historii Grecji nazwę „wieków ciemnych”. W tym czasie Grecy kolonizowali wybrzeża Anatolii, powstały m.in. miasta Efez i Milet.
„Właściwa” starożytna Grecja ukształtowała się między VIII a VI w. p.n.e. Uformowały się wówczas państwa-miasta, terytorialne wspólnoty obywateli zwane polis. Powstał alfabet, pierwsze zbiory praw, umocniła się wspólnota kulturowa Greków, bazująca na wspólnocie języka, religii i tradycji zawartej w poematach epickich takich jak Iliada i Odyseja, a także na uznaniu ogólnogreckich ośrodków kultu: Zeusa w Olimpii oraz Apollina w Delos i w Delfach, igrzysk w Olimpii i wyroczni delfickiej. Emigracja ludności poszukującej lepszych warunków życia zaowocowała powstaniem kolonii greckich w całym basenie Morza Śródziemnego (Italia, Sycylia, tereny dzisiejszej Francji i Hiszpanii, Libii, Egiptu, Cypru i pd. Turcji) oraz nad Morzem Czarnym.
Pod koniec tego okresu ustaliła się ostatecznie odmienność ustrojowa największej polis Sparty, stale zagrożonej buntami podbitej ludności, zmilitaryzowanej i zamkniętej w swych granicach. Drugie co do wielkości, ale najludniejsze miasto-państwo Hellady, otwarte i ożywione handlem Ateny, przechodziło w VI w. przemiany ustrojowe, które do udziału w sprawowaniu władzy włączały kolejne grupy obywateli. Demokracja ateńska rozwinęła się w pełni w V w. Losowanie urzędów i wynagradzanie obywateli za sprawowanie funkcji publicznych umożliwiło wówczas bezpośredni udział w rządach nawet najuboższym.
Konflikt między Persją i greckimi koloniami w Azji Mniejszej, a następnie atak perski na poleis na Półwyspie Bałkańskim sprawił, że u progu V w. p.n.e. zagrożeni w swych siedzibach Grecy wspólnie wystąpili przeciw najeźdźcom. Współdziałanie Aten i Sparty pozwoliło zwyciężyć Persów (490–470 p.n.e.), ale korzyści polityczne z sukcesu wyniosły głównie Ateny. Nadal obawiające się Persów mniejsze polis uznały ich hegemonię i przyłączały się do kierowanego przez nie Związku Morskiego. Rywalizacja obu państw doprowadziła do kilkudziesięcioletniej wojny, w której zaangażowali się także sojusznicy Sparty ze Związku Peloponeskiego i Aten ze Związku Morskiego. Mimo udziału w kolejnych wojnach, Ateny były w V w. p.n.e. niekwestionowaną stolicą kulturalną Grecji.
Grecja niepodległa.
1 lutego 1832 historia wyniosła księcia bawarskiego Ottona Wittelsbacha na tron Grecji. Król Ludwik Bawarski, ojciec Ottona, uzyskał zapewnienie, że nowy król Grecji będzie posiadał silną, dominującą pozycję w nowym państwie greckim.
Panowanie Ottona I Wittelsbacha trwało do 24 października 1862.
W pierwszym okresie swego panowania, w latach 1833–1843 Otton I Wittelsbach rządził w sposób absolutny. Cała władza ustawodawcza i wykonawcza skupiła się w rękach młodego króla. Także władza sądownicza była sprawowana w imieniu króla. Król nie był odpowiedzialny przed Narodem – jak stanowiła grecka konstytucja. Stolicą państwa zostały prowincjonalne wtedy Ateny, zmieniane z pomocą niemieckich architektów. Założono, że wystarczą pałace, jeden park i infrastruktura miejska dla około 100 tysięcy ludności. Liczbę tę skorygowano potem na 600 tysięcy, co i tak wystarczyło na życie jednego tylko pokolenia. Negatywnie zaważyła okoliczność, że aż do roku 1922 stołeczność Aten uznawano za stan tymczasowy, poprzedzający odzyskanie Konstantynopola.
Podstawowe kierunki polityki zagranicznej także określane były przez Wielką Ideę.
W 1839 r. zaczął narastać w Grecji kryzys ekonomiczny i polityczny. Bieda, niezadowolenie społeczne spowodowane "epizodem kreteńskim" i brak legalizacji partii politycznych powodowały rosnące niezadowolenie wielkich mocarstw Wielkiej Brytanii, Francji i Rosji – gwarantów niepodległości i konstytucji Grecji. Wzmogły one swoje wysiłki, aby zmienić tę sytuację. 3 września 1843 komendant stołecznego garnizonu, pułkownik kawalerii Dimitrios Kallergis stanął na czele rebelii. Dowodzony przez niego oddział kawalerii dotarł pod gmach pałacu królewskiego i zażądał przywrócenia konstytucji. Wsparty przez inne oddziały wojskowe i mieszkańców Aten, uzyskał zapewnienie Ottona I Wittelsbacha o przywróceniu praw konstytucyjnych w Grecji. Okres absolutyzmu w Grecji uległ zakończeniu, rozpoczął się zaś okres monarchii konstytucyjnej.
Wilhelm – Jerzy Glücksburg urodził się w Kopenhadze 24 grudnia 1845. 30 marca 1863 w wieku niespełna 18 lat został intronizowany jako król Grecji Jerzy I Glücksburg. Jednym z warunków, jakie zobowiązały się wypełnić trzy wielkie mocarstwa był zwrot Wysp Jońskich (w 1864 r. Anglia zwraca Grecji ten archipelag) oraz wypłacenie sumy 25 000 funtów rocznego „odszkodowania” w przypadku detronizacji króla. Król Jerzy I Glücksburg okazał się władcą o wiele bardziej elastycznym od swego poprzednika Ottona I Wittelsbacha. Konstytucja z 1864 r. znacznie ograniczyła zakres władzy królewskiej, dając duże uprawnienia wybieranemu w wyborach Parlamentowi. W zamian Grecja zobowiązała się powstrzymywać greckie rewolty na terenach zajmowanych przez wciąż potężną Turcję. Król Jerzy I Glücksburg wkrótce włączył się aktywnie do polityki greckiej, opanował język grecki, wizytował wszystkie, nawet odległe, tereny państwa. Widział ogromną nędzę i zacofanie swego nowego królestwa. W 1867 r. w Pałacu Zimowym w Petersburgu Jerzy I Glücksburg poślubił córkę wielkiego księcia Konstantego, piętnastoletnią Olgę. Dziewięć miesięcy później nowa królowa grecka wydała na świat następcę tronu, Konstantyna I Glücksburga. Konstantyn był najstarszym z siedmioosobowego potomstwa króla (pięciu chłopców, dwie dziewczynki). Pierwszy pałac królewski, zlokalizowany przy placu Syntagma, w centrum Aten, przekazano parlamentowi, a rodzina królewska zamieszkała w nowym pałacu Tatoi 27 km na północ od Aten. Król stał się w przeciągu kilku lat autorytetem i arbitrem greckiego życia politycznego.
W 1878 r. wielkie mocarstwa europejskie na kongresie w Berlinie zadecydowały o zwrocie Grecji Tesalii. Grecja odzyskała ją od Turcji w 1881 r. Lata 1880–1890 stanowiły dla Grecji okres rozwoju gospodarczego i społecznego. Budowane były drogi i linie kolejowe, rozkwit przeżywała flota i handel morski. Rozwijało się szkolnictwo i inne funkcje socjalne państwa.
W 1897 r. w czasie rewolty antytureckiej na Krecie Grecja wysłała militarne wsparcie powstańcom. Kilka miesięcy później wybuchło powstanie w Macedonii. 17 kwietnia Turcja wypowiedziała Grecji wojnę. Siły greckie w Tessalii, poniosły poważne porażki, cofając się pod naporem dwakroć silniejszej armii tureckiej. Już po kilku tygodniach wojny Turcja, wspierana przez Niemcy, zagroziła integralności Grecji. Porażki doznała też armia powstańcza w Macedonii dowodzona przez następcę tronu Konstantyna I Glücksburga. Na Krecie sytuacja została spacyfikowana przez rozmieszczanie tam sił międzynarodowych, w ramach wspólnej operacji desantowej mocarstw. Wydarzenia te określa się nieraz jako pierwszą w nowożytnej historii, pokojową, wojskową operację międzynarodową. Rosja i Anglia podjęły szeroką akcję dyplomatyczną, która doprowadziła do zakończenia walk i zawarcia rozejmu. Mocarstwa zadecydowały o autonomii Krety od Turcji oraz o ustanowieniu urzędu Wysokiego Komisarza – sprawowanego przez Greka. Grecja musiała jednak zapłacić Turcji ogromną, jak na swe możliwości, kontrybucję. W tym celu skarb państwa zaciągnął pożyczki zagraniczne, ustanowiono nowe podatki i monopole dla sfinansowania ich spłaty, kraj ogarnęła drożyzna, król utracił wiele ze swej popularności i odsunął się od aktywnej polityki.
Lata 1901–1936.
W 1909 r. grupa młodych oficerów zrzeszonych w Lidze Wojskowej zorganizowała pokojowy bunt w armii. Bunt ten stanowił protest przeciwko politycznej stagnacji i trudnościom ekonomicznym w kraju. Oficerowie prosili o przejęcie roli lidera politycznego przez dynamicznego polityka z Krety Elefteriosa Wenizelosa. Parlament uległ presji Ligi i wprowadził do konstytucji zmiany wzmacniające pozycję premiera.
W 1910 r. Elefterios Wenizelos stanął na czele rządu greckiego. W przeciągu kilku lat zainicjował głębokie reformy w gospodarce, służbach cywilnych, siłach zbrojnych i publicznym systemie oświaty. Posiadał też pełne poparcie króla Jerzego I Glücksburga.
Grecja pod rządami Wenizelosa dołączyła do sojuszu Bułgarii, Serbii i Czarnogóry przeciwko Turcji. Skutkiem tych działań były dwie wojny bałkańskie w latach 1912 i 1913. W pierwszej wojnie bałkańskiej w 1912 r. sojusznicy pokonali Turcję, wypierając ją prawie z całego europejskiego terytorium. Konstantyn I Glücksburg został szefem Sztabu Generalnego – głównodowodzącym armii. Zwycięska Grecja uzyskała rozległe terytoria na północy (Epir), wschodzie i zachodzie kraju (m.in. duże miasta Saloniki i Janinę). W wyniku porozumienia pokojowego w Londynie utworzono niepodległą Albanię. W drugiej wojnie bałkańskiej niezadowolona z jego wyniku Bułgaria, bez wypowiedzenia wojny zaatakowała Grecję i Serbię. W późniejszej fazie wojny (od lipca 1913) na Bułgarię uderzyły także Rumunia i Turcja. Zagrożona z czterech stron Bułgaria skapitulowała. Grecja uzyskała od Bułgarii południową część Macedonii z dużym portem Kawala. W tym samym roku Grecja przejmuje całkowitą kontrolę nad Kretą i większością wysp na Morzu Egejskim.
Na początku 1913 r. król Jerzy I Glücksburg oznajmił, że w 50. rocznicę objęcia tronu, w październiku, abdykuje na rzecz Konstantyna I Glücksburga. 18 marca król udał się w towarzystwie adiutanta na spacer do portu w Salonikach. W drodze powrotnej odwiedził kawiarnię, w której czekał uzbrojony szaleniec. Postrzelony w plecy król zmarł na miejscu, a zamachowiec został pochwycony (popełnił samobójstwo w czasie procesu).
W 1913 na tron wstąpił Konstantyn I Glücksburg, który w 1917 abdykował z powodu przystąpienia Grecji do państw ententy. 12 czerwca 1917 królem Grecji został Aleksander I. Zachęcony wynikiem wojny światowej premier Wenizelos doprowadza w 1919 roku do wojny z Turcją. 10 sierpnia 1920 r. w podparyskim Sèvres zostaje zawarty traktat pokojowy pomiędzy pokonaną Turcją a zwycięską Ententą. Na jego mocy Grecja odzyskała prawie całą Trację, jednakże bez stołecznego Konstantynopola. Ponadto uzyskała ona prawo do pięcioletniej okupacji greckojęzycznej części Jonii – rejonu Smyrny. Mocarstwa nałożyły na Grecję obowiązek dopuszczenia tam lokalnego parlamentu, który po pięciu latach miałby się wypowiedzieć o dalszej przynależności tego terytorium. 25 października 1920 umiera król Aleksander I, na tron powraca Konstantyn I Glücksburg. W 1922 abdykuje Konstantyn I Glücksburg, a na tron wstępuje Jerzy II Glücksburg.
Próba siłowego wprowadzenia "Wielkiej Idei" w życie i zdobycia Azji Mniejszej zakończyła się klęską armii greckiej oraz kolejnym, w ciągu kilku zaledwie lat, pogromem ludności helleńskiej zamieszkującej ten półwysep. 24 lipca 1923 podpisano Traktat pokojowy w szwajcarskiej Lozannie. Na jego mocy Grecja utraciła wschodnią część Tracji i oraz wszelkie prawa do terenów Azji Mniejszej. Pozostała przy niej jedynie zachodnia część Tracji. Z kolei Turcja zrzekała się wszelkich roszczeń do wysp Morza Egejskiego, poza wyspami Imroz i Tenedos oraz do Cypru. Granica państwa tureckiego przebiegać miała od tej chwili w odległości 3 km od Wybrzeży Azji Mniejszej. Nominalnie ten ustalony Traktatem w Lozannie przebieg grecko-tureckich granic obowiązuje do dziś, niemniej ostatnio Turcja kwestionuje granicę morską. W traktacie przewidziano także wymianę ludności pomiędzy Grecją i Turcją.
W wyniku tego postanowienia 1,5 miliona Greków zostało wysiedlonych z Turcji. Z Grecji zaś wyjechało 420 tysięcy Turków. W 1924 r. proklamowano Republikę.
Okres dyktatury generała Metaxasa, 1936-1940.
W okresie międzywojennym Grecja stanęła wobec wysiłku, związanego z koniecznością przyjęcia, ubrania, wyżywienia, pomieszczenia i zagospodarowania wielkiej rzeszy skrajnie biednych imigrantów. Na trudności te nałożył się także wielki kryzys. Toteż w 1935, z woli zmęczonych wyborców, przywrócono monarchię. Na tronie znów zasiadł Jerzy II Glücksburg. Po nierozstrzygniętych wyborach parlamentarnych 1936 r. król zainspirował wojskowy zamach stanu, blokując tym samym powstanie centro-lewicowego rządu koalicyjnego, w którego skład musiałaby wejść KPG. Generał Ioannis Metaxas zniósł demokrację parlamentarną i wprowadził dyktaturę. Rozwiązano partie polityczne i związki zawodowe, wprowadzono cenzurę (np. na mowę pogrzebową Peryklesa w „Wojnie Peloponeskiej” Tukidydesa), organizacja strajków stała się nielegalna. Większe strajki tłumiono zbrojnie, z ofiarami śmiertelnymi. Nastąpił okres brutalnych prześladowań części mniejszości etnicznych. Przez kolejne lata, poprzedzające oczekiwaną już włoską agresję, Grecja przybrała formę państwa totalitarnego. Posłużyło to do niemal skrytego, lecz starannego przygotowania obrony. Dyktator Ioannis Metaxas, deklarując faszystowską formę ustrojową kraju, opóźniał moment włoskiej agresji na Grecję. Wprowadzenie powszechnego przeszkolenia wojskowego młodzieży uzasadniał jej udziałem w faszystowskich organizacjach paramilitarnych. Represje wobec przeciwników politycznych nie były tak zbrodnicze, jak w pozostałych krajach faszystowskich. Dominował pragmatyzm, toteż do zwolnień i darowania wyroków, więźniom wystarczało opublikowanie pisemnego potępienia działalności „wywrotowej” lub „komunistycznej” (zobowiązanie lojalności). Po włoskiej agresji na Grecję, zwolniono i oddelegowano do wojska także prawie wszystkich pozostałych, więzionych komunistów.
Po raz pierwszy w Grecji wprowadzono obowiązkowe ubezpieczenia zdrowotne pracowników najemnych, zatrudnionych ze stałą umową o pracę. Zorganizowano w tym celu dominujący w Grecji do dziś Zakład Ubezpieczenia Społecznego (tzw. I.K.A.). IKA otwierała przychodnie i budowała szpitale. Do chwili wybuchu wojny, nie zdążyła jednak zmienić dramatycznej sytuacji zdrowotnej na prowincji państwa greckiego.
Lata 1936-1940, choć znaczone łamaniem praw obywatelskich, okazały się udane gospodarczo. Przy współpracy rządu, władz lokalnych i w dużym stopniu także Kościoła Greckiego, wykorzystując zaangażowanie przesiedleńców, szybko wzrastała produkcja przemysłowa i rolna. Grecka armia nabyła liczne, nowoczesne elementy uzbrojenia, w tym polskiej produkcji myśliwce PZL P.24, a grecki przemysł zbrojeniowy, za zgodą premiera Metaxasa, wydłużał serie produkcyjne, m.in. dostarczając nowoczesną artylerię republikańskiemu rządowi Hiszpanii, w Grecji uznawanemu ówcześnie za sprzyjający komunizmowi.
Lewicowa opozycja krytykowała okres dyktatury Metaxasa m.in. za płytkość i fasadowość reform socjalnych, połączone z rzeczywistym policyjnym terrorem, łamiącym nawet obowiązujące prawa faszystowskie i działającym wtedy w interesie pracodawców.
Wojskowi przeciwnicy polityczni Metaxasa wskazywali, że nawet w okresie nieuchronnie zbliżającego się starcia z Włochami i w trakcie mobilizacji, stanowiska dowódcze obsadzane były przede wszystkim według klucza przynależności politycznej, nie zaś kompetencji poszczególnych oficerów.
Grecja w II wojnie światowej.
Strefy okupacyjne.
Król udał się na emigrację, gdzie wyznaczył polityków, mających tworzyć rząd emigracyjny. Rząd ten pozostał bez zauważalnego wpływu na sytuację w kraju. Najeźdźcy podzielili Grecję na strefy: niemiecką, włoską i inkorporowaną do Bułgarii strefę bułgarską. Ludność żydowską deportowano do obozów śmierci. Wprowadzono obowiązek dostarczania kontyngentu żywnościowego do Rzeszy, toteż śmierć głodowa pochłonęła 300 tysięcy ofiar. Do tej tragedii walnie przyczyniła się także brytyjska blokada morska, uniemożliwiająca tradycyjny, duży import żywności, niezbędny Grekom, także w okresie pokoju. W strefach włoskiej i niemieckiej działał grecki rząd kolaboracyjny, jednak dysponowane przezeń zasoby żywności wystarczały na pokrycie 4% potrzeb. W efekcie powszechnego głodu, hiperinflacji i skrajnej spekulacji nastąpił szybki rozwój partyzantki, zwłaszcza jej lewicowej formacji Greckiego Ludowego Wojska Wyzwoleńczego (ELAS) i z dużym wpływem komunistów. Gorliwą kolaborację i drastyczne formy spekulacji partyzanci karali śmiercią. Skutecznie podjęli wyzwalanie znacznych obszarów państwa spod wszelkiej władzy okupacyjnej. Niemcy zastosowali taktykę kłócenia Greków pomiędzy sobą. Rząd kolaboracyjny utworzył antypartyzanckie siły zbrojne Bataliony Bezpieczeństwa, składające przysięgę wierności Hitlerowi i armii niemieckiej. Jednocześnie Niemcy wspomagali bojówki, złożone z lokalnych faszystów, następnie przekształcane w pomocnicze wobec Niemców oddziały zbrojne, z licznym udziałem w nich mniejszości narodowych i kulturowych. Niemcy tworzyli też odrębne oddziały mniejszości, wykorzystywane następnie do pacyfikowania buntującej się ludności greckiej. Najlepiej zaopatrzona żywnościowo, jednak najciężej dotknięta krwawymi represjami, była grecka ludność zaboru bułgarskiego.
Liczne włoskie oddziały okupacyjne współpracowały z ruchem oporu. W 1943 partyzanci przejęli nawet całość wyposażenia dwóch włoskich dywizji. Jeden z greckich oddziałów partyzanckich, utworzono głównie ze Ślązaków – dezerterów z niemieckiej armii.
Objawem rabunkowej eksploatacji Grecji przez okupantów był m.in. gigantyczna inflacja. Przykładowo, ceny chleba zmieniały się następująco:
Wskaźnik kosztów utrzymania, od kwietnia 1941 do października 1944, wzrósł o 230 598 491 – 100%.
Ugrupowania ruchu oporu 1941-1944.
Skupiały się wokół kilku obozów, niekiedy współdziałających w walce, częściej ścierających się:
Działalność ELAS.
ELAS ("Ελληνικός Λαϊκός Απελευθερωτικός Στρατός – Ellinikos Laikos Aeleftherotikos Stratos" – wierny przekład: "Greckie Ludowe Wyzwoleńcze Wojsko"). stanowiły oddziały o niejednorodnym pochodzeniu politycznym, lewicowe, wrogie monarchii, z dużym udziałem komunistów, jednak nie komunistyczne, jak się to często, acz błędnie uważa. „Elasites” stawiali cel wyzwolenia Grecji, a następnie zapewnienia jej republikańskiego ustroju, demokracji i suwerenności państwowej oraz przeprowadzenie reformy państwa, przypisującej mu funkcje socjalne, dziś uważane za naturalne w każdym państw Europy. Dokument założycielski określał, że oprócz wyzwolenia kraju, celem ELAS jest "Zapewnienie porządku i bezpieczeństwa do momentu przeprowadzenia wyborów, w których lud wyrazi w sposób nieskrępowany swą wolę". Już w 1943 roku to ELAS, a nie okupanci, faktycznie kontrolował dużą część terytorium Grecji. Na zajmowanych terenach, partyzanci organizowali tzw. ludowe państwo EAM-ELAS. Partyzantka ELAS, mimo że podporządkowana EAM i jego rządowi, w 1943 r. przyjęła też formalną podległość wojskowemu dowództwu sił sprzymierzonych, następnie kilkakrotnie formalnie potwierdzając ten status, a przez cały okres okupacji była też ich rzeczywistym sojusznikiem. Partyzanci ELAS pozostawali w opozycji wobec króla i królewskiego rządu na wychodźstwie, jako nie posiadających demokratycznej legitymizacji. Mogli też liczyć na przyszłą wrogość ZSRR i Wielkiej Brytanii, jako mocarstw, zainteresowanych podziałem Bałkanów pomiędzy siebie, z czego na ogół, nie zdawano sobie wtedy sprawy.
"Jesienią 1944 r. Oddziały ELAS liczyły ok. 75 tys. leśnych partyzantów i ok. 44 tys. rezerwistów – także partyzantów, biorących udział w akcjach oddziału, zamieszkujących w swych domach. Dysponowały artylerią polową – ponad stu działami i moździerzami. Istniała też kilkakrotnie liczniejsza od partyzantów grupa bojowników zakonspirowanych i niezgrupowanych w oddziałach. ELAS powołał też ELAN – marynarkę wojenną", z udziałem 1200 marynarzy, kontrolujących większość małych portów i patrolujących większość greckich wybrzeży, z około 100 bojowymi jednostkami pływającymi, O łącznym tonażu 4.000 DWT, czasem specjalnie w tym celu zbudowanymi, w trakcie okupacji.
O sile zdolności bojowej ELAS świadczy m.in. protokół zdawczy głównej części uzbrojenia ELAS:
"działa różnych typów – 100 szt.; ciężkie moździerze – 81 szt.; lekkie moździerze – 138 szt.; ciężkie karabiny maszynowe – 419 szt.; ręczne karabiny maszynowe – 1412 szt.; pistolety maszynowe – 1412 szt.; karabiny samopowtarzalne – 713 szt.; karabiny i pistolety – 48 973 szt.; ręczna broń przeciwpancerna – 57 szt.; radiostacje – 17 szt."
„Partyzanckie państwo” lewicy i republikanów.
Liczna i bitna partyzantka uniemożliwiła okupantom kontrolę większej części prowincji. Na wyzwolonych terenach, poza kontrolowanym przez rojalistów Epirem, tworzono partyzancką republikę, nieuznającą królewskiego rządu emigracyjnego, jako pozbawionego demokratycznej legitymizacji. Na zajmowanych terenach, partyzanci zorganizowali tzw. ludowe państwo EAM-ELAS, powołując samorząd terytorialny, „Ludowy Aparat Sprawiedliwości” z sądami ludowymi, składającymi się z pięciu sędziów, obieralnych przez zgromadzenia miejscowości, przyjęto przy tym zasadę nadrzędności decyzji sądów ludowych, nad wolą dowódcy wojskowego ELAS, w sprawach wykroczeń cywilnych, co następnie doprowadziło do przyjęcia zasady, że organ wojskowy (partyzanci) lub polityczny (EAM) może pełnić rolę oskarżyciela, jednak nie sędziego, działalność Sądów Ludowych (Λαϊκα Δικαστήρια) była skodyfikowana. Stymulowano życie ekonomiczne i realizowano praktycznie równouprawnienie kobiet. Organy „ludowego państwa” zreformowały oświatę, egalitarnie traktujac mniejszości językowe i blisko współpracując z mniejszością słowiańską. Podjęto organizację pierwszej w Grecji powszechnej oświaty przedszkolnej, pierwszej na prowincji publicznej służby zdrowia i sprawnego systemu łączności. Po wcieleniu lub eliminacji pomniejszych organizacji wojskowych, na początku 1944, w rejonach górskich sformowano, wyłoniony w demokratycznych wyborach, lewicowy rząd tymczasowy, pod nazwą PEEA (ΠΕΕΑ) – Polityczny Komitet Narodowego Wyzwolenia, konkurencyjny do emigracyjnego, uznawanego przez aliantów, jednak ze słabym poparciem w kraju. Zrealizowano wybory do 180-osobowego organu ustawodawczego, w którego pracy i głosowaniach mogli brać udział także posłowie ostatniego greckiego parlamentu, tj. rozwiązanego w 1936 r. Wydarzenia te bywają przez lewicę określane jako "„Ludowe Państwo EAM-ELAS”". Czołowi badacze wysoko oceniają ówczesną popularność realizacji tego programu i w jej wyniku poparcie dla ELAS, na greckiej prowincji.
Dla rojalistów "„Ludowe państwo EAM-ELAS”" stanowiło "„komunistyczną dyktaturę”". Współpraca z instytucjami „rządu z gór”, po wojnie traktowana była przez rojalistyczne sądy, jako ciężkie przestępstwo kryminalne. Za przestępstwo kryminalne, powojenne sądy uznawały też wszelkie akcje partyzanckie lewicy i republikanów, niezlecone im uprzednio przez sztab aliantów.
Po wycofaniu się Niemców, w Grecji wylądowały wojska brytyjskie oraz królewskie oddziały armii greckiej. W myśl wcześniejszych umów to oni odbyli triumfalny wjazd do stolicy, jako jej wyzwoliciele. Przywódcy lewicy oraz lewicowi partyzanci, ówcześnie nie posiadali wiedzy, o podpisanych na Kremlu tajnych porozumieniach, pomiędzy Winstonem Churchillem a Józefem Stalinem składającym losy Grecji, a więc domyślnie także los partyzantów, w ręce Wielkiej Brytanii.
Okres po II wojnie światowej.
W myśl wcześniejszych uzgodnień, utworzono koalicyjny rząd. Rząd ten rozpadł się w początkach grudnia 1944, wskutek bojkotu wobec sześciu ministrów, pochodzących z EAM. Bezpośrednim powodem było wyjście zeń ministrów EAM, nie godzących się na bezwarunkowe rozbrojenie ELAS i bez uzgodnionego wcześniej, jednoczesnego rozbrojenia także wszystkich innych ugrupowań.
Powstanie "„Dekemvriana”" w Atenach.
3 i 4 grudnia 1944, po zmasakrowaniu lewicowych demonstracji, według niektórych historyków bez wyjaśnionych do dziś przyczyn, ostrzelanych przez siły różnych formacji, uprzednio kolaboracyjnych i przy tym jawnie współpracujących z "SS" przez cały 1944 rok wybuchły gwałtowne, 35-dniowe walki w Atenach zapowiadając niebezpieczeństwo przyszłej, długotrwałej wojny domowej. Już 5 grudnia Winston Churchill zlecił brytyjskiemu dowódcy w Atenach potraktowanie stolicy Grecji jak zbuntowanego miasta wroga, a nie miasta sojuszniczego. Z wielkim trudem, używając także oddziałów byłych greckich hitlerowców, ściągając posiłki z Włoch oraz używając w mieście brygad komandosów, czołgów i bombardując robotnicze dzielnice stolicy Grecji z artylerii okrętowej i samolotów, wojska brytyjskie zdołały opanować sytuację. Walki przerywane były negocjacjami, w których uczestniczył nawet premier Wielkiej Brytanii Winston Churchill. W styczniu 1945 lewica musiała pogodzić się z porażką, partyzanci wycofali się z Aten. Ze swej strony sir Winston Churchill zdecydował o opóźnieniu powrotu do Grecji protegowanego przez Wielką Brytanię monarchy greckiego Jerzego II, do czasu odbycia referendum o ustroju. Otworzyło to drogę do porozumienia zgody narodowej, podpisanego 12 lutego 1945 r. w Warkizie. Zostało ono jednak tylko częściowo zrealizowane przez partyzantów – oddziały ELAS, z nielicznymi wyjątkami, rozeszły się do domów, uprzednio przekazując Brytyjczykom posiadane uzbrojenie, w tym całą broń ciężką, jednak prawdopodobnie zachowując znaczną część broni osobistej, co ówcześnie było na prowincji naturalne. Porozumienia nie realizowała także strona rządowa, gdyż już w kilka tygodni po podpisaniu umowy z Warkizy rozpoczęto masowe prześladowania członków byłego ruchu oporu ELAS.
Wojna domowa.
Na mocy porozumienia z Warkizy ELAS i inne ruchy partyzanckie zostały rozwiązane. W kraju przeprowadzono wybory powszechne (marzec 1946), co jednak odbyło się w atmosferze głębokiego terroru osobistego oraz urzędowych prześladowań wobec byłych uczestników lewicowego ruchu partyzanckiego ELAS. W szczególności w dniu przeprowadzenia wyborów, w więzieniach przebywało około , spośród co najmniej 80 tysięcy aresztowanych od chwili umowy z Warkizy, podejrzewanych o udział w lewicowym ruchu oporu. 767 biur i punktów informacyjnych lewicy EAM zostało uprzednio napadniętych i zdewastowanych. Okres pomiędzy starciami w Atenach a ponownym wybuchem walk partyzanckich, określany jest w greckiej historiografii mianem „białego terroru”; pojęciem tym posługują się również polscy autorzy "Historii Grecji". Komuniści wezwali do bojkotu urn, sukces odniosły siły rojalistyczne, reprezentowane przez Partię Ludową. Premierem zostaje lider tej partii Konstandinos Tsaldaris (bratanek Panajotisa Tsaldarisa). 1 września 1946 w wyniku ogólnonarodowego plebiscytu, w dalszym ciągu, w atmosferze terroru nastąpiła restauracja monarchii. 27 września 1946 r. król powrócił na tron, w kwietniu 1947 Jerzy II Glücksburg umiera, a jego następcą został brat, Paweł I Glücksburg.
Formalnie działały jeszcze lewicowe partie polityczne, w tym KPG. Część lewicy schodzi do podziemia, zwłaszcza dziesiątki tysięcy prześladowanych, masowo aresztowanych i następnie torturowanych partyzantów byłego ruchu ELAS. W październiku 1947 komuniści utworzyli ideowe siły zbrojne. Spośród kombatantów ruchu oporu, ukrywających się przed nową falą prześladowań, już jesienią 1945 roku powstawały pierwsze oddziały partyzanckie. Na razie nie podejmujące innej walki niż samoobrona. Komuniści przekształcają je następnie w ideowo-komunistyczne Demokratyczne Wojsko Grecji (DSE) – dowódca gen. Markos Wafiadis, które w 1948 r. liczyło ponad 26 000 żołnierzy zorganizowanych w 9 dywizjach i mniejszych jednostkach. Liczba ta była jednak nieporównywalnie mała w porównaniu z dawnymi siłami ELAS, w skład których wchodziło 119 tys. partyzantów i rezerwistów. Armia rządowa została uzbrojona przez Brytyjczyków. Od 1947 zadania zaopatrywania armii rządowej przejęli Amerykanie działający w myśl doktryny Trumana. Oddziały królewskie osiągnęły stan ponad 180 tys. żołnierzy i policjantów, w tym byłych żołnierzy i oficerów hitlerowskich Batalionów Bezpieczeństwa.
Pod koniec 1947 powstańcy, panujący nad północnymi terenami Grecji, sformowali tam ponownie rząd tymczasowy (pierwszy, partyzancki rząd tymczasowy centrolewicy istniał już za okupacji). Aż do tego momentu partyzanci byli postrzegani przez centrum i szeroką lewicę, jako kombatanci ruchu oporu, walczący o podstawowe prawa obywatelskie, o rzeczywistą demokrację i o suwerenność. Powołanie wyłącznie komunistów do drugiego rządu tymczasowego zakończyło ten idealistyczny okres postrzegania DSE. W początkach 1948 roku komuniści kontrolowali już większą część terytorium Grecji, jednak bez dużych miast. Od II połowy 1948 roku silniejsza i znacznie lepiej uzbrojona armia rządowa (lotnictwo, artyleria, ścisła blokada brzegów morskich) zaczęła odnosić sukcesy, wypierając komunistyczną partyzantkę w coraz bardziej w górzyste tereny. Po odcięciu dróg zaopatrzenia wiodących z Jugosławii (po poparciu przez KKE Stalina w konflikcie z Tito) oraz po wysiedleniu przez armię rządową około 800 tysięcy ludności cywilnej, z terenów zagrożonych walkami, komuniści znaleźli się w bardzo trudnej sytuacji. Po kolejny, przegranych bitwach, w masywach gór na Witsi i Grammos, w których przewaga armii rządowej była już co najmniej 10-krotna, komuniści zadecydowali o przerwaniu walk. Dopiero wtedy partia pozwoliła partyzantom udać się na emigrację, nieraz całymi rodzinami, wywieziono też wiele małych dzieci. W wyniku wojny domowej zginęło ponad 70 000 żołnierzy obu stron i ludności cywilnej. M.in. straty armii rządowej wyniosły 12 777 zabitych (w tym 1032 oficerów), 4527 zaginionych, 27 000 rannych.
Około 12,5-14 tysięcy spośród tych emigrantów osiedliło się w Polsce. Polska wspierała grecką partyzantkę, dostarczając materiałów opatrunkowych oraz organizując transport materiału wojennego, drogą morską, przekazywanego Grekom przez Komintern. Ponadto dla ciężko rannych greckich partyzantów, zorganizowano tajny szpital wojskowy w Dziwnowie na wyspie Wolin oraz zaopiekowano się ok. 3.050 małymi sierotami. Grecka strona rządowa, na forum organizacji międzynarodowych, utrzymywała, że chodzi o dzieci uprowadzone za granicę, porywane przez obce osoby. Szczęśliwie, już wkrótce po wojnie, większa część spośród sierot greckich w Polsce odnalazła jednego, lub oboje swych biologicznych rodziców, wśród emigrantów politycznych – partyzantów DSE. Na terenach swej dominacji DSE wspierało działalność kulturalną i edukacyjną, w tym także aktywność słowiańskojęzycznej mniejszości. Rojaliści przedstawiali tę okoliczność jako akt zdrady narodowej.
Obozy koncentracyjne.
W latach 1947–1950 osobom niewygodnym – kombatantom ruchu oporu, także cywilom i nieprzychylnym monarchii żołnierzom wojsk królewskich, stawiano zarzut pozostawania pod wpływem komuznizmu, po czym umieszczano ich w nowo tworzonych obozach koncentracyjnych. W największym z nich, na wyspie Makronisos, w latach 1947–1950 więziono łącznie 1100 oficerów zawodowych i rezerwistów – kombatantów ELAS i 27 tys. niższych stopniem bojowników ELAS, DSE i żołnierzy królewskich. Jednak największą grupę więźniów, liczącą ok. 30 tys. osób stanowili cywile, w tym kobiety i dzieci, kierowani tu decyzjami administracyjnymi. Większość więźniów zmuszano do wyczerpującej pracy fizycznej, w palącym słońcu i zwykle bezużytecznej. Planowo i systematycznie popełniano zbrodnie.
W latach 1967–1974 część obozów otwarto ponownie.

</doc>
<doc id="12997" url="https://pl.wikipedia.org/wiki?curid=12997" title="Falset">
Falset

Falset – (z ) "fistuła" – zwyczajowo mianem falsetu określa się rodzaj wysokiego głosu męskiego o groteskowym brzmieniu. Faktycznie oznacza jednak śpiew na niedomkniętych strunach głosowych zarówno u mężczyzn, jak i u kobiet. Realizowany jest poprzez silne, nienaturalne napięcie strun głosowych, przez co drgają w krótszej niż odpowiednia dla danego dźwięku długości, powodując wydobycie dźwięku o niewielkiej dynamice oraz charakterystycznej nosowej barwie. Nazwa pochodzi od włoskiego "falso" – „fałszywe”.
Falset spotykany jest coraz częściej w muzyce rozrywkowej, ale również w muzyce operowej oraz w folklorze muzycznym (na przykład jodłowanie w Szwajcarii i Tyrolu).
Męski falset często mylony jest z kontratenorem, który posiada naturalne, zbliżone do kobiecego głosu brzmienie.

</doc>
<doc id="12998" url="https://pl.wikipedia.org/wiki?curid=12998" title="Rodzaje zabezpieczeń zamkniętego oprogramowania">
Rodzaje zabezpieczeń zamkniętego oprogramowania



</doc>
<doc id="13001" url="https://pl.wikipedia.org/wiki?curid=13001" title="Kultura minojska">
Kultura minojska

Kultura minojska, kultura kreteńska – jedna z najstarszych cywilizacji epoki brązu w obszarze Morza Śródziemnego. Odkryta i poznana dokładniej na początku XX wieku dzięki pracom wykopaliskowym prowadzonym przez archeologa Arthura Evansa w Knossos. Zaczęła kształtować się około 3000 p.n.e. na wyspie Krecie, szczyt rozwoju osiągnęła w tzw. okresie młodszych pałaców (ok. 1675–1450 p.n.e.).
Minojczycy prowadzili handel z wyspami Morza Egejskiego, Grecją kontynentalną oraz z lepiej rozwiniętymi cywilizacjami Bliskiego Wschodu, które stały się także źródłem technologii, inspiracji w sztuce i rzemiośle. Minojskie miasta skupione były wokół wielkich pałaców (największe znaleziono w Knossos, Fajstos, Malii i Kato Zakros), które były nie tylko siedzibą władcy, ale też centrum wytwórczym, magazynem, ośrodkiem kultu. Kreteńczycy posługiwali się kilkoma rodzajami pisma, m.in. pismem linearnym A, które stało się później podstawą dla stworzonego przez Mykeńczyków pisma linearnego B. Z Mykeńczykami byli też silnie spokrewnieni genetycznie. Kryzys cywilizacji minojskiej zapoczątkowały katastrofy naturalne XVI wieku p.n.e. – trzęsienie ziemi i wybuch wulkanu na wyspie Thira (koniec XVI wieku p.n.e. lub ok. 1645/1628 p.n.e.). Osłabiona wyspa około 1450 p.n.e. padła ofiarą najazdu Mykeńczyków, którzy zniszczyli większość pałaców.
Do najważniejszych zabytków zalicza się pałac w Knossos (zwany też pałacem Minosa), związany z mitem o Minotaurze, pochodzący z okresu 2000–1570 p.n.e. Pałac pozbawiony jest fortyfikacji, co by wskazywało na okres względnego pokoju, a także na hegemonię tej kultury w tym rejonie.
Chronologia.
Chronologia dziejów cywilizacji minojskiej oparta jest o badania archeologiczne ceramiki. Podstawowy system został stworzony przez Arthura Evansa i rozwinięty później przez innych badaczy. Jego podobne wersje stosowane są także dla innych cywilizacji kultury egejskiej. Zakłada on podział dziejów cywilizacji Krety w epoce brązu na trzy okresy: wczesnominojski, średniominojski i późnominojski (od angielskich skrótów oznaczanych EM, MM i LM). Okresy te podzielono w wyniku dalszych badań na mniejsze jednostki. Datowanie zależne jest od tego, czy przyjmiemy chronologię niską lub wysoką (rozbieżności pomiędzy chronologiami dotyczą wątpliwości co do daty wybuchu wulkanu na Thirze).
Poniżej podano daty (wraz z podokresami) dla chronologii niskiej (wysoka w nawiasach):
Do celów periodyzacji dziejów Krety stosowany jest też system pałacowy, opierający się o fazy istnienia minojskich pałaców:
Miasta Krety minojskiej.
Prace wykopaliskowe potwierdziły przekazy Homera o stu miastach na Krecie. Do największych należały Knossos, Fajstos, Hagia Triada i Malia. W całości odkopane miasto nadbrzeżne Gurnia (1500 p.n.e.) liczyło około tysiąca mieszkańców. Żadne z odkopanych miast nie miało murów obronnych, znaleziono też niewiele broni.
Okresy w historii kultury minojskiej.
Przedpałacowy 3000 p.n.e. – 2000 p.n.e..
W tym okresie wytwarzano małe figurki postaci ludzkich wykonywane z gliny, kamienia, czasem kości słoniowej lub muszli. Były to postacie schematyczne, ukazane w pozycjach statycznych.
Cylindryczne pieczęcie zdobione wzorami geometrycznymi, najczęściej spiralami, używane były do znakowania wyrobów oraz własności prywatnych. Wykonywano ozdoby ze złotych blaszek. Ceramikę zdobiły malowane, proste elementy geometryczne.
Osady składały się z domów wznoszonych na planie prostokąta, budowanych z suszonej cegły na kamiennej podmurówce. Domy były podobne do siebie i ściśle do siebie przylegały. Były jakby „posklejane” ze sobą stanowiąc pomieszczenia jednego wielkiego domostwa-osady.
W połowie III tysiąclecia p.n.e. w dolinie Messara pojawiły się najstarsze groby tolosowe, służące jako miejsce pochówku całych rodzin. Przez lata pochowano w nich dziesiątki zmarłych. Przed grobowcami stawiano ołtarze, na których były odprawiane ceremonie ku czci zmarłych.
Starszych pałaców 2000 p.n.e. – 1700 p.n.e..
Powstały pozbawione murów obronnych, otwarte miasta: Knossos, Fajstos, Hagia Triada, Malia, Gurnia. Zabudowa miast była zwarta. Domy zewnętrzne, w dolnych partiach były pozbawione okien i drzwi. Stanowiły jakby mur obronny.
Powstały pałace w Knossos, Fajstos i Malia. Nie posiadały murów obronnych. Wznosiły się wśród miejskiej zabudowy. W bezpośrednim ich sąsiedztwie pobudowane były domy wysokich urzędników, piętrowe z balkonami. Pałace były siedzibą władcy oraz centrami życia społecznego, politycznego i gospodarczego. Znajdowały się w nich magazyny żywności, składy surowcowe i warsztaty rzemieślnicze. Na potrzeby administracji pałacowej wymyślono pismo linearne A. Przykładem są znaki tego pisma pokrywające dysk z pałacu w Fajstos.
Jest to okres dynamicznego rozwoju sztuki minojskiej. Nadal wytwarzano małe figurki postaci ludzkich, ale tym razem starano się przedstawić je realistycznie. Nadal jednak postaci są statyczne. Realistycznie przedstawiano postaci ludzkie na pieczęciach i naczyniach ceramicznych. W odróżnieniu od figurek, postaci na pieczęciach lub ceramice na ogół znajdują się w ruchu (np. w tańcu, podczas pracy). Dopiero w XVII wieku p.n.e. figurki przedstawione są w pozach „zatrzymanego ruchu”.
Oprócz grobów tolosowych były również groby izbowe, przypominające kształtem prostokątne izby typowych mieszkań. Niektóre z nich miały nawet brukowane otoczenie. Największe miały wymiary 40 × 30 m i otaczano je kolumnadą, zaś ich wnętrza składały się z mniejszych pomieszczeń.
Charakterystyczna dla tego okresu jest pięknie zdobiona ceramika kamaresowa, której nazwa pochodzi od groty Kamares koło Fajstos, będącej pierwszym miejscem jej znalezienia. Produkowano cienkościenne wazy, dzbany i inne naczynia. Dekorowano je bogatymi ornamentami o żywej kolorystyce. Dekoracje malowane były na ciemnym tle w kolorze białym, żółtym, czerwonym, brązowym. Artyści chętnie zestawiali kontrastowe kolory, a ornamenty tworzyli z prostych elementów geometrycznych i stylizowanych motywów roślinnych. Do wyjątków należą przedstawienia figuralne. Dekoracja była tak komponowana, aby podkreślić kształt naczynia. Rzadziej spotykana w tym okresie była ceramika zwana w archeologii "egg shell" („skorupka jaja”). Są to maleńkie czarki o bardzo cienkich ściankach.
Z nieznanych przyczyn w roku 1700 p.n.e. pałace zostały gruntownie zniszczone. Istnieją różne teorie na temat przyczyny zniszczeń. Najbardziej prawdopodobne jest, że zniszczenia były wywołane przez ogromny wybuch wulkanu na wyspie Santorini, który był połączony z trzęsieniem ziemi.
Młodszych pałaców 1700 p.n.e. – 1400 p.n.e..
Nastąpiła szybka odbudowa pałaców. Na ich ścianach pojawiły się niespotykane dotąd duże freski. Malarstwo minojskie było pod silnym wpływem malarstwa egipskiego, zarówno pod względem tematyki, jak i techniki wykonania. Jest to malarstwo naturalistyczne, wiernie odtwarzające naturę. Nie jest to naturalizm w dzisiejszym rozumieniu, stosowanie barw ma charakter często umowny (małpki w kolorze niebieskim). Malowano sceny z życia dworu, uroczystości świeckie i religijne. Do rzadkości należą przedstawienia scen związanych z prowadzonymi wojnami.
Tendencje realizmu w rzeźbie pogłębiły się. Figurki datowane na XVI – XV wiek przedstawiają ludzi w ruchu poprzez wygięcie ciała, ułożenie rąk. Figurki kobiet ubrane są w tzw. stroje dworskie. Ubiór składał się z szerokiej spódnicy i obcisłego kaftanika odsłaniającego piersi. Są to postacie kapłanek lub wyobrażenia boginek. Figurki nadal wykonywano z gliny, fajansu, kości słoniowej oraz brązu.
Pojawiły się kamienne naczynia. Były to wazy zdobione reliefami, oraz rytony (naczynia libacyjne).
W tym czasie Kreta utrzymywała częste kontakty handlowe z Egiptem, Ugarit i Byblos, nie były to jednak kontakty stałe. W 1550 p.n.e. na Melos Kreteńczycy założyli faktorię Filakopi. Stała się ona ośrodkiem handlu z Cykladami.
Popałacowy 1400 p.n.e. – 1100 p.n.e..
w XV stuleciu p.n.e. nastąpiły zmiany motywów dekoracyjnych w ceramice:
Gospodarka.
Terminy, którymi określa się cywilizację minojską, to: cywilizacja pałacowa (pałac był siedzibą władcy oraz centrum życia społecznego, politycznego i gospodarczego, a zarazem magazynem żywności i surowców oraz ich dystrybucji) oraz talassokracja (określenie na dominację Krety na morzu).
Jednak u podstaw twierdzenia o talassokracji legły przekazy mityczne. Na nich oparli swe przekazy Herodot i Tukidydes. Ich relacje właściwie były interpretacją mitów, dlatego część współczesnych badaczy kwestionuje pogląd o panowaniu Kreteńczyków na morzu. Wskazują oni na następujące realia gospodarcze ówczesnego świata:
Tak więc obrót towarowy ze światem zewnętrznym był dla Krety ważny, ale w całokształcie jej ekonomiki stanowił margines. Poglądy o talassokracji minojskiej powstały pod wpływem wiedzy o mechanizmach gospodarki nowożytnej (popartej mitami), przeniesionych w odległą przeszłość, gdy realia gospodarcze były zupełnie inne (ale nie wiemy dokładnie jakie).
Z drugiej strony wpływy kultury minojskiej sięgały na północy wybrzeży Peloponezu, Attyki i Eubei, Itaki, Kefallenii, na wschodzie – Azji Mniejszej (późniejszej Jonii) i Rodos, a na zachodzie – Sycylii i Kalabrii, a do tak rozległych kontaktów potrzebna była flota. Dominacja Krety jest poświadczona w mitach greckich, m.in. o Tezeuszu, o Dedalu. Podczas gdy Mykeńczycy w Grecji lądowej oraz mieszkańcy Cyklad budowali fortyfikacje, na Krecie wszystkie miasta były otwarte, choć wyspy były zamieszkałe i dochodziło między nimi do konfliktów, więc bezpieczeństwo Kreteńczyków mogło się opierać na silnej flocie.

</doc>
<doc id="13004" url="https://pl.wikipedia.org/wiki?curid=13004" title="Zarządzanie prawami cyfrowymi">
Zarządzanie prawami cyfrowymi

Zarządzanie prawami cyfrowymi (z ang. digital rights management, DRM) – system zabezpieczeń oparty na mechanizmach kryptograficznych lub innych metodach ukrywania treści mający przeciwdziałać używaniu danych w formacie elektronicznym w sposób sprzeczny z wolą ich wydawcy.
W założeniu mechanizm taki ma służyć ochronie praw autorskich twórców, w praktyce może być wykorzystany do dowolnego ograniczenia możliwości korzystania z danych w systemach komputerowych i multimedialnych. DRM jest szczególnym przypadkiem systemu zarządzania prawami do informacji (IRM), stosowanego także do ochrony informacji objętych różnymi formami utajnienia.
Podstawy działania.
W spotykanych obecnie systemach DRM, dostawca treści, zanim przekaże dane odbiorcy, zabezpiecza je przed odczytem przez zaszyfrowanie (lub zastosowanie innej transformacji mającej na celu utrudnienie odtworzenia pierwotnej postaci pliku). Informacje niezbędne do odszyfrowania danych nie są ujawniane odbiorcy, a jedynie zaszyte w odpowiednio zaprojektowanej aplikacji lub platformie sprzętowej (np. komputerze PC z układami TCPA albo w odtwarzaczu multimedialnym).
Dzięki wykorzystaniu tej architektury, dostawca może wymusić na użytkowniku niedysponującym odpowiednim zapleczem technicznym dowolnie zdefiniowane zasady korzystania z dostarczonych treści (np. może ograniczyć liczbę wykonywanych kopii, pozbawić go możliwości modyfikacji danych), czy wręcz odebrać użytkownikowi jakiekolwiek możliwości odczytu treści po upływie zadanego czasu.
Skuteczność stosowania.
Współcześnie używane mechanizmy DRM stanowią skuteczną metodę ograniczania działań przeciętnych użytkowników komputera lub systemu multimedialnego. Mimo to niemal wszystkie z nich okazują się podatne na ataki ze względu na wyidealizowane założenia technologiczne, błędy projektowe albo usterki programistyczne; taki los spotkał mechanizmy stosowane w nośnikach DVD, Blu-ray, HD-DVD i wiele innych. Przełamanie tych mechanizmów ma różnego rodzaju skutki, na przykład umożliwia kopiowanie danych czy też tworzenie odtwarzaczy open source dla nośników multimedialnych.
Ze względu na podatność stosowanych rozwiązań na próby przełamania zabezpieczeń, producenci systemów DRM często starają się ograniczyć badanie systemów DRM oraz publikowanie informacji o błędach w nich przez stosowanie gróźb prawnych, ale działania te z reguły okazują się nieskuteczne. Prawdopodobnie najbardziej znaną sprawą tego typu był proces rozpoczęty na wniosek DVD Copy Control Association i Motion Picture Association przeciwko Norwegowi Jonowi Johansenowi za złamanie zabezpieczeń Content Scrambling System płyt DVD; w 2003 sąd w Oslo uniewinnił Johansena. Innym głośnym przypadkiem było zatrzymanie w Stanach Zjednoczonych rosyjskiego programisty Dmirtija Szklarowa, którego po wielomiesięcznym pobycie w areszcie ostatecznie nie oskarżono przed sądem za ominięcie mechanizmów DRM w plikach PDF.
W wielu krajach, grupy związane z dostawcami treści lobbują za zaostrzeniem przepisów i zakazaniem publikowania informacji o błędach w systemach DRM.
Dziura analogowa.
Poważnym problemem, z którym borykają się technologie DRM jest brak możliwości kontroli danych na wyjściach analogowych z urządzenia (złącza słuchawkowe, video), gdzie możliwe byłoby podłączenie urządzeń rejestrujących i utworzenie nowej kopii cyfrowej o stosunkowo wysokiej jakości. Aby uchronić się przed takimi atakami, wyjścia wysokiej jakości implementowane są coraz częściej z wykorzystaniem technologii cyfrowych z wbudowanym DRM (np. HDMI z HDCP); zaś odtwarzanie treści przez złącza analogowe lub w przypadku wykrycia nieautoryzowanego podłączenia cyfrowego odbywa się przy znacznej degradacji jakości sygnału.
Idąc krok dalej, system operacyjny Windows Vista podczas odtwarzania utworów zabezpieczonych przez WMDRM z włączoną opcją PVP obniża jakość chronionego sygnału wyjściowego na monitorach oraz złączach audio, z których zabezpieczony utwór mógłby zostać nagrany. Ta funkcja budzi wiele zastrzeżeń ze strony części ekspertów, w tym Petera Gutmanna, ponieważ oznacza, że pewne produkty będą znacząco dyskryminowane przez system operacyjny, jeśli ich producent nie uiści opłat za certyfikację.
Kontrowersje.
Technologie DRM stały się przedmiotem znaczącej kontrowersji. Zdaniem części dostawców treści, korzystanie z takich rozwiązań jest koniecznością w celu ochrony dochodów twórców w dobie piractwa elektronicznego i sieci P2P. Krytycy, z Free Software Foundation i Electronic Frontier Foundation na czele, uważają jednak, że nieuczciwie odbierają im kontrolę nad własnymi komputerami oraz ograniczają ustawowe prawa do korzystania z treści w celu wygenerowania dodatkowych zysków.
Podstawowym zarzutem wobec systemów DRM jest fakt, że stosowane są często nie tyle do ochrony praw autorskich, co jako metoda arbitralnego, potencjalnie bezprawnego ograniczenia przywilejów konsumenckich, np. przez uniemożliwienie wykonywania prywatnych kopii zakupionych utworów, czy, jak np. w przypadku płyt DVD, utrudnienie korzystania z utworów w określonych rejonach geograficznych, uniemożliwienie przewinięcia reklam i obwieszczeń poprzedzających film (patrz Content Scrambling System). Klienci, którzy przekonani są, że nabywają pełnowartościową kopię utworu i będą mogli wykorzystać ją w pełnym zakresie dozwolonym przez prawo, mogą więc czuć się w związku z tym wprowadzeni w błąd.
W pewnych przypadkach, oprogramowanie DRM dostarczane jest bez wiedzy i zgody użytkownika, jak miało to miejsce m.in. w przypadku płyt CD Sony: niektóre wyprodukowane przez tę firmę płyty kompaktowe z muzyką instalowały w systemie Windows bez wiedzy użytkownika oprogramowanie typu rootkit, równocześnie – ze względu na błędy programistyczne – znacznie obniżając poziom bezpieczeństwa systemu. Sprawa ta zakończyła się serią procesów, także z urzędu oraz wieloma ugodami sądowymi na niekorzyść firmy. Oprogramowanie takie może też po prostu bez wiedzy użytkownika ograniczać sposoby, na jakie może on prywatnie korzystać z posiadanego urządzenia.
Zintegrowane układy wspierające DRM oraz współpracujące z nim oprogramowanie są w ostatnich latach rutynowo instalowane w masowo produkowanych komputerach, a docelowo miałyby znaleźć się na każdej platformie produkowanej przez szerokie konsorcjum dostawców – co budzi wątpliwości dotyczące możliwości dokonywania swobodnego, świadomego wyboru przez potencjalnych nabywców.
Krytyka technologii DRM posunęła się w środowiskach FLOSS tak daleko, że w szkicu trzeciej wersji licencji GNU GPL znalazł się nawet kontrowersyjny (i krytykowany przez Linusa Torvaldsa) punkt zabraniający wykorzystywania oprogramowania na tej licencji w systemach DRM. Należy odnotować jednak, że istnieją mniej restrykcyjne formy DRM (np. FairPlay).
DRM przez przeciwników nazywany bywa digital restrictions management – „cyfrowe zarządzanie ograniczeniami”.
Kampanie przeciwko DRM.
Przeciwko DRM wypowiadają się obecnie też sprzedawcy oprogramowania. Przykładowo GOG.com rozpoczął kampanię FCK DRM. Są również inne - np. przeciwko stosowaniu DRM przez firmę HP.
Inne zastosowania.
Wspierany sprzętowo DRM (w oparciu o TCPA i Palladium) jest rozważany jako mechanizm do nadzorowania obiegu dokumentów w firmach. W takim rozwiązaniu autor lub pracodawca może ograniczyć możliwość drukowania lub przesyłania wybranych, poufnych plików. Technologia ta określana jest jako E-DRM ("Enterprise DRM") lub IRM ("Information Rights Management").

</doc>
<doc id="13005" url="https://pl.wikipedia.org/wiki?curid=13005" title="Imiesłów">
Imiesłów

Imiesłów (łac. "participium") – nieosobowa forma czasownika mająca cechy składniowe i fleksyjne przymiotnika. W języku polskim istnieją również imiesłowy o funkcji zbliżonej do przysłówka (imiesłowy przysłówkowe). Imiesłów jest przykładem kategorii gramatycznej, która znajduje się na granicy fleksji i derywacji.
Imiesłów w języku polskim.
Imiesłów w języku polskim zakłada tożsamość agensa imiesłowu i orzeczenia (stąd zdanie "Usiadłszy na ławeczce lunął deszcz" jest bezsensowne).
Dzieli on znaczenie leksykalne z czasownikiem, od którego jest utworzony. Dziedziczy po nim również ramę walencyjną, por.
"Janek dał Basi pierścionek – (Janek) dający Basi pierścionek", 
a także zachowuje aspekt. Ma on natomiast dystrybucję taką, jak przymiotniki: "migocąca lampa – wyłączona lampa – jasna lampa", stanowiąc przydawkę, oraz, podobnie jak przymiotniki, odmienia się przez przypadki, rodzaje i liczbę. Nie przysługuje mu natomiast kategoria stopnia.
Przymiotnikowy.
Końcówki imiesłowów przymiotnikowych czynnych
Końcówki imiesłowów przymiotnikowych biernych
Imiesłów przymiotnikowy może w zdaniu pełnić rolę przydawki lub orzecznika.
Przysłówkowy.
Imiesłów przysłówkowy współczesny – informuje o czynności odbywającej się jednocześnie z czynnością wyrażoną czasownikiem; tworzony jest tylko od czasowników niedokonanych za pomocą zakończenia „-ąc”, np. "czytając, wołając, idąc"
Imiesłów przysłówkowy uprzedni – nazywa czynność wcześniejszą od tej wyrażanej przez orzeczenie; tworzony jest tylko od czasowników dokonanych za pomocą końcówki: „-wszy”, „-łszy”, np. "zrobiwszy", "poszedłszy"
Ortografia i interpunkcja.
Dawniej „nie” z tymi imiesłowami pisane było prawie zawsze oddzielnie. Działo się tak, jeśli dany imiesłów miał cechy czasownika, np. „nie zamknięte drzwi”. Odstępstwo od tej reguły mogło nastąpić wyłącznie, gdy dany imiesłów pełnił wyraźną funkcję przymiotnika i oznaczał cechę, np. „niepomalowany stół”. Zdarzało się często, że pewien imiesłów mógł mieć znaczenie i czasownikowe, i przymiotnikowe. Wtedy prawidłowa była podwójna pisownia, np. „Nie palący pracownicy idą z nami” (ci, którzy teraz nie palą) oraz „Mam niepalącego wujka” (w ogóle nie pali).
9 grudnia 1997 roku Rada Języka Polskiego wydała uchwałę, zgodnie z którą, od 1 stycznia 1998 roku, imiesłowy przymiotnikowe z partykułą „nie” powinno się (co do zasady) pisać łącznie. Działanie to miało na celu wyeliminowanie błędów ortograficznych popełnianych przez większość społeczeństwa. Wzbudziło to jednak liczne obawy i krytykę; zarzucano przede wszystkim, że zmiana w konwencjach ortograficznych uczyni język polski uboższym i uniemożliwi łatwe rozróżnianie funkcji czasownikowej od przymiotnikowej, np. we wyrażeniach „Rada Nieustająca” i „nie ustający deszcz”. Członek Rady Języka Polskiego, prof. dr hab. Jerzy Podracki argumentował jednak, że „nie jest łatwo i prosto (nawet dla specjalisty) odróżnić w użyciach imiesłowów przymiotnikowych znaczenie przymiotnikowe od czasownikowego, dlatego wprowadzono nową uproszczoną regułę ortograficzną”.
Wyżej wymieniona uchwała z 9 grudnia 1997 zawiera następujące stwierdzenie: 
Wynika z niego, że można bez przeszkód stosować się także do starych zasad ortograficznych, jeśli tylko czyni się to poprawnie i konsekwentnie. Przyzwyczajenia części społeczeństwa i potrzeba rozróżniania funkcji czasownikowej i przymiotnikowej spowodowały, że w języku naukowym i literackim nadal można spotkać starą zasadę pisowni.
Imiesłów w językach nowożytnych.
W języku angielskim funkcję imiesłowu przymiotnikowego czynnego pełni forma Present Participle, czyli czasownik z końcówką -ing ("a speeding car –" „pędzący samochód”). Ta sama forma może także pełnić rolę imiesłowu przysłówkowego współczesnego ("she stood in the hallway smiling innocently" – „stała w korytarzu, uśmiechając się z miną niewiniątka”).
Imiesłów przysłówkowy uprzedni w języku angielskim przybiera formę złożoną z czasownika pomocniczego "to have" w formie Present Participle ("having") oraz czasownika właściwego w formie Past Participle ("having finished she sat back down on the sofa –" „skończywszy, usiadła z powrotem na sofie”).
Funkcję imiesłowu przymiotnikowego biernego pełni forma Past Participle, czyli czasownik regularny z końcówką -ed lub trzecia forma czasownika nieregularnego ("a tortured look –" „udręczone spojrzenie”; "a broken glass" – „stłuczona szklanka”).
W języku niemieckim, aby utworzyć od czasownika imiesłów czynny należy dodać do bezokolicznika końcówkę "-d". Imiesłowem biernym jest III forma czasownika.

</doc>
<doc id="13006" url="https://pl.wikipedia.org/wiki?curid=13006" title="Kultura mykeńska">
Kultura mykeńska

Kultura (cywilizacja) mykeńska (ok. 1700/1600 – 1150 p.n.e.) – najstarsza greckojęzyczna kultura rozwijająca się w późnej epoce brązu na terenie Grecji kontynentalnej (stopniowo rozprzestrzeniła się na inne obszary regionu egejskiego), ostatnia faza kultury helladzkiej. 
Nazwa pochodzi od ważnego ośrodka tej cywilizacji – Myken w Argolidzie. Szczyt jej rozwoju nastąpił w tzw. okresie pałacowym, kiedy rozległe pałace mykeńskie stały się ośrodkami władzy, kultu i centrami gospodarczymi. Kulturę tę poznano dokładniej dopiero pod koniec XIX wieku dzięki pracom wykopaliskowym prowadzonym przez archeologa Heinricha Schliemanna w 1874 roku, a później przez jego następców.
Periodyzacja.
Najczęściej wyróżnia się trzy (różnie nazywane) fazy rozwoju kultury mykeńskiej:
Zarys historyczny.
Achajowie ("Achajoi") pojawili się w Grecji w XVI wieku p.n.e. Ich pochodzenie nie jest znane. W połowie XV w. p.n.e. podbili Kretę (a przynajmniej Knossos), przejmując zdobycze cywilizacji minojskiej – m.in. pismo linearne B zdradzające podobieństwo do pisma linearnego A. Zapisywanie języka Achajów w sylabicznym systemie (samogłoski i sylaby otwarte) pisma linearnego B sprawiało spore kłopoty, co stanowi dodatkowy dowód zapożyczenia od ludu niegreckiego. Pismem tym Achajowie posługiwali się wyłącznie w celach administracyjnych.
W XIV w. p.n.e. zbudowano pierwsze pałace obronne. Powstały one w Atenach i Tirynsie. W następnym stuleciu (XIII) pałace wzniesiono w Mykenach, Pylos, Gla i Tebach. Były one siedzibami władców noszących tytuł „wanaks”, będąc tym samym ośrodkami władzy, kultury, rzemiosła i handlu. Rzemieślnicy wytwarzali dobra luksusowe i broń. Przedmiotami luksusowymi handlowano. Handel zewnętrzny organizowany był wyłącznie przez władców. Zajmowali się nim wyznaczeni przez wanaksów pośrednicy, gdyż kupców samodzielnie prowadzących handel nie było. Eksportowano ceramikę, naczynia z brązu, oliwę i tkaniny. Domostwa rzemieślników skupiały się wokół pałacu. Poza warsztatami pałacowymi i służebnymi istniały również warsztaty miejskie produkujące na potrzeby miasta w którym odbywał się drobny handel wewnętrzny. W miastach mykeńskich rozwijały się przede wszystkim warsztaty kowalskie, kamieniarskie, garncarskie, złotnicze i inne, a rzemieślnicy zajmowali się zarazem produkcją jak i sprzedażą produktów na lokalnym rynku. Importowano miedź, cynę, złoto, srebro, kość słoniową i bursztyn. Wieś okresu mykeńskiego tworzyły w dużym stopniu społeczności samowystarczalne. Jednak bliskość rozwiniętych ośrodków rzemieślniczo-handlowych stwarzała warunki do tworzenia się relacji gospodarczych pomiędzy miastem a wsią. Podstawowe narzędzia pracy, tkaniny i ubrania rolnicy w dużej mierze wytwarzali sami i nabywali oni tylko te produkty z miasta, których wieś nie posiadała. Ponieważ właścicielem ziemi był wanaks, użytkujący ją mieszkańcy miast i okolicznych wsi uiszczali mu daninę. Mykeńscy, szlachetnie urodzeni właściciele ziemscy, podobnie jak pozostali mieszkańcy, mogli podlegać zobowiązaniom typu "feudalnego". Była to sytuacja w której urzędnicy, przywódcy wojskowi, żołnierze, rzemieślnicy i rolnicy posiadali ziemię pod warunkiem, że świadczyli oni odpowiednie usługi.. Mykeny przez wiele wieków były najważniejszym ośrodkiem władzy, wywierającym wpływ na Beocję, Attykę i Tesalię. O pozycji ich decydował fakt, że dzięki dostępowi do morza utrzymywały szerokie kontakty handlowe.
Upadek.
Do upadku cywilizacji mykeńskiej doprowadziła inwazja tzw. Ludów Morza (ok. 1200 r. p.n.e.), a następnie najazdy plemienia Dorów (ok. 1100 r. p.n.e.).
Około roku 1200 p.n.e. „Ludy Morza” zniszczyły państwo Hetytów i zrujnowały centra handlowe w Syrii, przerywając tym samym dostawy do Grecji mykeńskiej złota, srebra, kości słoniowej i bursztynu. Najdotkliwsze było odcięcie dostaw miedzi i cyny, niezbędnych do wytopu brązu wykorzystywanego do produkcji broni. Środki utrzymania pałaców skurczyły się. Podstawy materialne władzy wanaksów uległy zachwianiu. Nasiliły się wojny między „państwami pałacowymi”, których celem przestało być zdobycie sławy i zwierzchnictwa; teraz stały się sposobem pozyskania deficytowych dóbr poprzez łupienie przeciwnika. Wiele pałaców było niszczonych, odbudowywanych, a po kilku latach znowu niszczonych. Mykeny i Tiryns burzono trzykrotnie, pozostałe ośrodki pałacowe niszczono w różnych odstępach czasu. Rzemieślnicze „osady pałacowe” zostały opuszczone, rzemiosło upadło, handel zamarł. Całkowicie zaniechano budowania grobów kopułowych – miejsc pochówku wanaksów. Na tronach władców zaszły gwałtowne zmiany. W Tirynsie utracił władzę Diomedes; następca Achillesa, Neoptolemos władający Ftyją, został wygnany z kraju i uciekł do Epiru. Wyludniła się Lakonia i żyzna Messenia. Proces upadku trwał kilka pokoleń.
Sytuacja ta zachęciła Dorów do powrotu na Peloponez. W 1150 p.n.e. Kleodajos na czele Dorów wyruszył na Mykeny, lecz poniósł klęskę na Przesmyku Korynckim. Po dwudziestu latach, w roku 1130 p.n.e. Arystomachos ponownie powiódł Dorów przeciwko Mykenom. Również i on został pokonany na Istmie. Trzydzieści lat później Temenos i Kresfontes zwyciężyli wanaksa Myken – Tisamenosa. Dorowie zajęli Argolidę, Lakonię i Messenię.
Wieki ciemne.
Po tych wydarzeniach nastąpił okres nazywany wiekami ciemnymi. Był to okres kryzysu w rolnictwie i zmniejszenia się areału upraw winorośli i oliwki. Nastąpił częściowy nawrót do pasterstwa. Wyposażenie grobów z tej epoki było skromne i pozbawione cennych kruszców. 
Nie wszędzie jednak doszło do zupełnego upadku. Wykopaliska z Attyki i wyspy Eubei wskazują na dość dobrą sytuację ekonomiczną i utrzymanie wymiany handlowej z Egiptem, Syrią i Cyprem. Mykeńskie budownictwo monumentalne zachowało się w Jolkos i na Naksos. Czołowymi ośrodkami politycznymi były Ateny, Argos i Kreta. Jedynym typem osadnictwa pozostały osady wiejskie. Nawet ówczesne Ateny czy Argos były dużymi osadami, ale nie były miastami – pojawią się one dopiero w połowie VIII w. p.n.e. z nastaniem nowego okresu w dziejach starożytnej Grecji. Wkrótce w Atenach pojawia się dekoracyjna ceramika „geometryczna”, a wyposażenie pochówków wskazuje na powolny wzrost zamożności. Ceramika wykonywana na obrotowym kole garncarskim stała się poszukiwanym produktem eksportowym Grecji w okresie „wieków ciemnych”.
Również w tym okresie dokonał się inny zwrot w cywilizacji technicznej Greków – upowszechnienie żelaza. Było ono znane Achajom, jednak dostatek miedzi i cyny powodował, że używano łatwiejszego w wytopie brązu, z którego wytwarzano broń, naczynia i ozdoby. Z rud żelaza otrzymywano jedynie gąbczastą surówkę, z której możliwe było wykuwanie tylko drobnych przedmiotów; większe (siekiery, miecze, sztylety) były lichej jakości, gorsze od wykonanych z brązu, wskutek czego broń żelazna służyła do ozdoby, nie do walki. Dopiero niedostatek cyny i miedzi wymusił udoskonalenie techniki obróbki żelaza.
W okresie „wieków ciemnych” zaczęła się kształtować religia właściwa późniejszej Grecji klasycznej. Z okresu mykeńskiego znamy (tylko z nazwy) imiona takich bóstw jak: Posidaeja, Diwija, Pajawon, Pani Labiryntu, Pani na koniu, Pani ze szczytów, Pipituna, Eleutia, Mater Theia, Manasa, Drimios, Dipsioi, Enuualios. Naczelnym bóstwem był Posejdon. Znana była Hera, Artemida, Atena, Ares i Dionizos. Zeus był bóstwem drugorzędnym.
Gospodarka Grecji mykeńskiej.
Głównym centrum był pałac, który kierował produkcją i handlem. Ważne miejsce w gospodarce zajmowało rolnictwo; na istnienie pewnych nadwyżek wskazuje obecność spichlerzy. Ponieważ właścicielem ziemi był wanaks, istniały dwa rodzaje użytkowania ziemi przez poddanych:
Poza rolnictwem rozwijało się również rzemiosło nastawione na eksport. Odkrycie w Barbati na Peloponezie wielkiego centrum produkcji ceramiki, w Mykenach ośrodka, w którym koncentrował się eksport oliwy oraz produkcja mebli – daje wyobrażenie o możliwościach ekonomicznych Grecji mykeńskiej. Zasięg handlu wyznaczają znaleziska zabytków kultury materialnej Myken, napotykanych od Sycylii po Egipt i Syrię.
Społeczeństwo epoki mykeńskiej.
W społeczeństwie mykeńskim władza i ziemia należała do króla z tytułem "wanaks", obok zaś niego stał dowódca wojskowy "lawagetas" (z greckiego ‘wojsko’ i ‘prowadzić’). Wanaks nadawał w użytkowanie działki ziemi swym przybocznym towarzyszom ("hequetai"), w zamian za co obowiązani byli oni do służby wojskowej. Część z nich walczyła na rydwanach; w czasie pokoju dbali o konie i rydwany będące własnością wanaksa. Inni "hequetai" dowodzili oddziałami pieszymi. Ścisłej grupy urzędniczej nie było, ponieważ nie istniał system biurokratyczny. W razie potrzeby władca wybierał odpowiednie osoby spośród "hequetai" i zlecał im wykonanie określonych zadań. W takich warunkach nie wykształciła się jeszcze znana z późniejszych wieków arystokracja. Najniżej w społeczeństwie stali niewolnicy – "douloi", choć byli oni nieliczni i trudno wskazać istotne różnice w statusie pomiędzy nimi a ludźmi wolnymi.
Mykeńczycy byli mocno spokrewnieni z Minojczykami, których cywilizacja rozkwitała na Krecie pomiędzy 3000 a 1400 rokiem przed Chrystusem.

</doc>
<doc id="13008" url="https://pl.wikipedia.org/wiki?curid=13008" title="Kreatywna księgowość">
Kreatywna księgowość

Kreatywna księgowość (ang. "creative accounting") – rejestrowanie, ewidencjonowanie, przetwarzanie i prezentowanie zdarzeń gospodarczych z wykorzystaniem obowiązujących przepisów i właściwie interpretowanych zasad rachunkowości w sposób, który nie jest bezpośrednio w tych przepisach wskazany, a który jest wynikiem zastosowania pomysłowego, twórczego i niestandardowego podejścia do tych przepisów i zasad.
Rachunkowość kreatywna oznacza działania zgodne z szeroko rozumianym prawem (tj. karnym, cywilnym, gospodarczym, a w szczególności „bilansowym”) i w konsekwencji sama w sobie nie jest pojęciem wartościującym.
Agresywna księgowość.
Agresywna księgowość (rachunkowość) to świadome, zamierzone i celowe prowadzenie rejestracji, ewidencji, przetwarzanie i prezentacja zdarzeń gospodarczych w sposób sprzeczny z przepisami lub przy niewłaściwie i tendencyjnie interpretowanych przepisach oraz zasadach rachunkowości, które może zaszkodzić użytkownikom informacji księgowych poprzez przedstawienie innej (lepszej lub gorszej) niż rzeczywista sytuacji ekonomicznej jednostki.
Ocena zjawiska.
Określenie zyskało popularność w związku z ujawnionymi przypadkami nieprawidłowości księgowych, które wystąpiły w niektórych korporacjach międzynarodowych.
Należy zauważyć, że termin kreatywna księgowość nie jest określeniem wartościującym i nie jest jednoznaczny ze zjawiskiem łamania przepisów prawa.

</doc>
<doc id="13009" url="https://pl.wikipedia.org/wiki?curid=13009" title="Laptop">
Laptop

Laptop (z ang. "lap" - kolana, podołek + "top" - wierzch), notebook (z ang. "notebook", notatnik, zeszyt) – rodzaj przenośnego komputera osobistego. 
Do podtypów laptopów można zaliczyć ultrabooki i netbooki. Urządzeniami mniejszymi od laptopów są tablety i smartfony, które również są przenośnymi komputerami, choć nie są zgodne z IBM PC.
Historia.
Początkowo istniał umowny podział komputerów przenośnych na "laptop" (większy i cięższy komputer, który wymagał do działania zewnętrznego zasilania) oraz "notebook" (mniejszy komputer, łatwy do przenoszenia i mający własne źródło zasilania – pierwotnie rozmiarów notatnika formatu A4, stąd nazwa). W chwili obecnej obydwa te określenia funkcjonują wymiennie.
Pierwszym urządzeniem z tej kategorii był DYNABOOK. Jego projekt stworzył Alan Kay w laboratoriach Xerox Parc.
Pierwszym oferowanym komercyjnie laptopem, który mieścił się w torbie, był Grid Compass Computer 1109. W roku 1979 zaprojektował go William Moggridge dla Grid Systems Corporation. Komputer ten był używany w programie NASA dotyczącym promów kosmicznych we wczesnych latach 80. Komputer miał 340 kilobajtów RAM, obudowę ze stopu magnezu oraz podświetlany wyświetlacz. W Stanach Zjednoczonych kosztował ponad 8000 dolarów. Urządzenie nie było kompatybilne z IBM PC, dlatego też nie utrzymało się na rynku.
Obecnie w sprzedaży znajdują się laptopy kompatybilne z architekturą Intel x86, z procesorami Intela, VIA i AMD. Układy x86 stosowane są również w notebookach Apple. Inne architektury wykorzystywane są sporadycznie: IBM w serii RS/6000 oraz Apple (do 2006) używało układów PowerPC. Na rynku netbooków, mniejszych kuzynów laptopów, pojawiają się też urządzenia z procesorami ARM.
Budowa.
Laptopy są zbudowane przeważnie jako pojedyncze, niewielkie zamykane urządzenia, w których znajdują się wszystkie podzespoły wewnętrzne, wybrane wejścia dla nośników (DVD-ROM, USB), złącza (HDMI, D-Sub) urządzenia komunikacji z użytkownikiem (klawiatura, ekran TFT oraz TrackPoint lub touchpad). Ekran notebooka jest wykonany w technologii TFT o rozmiarze 7–21 cali (część laptopów o przekątnych poniżej 12 cali jest nazywana netbookami). Wszystkie obecnie produkowane laptopy są wyposażone w ekrany panoramiczne (zwykle o proporcjach 16:9). Najpopularniejsze laptopy mają ekrany o przekątnej 15,6" (1366 × 768 px) oraz 17.3" (1600 × 900 px lub 1920 × 1080 px – Full HD). Matryce o wyższych rozdzielczościach, zapewniające lepszy komfort pracy, stosowane są w laptopach wyższej klasy. Klawiatury laptopów są wyposażone w dodatkowy klawisz funkcyjny – Fn.
Laptopy mają wewnętrzne akumulatory pozwalające na kilka godzin pracy bez napięcia sieciowego (w popularnych urządzeniach zwykle ok. 2-3 godzin, w najwyższej jakości laptopach po uruchomieniu wszystkich opcji oszczędzania nawet 8 godzin). Obecnie stosowane są akumulatory litowo-jonowe (rzadziej litowo-polimerowe). Zewnętrzne zasilacze umożliwiają pracę oraz ładowanie akumulatorów z sieci elektrycznej. Istnieją także ładowarki podłączane do gniazda zapalniczki w samochodzie i samolocie.
Masa współczesnego laptopa waha się zazwyczaj w granicach od 1 do 4 kilogramów. Notebooki mniejsze od kartki formatu A4 i ważące około 1 kg określa się mianem netbooka, a te cięższe, ważące około 5 kg – DTR (ang. "desktop replacement computer", czyli zastępczy komputer biurkowy).

</doc>
<doc id="13010" url="https://pl.wikipedia.org/wiki?curid=13010" title="Dyskietka">
Dyskietka

Dyskietka, inaczej dysk miękki () – dysk wymienny, przenośny nośnik magnetyczny o niewielkiej pojemności, umożliwiający zarówno odczyt, jak i zapis danych. Nośnikiem danych jest wirujący krążek z wytrzymałego tworzywa sztucznego (najczęściej mylaru – politereftalanu etylenu w postaci cienkiej folii) pokryty warstwą magnetyczną. Średnica krążka oraz ilość możliwych do zapisania danych stanowią podstawowe parametry dyskietki.
Polska nazwa "dyskietka" została prawdopodobnie zaproponowana przez Jana Bieleckiego. Niektórzy (m.in. autorzy książki o komputerze Elwro 800 Junior) uważali, że bardziej poprawną formą jest "dysketka" z racji tego, że jest to słowo z języka francuskiego.
W drugiej dekadzie XXI wieku dyskietki zostały niemal wyparte przez pamięci USB i pamięci flash, które cechują jeszcze mniejsze rozmiary i znacznie większa pojemność. Dyskietki nadal są wykorzystywane przez niektóre siły zbrojne oraz powszechnie w starszych maszynach przemysłowych jak obrabiarki CNC, maszyny hafciarskie itp.
Historia.
Jako pierwsze pojawiły się dyskietki 8-calowe. Następnie zaczęto stosować dyskietki 5¼-cala o pojemności 360 kB (DD – podwójna gęstość; bardzo często ówczesne napędy potrafiły formatować na 180 kB lub nawet mniej), a następnie 1,2 MB (HD – wysoka gęstość; istniały programy, które potrafiły formatować je na 1,4 lub nawet 1,6 MB). Miały miękką obudowę, nie było zamknięcia otworu odczytu – należało je przechowywać w papierowych kopertach. Miały jednak tę zaletę, że po wycięciu otworu zezwalającego na zapis można było używać obu ich stron w napędach jednostronnych. Zabezpieczenie przed zapisem polegało na zaklejeniu nieprzezroczystym kawałkiem taśmy samoprzylepnej wycięcia z boku dyskietki. Mniej popularne były inne dyskietki – 3-calowe stosowane w komputerach firmy Amstrad i 2,5-calowe w pierwszych komputerach przenośnych.
W komputerach klasy PC do niedawna najpowszechniej używane były dyskietki 3,5-calowe HD (High Density) o pojemności 1,44 MB (megabajt był tutaj jednostką mieszaną – 1000×1024, a dyskietki te miały pojemność 1440 kB), na których można było zapisać do 1,37 MB danych. Dyskietka taka składa się z twardej plastikowej obudowy z otworem dostępowym do nośnika zasuwanym sprężynowo metalową (później plastikową) zasuwką. Konstrukcja ta powstała z wcześniej używanych dyskietek identycznej budowy mechanicznej DD (Double Density) o pojemności 720 kB, powszechnie używanych w komputerach klasy Amiga (komputer ten stosuje system plików pozwalający na zapis 880 kB, modele wyposażone w stacje HD zapisują na dyskietkach 1,76 MB) oraz Atari ST (dyskietki DD mogą mieć 946 176 bajtów oraz format zgodny z PC, natomiast HD może mieć maksymalną pojemność 1 892 352 bajtów). Rozwinięciem tej konstrukcji jest standard dyskietek ED (Extra Density) 2,88 MB (dla Atari ST dostępne były napędy ED zapewniające odpowiednio większe pojemności), ale nie przyjął się, m.in. z powodu konkurencji ze znacznie bardziej pojemnymi dyskietkami napędów typu ZIP czy JAZ. Powodów nie przyjęcia ED mogło być więcej – m.in. w momencie wdrożenia do produkcji stacje dyskietek 1,44 były już bardzo popularne, natomiast ówczesne kontrolery dyskietek obsługiwały przepustowość ok. 500 kb/s. Stacja dyskietek 2,88 wymaga 1 Mb/s, co oznaczałoby konieczność zakupu/instalacji nowych kontrolerów. Z racji małej popularności cena dyskietki też była kilkukrotnie (a nie np. dwukrotnie) wyższa. Z powodu ceny dyskietek i kosztów kontrolerów, stacji powstawało „błędne koło” – mała popularność. Zachowana jest za to kompatybilność wsteczna.
Niektóre programy wymagały bardzo wielu dyskietek, przykładowo na kompletną wersję oprogramowania opisanego jako „Tax” w pewnym momencie składało się 58 dyskietek. Jedna z wersji Slackware Linux wymagała 33 dyskietek. Niektórzy twierdzą, że na życzenie jednego z klientów posiadającego dość mocny, ale stary komputer, dostarczono system operacyjny Windows XP na ponad 250 dyskietkach.
Współcześnie dyskietki wyszły z powszechnego użycia, jednakże są jeszcze dalej produkowane w niewielkich ilościach. Używane są przeważnie w starszych komputerach typu PC, Apple Macintosh, Amiga i Atari. Z uwagi na niewielką pojemność, zostały wyparte przez nowocześniejsze nośniki pamięci, takie jak płyty CD, DVD oraz ich odpowiedniki wielokrotnego zapisu, przenośne dyski twarde, pamięć półprzewodnikową typu flash, wbudowaną w karty pamięci, a także pamięci USB (pendrive) oraz odtwarzacze MP3. Obecnie stacje dyskietek nie są już montowane w laptopach ani w stacjonarnych komputerach osobistych. W komputerach Macintosh zaprzestano montowania stacji dysków już w 1998, od modelu iMac.
Istnieją też zewnętrzne urządzenia do odczytu dyskietek podłączane kablem do komputera, zazwyczaj przez port USB.
Współczesne urządzenia do masowego kopiowania dyskietek czy robienia kopii dyskietek na dysku twardym nie wymagają wielu stacji dyskietek.
Zakończenie produkcji.
Firma Sony produkowała 3,5-calowe dyskietki od 1981, a ich rekordową sprzedaż zanotowała w 2002, gdy nabywców znalazło ponad 47 mln sztuk. Od tamtego czasu sprzedaż malała, aż do wielkości 12 mln dyskietek w 2009. W tym samym roku Sony zaprzestała produkcji napędów do tego typu nośników. Oceniano wówczas, że z magnetycznych nośników danych korzystają jeszcze użytkownicy przestarzałego sprzętu w środowisku akademickim oraz w oświacie.
Firma Verbatim w 2009 roku nadal produkowała 3,5-calowe dyskietki, oceniając popyt w tym czasie na 50 milionów sztuk rocznie. Badania firmy wskazywały, że ten rodzaj pamięci przenośnej wciąż był wymagany przez użytkowników sprzętu starego typu, jak instrumenty klawiszowe czy maszyny przemysłowe. Dyskietki były też wykorzystywane w samolotach starszego typu, np. Boeing 737. Istniały aparaty fotograficzne wykorzystujące dyskietki (zamiast lub obok kart pamięci), np. dyskietki 3,5, Sony FD Mavica MVC-FD97. Firma prognozowała utrzymanie się popytu na dyskietki 3,5-calowe na stałym poziomie jeszcze przez pewien czas.
W 2009 zaprzestały produkcji dyskietek firmy Hitachi Maxell i Mitsubishi Kagaku Media. W kwietniu 2010 firma Sony, jedna z największych spośród producentów dyskietek magnetycznych, zaczęła wycofywać je z rynku i ogłosiła zakończenie sprzedaży dyskietek na rynku japońskim w przyszłym roku. Przed 2010 sprzedaży dyskietek zaprzestano już w wielu krajach, a na początku 2011 dyskietki Sony zniknęły ostatecznie z rynku japońskiego. Przedstawiciele koncernu uzasadniali decyzję spadkiem zapotrzebowania.
Co najmniej w 2011 roku produkowano jeszcze dyskietki 3,5 DD, z racji wykorzystywania ich w maszynach przemysłowych (często nie obsługują one formatu HD lub nie potrzebują z racji wielkości plików). Dodatkowo w teorii takie dyskietki mogą być bardziej trwałe i lepsze do namagnesowania przez stację dyskietek DD od dyskietek HD..
Nadal jednak istnieją firmy (jak Athana), które są w stanie wyprodukować dyskietki na zamówienie lub wydać gry czy inne programy na dyskietkach (popularnych – od 8 cali przez 5,25 do 3,5). Poza tym zajmują się sprzedażą detaliczną dyskietek i taśm do komputerów (jak np. Odra czy Riad).
Możliwości odczytu w nowszych urządzeniach.
Dyskietkę można odczytać (za pomocą np. stacji na USB) w smartfonie i w popularnych, współczesnych systemach operacyjnych – np. smartfon czy tablet z Androidem (wymaga OTG).
Istnieją projekty stacji (a właściwie przelotki) USB – 5,25 cala.
Organizacja danych.
Najmniejszą fizyczną ilością danych jaką można zapisać i odczytać z dyskietki jest sektor. Jego pojemność informacyjna wynosi w większości systemów plików 512 bajtów. Przed każdym sektorem zapisywane są dane synchronizacyjne i informacyjne oraz suma kontrolna. Informacje te są niedostępne dla użytkownika – wykorzystywane są przez kontroler dysku oraz mechanizmy korekcji błędów.
Logiczną jednostką zapisu danych na dyskietkach jest klaster (ang. cluster), zwany także czasami "JAP", czyli Jednostką Alokacji Pliku. W odróżnieniu od dysków twardych, na dyskietce klaster ograniczony jest do maksymalnie dwóch sektorów (1024 bajty), aczkolwiek istniały programy pozwalające obejść to ograniczenie.
Cały nośnik podzielony jest na ścieżki (ang. track), których liczba zależy od formatu i zazwyczaj wynosi 40 lub 80, choć niektóre napędy umożliwiały zapisane kilka ścieżek ponad standard (komputery zgodne z Atari ST zapisują do 83 ścieżek). Ścieżka, w zależności od typu dysku, może składać się z 8 lub nawet 36 sektorów. Dla przykładu dyskietka w gęstości HD zgodna z MS/DR-DOS zawiera 18 sektorów na ścieżce. Każda ścieżka składa się z dodatkowych znaczników, które oznaczają początek (BOT) i koniec ścieżki (EOT).
Dyskietki wymagają procesu zwanego "formatowaniem nośnika". Podczas formatowania powierzchnia nośnika zostaje podzielona na ścieżki i sektory poprzez zapisanie na niej przebiegu synchronizującego, danych informacyjnych oraz testowych danych w sektorach. Dane te są wykorzystywane do sprawdzenia poprawności formatowania. Zapisywane są też dane systemowe. Pełne formatowane wiąże się z utratą danych.
Dyskietka z wbudowaną kartą pamięci.
Z racji wykorzystywania dyskietek w niektórych kamerach Sony Mavica jako nośnika danych, opracowano adapter umożliwiający wykorzystanie kart pamięci Memory Stick. Adapter o wymiarach dyskietki, zasilany bateryjnie, można było wykorzystać też w komputerach. Wymagało to zainstalowania sterowników, ale pozwalało na odczytywanie danych bez użycia czytnika kart pamięci. Istnieje także możliwość włożenia karty SD do dyskietki 3,5″ i po odpowiednim odgięciu styków złącza kabla stacji dyskietek 5.25 cala, użycie go wraz z czytnikiem kart SD na magistrali USB (elementy umieszczone w obudowie stacji dyskietek 3.5 cala) z niej jako „dyskietki” o dużej pojemności.
Zobacz też.
Popularne firmy z branży nośników pamięci:

</doc>
<doc id="13011" url="https://pl.wikipedia.org/wiki?curid=13011" title="Przymiotnik">
Przymiotnik

Przymiotnik – część mowy określająca cechy istot żywych, rzeczy, zjawisk, pojęć i stanów. Nazwa wywodzi się od słowa „przymiot” – czyli "cecha", "właściwość", która określa właściwości dostrzegalne ludzkimi zmysłami oraz pozazmysłowe, wywnioskowane z zachowania istot żywych bądź właściwości przedmiotów. W przypadku zjawisk czy pojęć przymiotniki mogą mieć także charakter abstrakcyjny.
Klasyfikacja i podział.
Stosowana w przeszłości definicja przymiotnika jako części mowy odpowiadającej w mianowniku liczby pojedynczej na pytania: "jaki? jaka? jakie?" (a także – "czyj? czyja? czyje? który? która? które?") obecnie uznana została za nieprecyzyjną, niepoprawną logicznie, przydatną jedynie w celach dydaktycznych. Podstawą zaliczenia jakiegoś wyrazu do przymiotników nie jest bowiem fakt "odpowiadania" przez niego na określone pytanie, lecz "funkcja", jaką pełni on w języku.
Przymiotnikami nazywana jest pewna klasa wyrazów, wyróżniana w oparciu o następujące kryteria:
Kryteria słowotwórcze i fleksyjne są często określane wspólną nazwą "kryteriów morfologicznych".
W języku polskim, aby dany wyraz mógł być zaliczony do przymiotników, powinien on:
(funkcje pierwszorzędne – prymarne);
(funkcje drugorzędne – sekundarne);
Przymiotnik jest więc zasadniczo wyrazem odmiennym i autosyntagmatycznym (tzn. samodzielnym składniowo – może spełniać zarówno funkcję składnika wypowiedzenia, jak i sam stanowić równoważnik zdania). Odnosząc się do cechy, czyli pewnego elementu rzeczywistości pozajęzykowej, przymiotnik stanowi także wyraz samodzielny znaczeniowo (samodzielnie znaczący, samoznaczący, autosemantyczny, pełnoznaczny).
Sytuacja idealna występuje wówczas, gdy wyraz spełnia wszystkie podane
kryteria. Wówczas jego przynależność do przymiotników nie budzi żadnych wątpliwości,
np. "chory, zdrowy, bogaty, biedny" itp. Często jednak zalicza się do przymiotników
także wyrazy spełniające tylko część podanych kryteriów.
W języku polskim wyróżniano dawniej cztery następujące grupy przymiotników:
Ten podział przymiotników jest nadal stosowany, lecz uznawany za niepełny.
Ostatnio w wielu nowych opracowaniach gramatycznych wszystkie wyżej wymienione
kryteria klasyfikacyjne traktuje się równorzędnie, a za przymiotnik uznawany jest wyraz spełniający przynajmniej niektóre z nich. Zgodnie z tymi zasadami do przymiotników włączono
więc wiele klas wyrazów wcześniej zaliczanych do zaimków i liczebników, a także pewne formy fleksyjne czasowników.
Stosowana jest również klasyfikacja:
Zdecydowanie mniej użyteczne i rzadziej stosowane są kryteria semantyczne i słowotwórcze.
Z powyższych względów nie ma obecnie powszechnej zgody wśród językoznawców co do przynależności niektórych grup wyrazów do przymiotników.
W zależności od wybranego kryterium do przymiotników zaliczane są, oprócz wcześniej wymienionych, także niektóre z następujących grup wyrazów:
Wymienione powyżej grupy wyrazów nie spełniają wszystkich cech przymiotników (głównie
semantycznych), jednak zalicza się je do przymiotników ze względu na ich "przymiotnikową" funkcję w zdaniu i/lub morfologię.
Stopniowanie.
Za pomocą przymiotników określane są cechy osób i rzeczy. Natężenie tych cech może być różnicowane, co gramatycznie wyraża się poprzez stopniowanie, któremu podlegają wyłącznie przymiotniki jakościowe. Wyróżnia się trzy stopnie intensywności cechy: równy
(), wyższy (), najwyższy ().
W języku polskim istnieją trzy formy stopniowania:
Możliwe jest także stopniowanie „w dół”, czyli cecha może być osłabiana, a nie wzmacniana, np. "interesujący, mniej interesujący, najmniej interesujący" – mamy wówczas do czynienia ze stopniem równym, niższym i najniższym. Stopniowanie w kierunku ujemnym jest zawsze opisowe.
Następujące przymiotniki stopniują się nieregularnie (w stopniu wyższym i najwyższym następuje zamiana wyrazu): "dobry – lepszy – najlepszy"; "zły – gorszy – najgorszy";
"duży – większy – największy".
Stopniowanie innych przymiotników jakościowych jest regularne, lecz czasami występują w nim oboczności i inne ślady procesów fonetycznych, np. "mały – mniejszy – najmniejszy", "lekki – lżejszy – najlżejszy".
Większość przymiotników jakościowych można stopniować na dwa sposoby, ale niektóre tylko opisowo, np. "rycerski", "znany".
W polszczyźnie mówionej spotyka się niekiedy skontaminowane formy stopniowania przymiotnikowego w stopniach wyższym i najwyższym, będące wynikiem skrzyżowania dwóch rodzajów stopniowania – prostego i opisowego. Konstrukcje takie (np. "Ta paczka jest o wiele bardziej cięższa od tamtej.") są sprzeczne z normami polszczyzny standardowej, w której należałoby powiedzieć: "Ta paczka jest o wiele cięższa (znacznie cięższa, dużo cięższa, wyraźnie cięższa) od tamtej."
Esperanto.
W esperanto przymiotnik zawsze przyjmuje końcówkę "-a". Przez przypadki i liczby odmienia się tak jak rzeczownik. Stopniuje się przez dodanie wyrazu "pli" (stopień wyższy) i "plej" (stopień najwyższy).

</doc>
<doc id="13012" url="https://pl.wikipedia.org/wiki?curid=13012" title="Przypadek">
Przypadek

Przypadek – kategoria gramatyczna, przez którą odmieniają się rzeczowniki, przymiotniki, liczebniki, zaimki, imiesłowy (określane przez to zbiorczym mianem "imion"), a niekiedy też czasowniki (co w języku polskim nie występuje), będąca odzwierciedleniem ich różnorodnych funkcji.
Historia.
Teoria deklinacji została wypracowana w Grecji w IV wieku p.n.e. Również Grecy nadali przypadkom nazwy, które przez Rzymian zostały przetłumaczone na łacinę. Nazwy przypadków w języku polskim (a także sam termin "przypadek", łac. "casus") są częściowo tłumaczeniami terminów łacińskich. Również kolejność przypadków odpowiada mniej więcej kolejności zaproponowanej przez gramatyków starożytnych.
Istota systemu deklinacyjnego.
System deklinacyjny jest używany do ustalenia właściwych relacji poszczególnych wyrazów w zdaniu. Konsekwencją jego istnienia jest swoboda kształtowania kolejności wyrazów w zdaniu: podmiot, orzeczenie i dopełnienie nie mają raz na zawsze ustalonych miejsc, lecz mogą następować w dowolnej kolejności.
Języki mające przypadki mają ich zwykle od czterech do siedmiu. Zdarzają się też języki z dwoma przypadkami (zwykle zanikający, uprzednio bogatszy system), czy też kilkunastoma (z których część powstała przez fonetyczną inkorporację uprzednio niezależnych morfemów) jak fiński lub węgierski (trzeba jednak pamiętać, że języki te, jako aglutynacyjne, nie są w tym zestawieniu adekwatne).
Nomenklatura.
Przypadkom różnych języków nadaje się takie same nazwy – jest to czasem mylące, ponieważ zasięg użycia przypadka o tej samej nazwie bywa w różnych językach odmienny – np. zastosowanie „dopełniacza” w językach polskim i niemieckim pokrywa się w niewielkim stopniu.
Z drugiej zaś strony system deklinacyjny języków indoeuropejskich, jako odziedziczony po wspólnym przodku – języku praindoeuropejskim – wykazuje nadal wiele cech wspólnych. Przykładowo każdy dopełniacz (i polski, i niemiecki) ma funkcję posesywną.
Klasyfikacja.
Podstawowy podział przypadków przebiega pomiędzy "casus recti" (przypadki niezależne) oraz "casus obliqui" (przypadki zależne). Te pierwsze to mianownik i wołacz, te drugie to reszta. W językach indoeuropejskich obserwuje się tendencję do stopniowej redukcji liczby przypadków tak, by pozostał tylko jeden "casus rectus" oraz jeden "casus obliquus". Ponadto w wielu językach europejskich (np. w języku francuskim, włoskim i angielskim) zróżnicowanie form przypadka ogranicza się do zaimków. Inny podział przypadków to rozróżnienie między przypadkami konkretnymi (wskazującymi kierunek, np. polski miejscownik) a gramatycznymi, których znaczenie wynika z systemu konotacji.
Tabela powyżej pokazuje orientacyjnie liczbę przypadków w różnych językach. Należy zwrócić uwagę, że jakkolwiek tabelka uporządkowana jest w kolejności malejącej liczby przypadków, nie znaczy to jednak, że we wszystkich językach panuje bezspornie tendencja do ich redukcji. Przeciwnie, niektóre języki (np. litewski) mają tendencje do przebudowy systemu i zwiększania liczby przypadków.
Przypadki w językach indoeuropejskich.
To, że biernik, ablatyw i miejscownik wskazują kolejno kierunek ruchu, jego punkt początkowy oraz aktualne położenie, jest reliktem deklinacji praindoeuropejskiej.
Zagadnieniem związanym z tematyką przypadków są tzw. funkcje syntaktyczne przypadków. Nawet w językach o dużej liczbie przypadków i rozwiniętej fleksji (polski – 7, łacina – 6/7, greka – 5) poszczególne przypadki spełniają po kilka funkcji syntaktycznych. Np. dopełniacz, oprócz funkcji posesywnej, pełni też funkcję porównawczą, bo występuje w wyrażeniach porównawczych typu "większy od czego?", funkcję separatywną typu "odrywać coś od czego?" itp. Takie pomieszanie funkcji wynika częściowo z synkretyzmu przypadków, a częściowo z dostosowywania pierwotnych ich funkcji do nowych zadań.
Przypadki w językach ugrofińskich.
Języki ugrofińskie są językami aglutynacyjnymi. W miejscu przyimków znanych z języków indoeuropejskich pojawiają się morfemy, które przez tradycyjną gramatykę traktowane są jako przypadki – stąd ich wielość.
Język fiński.
W języku fińskim istnieje piętnaście przypadków. W wielu podręcznikach można znaleźć różną ich liczbę, od 14 do 18, w zależności od sposobu sklasyfikowania przypadków wymarłych, pozostałych jedynie w utartych zwrotach. Większość końcówek przypadków funkcjonuje w językach indoeuropejskich (w tym polskim) jako przyimki. Przypadki dzielą się wewnętrznie na gramatyczne, mające podobne funkcje do polskich (np. mianownik, biernik), lokalne, określające relacje miejsca w stosunku do desygnatu, oraz tzw. przypadki marginalne, rzadko używane w języku współczesnym i często zastępowane przyimkami i poimkami. Oprócz tych 15 przypadków istnieje dalszych 12 przypadków przysłówkowych, które używane są bardzo rzadko i zazwyczaj w skostniałych strukturach, np. prolativus, określający relację drogi i sposób poruszania się, np. "ohitse" – obok, "meritse" – przez morze, morzem, "puhelimitse" – przez telefon.
Przypadki tworzy się w sposób podobny jak np. w języku polskim – dodając końcówkę przypadka do rdzenia wyrazu. Końcówki przypadków są niezależne od poszczególnych typów morfologicznych rzeczowników – mają charakter dystrybutywny. Końcówki liczby mnogiej są w większości identyczne z końcówkami liczby pojedynczej, przy czym między rdzeniem i odpowiednim sufiksem dochodzi wrostek -"i"- (np. lp. "talossa", lm. "taloissa". Wyjątkiem jest mianownik liczby mnogiej, przyjmujący końcówkę -"t"-, "talot")
Nie wszystkie przypadki używane są równie często. Najczęściej pojawiają się: mianownik l. poj – 35,24 proc (spośród wszystkich form deklinacyjnych), dopełniacz l. poj – 15,69 proc., mianownik l. mn. – 9,89 proc. najrzadziej – abessivus – 0,01 proc.
Grupy przypadków.
Przypadki fińskie możemy podzielić na cztery zasadnicze grupy:
Niekiedy wyróżnia się grupę lokalizacji abstrakcyjnej – abessivus, essivus, translativus.

</doc>
<doc id="13013" url="https://pl.wikipedia.org/wiki?curid=13013" title="Forma słownikowa">
Forma słownikowa

Forma słownikowa, także: forma hasłowa, lemma, lemat – ta spośród form gramatycznych wyrazu odmiennego, która jest tradycyjnie wykorzystywana w słownikach i reprezentuje tam w nagłówku artykułu hasłowego cały wyraz ze wszystkimi jego formami. Forma ta stanowi niejako „umowną etykietę zbioru form” i decyduje o umiejscowieniu artykułu hasłowego w słowniku.
Wybór formy słownikowej bywa ustalony tradycją i różni się w zależności od języka.
Forma słownikowa bywa zwykle traktowana przez osoby uczące się języka obcego jako podstawowa, tj. taka, w której przyswajane są nowe wyrazy i od której tworzy się pozostałe formy odmiany.
Problemy.
Zdarza się, że w danym języku istnieją wyrazy nieużywane bądź rzadko używane w tej akurat formie, która tradycyjnie pełni rolę słownikowej (np. polskie rzeczowniki "sanie", "nożyce" – nie mają liczby pojedynczej, przymiotniki "ciężarna", "dojna" – w zasadzie nie występują w rodzaju męskim itp.), stanowią one jednak zawsze stosunkowo małą grupę. W przypadku słowników historycznych czy dialektalnych istnieje niebezpieczeństwo utworzenia form sztucznych albo wręcz błędnych, ponieważ np. polski bezokolicznik jest formą rzadko używaną i może nie występować w zabytkach językowych bądź zapisach tekstów gwarowych.
Ponadto tradycyjna forma słownikowa nie zawsze pozwala ustalić sposób odmiany wyrazu, np. w języku japońskim forma twierdząca czasownika, używana jako słownikowa, nie wskazuje, czy należy on do klasy samogłoskowej (jap. "ichidan") czy spółgłoskowej (jap. "godan"), podczas gdy forma przecząca jest pod tym względem w pełni jednoznaczna. Podobnie sprawa ma się z polskim bezokolicznikiem, w którym zatarciu ulega struktura czasownika i typ koniugacyjny (np. "umieć – umie", "szaleć – szaleje", "widzieć – widzi", "słyszeć – słyszy", "mieć – ma", gdzie identycznemu zakończeniu bezokolicznika "-eć" odpowiadają różne typy odmiany).

</doc>
<doc id="13014" url="https://pl.wikipedia.org/wiki?curid=13014" title="Gentle Giant">
Gentle Giant

Gentle Giant – brytyjska progresywna grupa rockowa, aktywna w latach 1970-1980. Obok The Nice, Yes, King Crimson i Emerson, Lake &amp; Palmer wyznaczyła artystyczne granice gatunku, nigdy jednak nie osiągnęła sukcesu tej miary co tamte zespoły. Podobnie jak inne grupy z tego kręgu, muzycy z Gentle Giant charakteryzowali się techniczną wirtuozerią i innowacyjnością w podejściu do tworzenia muzyki oraz zastosowaniem szerokiego zakresu instrumentów akustycznych i elektronicznych. Skupiali się raczej na komponowaniu krótszych utworów, dbając o ich strukturalną i stylistyczną integralność. W muzyce Gentle Giant daje się zauważyć wyraźne wpływy muzyki poważnej, folkowej, jazzu oraz hard rocka. Charakterystyczną cechą dla stylu grupy jest szerokie wykorzystanie techniki kontrapunktu, rzadko stosowanej w muzyce rockowej nawet wśród zespołów progresywnych.
Historia.
Początki.
Trzonem tego, co miało stać się jako Gentle Giant, tworzyli trzej bracia: Phil Shulman (ur. 27 sierpnia 1937), Derek Shulman (ur. 11 lutego 1947) i Ray Shulman (ur. 8 grudnia 1949). Bracia byli pochodzenia szkocko-żydowskiego. Phil i Derek urodzili się w Glasgow, w Szkocji, w dzielnicy Gorbals, która była wówczas osławionym slumsem. Rodzina przeniosła się do Portsmouth w Anglii, gdzie urodził się Ray. Ich ojciec był muzykiem wojskowym, który stał się trębaczem jazzowym i kontynuował swoją pracę muzyczną w Portsmouth. Zachęcał swoich synów do nauki gry na różnych instrumentach, a Phil, Derek i Ray zostali multiinstrumentalistami. Na początku lat 60. Derek i Ray zainteresowali się graniem rhythm and bluesa i założyli razem zespół. Phil – początkowo pełniący rolę menadżera, aby opiekować się swoimi dużo młodszymi braćmi – w końcu sam został członkiem zespołu.
Do 1966 roku zespół Shulmanów – początkowo pod nazwą The Howling Wolves, potem The Road Runners – przyjął nazwę Simon Dupree and the Big Sound i dążył bardziej w kierunku soul i pop. Jako główny wokalista i frontman, Derek Shulman przyjął pseudonim „Simon Dupree”, podczas gdy Phil grał na saksofonie i trąbce, a najmłodszy brat Ray na gitarze i skrzypcach (zarówno Ray, jak i Phil grali również na trąbce i śpiewali chórki dla grupy, która w czasie swojego istnienia krótko występowała z Reginaldem Dwightem (przyszłym Eltonem Johnem) jako pianistą, jak również nagrała singiel z Dudleyem Moore'em jako gość). Podpisując kontrakt z wytwórnią EMI, Simon Dupree and the Big Sound nagrali kilka singli, które nie odniosły sukcesu, po czym zostali popchnięci przez swój management i wytwórnię w stronę psychodelii. Zaowocowało to brytyjskim Top 10 hitem „Kites” jesienią 1967 roku (i wydaniem albumu "Without Reservations" później w tym samym roku). 
Sukces sfrustrował braci Shulman, którzy uważali się za wykonawców białego soulu i uważali, że ich zmiana stylu była nieszczera i nieistotna. Derek Shulman nawet miał później określić „Kites” jako "„totalne gówno”". Opinię Shulmanów potwierdziły w ich oczach, kolejne komercyjne porażki singli będących kontynuacją „Kites”. Próbując uciec od swojego nowego wizerunku, wydali pod koniec 1968 roku singiel z podwójną stroną A pod inną nazwą jako The Moles – „We Are the Moles (parts 1 &amp; 2)”. To spotęgowało ich kryzys tożsamości, bowiem singiel został później podchwycony przez plotkę, iż The Moles to w rzeczywistości The Beatles nagrywający pod inną nazwą i z Ringo Starrem jako głównym wokalistą. Plotka ta została ostatecznie obalona przez lidera Pink Floyd, Syda Barretta, który ujawnił, że za nagraniem stoi Simon Dupree and the Big Sound.
W 1969 roku bracia Shulman ostatecznie rozwiązali grupę, aby uciec od środowiska muzyki pop, które ich dobijało. Co zaskakujące, nie powrócili bezpośrednio do rhythm and bluesa i soulu, lecz wybrali bardziej skomplikowany kierunek. Ray Shulman powiedział później: "„Wiedzieliśmy, że nie możemy kontynuować działalności z tymi muzykami, których mieliśmy wcześniej. Nie interesowali nas pozostali muzycy w zespole – niczego nie mogli wnieść. Musieliśmy ich uczyć, co mają robić. Stawało się to dość obciążające, podczas gdy mogliśmy grać na perkusji lepiej niż perkusista, a nawet na nagraniach robiliśmy coraz więcej overdubbingów. Stawało się to głupie mając taki zespół. Pierwszą rzeczą było znalezienie muzyków na wyższym poziomie”".
Powstanie Gentle Giant.
Gentle Giant powstał w 1970 roku, kiedy to bracia Shulman połączyli siły z dwoma innymi multiinstrumentalistami, Garym Greenem (gitara, mandolina, flet itd., ur. 20 listopada 1950) i Kerrym Minnearem (klawisze, wibrafon, wiolonczela itd., ur. 2 stycznia 1948), oraz perkusistą Martinem Smithem (ur. 17 grudnia 1946, zm. 2 marca 1997), który ten ostatni już wcześniej grał w Simon Dupree and the Big Sound. Klasycznie wykształcony Minnear ukończył niedawno Royal College of Music z dyplomem z kompozycji i grał w zespole Rust. Z kolei Gary Green był właściwie bluesmanem i nigdy nie pracował z zespołem powyżej półprofesjonalnego poziomu, ale z łatwością przystosował się do wymagającej muzyki nowego zespołu. Bracia Shulman, w międzyczasie, zadomowili się w typowych dla siebie rolach multiinstrumentalistów – Derek na saksofonie i flecie, Ray na basie i skrzypcach, a Phil na saksofonie, trąbce i klarnecie (wszyscy trzej bracia grali też na innych instrumentach w zależności od potrzeb).
W nowym zespole znalazło się także trzech głównych wokalistów. Derek Shulman śpiewał w ciężkim rhythm and bluesowym stylu i generalnie zajmował się bardziej zorientowanymi rockowo wokalami; Phil Shulman zajmował się bardziej folkowymi lub jazzowymi piosenkami; a Kerry Minnear (który miał szczególnie delikatny głos) śpiewał lżejsze folkowe i kameralne klasyczne wokale. Minnear nie śpiewał na koncertach, z powodu jego niezdolności do synchronizacji głosu na odpowiednim poziomie dla nagłośnienia na żywo (Derek i Phil Shulman śpiewali partie wokalne Minneara, gdy zespół grał na żywo). Według doniesień, Elton John bezskutecznie ubiegał się o stanowisko głównego wokalisty w nowo powstałej grupie.
Według książeczki, która była dołączona do ich pierwszego albumu, nazwa zespołu była odniesieniem do fikcyjnej postaci, „łagodnego olbrzyma”, który spotyka grupę muzyków i jest zachwycony ich muzyką. Postać ta przypomina te z renesansowych opowieści Françoisa Rabelaisiego.
Od początku Gentle Giant był zespołem szczególnie elastycznym ze względu na wyjątkowo szerokie umiejętności muzyczne jego członków. Na każdym albumie Gentle Giant zawierał w sumie czterdzieści sześć instrumentów – wszystkie z nich były grane przez członków grupy – a pięciu z sześciu członków śpiewało, co umożliwiało zespołowi pisanie i wykonywanie poszczególnych harmonii wokalnych i kontrapunktów. Podejście zespołu do pisania piosenek było równie zróżnicowane, łącząc wiele pomysłów i wpływów, niezależnie od tego, czy były one uważane za komercyjne czy nie.
Debiutancki album, "Acquiring the Taste" i "Three Friends" (Lata 1970-1972).
Pierwszy album zespołu nosił tytuł "Gentle Giant" i ukazał się w 1970 roku nakładem Vertigo Records. Łącząc w sobie wpływy rocka, bluesa, muzykę klasyczną i brytyjskiego soulu lat 60., Gentle Giant zebrał przychylne recenzje, choć był krytykowany za brzmienie i za nie najlepszą jakość nagrań.
Drugi album, "Acquiring the Taste" został wydany w 1971 roku. Pokazał zespół, który szybko się rozwijał. Był o wiele bardziej eksperymentalny i dysonansowy niż jego poprzednik. "Acquiring the Taste" został ukształtowany przede wszystkim poprzez szerokie wyszkolenie Kerry'ego Minneara w zakresie klasycznej i współczesnej muzyki poważnej. Pokazał również, że zespół poszerzył swoją i tak już imponującą paletę instrumentów (choć wiele lat później Derek Shulman przyznał, że "„nagraliśmy" [Acquiring the Taste] "bez żadnego pomysłu na to, jak to będzie, zanim weszliśmy do studia. To był bardzo eksperymentalny album i wciąż nie mieliśmy ostatecznego kierunku”"). Poczucie ogromnego wyzwania, przed jakim stanął zespół, uwidoczniło się w notce do "Acquiring the Taste", który zawierał szczególnie wzniosłą deklarację, nawet jak na standardy rocka progresywnego jak „poszerzyć granice współczesnej muzyki popularnej, ryzykując, iż stanie się bardzo niepopularna”. Producent Tony Visconti rościł sobie prawo do autorstwa tej notki, jak i również „gigantycznej” historii towarzyszącej pierwszemu albumowi.
Po "Acquiring the Taste" z zespołu odszedł Martin Smith, w wyniku nieporozumień zarówno z Rayem, jak i Philem Shulmanem. Zastąpił go Malcolm Mortimore (ur. 16 czerwca 1953).
Kolejnym nagraniem Gentle Giant był album "Three Friends" (1972). Był to pierwszy album koncepcyjny zespołu, oparty na temacie trzech chłopców, którzy „nieuchronnie zostają rozdzieleni przez przypadek, umiejętności i los”, gdy stają się dorośli. Na przestrzeni albumu, trzej przyjaciele przechodzą drogę od bycia szkolnymi kolegami z dzieciństwa do stania się, odpowiednio, robotnikiem drogowym, malarzem i pracownikiem biurowym. W tym procesie tracą umiejętność do nawiązywania relacji i zrozumienia stylu życia innych. Rozwój i losy każdej z postaci są muzycznie reprezentowane przez odrębne, zintegrowane style, od ciężkiego rhythm and bluesowego rocka po symfoniczną klasykę. Album zajął 197 miejsce na amerykańskiej liście przebojów.
W marcu 1972 roku Malcolm Mortimore uległ wypadkowi motocyklowemu. Aby wypełnić zobowiązania koncertowe w kwietniu, Gentle Giant zatrudnił Johna „Pugwash” Weathersa (ur. 7 lutego 1947) (ex-Grease Band, Wild Turkey, Graham Bond's Magic). Weathers był muzykiem bardziej wszechstronnym, który oprócz gry na perkusji również śpiewał oraz grał na instrumentach perkusyjnych i gitarze, co jeszcze bardziej poszerzyło możliwości instrumentalne Gentle Giant. Ze względu na przedłużającą się rekonwalescencję Mortimore'a, zespół zdecydował się oficjalnie zastąpić go Weathersem pod koniec kwietniowej trasy koncertowej w 1972 roku.
"Octopus" i odejście Phila Shulmana (Lata 1972-1973).
Nowy skład Gentle Giant wydał "Octopus" pod koniec 1972 roku. Tytuł albumu zespołu został nazwany przez żonę Phila Shulmana, Robertę, jako kalambur na „octo opus” (osiem dzieł muzycznych, odzwierciedlający osiem utworów na płycie). Zachował on wyraźnie szeroki i ambitnie zintegrowany styl Gentle Giant, a jednym z najważniejszych momentów jest skomplikowany wokalny utwór w stylu madrygału „Knots” (którego tekst jest zaczerpnięty z różnych wersów z książki R. D. Lainga o tym samym tytule). Album ten osiągnął miejsce 170 na amerykańskiej liście przebojów.
Wydanie "Octopus" jest powszechnie uważany za początek klasycznego okresu działalności Gentle Giant. W 2004 roku Ray Shulman skomentował: "„To był prawdopodobnie nasz najlepszy album, może z wyjątkiem Acquiring the Taste. Zaczęliśmy od pomysłu napisania piosenki o każdym członku zespołu. Posiadanie koncepcji w głowie był dobrym punktem wyjścia do napisania. Nie wiem czemu, ale pomimo wpływu, jakie wywołały Tommy i Quadrophenia The Who, albumy koncepcyjne są z dnia na dzień postrzegane jako raczej tandetne i pretensjonalne”".
Przed wyruszeniem w trasę promujący "Octopus", zespół zagrał wyczerpującą serię koncertów jako support Black Sabbath, podczas który okazał się być bardzo niepopularny wśród większości fanów zespołu. Derek Shulman wspominał: "„To było prawdopodobnie najbardziej absurdalne połączenie grup w historii show businessu. W większości zostaliśmy wygwizdani na scenie”". Po trasie Gentle Giant przeszedł najbardziej znaczącą zmianę w składzie, kiedy wypalony i zniechęcony Phil Shulman opuścił zespół po nieporozumieniach z braćmi w styczniu 1973 roku. Derek Shulman przejął partie wokalne Phila na koncertach, stając się "de facto" głównym wokalistą Gentle Giant (niemniej Kerry Minnear nadal śpiewał w niektórych utworach na późniejszych płytach studyjnych).
Gary Green wspominał później: "„Z tego co pamiętam, kiedy Phil ogłosił to pod koniec włoskiej trasy, powiedział, że opuszcza zespół. Nie mógł tego kontynuować. Było zbyt wiele stresu związanego z byciem w trasie i rodziną. Do tego bracia mieli trochę trudny okres. Są braćmi i kłócili się jak cholera, czasami do tego stopnia, iż myślałeś, że się pobiją. Choć myślę, że to była braterska miłość" [śmiech]". Ale kiedy Phil powiedział, że odchodzi, wszyscy byliśmy jak wryci, „Och! Co zrobimy? Dobra, kupimy syntezator Mooga!”. To trochę banalne, nie mam na myśli tego w ten sposób. Musieliśmy coś zrobić”".
Gary Green: "„John" [Weathers] "i ja naprawdę naciskaliśmy na to, żeby zespół kontynuował swoją działalność, ponieważ wyglądało na to, że zamierzamy się wycofać. A to wydawało się niedorzeczne – mieliśmy Kerry'ego w pełni sił i Raya, który pisał świetnie. Byliśmy naprawdę silni na żywo i mieliśmy stać się jeszcze silniejsi. Myślę, że staliśmy się silniejszym zespołem po odejściu Phila. I to nie jest wymierzone przeciwko Philowi. My dopiero wchodziliśmy na wyższy poziom jako muzycy”".
Ponad trzydzieści lat później, Phil Shulman ujawnił swoje powody odejścia w wywiadzie podcastowym z 2008 roku przeprowadzonym przez jego syna Damona i wnuka Elliota. W wywiadzie tym stwierdził, że jego główną motywacją do odejścia było to, że zdał sobie sprawę, iż styl życia muzyka koncertującego niszczy jego życie rodzinne. Dwie frakcje braci Shulman – z Philem po jednej stronie oraz Rayem i Derekiem po drugiej – ostatecznie rozwiązały swoje różnice i uzdrowiły swoje relacje, chociaż Phil nigdy nie dołączył ponownie do zespołu, ani nie powrócił do kariery muzyka. Ray Shulman pomagał później synowi Phila, Damonowi Shulmanowi, w tworzeniu jego własnej muzyki.
"In a Glass House" i "The Power and the Glory" (Lata 1973-1975).
Zespół już jako kwintet przegrupował się aby nagrać bardziej hardrockowy "In a Glass House", który został wydany w 1973 roku przez WWA. Swój pierwszy koncert jako pięcioosobowy zespół zagrali w King Alfred's College w Winchesterze 4 marca 1973 roku. "In a Glass House" to drugi wyrafinowany album koncepcyjny – nazwany zgodnie z aforyzmem, iż „ludzie, którzy mieszkają w szklanych domach nie powinni rzucać kamieniami” (angielski odpowiednik idiomu "kto sam nie jest bez winy, nie powinien potępiać innych") – był najbardziej najtrudniejszym w odbiorze dziełem zespołu. Album wyróżniał się także trójwymiarową okładką, wykorzystującą celofanową wkładkę (odtworzoną na reedycji CD Terrapin oraz na digipaku późniejszej reedycji CD Alucard). "In a Glass House" nigdy nie został wydany w USA, niemniej jednak był bardzo poszukiwany jako import.
Następny album, "The Power and the Glory" ukazał się w 1974 roku. Był to trzeci album koncepcyjny Gentle Giant, tym razem tematykę obejmowała władza i korupcja. Zespół napisał również osobny singiel o tym samym tytule. Według Dereka Shulmana, "„WWA stwierdziło, „Teraz chłopcy, musicie być komercyjni, musicie stworzyć singiel. Teraz idźcie i napiszcie nam singla”. Więc zrobiliśmy trzy okropne numery. Ta piosenka jest najgorsza – „Macie to, chłopaki!” – poszliśmy do studia i oddaliśmy taśmy, kiedy wyszliśmy. Wypuścili, nawrzeszczeliśmy na nich, a oni oddali to z powrotem – wycofali z rynku”" (singiel został później dodany do reedycji CD tego albumu). "The Power and the Glory" uplasował się na 78 miejscu na amerykańskiej liście przebojów.
"Free Hand", "Interview" i koncertowy "Playing the Fool" (Lata 1975-1977).
Niezadowoleni ze współpracy z WWA, Gentle Giant podpisali nowy kontrakt z Chrysalis Records, z którą pozostali do końca swojej kariery. Mimo że zespół wciąż pisał i wykonywał jedną z najbardziej złożoną muzykę rockową tamtego okresu, to właśnie w tym momencie zaczął szlifować i nieco upraszczać swoje piosenki, żeby dotrzeć do szerszej publiczności (szczególnie amerykańskiej). Ich starania okazały się na tyle skuteczne, że album "Free Hand" z 1975 roku trafił na 48 miejsce na amerykańskiej liście przebojów. Silnie inspirowany muzyką renesansową, średniowieczną oraz jazz-rockiem album zawierał tematykę m.in. na temat utraconej miłości oraz zniszczonych związków, w tym rozpadu relacji zespołu z byłym menadżerem. Stał się on jednym z najbardziej popularnych i przystępnym albumem zespołu.
Następnym wydawnictwem Gentle Giant był "Interview" z 1976 roku – kolejny album koncepcyjny, tym razem oparty na wyimaginowanym wywiadzie z zespołem. Muzyka wyśmiewała stan przemysłu muzycznego oraz głupie pytania, które zadaje się gwiazdom rocka, aby stworzyć ich wizerunek marketingowy. Jak na ironię, to bardziej satyryczne i wywrotowe podejście ostatecznie podkopało pracę i artystyczną integralność zespołu. Derek Shulman przyznał później: "„Myślę, że Interview był początkiem erozji. Myślę, że soki twórcze zaczęły trochę słabnąć... Myślę, że Interview był początkiem uświadomienia sobie, że teraz to jest biznes, a to też jest częścią tego, czym ten biznes się stał. W tym czasie zarządzałem zespołem, a biznes muzyczny stał się poważnym biznesem”". Pomimo takiego podejścia, album nie powtórzył sukcesu poprzednika na amerykańskiej liście przebojów, plasując się na pozycji 137.
W tym czasie Gentle Giant stał się już uznanym zespołem koncertowym w Ameryce i Europie, który koncertował i dzielił sceny z takimi tuzami jak Sha Na Na czy wykonawcami rocka progresywnego jak Jethro Tull i Yes. Wirtuozerskie występy zespołu na żywo (z błyskawiczną wymianą instrumentów i wymagającymi zmianami aranżacji i tak już skomplikowanych utworów studyjnych) wywierały ogromne wrażenie na publiczności, co oznaczało, że Gentle Giant mógł się równać z niemal każdym zespołem na liście przebojów. Na jednym z koncertów w 1975 roku (w Detroit Cobo Hall) Gentle Giant skradł show zarówno Gary'emu Wrightowi (debiutującemu albumem "Dream Weaver"), jak i Rickowi Wakemanowi (występującemu z koncertową wersją "The Myths and Legends of King Arthur and the Knights of the Round Table"). W 1976 roku ta koncertowa strona zespołu została uwieczniona na albumie "Playing the Fool" (1977; 89 miejsce na amerykańskiej liscie przebojów), nagrana podczas europejskiej trasy "Interview".
"The Missing Piece" i "Giant for a Day!" (Lata 1977-1979).
Podczas gdy umiejętności Gentle Giant jako wykonawców pozostały niezmienione, ich twórczy szczyt miał już za sobą. Pod wpływem zmian w popularnym stylu (włączając w to rozwój punk rocka), a także presja ze strony wytwórni Chrysalis wymuszającą komercjalizację, zespół podjął wspólną decyzję o zmianie stylu pisania i wykonywania utworów w pogoni za szerszym rynkiem, szczególnie w Ameryce. Przez następne dwa lata zespół stopniowo porzucał wiele ze swoich skomplikowanych stylów, aby próbować pisać łatwiejszą w odbiorze muzykę pop i próbować stworzyć przeboje.
"The Missing Piece" (nagrany w Holandii i wydany w 1977 roku) był albumem przejściowym, który odzwierciedlał to nowe podejście. Podczas gdy druga strona zawierała dłuższe i bardziej eklektyczne utwory przypominające wcześniejsze dokonania zespołu, pierwsza strona zawierała jawne przykłady pop rocka („I'm Turning Around”), blue-eyed soul („Mountain Time”), a nawet punk rocka („Betcha Thought We Couldn't Do It”). Trzy single („Two Weeks in Spain”, „Mountain Time” i „I'm Turning Around”) zostały wydane z tej płyty, ale nie stały się przebojami. Sam album radził sobie słabo na rynku, nie tylko nie zdobywając nowych fanów, ale też nie znajdując uznania wśród dotychczasowych miłośników zespołu. Album osiągnął 81 miejsce na amerykańskiej liście przebojów i to był już ostatni amerykański sukces.
Mimo niepowodzenia komercyjnego, zespół kontynuował ten kierunek aż do końca, wydając w 1978 roku album "Giant for a Day!", na którym styl rocka progresywnego zniknął na rzecz przyjaznego radiu soft rocka oraz kolejnych prób stworzenia hitów, niestety nieudanych. Aby zaprezentować bardziej bezpośrednią tożsamość grupy, Derek Shulman zaśpiewał prawie wszystkie utwory z tej płyty, a zespół porzucił swój konwencjonalny zestaw instrumentów smyczkowych, dętych, perkusyjnych i interakcji wokalnych na rzecz prostszego instrumentarium: gitara, bas, klawisze, perkusja i śpiew. "Giant for a Day!" był kolejnym najgorzej sprzedającym się albumem, który później został uznany przez zespół za twórczą pomyłkę. Derek Shulman ostatecznie zapamiętał go jako "„naprawdę wydumany”", podczas gdy Kerry Minnear wyznał, że nie był pewien, czy coś wniósł na ten album (chociaż podjął próbę napisania utworu „It's Only Goodbye”).
"Civilian" (Lata 1979-1980).
W 1979 roku Gentle Giant przeniósł się do Los Angeles, aby nagrać – jak się później okazało ostatni – album "Civilian" z 1980 roku. Była to płyta zawierająca krótkie rockowe piosenki z ogromnym wpływem new wave. Zachowując zminimalizowane instrumentalne podejście "Giant for a Day!", zespół pozwolił sobie na znacznie więcej swobody w aranżacji i pracy nad wokalem niż na poprzednim albumie. Mimo uproszczenia, sposób pisania i wykonania piosenek bardziej przypominał wcześniejsze dokonania zespołu.
O ile Kerry Minnear twierdził, że jest znacznie bardziej zadowolony z tego albumu i zawartych w nim piosenek, o tyle Ray Shulman w końcu odrzekł: "„Nienawidziłem robić" [tej] "ostatniej płyty, nienawidziłem być w to zamieszany”". W 2005 roku Derek Shulman powiedział: "„Civilian był zrobiony z mniejszą pasją niż niektóre inne albumy. Jak się okazało, jako zespół po prostu nie byliśmy dobrzy w byciu gwiazdami rocka czy popu. Chcieliśmy być tak bardzo popularni jak Genesis, Rush czy Yes. Z perspektywy czasu myślę czasami, że Gentle Giant został niesłusznie umieszczony w kategorii rocka progresywnego. Wiele z tego, co robiliśmy, było bardzo wymyślne, ale z pewnością nie robiliśmy tych długich skomplikowanych melodii, jak Yes czy Genesis”".
Rozpad zespołu.
Latem 1980 roku Gentle Giant przestał istnieć. W 2005 roku Derek Shulman wspominał, że "„po prostu twórcze soki nie płynęły. Mieszkałem wtedy w Los Angeles, kiedy się rozpadliśmy. Nie byliśmy pewni, jaki kierunek obrać. Nie żałuję decyzji, którą podjęliśmy o rozwiązaniu zespołu i zrobiłbym to ponownie, gdybyśmy mieli robić to wszystko od nowa”". Ray Shulman skomentował: "„Zdecydowanie zapadła decyzja, że ta trasa będzie ostatnia. Kiedy już o tym wiedzieliśmy, bawiliśmy się dobrze. Zdecydowaliśmy się wtedy zakończyć, zamiast pozwolić, aby trwało to zbyt długo”". W wywiadzie dla Mojo w 2000 roku, Kerry Minnear zapewnił, że rozłam "„nie był spowodowany punkiem; był spowodowany tym, że muzycznie się pogubiliśmy”".
Opinia Gary'ego Greena na temat rozpadu jest nieco inna. W 2003 roku skomentował: "„Moim osobistym zdaniem jest takie, że zespół rozpadł się, ponieważ Derek naprawdę chciał mieć hitowy album i myślę, że Ray też, a oni mieli dość. Byli muzykami dłużej niż ja i zasmakowali tego całkiem dobrze, kiedy byli w Simon Dupree" [and the Big Sound]", przynajmniej w Wielkiej Brytanii. I szukali tego samego w" [Gentle] "Giant. Mam wrażenie, że mogliśmy kontynuować działalność, tak jak zrobił PFM czy Yes, i nadal kontynuować. Gdybyśmy się tego trzymali, od którego zaczęliśmy, moglibyśmy nadal grać i zarabiać na życie. Ale było, mineło i teraz jest dobrze. Wydawało mi się to trochę głupie, żeby odcinać swoją kreatywność dla tego typu sprawy”".
Gentle Giant swój ostatni koncert zagrali w Roxy Theatre w West Hollywood w Kalifornii 16 czerwca 1980 roku.
Dalsze losy.
Po rozwiązaniu zespołu Derek Shulman rozpoczął udaną karierę w organizacyjnej stronie biznesu muzycznego (początkowo zajmował się promocją i rozwojem artystów w PolyGram, następnie A&amp;R w Mercury Records, został prezesem Atco Records, po czym objął stanowisko prezesa Roadrunner Records. Obecnie jest właścicielem nowej firmy muzycznej 2Plus Music &amp; Entertainment). Ray Shulman zajął się tworzeniem muzyki dla telewizji i reklamy, a następnie został producentem płyt (współpracował m.in. z Echo &amp; the Bunnymen, The Sundays i The Sugarcubes), tworzeniem soundtracków do gier komputerowych, a także produkcją płyt DVD dla takich artystów jak Genesis i Queen.
John Weathers grał na perkusji w walijskim zespole Man (do 1996 roku), a później w Wild Turkey Glenna Cornicka, ex-basisty Jethro Tull. Gary Green (po osiedleniu się w Ameryce, niedaleko Chicago) grał z różnymi zespołami z Illinois (m.in. Blind Dates, The Elvis Brothers, Big Hello i Mother Tongue) oraz gościł na nagraniach i koncertach Eddiego Jobsona i Divae. Gary Green zagrał również na gitarze na albumie "Deeper Imaginings" Paula Adamsa i Australijki Elizabeth Geyer, który został nominowany do nagrody Independent Music Awards za najlepszy album New Age roku 2019. Kerry Minnear powrócił do Wielkiej Brytanii i osiadł w Kornwalii, spędzając wiele lat poświęcając się muzyce gospel. Obecnie prowadzi Alucard Music, organizację nadzorującą kwestie prawne i tantiemy dotyczące muzyki Gentle Giant.
Po okresie pracy w Gentle Giant, Phil Shulman wycofał się całkowicie z biznesu muzycznego. Następnie pracował jako nauczyciel oraz w handlu detalicznym, a przed emeryturą prowadził sklep z pamiątkami w Gosport, Hampshire. Przez krótki czas grał w zespole ze swoim synem Damonem Shulmanem i nagrał z nim kilka utworów. Kilka z nich (pod zbiorczym tytułem "Then") to były tzw. utwory mówione (spoken word), w których wspominał o swoim wychowaniu w slumsach Glasgow. Jeden z tych utworów – „Rats” – ukazał się na solowym albumie Damona Shulmana "In Pieces" (2003) i można go usłyszeć jako audio stream na stronie internetowej Damona Shulmana i stronie MySpace (udostępnione w kwietniu 2008). Pierwszy perkusista Gentle Giant Martin Smith osiadł w Southampton i grał tam z różnymi zespołami. Zmarł 2 marca 1997 roku. Drugi perkusista Gentle Giant, Malcolm Mortimore, kontynuował pracę jako odnoszący sukcesy perkusista sesyjny w dziedzinie rocka, jazzu i teatru.
Próby reaktywacji.
Pomimo tego, że wielu grup z kręgu rocka progresywnego ponownie łączyło się w trasy koncertowe, Gentle Giant konsekwentnie odmawiał ponownej reaktywacji. W 1997 roku fani Gentle Giant bezskutecznie próbowali namówić członków zespołu do ponownego występu. Powody podawane przez członków dla ich odmowy obejmują zajęte terminy, problemy zdrowotne, brak ćwiczeń na instrumentach oraz inne powody osobiste. Zapytany o możliwy reunion w 1995 roku, Phil Shulman odpowiedział: "„Prowadzimy teraz rozbieżne życie, różne style życia, różne postawy... Myślę, że to jest niemożliwe”". W 1998 roku Ray Shulman zapewniał: "„Dla mnie i Dereka, zakłócenia w naszym obecnym życiu, nie widzę jak mogłoby to być tego warte. Byłoby to bardzo trudne. Cały proces trwałby bardzo długo i musiałbyś zrezygnować z tego, co robisz. Oboje mamy kariery niezależne od GG”".
Istniały dwa wspólne starania z udziałem od dwóch do czterech członków zespołu, z których żaden nie został uznany jako formalny reunion Gentle Giant.
Pierwszym z nich była współpraca czterech byłych członków Gentle Giant – Kerry'ego Minneara, Johna Weathersa, Gary'ego Greena i Phila Shulmana (który brał udział tylko jako autor tekstów). Grupa ta nagrała trzy nowe utwory w oparciu o stare dema Kerry'ego Minneara na boksie "Scraping the Barrel" z 2004 roku („Home Again”, „Moog Fugue” i „Move Over”). Członkowie zespołu nagrywali swoje partie osobno i nigdy nie spotkali się ponownie osobiście.
Drugi natomiast rozpoczął się w 2008 roku. W ramach częściowego reunionu Gentle Giant, powstał nowy zespół o nazwie Rentle Giant, który miał grać materiał Gentle Giant. W skład zespołu weszli byli członkowie: gitarzysta Gary Green i perkusista Malcolm Mortimore. Roger Carey grał na basie i wokalu, Andy Williams na gitarze, a John Donaldson na pianinie i instrumentach klawiszowych. Green udzielał się jako główny wokalista w niektórych utworach.
W marcu 2009 roku do Greena i Mortimore'a dołączył trzeci muzyk Gentle Giant Kerry Minnear, co w rezultacie Rentle Giant zmienił nazwę na Three Friends. Również w tym czasie do zespołu dołączył Mick Wilson, jako dedykowany główny wokalista. Po krótkiej trasie koncertowej ogłoszono, że Minnear odchodzi z zespołu z przyczyn osobistych, a Three Friends planuje kontynuować działalność jako sześcioosobowy zespół. W 2011 roku zespół opuścili Carey, Williams i Donaldson, a ich miejsce zajęli Lee Pomeroy na basie i Gary Sanctuary na klawiszach. W 2012 roku do zespołu dołączyła Charlotte Glasson dodając skrzypce, saksofon barytonowy, altowy i flet prosty, co umożliwiło grupie stworzenie brzmienia na żywo bliższego oryginalnym nagraniom. W tym składzie zespół odbył w 2012 roku trasę koncertową po Włoszech, Kanadzie i Stanach Zjednoczonych. W 2015 roku w skład zespołu wchodzili Green, Mortimore, Glasson, Neil Angilley i Jonathan Noyce. Od tego czasu nie występowali na żywo.
Teledysk do utworu „Proclamation” został umieszczony na YouTube 15 lipca 2020 roku. W teledysku wystąpili członkowie Gentle Giant: Gary Green, Kerry Minnear, Derek Shulman, Ray Shulman, Phil Shulman, John Weathers i Malcolm Mortimore. Wśród dodatkowych muzyków znaleźli się między innymi Jakko Jakszyk, Billy Sherwood (basista Yes), Steve Hackett, Lee Pomeroy, Rachel Flowers, Dan Reed (Dan Reed Network), Richard Hilton (Chic) i Mikey Heppner (Priestess). Teledysk został wyreżyserowany i zmontowany przez Noah Shulmana, a zmiksował jego wuj Ray Shulman.
Styl muzyczny.
Muzyka Gentle Giant była w większości komponowana przez Kerry'ego Minneara i Raya Shulmana, z dodatkowymi pomysłami muzycznymi wnoszonymi przez Dereka Shulmana (który był również znany z tworzenia całych utworów). Teksty były pisane głównie przez Phila Shulmana i Dereka Shulmana (Kerry Minnear napisał kilka tekstów). Po odejściu Phila Shulmana po wydaniu albumu "Octopus" – późniejsze teksty były pisane głównie przez Dereka Shulmana, z pomocą Kerry'ego Minneara. Jak na standardy rocka progresywnego, muzyka Gentle Giant jest powszechnie uważana za szczególnie złożoną i wymagającą. Dzieli ona kilka aspektów z muzyką innych zespołów rocka progresywnego, w tym:
Zauważono jednak, że pomimo stosunkowo złożonego początkowego brzmienia, muzyka Gentle Giant jest w rzeczywistości dość tradycyjna pod względem harmonii i zawiera stosunkowo niewiele złożonych akordów. Podobnie jak większość rocka progresywnego z lat 70., kompozycje Gentle Giant są bliższe neoklasycyzmowi z początku XX wieku niż współczesnej muzyce klasycznej (niektóre utwory Gentle Giant, takie jak „Black Cat”, „Experience” i „So Sincere”, wykorzystują bardziej skomplikowaną modernistyczną harmonię). Ogólnie rzecz biorąc, zespół polegał na nagłych i nieoczekiwanych zwrotach kompozycyjnych, aby pobudzić publiczność, w tym:
Reedycje.
Od 1990 roku zainteresowanie Gentle Giant wzrosło, powstały nowe fankluby, nowe wydania koncertów i wcześniej nieopublikowanych materiałów, a także kilka tribute albumów. Prawa do katalogu zespołu są rozproszone pomiędzy wiele firm, z których nie wszystkie są chętne do wznawiania albumów w odpowiedni sposób. W szczególności pierwsze cztery albumy nie doczekały się jeszcze definitywnych wydań CD. Na przykład, tytułowy utwór "Acquiring the Taste" (1971) zaczyna się z dzwiękowym defektem, pochodzącym prawdopodobnie z uszkodzonej taśmy-matki, na wszystkich obecnych wydaniach kompaktowych i winylowych. Kompilacja "Edge of Twilight" z 1996 roku zawiera poprawioną wersję utworu. Sprzeczne dowody donoszą, że ten defekt istnieje na oryginalnym wydaniu winylowym albumu z 1971 roku, gdzie początkowa nuta „wygina się” w górę, gdy taśma nabiera prędkości – prawdopodobnie był to błąd inżynieryjny.
W lipcu 2004 roku pierwszy album został ponownie wydany przez niemiecką wytwórnię Repertoire; w grudniu 2005 roku ukazał się "Acquiring the Taste" (1971); w grudniu 2006 roku ukazał się "Octopus" (1972) w mini-sleeve z oryginalną okładką Rogera Deana, a w grudniu 2007 roku Repertoire wydała "Three Friends" (1972) w mini-sleeve z oryginalnym projektem brytyjskiego wydania. Mimo że nie są one szeroko rozpowszechnione, reedycje te były chwalone za jakość produkcji i remastering. Wcześniej wszystkie cztery pierwsze albumy zostały wznowione przez wytwórnię Universal Japan.
W 2005 roku, z okazji 35-lecia rocznicy zespołu, firma Dereka Shulmana, DRT Entertainment, wydała serię zremasterowanych i specjalnie zapakowane płyt CD późniejszych albumów. Wszystkie zawierały niewydane utwory koncertowe (o różnej jakości) jako bonusy. Wiele z tych albumów (przede wszystkim "In a Glass House") było wcześniej trudno dostępne w Ameryce Północnej bez możliwości importu. Wznowione albumy to: "In a Glass House" (1973), "The Power and the Glory" (1974), "Free Hand" (1975), "Interview" (1976), "The Missing Piece" (1977), "Playing the Fool" (1977, koncertowy) i "Giant for a Day!" (1978).
W latach 2009-2010 rozpoczęto serię reedycji na CD z bonusami w formie cyfrowej do pobrania. W wywiadzie z 2009 roku Derek Shulman poinformował również, że trwają prace nad filmem animowanym opartym na albumie "The Power and the Glory" (do tej pory nie doszedł on do skutku). W 2011 roku odnaleziono oryginalne taśmy z nagraniami płyt "Three Friends" (1972) i "Octopus" (1972), a Alucard Music wznowił każdy z nich z koncertowymi bonusami. Każdy z albumów został zremasterowany przez Raya Shulmana i Francisa Kervorkiana (obaj pracowali nad zremasterowanymi wersjami z 2009 roku).
"Free Hand" (1975) i "Interview" (1976) zostały wznowione w 2012 roku na CD/DVD oraz winylu. CD/DVD zawiera wcześniej niepublikowany miks kwadrofoniczny. Specjalny miks 4.1 Surround Sound (audiofile zauważają, że jest to DTS 96/24 i Dolby Digital 48 kHz/24bit) został zaadaptowany z oryginalnych miksów kwadrofonicznego. Członkowie zespołu napisali nowe notki na obu albumach.
Wydany w 2012 roku "I Lost My Head – The Chrysalis Years" to 4-płytowy zestaw wszystkich albumów Gentle Giant wydanych w ramach Chrysalis Records z dodatkowymi utworami, w tym sesjami dla Johna Peela, 7-calowymi miksami, utworami koncertowymi, stronami „B” itp.
W 2014 roku, "The Power and the Glory" (1974) został ponownie wydany jako zestaw CD/DVD z nowymi miksami Stevena Wilsona (z Porcupine Tree) z wielośladowych masterów. DVD zawiera nowe miksy 48 kHz/24-bit Stereo LPCM, DTS 96 kHz/24-bit 5.1 i Dolby AC3 5.1, a także transfer 96 kHz/24-bit LPCM oryginalnego miksu studyjnego z 1974 roku.
W 2017 roku ukazał się box "Three Piece Suite". Zawierała ona reedycje trzech pierwszych albumów: "Gentle Giant", "Acquiring the Taste" oraz "Three Friends". Utwory te zostały ponownie zmiksowane przez Stevena Wilsona z dostępnych taśm wielośladowych. Niektóre utwory z pierwszych trzech płyt nie zostały włączone do zestawu, ponieważ wieloślady do tych konkretnych utworów zaginęły. Zestaw był dostępny jako CD z ponownie zmiksowanymi utworami oraz jako dysk Blu-ray. Na dysku Blu-ray znalazły się wersje 96/24 Stereo LPCM i DTS-HD 5.1 Surround Sound zremiksowanych utworów, dodatkowe bonusy, wersje instrumentalne niektórych utworów oraz oryginalne miksy albumów w nienagannym stanie. Na ścieżkach 5.1 Surround znalazły się również nowe animacje wideo. Wydanie to zostało zapakowane jako pojedynczy digipak z dwoma dyskami, 16-stronicową książeczką, nową oprawą graficzną i zostało zatwierdzone przez zespół do wydania.

</doc>
<doc id="13015" url="https://pl.wikipedia.org/wiki?curid=13015" title="Imiesłów przymiotnikowy czynny">
Imiesłów przymiotnikowy czynny

Imiesłów przymiotnikowy czynny – nieosobowa forma czasowników niedokonanych mówiących o sprawcy czynności.
Dla czynności teraźniejszej tworzy się go za pomocą cząstki -ący (np. biorący, tworzący, rozumiejący, piszący). Cząstkę tę dodaje się do tematu 3. osoby liczby mnogiej czasu teraźniejszego czasownika (np. pisać → pisz-ą → piszący; rozumieć → rozumiej-ą → rozumiejący). Podobnie jak przymiotnik odmienia się przez liczby, przypadki i rodzaje. W przeciwieństwie do przymiotnika nie odmienia się przez stopnie.
Czynności w przeszłości opisywane są przez imiesłowy przymiotnikowe przeszłe czynne, które są rzadko używane, a nowych się nie tworzy.
Tworzono je z aspektu dokonanego czasownika oraz cząstki -ły, -ła, -łe, -li (np. zwiędła, zbiegli, zeszłe, zrozumiały, osiwiały). Są postrzegane jako przymiotniki.
Przykład imiesłowów przymiotnikowych czynnych (r.m.M.l.p) od czasownika bazowego "więdnąć":

</doc>
<doc id="13016" url="https://pl.wikipedia.org/wiki?curid=13016" title="Imiesłów przymiotnikowy bierny">
Imiesłów przymiotnikowy bierny

Imiesłów przymiotnikowy przeszły bierny – część mowy, imiesłów odnoszący się do przedmiotu czynności.
W języku polskim imiesłów przymiotnikowy przeszły bierny jest tworzony poprzez dodanie przyrostka -ny, -ony (także -’ony ← -’eny), -ty do tematu czasu przeszłego danego czasownika (np. pisać → pisa-ć → pisa-ny, zrobić → zrobi-ć → zrobi-ony, nieść → niós-ł (← nies-ł) → nies-’ony → niesiony). Podobnie jak przymiotnik, odmienia się przez liczby, przypadki i rodzaje. W przeciwieństwie do przymiotnika nie odmienia się przez stopnie. Czasowniki z bezokolicznikiem zakończonym na -nąć (np. spuchnąć, zdmuchnąć) mają w imiesłowie przymiotnikowym biernym cechę -nię, do której dodawana jest charakterystyczna cząstka -ty (spuchnięty, zdmuchnięty).

</doc>
<doc id="13019" url="https://pl.wikipedia.org/wiki?curid=13019" title="Endocentryzm">
Endocentryzm

Endocentryzm – właściwość konstrukcji gramatycznej złożonej z dwóch lub więcej elementów polegająca na tym, że ta konstrukcja należy do tej samej klasy, co jeden z elementów. W praktyce oznacza to, że można zastąpić całe wyrażenie tym elementem.
Np. wyrażenie „czarny kot” jest endocentryczne i można je zastąpić wyrażeniem „kot”: „czarny kot przebiegł drogę” – „kot przebiegł drogę”; słowo "ojcobójca" można zastąpić słowem "zabójca".

</doc>
<doc id="13020" url="https://pl.wikipedia.org/wiki?curid=13020" title="Egzocentryzm">
Egzocentryzm

Egzocentryzm – właściwość konstrukcji gramatycznej złożonej z dwóch lub więcej elementów polegająca na tym, że ta konstrukcja należy do innej klasy niż te elementy i nie można zastąpić jej żadnym z nich. Tadeusz Milewski podaje przykład "krzywonos" (osoba o krzywym nosie). Wyraz ten składa się z form "krzywy" i "nos", jednak zakres znaczeniowy leży poza zakresem obu części składowych.

</doc>
<doc id="13021" url="https://pl.wikipedia.org/wiki?curid=13021" title="Związek zgody">
Związek zgody

Związek zgody (kongruencja) – połączenie wyrazu określającego z wyrazem określanym, w którym oba wyrazy zgadzają się w rodzaju, liczbie i przypadku.
Między podmiotem (wyjąwszy przypadek podmiotu logicznego) a orzeczeniem (związek główny) zawsze występuje związek zgody – jest to zazwyczaj zgoda w stosunku do liczby, np. "przestępcy kradną". Związek zgody zachodzi między rzeczownikami a określającymi je wyrazami, takimi jak przymiotniki, czy liczebniki, dlatego też pytaniami pomocnymi w ustalaniu związku zgody między wyrazami są pytania przydawki: "(jaki?), (który?)" itp., lecz nie "(czyj?)" – pytanie przydawki, która łączy się z wyrazem w związku rządu.

</doc>
<doc id="13022" url="https://pl.wikipedia.org/wiki?curid=13022" title="Propaganda">
Propaganda

Propaganda (od – rozszerzać, rozciągać, krzewić) – celowe działanie zmierzające do ukształtowania określonych poglądów i zachowań zbiorowości ludzkiej lub jednostki.
Propaganda często jest kojarzona z materiałami przygotowywanymi przez władze danego kraju w celu krzewienia pozytywnych postaw obywateli zgodnych z racją stanu jak np. zachęcanie do wstępowania do wojska celem obrony kraju w czasie wojny. Grupy aktywistów, przedsiębiorstwa czy media również mogą produkować propagandę.
W XX wieku termin propaganda często wiązał się z podejściem manipulacyjnym z uwagi na używanie jej przez totalitarne reżimy, ale historycznie propaganda jest neutralnym terminem opisowym.
Propaganda totalitarnych reżimów polega na manipulacji intelektualnej i emocjonalnej z użyciem jednostronnych, niewłaściwych etycznie lub nawet całkowicie fałszywych argumentów i wiąże się ściśle z użyciem dezinformacji, zmierza do upowszechnienia trwałych postaw społecznych poprzez narzucenie i zmuszenie odbiorców do przyjęcia określonych treści i stanowi jeden z elementów indoktrynacji.
W języku potocznym utrwaliło się wartościujące znaczenie terminu propaganda jako synonimu stosowania kłamstw, półprawd, manipulacji – jako przeciwieństwo informacji, refleksji i dyskusji. Często nazywa się tak zabiegi marketingu politycznego. Jednak, aż do XVIII wieku, był on bardziej rozumiany jako rozpowszechnianie pewnych treści, co bezpośrednio odnosi się do łacińskiego słowa "prōpāgāre" – rozszerzać, krzewić.
Propaganda obejmuje szeroki zakres form przekazywania treści. Może być to sztuka wizualna, polegająca na używaniu zrozumiałych i powszechnie znanych symboli, przedmiotów, fotografia, muzyka, radio (a obecnie również telewizja i Internet), język ciała, taniec, literatura (praktycznie w każdej znanej formie, także ulotki), teatr oraz kino.
Rodzaje propagandy (biała, szara i czarna).
Propagandę można kwalifikować jako białą, szarą lub czarną:
Przesłanki skuteczności propagandy.
Przesłanki/warunki maksymalnej skuteczności propagandy (według Noama Chomskiego):
Ogólną zasadą propagandy jest apelowanie do emocji, a nie do rozumu.
Historia.
Słowo propaganda zostało wprowadzone do języka polityczno-prawnego w 1622 roku przez papieża Grzegorza XV wraz z powołaniem przez niego Kongregacji Propagandy Wiary (Congregatio de Propaganda Fide). Od tego czasu słowo to zaczęło nabierać negatywnego wyrazu w szczególności w ówczesnych krajach protestanckich. Szczególny rozwój propagandy zaczął się od XIX wieku wraz z rozwojem demokracji parlamentarnej, a co za tym idzie rywalizacji wyborczej. Równocześnie powstała opinia publiczna. Propaganda wyborcza stała się narzędziem debaty politycznej i walki wyborczej o władzę w krajach demokratycznych.
Propaganda odgrywała dużą rolę w
komunistycznym i narodowo-socjalistycznym ustroju totalitarnym, gdzie pojawiła się w formie propagandy totalnej jako jedno z narzędzi dezinformacji, wykluczając jakąkolwiek samodzielność w tworzeniu opinii widza czy słuchacza.
W epoce nowoczesnej pierwszy użył masowo propagandy Biały Dom prezydenta Woodrowa Wilsona w latach 1916/17 w celu pozyskania Amerykanów, dotąd nastawionych antywojennie, do idei udziału USA w I wojnie światowej. Jeszcze podczas kampanii prezydenckiej 1916 Wilson, schlebiając nastrojom społecznym, deklarował pacyfizm. Zaraz po zwycięstwie wyborczym polecił jednak zalanie mediów potokiem „newsów” – preparowanych przeważnie przez wywiad brytyjski – o barbarzyństwach Hunów (przysłowiowe „odrywanie rączek niemowlętom” itp.). Po półrocznym propagandowym ostrzale udało się tzw. Komisji Creela (Committee on Public Information) doprowadzić niemal do histerii wojennej w Ameryce. Członek komisji Walter Lippmann nazwał to „rewolucją w sztuce demokracji” polegającą na „fabrykowaniu przyzwolenia” i uzasadniał nieodpowiedzialnością społeczeństwa: „dobro ogólne całkowicie umyka opinii publicznej” (cyt. za: Noam Chomsky „Kontrola nad mediami”, tłumaczenie Ewy Mykiny). Chomsky zauważa, że podobnie do Wilsona postępował Włodzimierz Lenin, według którego rewolucyjna elita (partia) powinna wykorzystać bunty ludowe, a następnie popędzić naiwne masy ku świetlanej przyszłości.
Zmarły w 1995 Edward Bernays, uznawany w USA za ojca Public Relations (włączony przez magazyn „Life” do 100 najwybitniejszych Amerykanów XX stulecia), rozwijał również to elitarystyczne podejście do propagandy: „Świadoma i naukowa manipulacja nawykami i poglądami szerokich mas jest ważnym elementem społeczeństwa demokratycznego. /.../ Ludzie, o których nigdy nie słyszeliśmy, kierują nami, narzucają schematy myślowe, kształtują gusty i podrzucają idee. I jest to w pełni logiczna droga rozwoju społeczeństwa demokracji (E. Bernays, "Propaganda", rozdz. 1. „Organizując chaos”).
„Propaganda może łatwiej manipulować publicznością, która nie czyta, nie jest zaangażowana” – stwierdza powieściopisarz amerykański T.C. Boyle, komentując badania dotyczące czytelnictwa w Stanach Zjednoczonych.
Propaganda reżimów totalitarnych.
Propaganda komunistyczna (Rosja Radziecka, później ZSRR).
Wraz z dynamicznymi zmianami społecznymi oraz rozwojem nauki i techniki rozwijała się teoria i praktyka propagandy i dezinformacji. Powstały sieci środków masowej komunikacji, takie jak radio czy telewizja, które pozwalały wpływać na życie całych społeczeństw, narodów i państw. „Złotym wiekiem” dla rozwoju tego rodzaju działalności był wiek XX. Jednym z kluczowych beneficjentów rozwoju propagandy jako narzędzia systemu totalitarnego, a jednocześnie motorem tego rozwoju, była od samego początku Rosja Radziecka, a potem ZSRR. Władze tego państwa przywiązywały ogromną wagę do tego typu oddziaływań jak propaganda i dezinformacja. 
Lenin był obok Stalina największym propagatorem komunizmu. Zaczął od wydawania „organu prasowego”, później tekstów propagandowych skierowanych do robotników. Propaganda Lenina przytłumiona I wojną światową wybuchła w 1917 roku. Lenin do działalności zaczął wykorzystywać radio, opracował symbolikę sierpa i młota oraz czerwoną gwiazdę. Równocześnie trwała propaganda za granicą z udziałem Lwa Trockiego. W Baku w 1918 utworzono Radę Propagandy, która miała wydawać dzienniki w językach azjatyckich.
Stalin korzystał z podobnych rodzajów i technik propagandy co współcześni mu Hitler i Mussolini. Apelował on do uczuć nacjonalistycznych swoich rodaków, narodowej dumy, odcinał się od potencjalnej pomocy z zagranicy. Po wydaleniu z kraju Trockiego nie miał on równego sobie przeciwnika, co pozwoliło prowadzić odpowiednią kampanię. Zaczęto propagować etos pracy przez wprowadzanie gospodarki planowej oraz ideologię stachanowców. Wykorzystywano przy tym szczególnie kino – które stawało się coraz bardziej dostępne dla mas, literaturę szczególnie przydatną przy indoktrynacji młodzieży, a także architekturę – metro moskiewskie, popularyzacja posągów wodza, posągów zwycięstwa, oraz szeregu innych działań propagandowych dotyczących wprowadzania kultu jednostki. Od 1947 roku za propagandę miał być odpowiedzialny Kominform, który jednak nie spełnił swojego zadania.
„Wielcy dyktatorzy uznają gigantyczną propagandową rolę kina. Zwłaszcza w pełnym analfabetów Związku Radzieckim z treścią propagandową docierał tylko film i plakat”.
Charakterystyczną cechą okresu stalinizmu było wykorzystywanie propagandy do walki politycznej i ataków na rzeczywistych lub domniemanych przeciwników komunizmu, co miało miejsce np. w przypadku sprawy lekarzy kremlowskich – 13 stycznia 1953 państwowa gazeta „Prawda” podała informacje o rzekomym „spisku lekarzy”, którego celem miało być pozbawienie głównych przywódców ZSRR życia w wyniku niewłaściwego leczenia (jak ujawniono później była to prowokacja Ministerstwa Bezpieczeństwa Państwowego ZSRR, wykonana z polecenia Stalina).
Propaganda narodowego socjalizmu i faszyzmu (III Rzesza i Włochy).
Propaganda i dezinformacja została podniesiona do rangi kluczowego narzędzia polityki wewnętrznej i międzynarodowej III Rzeszy. Joseph Goebbels, niemiecki minister propagandy i oświecenia publicznego, był twórcą aparatu dezinformacyjno–propagandowego, dezinformacja i propaganda miały być instrumentami przeciwdziałającymi frustracji i wskazującymi wroga obywatelom III Rzeszy, którego należało nienawidzić i zwalczać wszelkimi sposobami. Adolf Hitler od początku swojej działalności specjalizował się w tematyce antysemickiej, rozprowadzał ulotki, wydawał gazetę. Już w "Mein Kampf" doceniał rolę propagandy jako środka do osiągnięcia celu, którym była władza. W 1925 r., kiedy dyktował "Mein Kampf", wymyślił termin „Wielkie Kłamstwo” (), który był określeniem techniki propagandowej. Chodziło o użycie „kłamstwa tak kolosalnego, że nikt nie będzie w stanie uwierzyć, że ktoś mógłby mieć bezczelność tak wypaczyć prawdę, kłamać”. Hitler miał cały sztab ludzi (w tym plastyków i dekoratorów) zarówno do tworzenia ideologii, jak i wprowadzania jej w życie. Do rozpowszechnienia ideologii zaczęto używać wyprodukowane specjalnie w tym celu radia, odbierające tylko jedną częstotliwość. Korzystano także z kina, gdzie prezentowano filmy sportowe mające promować tzw. „aryjski typ człowieka”, oraz z plakatów, na których umieszczano karykatury (szczególnie antysemickie) i chwytliwe slogany. Hitler posługiwał się także masowymi widowiskami, paradami, wiecami i zawodami sportowymi. Jednakże Hitler dostał się do władzy na skutek decyzji Hindenburga, czyli decyzji politycznej, a nie za pomocą wyłącznie propagandy. Za to w dalszej karierze politycznej odgrywała już ona znaczącą rolę.
Benito Mussolini, premier i duce Włoch znany był ze swoich płomiennych, porywających przemówień, do oddziaływania propagandowego wykorzystywał także kino.
Pierwszym ministrem propagandy, działającym w latach 1928–1945 w III Rzeszy, był Joseph Goebbels (1897-1945).
Sformułował on zasady propagandy goebbelsowskiej, które były wielokrotnie modyfikowane i wykorzystywane w przyszłości przez różne reżimy totalitarne. Uprawiana przez Goebbelsa propaganda była kierowana raczej do odbiorców wykształconych lub chcących za takowych uchodzić. Znienawidzonych Żydów porównywano do bakterii chorobotwórczych, używając w celu poniżenia przeciwnika takich określeń jak „sterylność”, „zakażenie”, „higiena”, „zarazek” itd. Innym przykładem była propaganda fabrykowana przez Juliusa Streichera, redaktora naczelnego niemieckiego tygodnika "Der Stürmer", która odwoływała się do najbardziej niskich instynktów. Streicher szydził z ludzkiej ułomności, chorób, niedoskonałości, używał wulgarnego słownictwa, a nawet pornografii. To przykład dwutorowej propagandy nakierowanej jednak na ten sam cel. Streicher został uznany winnym zbrodni przeciwko ludzkości przez Międzynarodowy Trybunał Wojskowy w Norymberdze i skazany na karę śmierci przez powieszenie. Wyrok wykonano 16 października 1946 roku.
Streicher jest przykładem człowieka skazanego za zbrodnie przeciwko ludzkości, który sam osobiście nikogo nie zamordował, jednak jego działalność propagandowa wydatnie przyczyniła się do tych zbrodni.
W czasie II wojny światowej pojawiła się propaganda antynazistowska.
W 1943 roku polski rząd londyński zamówił film "Calling mr. Smith" opowiadający anglosaskiej opinii publicznej o zbrodniach nazistowskich Niemiec w okupowanej Polsce. Był to jeden z pierwszych filmów w historii opowiadających o kłamstwach nazistowskiej propagandy.
Propaganda komunistyczna w PRL.
Pod koniec XX wieku wraz z upowszechnieniem się środków masowego przekazu, radia, telewizji propaganda przybrała formę reklamy, łącząc się z kulturą masową. Określenie „propaganda”, nabrało negatywnego wydźwięku między innymi na skutek takich zjawisk, jak propaganda goebbelsowska, propaganda sukcesu, pranie mózgu czy nowomowa.
Przeciwstawianie się propagandzie.
Odbiorcy propagandy – społeczeństwo, nie muszą bezkrytycznie wierzyć w narzucane im treści i mogą się im przeciwstawiać w sposób bezpośredni lub pośredni poprzez żarty, satyrę lub odcięcie się od źródeł propagandy (np. wyłączenie nadajników).

</doc>
<doc id="13023" url="https://pl.wikipedia.org/wiki?curid=13023" title="Morfologia">
Morfologia

Morfologia (gr. "morphḗ" „kształt”, "lógos" „nauka”) – „nauka o formach”; „morfologiczny” – związany z „morfologią”; dotyczący postaci i budowy.

</doc>
<doc id="13024" url="https://pl.wikipedia.org/wiki?curid=13024" title="Związek rządu">
Związek rządu

Związek rządu (rekcja) – relacja między powiązanymi elementami zdania, w której jeden musi mieć pewną z góry ustaloną formę, niezależnie od formy drugiego. Związek rządu typowy jest dla endocentryzmu – element centralny narzuca formę pozostałym elementom. Jest to zdolność łączenia elementów nominalnych z określonym przypadkiem.
Język polski.
W języku polskim związek główny podmiotu logicznego z orzeczeniem jest związkiem rządu. Ponadto pytaniami pomocnymi w ustalaniu związku rządu między wyrazami są pytania dopełnienia (czyli pytania odmiany rzeczownika bez mianownika i wołacza: "kogo? czego?; komu? czemu?; kogo? co?; z kim? z czym?; o kim? o czym?"). Związek rządu zachodzi również między rzeczownikami, gdy jeden jest wskazaniem własności drugiego, np. „światło słońca”.
Związek rządu zachodzi w przypadkach:
Język niemiecki.
W języku niemieckim przez związek rządu (rekcję, niem. "Rektion") określa się najczęściej wymóg użycia po danym czasowniku określonego przyimka, a po nim rzeczownika w określonym przypadku gramatycznym. Na przykład czasownik "warten" („czekać”) wymaga użycia przyimka "auf" i rzeczownika w bierniku: "Ich warte auf den Lehrer" („Czekam na nauczyciela”). Termin ten dotyczy jednak również innych konstrukcji, analogicznych do tych w języku polskim.

</doc>
<doc id="13025" url="https://pl.wikipedia.org/wiki?curid=13025" title="Reklama">
Reklama

Reklama (z łac. "reclamo, reclamare" ‘odzew’; "re" 'w tył, znów, naprzeciw’ i "clamo, clamare" ‘wołać’) – informacja połączona z komunikatem perswazyjnym. Zazwyczaj ma na celu skłonienie do nabycia lub korzystania z określonych towarów czy usług, popierania określonych spraw lub idei (np. promowanie marki).
Jawność przekazu.
Reklama może być:
Działanie.
Reklama jako środek masowego przekazu ma za zadanie budować zachowania, generować potrzeby, wywoływać pragnienie. Reklama przybiera różną postać – od rzetelnej informacji o cechach produktu, spotykanej głównie w prasie specjalistycznej, po wychwalanie produktu bez rzetelnej informacji merytorycznej o przedmiocie reklamy, co często przypisuje się reklamie telewizyjnej.
Czasami reklama występuje w formie ukrytej – np. firmy organizują prezentacje własnych technologii czy też piszą artykuły do prasy specjalistycznej na ich temat – co jest na pograniczu reklamy i edukacji lub ukazywane są przedmioty będące towarami określonej marki, umieszczone w kontekście filmu fabularnego.
Czasem reklama łączona jest z korzyściami dla osób decydujących o skorzystaniu z przedmiotu reklamy – np. firmy sponsorują wyjazdy szkoleniowe lub pseudoszkoleniowe w atrakcyjne miejsca – co jest na pograniczu reklamy i korupcji.
Celem reklamy jest skuteczność ich oddziaływania na odbiorcę, dlatego w reklamie można się spotkać z treściami wywołującymi np. skandal obyczajowy lub procesy sądowe. Dzięki temu wzrasta zainteresowanie wokół reklamy, a tym samym siła oddziaływania kampanii reklamowej.
Ważną cechą odróżniającą w komunikacji poprzez media reklamę od public relations jest to, że reklama jest formą płatną, tzn. reklamodawca płaci mediom za nadanie komunikatu reklamowego i ma nad tym komunikatem pełną kontrolę.
Zdecydowana większość reklam charakteryzuje się celami komercyjnymi. Można jednak wyróżnić również reklamę społeczną oraz reklamę polityczną. Ponadto istnieją zjawiska łączące ze sobą wymienione typy reklam – reklamy powstające w ramach kampanii marketingowych łączących cele komercyjne z celami społecznymi (tak prowadzony marketing określa się mianem marketingu społecznie zaangażowanego, ang. "Cause Related Marketing"). Tego typu reklam nie należy mylić z reklamami społecznymi.
Historia reklamy.
Swoiste formy reklamy pochodzą z czasów starożytnych. Stosowano wówczas reklamę w postaci napisów na ścianach budynków, kamiennych lub terakotowych szyldów karczmy, zajazdu. Starożytni handlowcy wykrzykiwali oraz zachwalali cechy swoich towarów i dóbr. W ten sposób powstała pierwsza w historii forma reklamy – reklama ustna. W starożytnej Grecji pojawiła się reklama pisemna. Miała ona charakter spisanych informacji dotyczących wydarzeń kulturalnych i sportowych.
Wynalezienie przez Gutenberga druku zrewolucjonizowało reklamę. Za umowną datę wynalezienia druku uznaje się rok 1450. Pojawiły się pierwsze gazety, a w nich pierwsze reklamy prasowe.
Modele reklamy.
Model SLB (II poł XX w.):
Model AIDA (1900):
Model AIDCAS (1911):
Model DAGMAR (1961):
Model DIPADA (1961):
Model Lavidge’a-Steinera (1961);
Model Raya (1987):

</doc>
<doc id="13029" url="https://pl.wikipedia.org/wiki?curid=13029" title="Pranie pieniędzy">
Pranie pieniędzy

Pranie pieniędzy (ang. "money laundering") – działania zmierzające do wprowadzenia do legalnego obrotu pieniędzy lub innych wartości majątkowych uzyskanych z nielegalnych źródeł bądź służących do finansowania nielegalnej działalności. W większości przypadków dotyczy to przestępczości narkotykowej, terroryzmu lub innych zorganizowanych działań karalnych.
Opis.
Najbardziej znaną metodą tego procederu jest zawyżanie przychodów z legalnej działalności, której dokładne rozmiary są trudne do skontrolowania, w szczególności drobnej działalności usługowej. Nazwa procesu wzięła się od amerykańskich pralni na monety, w przypadku których trudno skontrolować rzeczywiste przychody.
W międzynarodowym praniu pieniędzy na większą skalę włącza się skomplikowane operacje finansowe, co ma być znacznie ułatwione przez postęp techniczny w sektorze finansowym.
Pojęcie prania pieniędzy użyto po raz pierwszy w latach 20. XX wieku w Stanach Zjednoczonych. Mafia chicagowska kierowana przez Ala Capone czerpała zyski z nielegalnej produkcji, sprzedaży i przemytu alkoholu. Aby ukryć proceder, członkowie mafii prowadzili legalną działalność handlowo-usługową, czyli sklepy i pralnie. Dochody nielegalne dopisywano do codziennych utargów, aby ukryć ich pochodzenie.
Ośrodek Szkolenia Departamentu Skarbu USA określił pranie pieniędzy w następujący sposób: "Pranie pieniędzy to proces, przy pomocy którego dochody przypuszczalnie uzyskane z działalności przestępczej są przekazywane, przekształcane, wymieniane albo też łączone i mieszane z legalnymi funduszami w celu ukrycia lub zatajenia prawdziwego charakteru, źródła, ukierunkowania, przepływu lub własności tych dochodów. Celem procesu prania pieniędzy jest nadanie pozorów legalności funduszom uzyskanym z działalności pozaprawnej lub działań z nią powiązanych."
W 1989 roku podczas szczytu G7, została powołana Grupa Specjalna ds. Przeciwdziałania Praniu Pieniędzy (The Financial Action Task Force on Money Laundering), która w kwietniu 1990 wydała rekomendacje dotyczące walki z praniem pieniędzy. Stały się one podstawą wydania w 1991 roku przez Radę Wspólnot Europejskich dyrektywy w sprawie ochrony systemu finansowego przed wykorzystaniem go do celów prania pieniędzy, która została zastąpiona Dyrektywą Parlamentu Europejskiego i Rady z dnia 26 października 2005 roku w sprawie przeciwdziałania korzystaniu z systemu finansowego w celu prania pieniędzy oraz finansowania terroryzmu.
Rekomendacje FATF zostały zaktualizowane w lutym 2012 roku i stały się podstawą do uchwalenia w maju 2015 roku Dyrektywy Parlamentu Europejskiego i Rady nr 2015/849 w sprawie zapobiegania wykorzystywania systemu finansowego do prania pieniędzy lub finansowania terroryzmu
Art. 1 dyrektywy definiuje to zjawisko następująco:
Rada Europy w Konwencji z 2005 roku określa pranie jako świadome działanie mające na celu:
Przepisy dotyczące przeciwdziałania praniu pieniędzy określa się mianem AML ("Anti-Money Laundering"). Pierwsza regulacja AML została przyjęta w roku 2010. Od tego czasu wprowadzono cztery jej nowelizacje. Ostatnią Parlament Europejski uchwalił w roku 2016 i zaczęła obowiązywać od 12 maja 2018 roku.
Konwencja ONZ przeciwko międzynarodowej przestępczości zorganizowanej z 2000 r. w art. 7 postanawia
Etapy prania pieniędzy.
Pranie pieniędzy to sekwencja kilku następujących zachowań obejmujących w szczególności: zatarcie nielegalnego źródła pieniędzy oraz utworzenie dla nich nowego „legalnego” pochodzenia.
1. Faza wstępna
Polega na przygotowaniu całego procesu. Do fazy wstępnej zalicza się w szczególności dyslokacje kapitału (transport bądź to z miast na wieś, gdzie jest mniejsza szansa wykrycia procederu bądź za granicę).
Przykłady sposobów transferowania kapitału za granicę:
2. Umiejscowienie ("placement")
Polega na wprowadzeniu nielegalnych środków do systemu finansowego (zwykle poprzez wpłatę na konto). Jest to najbardziej ryzykowny etap całego procederu. Organizacje przestępcze stosują różne metody „obchodzenia” bankowej kontroli wpłat. Najczęściej polega on na dzieleniu całej kwoty na mniejsze sumy, poniżej progu rejestracji (structuring), także wpłaty przy użyciu setek wynajętych osób (tzw. smurfing). Często ten etap możliwy jest dzięki „współpracy” pracowników banków lub instytucji finansowych. Czasem stosuje się także występujące w niektórych krajach zwolnienia z obowiązku rejestracji dla określonych rodzajów działalności ("exempt transactions").
3. Maskowanie ("layering")
Etap ten polega na „urwaniu” śladu prowadzącego do rzeczywistego źródła pieniędzy. Następuje zazwyczaj poprzez dokonywanie wielokrotnych operacji transferu pieniędzy na konta w różnych bankach i państwach. W razie gdy transferu dokonano na konto banku, który znajduje się w tzw. „oazie podatkowej”, ślad urywa się, gdyż banki w tych państwach nie muszą rejestrować informacji kto wpłacił pieniądze lub skąd zostały przesłane. Do transferu pieniędzy wykorzystywany jest np. międzynarodowy system SWIFT. Zamiast przechodzić przez te etapy przestępcy często reinwestują pieniądze w działalność przestępczą.
4. Integracja/legitymizacja ("integration")
Polega na „dorobieniu” legalnego świadectwa dla pieniędzy. Stosuje się tutaj najróżniejsze metody, np.:
Pranie pieniędzy a kryptowaluty.
W powszechnej opinii od ponad dekady do procederu prania pieniędzy dochodzi za pośrednictwem kryptowalut, w tym Bitcoin. Mimo faktu, że pozornie kryptowaluty dają anonimowość, to w przypadku większości z nich, zwłaszcza tych z transparentnym kodem źródłowym, opartych na otwartej sieci blockchain transakcje zawierane są jawnie. Oznacza to, że można prześledzić całą historię przepływów finansowych na konkretnym adresie, aż do początku istnienia całej sieci. Organy ścigania często nie podzielają opinii o transparentności sieci, stąd też bitcoin jest przez nich bardzo często wybierany jako jeden z elementów służących do prania pieniędzy. Istotne, z punktu widzenia AML, jest tutaj weryfikowanie źródła pochodzenia środków. W przypadku polskich giełd kryptowalut istnieje tylko jedna, której Polityka AML została zaakceptowana przez Komisję Nadzoru Finansowego. Jest nią giełda kryptowalut BitClude, która posiada również licencję Małej Instytucji Płatniczej nr MIP11/2019
Przeciwdziałanie praniu pieniędzy w Polsce.
Do przeciwdziałania praniu pieniędzy powołany został w Polsce Generalny Inspektor Informacji Finansowej, działający na podstawie i zgodnie z ustawą z dnia 16 listopada 2000 r. o przeciwdziałaniu praniu pieniędzy oraz finansowaniu terroryzmu.
Na potrzeby procesowe wykorzystuje się w Polsce definicję prania pieniędzy zawartą w kodeksie karnym z dnia 6 czerwca 1997 r., którego art. 299 stanowi:
Instytucje obowiązane.
Instytucje obowiązane to podmioty, które obowiązane są o postępowania według ustawy o przeciwdziałaniu praniu pieniędzy i finansowaniu terroryzmu. Są to m.in.:
Obowiązki.
Instytucje obowiązane muszą spełniać określone zadania, wśród których najważniejsze to:
Środki bezpieczeństwa.
Zakres środków bezpieczeństwa finansowego został określony w art. 34 ustawy, a wśród nich m.in.:
Kary.
Za niedopełnienie lub nieprawidłowe wypełnienie obowiązków określonych w ustawie, instytucji obowiązanej grożą sankcje administracyjne oraz karne.
Kary administracyjna nakładają Generalny Inspektor, Prezes NBP oraz KNF. Przykłady sankcji administracyjnych:
Przykłady sankcji karnych.
Wysokość kary jest zależna od wagi naruszenia, czasu trwania, zakresu odpowiedzialności podmiotu, jego możliwości finansowej oraz od skali korzyści lub unikniętych strat, strat innych osób oraz czy wystąpiło uprzednie naruszenie innych przepisów.

</doc>
<doc id="13035" url="https://pl.wikipedia.org/wiki?curid=13035" title="Bitwa pod Navarino (1827)">
Bitwa pod Navarino (1827)

Bitwa pod Navarino – bitwa stoczona 20 października 1827 w czasie wojny o niepodległość Grecji, pomiędzy flotą turecko-egipską a francusko-brytyjsko-rosyjską, uznawana za ostatnią większą bitwę stoczoną przez okręty żaglowe.
Tło bitwy.
Od sześciu lat trwała wojna o niepodległość Grecji, znajdującej się pod panowaniem tureckim. Francja, Wielka Brytania i Rosja pod presją opinii publicznej jak i kierowane obawą o los własnych interesów handlowych, wystąpiły do sułtana o wykonanie Konwencji Londyńskiej 1827 nadającego Grecji autonomię, co spotkało się z odmową ze strony Wysokiej Porty. W związku z tym główne mocarstwa ówczesnej Europy: Wielka Brytania, Rosja i Francja, na mocy dyplomatycznych umów skierowały na wody greckie swoje eskadry. Zadaniem tych eskadr miało być niedopuszczenie posiłków tureckich do Grecji, lecz miały one nie brać udziału w konflikcie.
Eskadry te zostały połączone a na czele tak powstałej floty stanął brytyjski wiceadmirał Edward Codrington – równocześnie dowodzący eskadrą brytyjską. Eskadrą rosyjską dowodził kontradmirał Ludwig Hayden, a francuską – kontradmirał Henri Gauthier de Rigny.
Bitwa.
20 października 1827 roku flota ekspedycyjna, w składzie 10 okrętów liniowych oraz 10 fregat i sile ognia 1676 armat, weszła do zatoki przed portem Navarino (Pylos) na Peloponezie. Tu, pod osłoną nadbrzeżnych baterii tureckich liczących 165 armat, stacjonowała flota turecko-egipska w składzie 3 okrętów liniowych, 17 fregat i ok. 40 mniejszych jednostek (w tym 5-6 branderów), mających do 2200 armat. Flota turecko-egipska była dowodzona przez admirała Muharrem Beja, podlegającego Ibrahimowi Paszy, dowodzącemu tureckimi wojskami w Grecji. Wiceadmirał Codrington blokując flotę turecko-egipską wykonywał zlecone mu zadanie: udzielić pomocy Grekom i nie wystąpić zbrojnie w tym konflikcie. Siły tureckie ustawione były w podkowę wzdłuż wschodniego i północnego wybrzeża zatoki. Okręty alianckie podpłynęły do liniowców tureckich i zatrzymały się w niewielkiej odległości.
W pewnej chwili Turcy obsadzili załogą manewrową brander stojący w pobliżu brytyjskiej fregaty "Dartmouth". Dowódca okrętu brytyjskiego skierował w jego kierunku łódź z parlamentariuszami. Została ona ostrzelana przez załogę tureckiego brandera, padli pierwsi zabici. Następnie z okrętów tureckich padły dwa strzały armatnie, trafiając niegroźnie "Dartmoutha" i "Sirène". W efekcie doszło do bitwy.
Starcie rozpoczęło się o godz. 14:25. W ciągu 4 godzin spalono i zatopiono 65 okrętów i statków tureckich. Flota turecko-egipska ustawiona była w dobrej pozycji obronnej, ale rezultat starcia był wynikiem przewagi technicznej, a przede wszystkim lepszego wyszkolenia marynarzy mocarstw europejskich. W boju morskim wyróżnił się flagowy okręt rosyjski "Azow" pod dowództwem komandora M. P Łazariewa.
Straty tureckie wyniosły ok. 3000 zabitych i 1109 rannych. Straty floty sprzymierzonych – 181 zabitych i 480 rannych. 
W bitwie brało udział 27 okrętów sił sprzymierzonych (francusko-brytyjsko-rosyjskich):
Po stronie turecko-egipskiej brało udział 89 okrętów (3 liniowce, 17 fregat, 30 korwet, 28 brygów, 5 szkunerów oraz 5 lub 6 innych) między innymi:
W źródłach występują różnice jeżeli chodzi o liczbę mniejszych jednostek, które wzięły udział w bitwie.
Skutki bitwy.
W wyniku bitwy złamano potęgę morską Turcji. Zwycięstwo przyczyniło się do rozszerzenia walk wyzwoleńczych Greków. W 1829 sułtan podpisał traktat adrianopolski uznający autonomię Grecji. W 1830 proklamowano w Londynie niezależność Grecji pod protektoratem Francji, Rosji i Wielkiej Brytanii. Rosja odniosła zwycięstwo w wojnie rosyjsko-tureckiej 1828 - 1829. Wielka Brytania nie odniosła jednak żadnych korzyści politycznych ze zwycięstwa, natomiast wypadki następujące po nim doprowadziły do wzrostu potęgi Egiptu względem Turcji.

</doc>
<doc id="13037" url="https://pl.wikipedia.org/wiki?curid=13037" title="Ekwador">
Ekwador

Ekwador (Republika Ekwadoru; ) – państwo w Ameryce Południowej położone nad Oceanem Spokojnym, jedno z czterech powstałych w wyniku rozpadu Wielkiej Kolumbii w 1830 r. Sąsiaduje od północy z Kolumbią, a od południa z Peru. W skład Ekwadoru wchodzą także położone na Oceanie Spokojnym Wyspy Galapagos – są jego największą atrakcją turystyczną. Nazwa kraju pochodzi od hiszpańskiego słowa oznaczającego równik.
Geografia.
Położenie.
Państwo położone w północno-zachodniej Ameryce Południowej nad Oceanem Spokojnym. Graniczy z Kolumbią od północy i z Peru od południa. Do Ekwadoru należą również Wyspy Galapagos położone na Oceanie Spokojnym ok. 1000 km na zachód od części kontynentalnej.
Warunki naturalne.
Obszar Ekwadoru rozciąga się od nizin na wybrzeżach Oceanu Spokojnego w zachodniej części kraju, poprzez łańcuchy górskie Andów, po zachodnie krańce Niziny Amazonki na wschodzie. Linia brzegowa jest słabo rozwinięta, naprzeciw jedynej dużej zatoki Guayaquil leży wyspa Puná o powierzchni ok. 900 km².
W Ekwadorze można wyróżnić 2 prowincje fizycznogeograficzne i 5 podprowincji:
Stosunki wodne.
Dobrze rozwiniętą, gęstą sieć rzeczną tworzą m.in. należące do dorzecza Amazonki rzeki: Napo, Pastaza, Morona i Putumayo oraz uchodzące do Oceanu Spokojnego: Esmeraldas, Guayas, i Daule. Brak większych jezior, w widłach rzek Guayas i Daule bagna.
Klimat.
Klimat równikowy, w Andach górski z piętrami klimatycznymi, w południowej części wybrzeża suchy, pozostający pod wpływem zimnego Prądu Peruwiańskiego. Średnia roczna suma opadów od 200 mm w południowej części wybrzeża i 400 mm w śródgórskich kotlinach oraz w południowej części Andów, do 3000 mm w północnej części wybrzeża, na wschodnich stokach Kordyliery Środkowej i we wschodnim Ekwadorze. Średnie temperatury utrzymują się mniej więcej na jednakowym poziomie przez cały rok: w stolicy kraju Quito wynoszą ok. 15 °C (od 7 °C do 23 °C), w największym mieście kraju Guayaquil ok. 26 °C (od 24 °C do 27 °C)
Fauna i flora.
Naturalną szatę roślinną stanowią lasy, pokrywają ponad 50% powierzchni Ekwadoru. We wschodnim Ekwadorze w dorzeczu Amazonki wilgotne lasy równikowe (mahoniowiec, palisander, balsa, kauczukowiec), w Andach wiecznie zielone lasy liściaste, na wybrzeżu lasy suche. Śródgórskie płaskowyże porasta trawiasto-krzewiasta formacja zwana "parámo" wraz z innymi formacjami trawiastymi.
Historia.
Okres przedhiszpański.
Pierwsze ślady osadnictwa na ziemiach należących do Ekwadoru pochodzą z ok. 8000 p.n.e. Tereny te, zamieszkane przez liczne rolnicze plemiona indiańskie, król "Tupa Inca Yupanqui" włączył w granice państwa Inków w drugiej połowie XV w.
Podbój Ekwadoru.
Obszar Ekwadoru został odkryty i od 1526 roku penetrowany przez Hiszpanów (wyprawy Francisco Pizarra i Diego de Almagra). Ostatecznie konkwistadorzy, dowodzeni przez podwładnego Pizarra, Sebastiána de Belalcázara, opanowali te tereny w latach 1531–1535 i założyli miasta Quito oraz Guayaquil. W 1536 roku Ekwador włączono do Wicekrólestwa Peru. W 1563 utworzono audiencje Quito, ważną gospodarczo bo bogatą w srebro i złoto, miasto Quito było także jej centrum kulturalno-naukowym. We wschodniej części audiencji istniało w latach 1638–1773, posiadające sporą autonomię państwo Maynas, administrowane przez jezuickich misjonarzy. Następnie w 1739 tereny te włączono do Wicekrólestwa Nowa Granada.
Ruchy niepodległościowe, Wielka Kolumbia.
W XVII i XVIII wieku niewolniczy przymus pracy na roli i w kopalniach powodował liczne powstania Indian. Od drugiej połowy XVIII wieku pojawiły się dążenia niepodległościowe wśród Kreoli, i w związku z tym próby uniezależnienia Quito od władzy hiszpańskiej.
W początkach XIX wieku rozpoczęła się walka miejscowej ludności z kolonizatorami hiszpańskimi. W 1809 roku wybuchło powstanie, utworzono juntę rządzącą i proklamowano niepodległość, której nie udało się jednak utrzymać na skutek stłumienia rewolty. Kolejne powstanie z 1812 również zostało stłumione. Od 1819 wybuchają dalsze walki pod dowództwem gen. Antonio José de Sucre. Dzięki decydującemu zwycięstwu generała de Sucre pod Pichincha (24 maja 1822) umożliwia wojskom Simona Bolivara wyzwolenie miasta Quito (16 czerwca 1822). Działania wojskowe zostają zakończone w 1822 r. ostatecznym zwycięstwem. W następnych latach Ekwador wstępuje, jako prowincja Quito, do stworzonej przez Simona Bolivara federacyjnej republiki Wielkiej Kolumbii (powstałej w 1819).
Niepodległość.
W 1824 prowincja przyjmuje dzisiejszą nazwę Ekwador. Po rozpadzie Wielkiej Kolumbii w maju 1830, Ekwador ogłasza się niezależnym państwem. Pierwszym prezydentem zostaje generał Juan José Flores. Przez cały okres niepodległego bytu wewnętrzna sytuacja polityczna kraju była bardzo skomplikowana i pełna napięć. Władzę sprawowano w sposób niezgodny z zasadami demokracji, zmiany kolejnych ekip rządzących dokonywały się często na drodze przewrotów wojskowych i zamachów stanu. Mimo niepewnej sytuacji politycznej w niepodległym Ekwadorze udało się przeprowadzić szereg postępowych reform społecznych i gospodarczych. Starano się rozwijać infrastrukturę komunikacyjną kraju, budując wiele kilometrów linii kolejowych i dróg.
XIX-wieczną historię Ekwadoru zdominowała rywalizacja dwóch regionów gospodarczo-polityczno-kulturalnych: "Sierry" z ośrodkiem w Quito i "Costy" z ośrodkiem w Guayaquil. Nowo odkryte tereny Amazonii, nieznane i niezagospodarowane, pozostawały poza kontrolą państwa i stanowiły obszar sporny między Ekwadorem, Peru i Kolumbią. Rządy konserwatystów z Sierry – reprezentujących wielkich właścicieli ziemskich i armię, eksponujących rolę Kościoła katolickiego (należeli do nich prezydenci Juan Jose Flores i G. García Moreno) – przeplatały się z rządami liberałów z Costy – przedstawicieli burżuazji handlowo-przemysłowej. Walkom o władzę towarzyszyły konflikty zbrojne z Peru i Kolumbią. Od 1852 roku rządy objęli liberałowie, nastąpiło zniesienie niewolnictwa i wygnanie jezuitów, wprowadzono bezpłatne szkolnictwo. W 1861 do władzy doszli konserwatyści, w 1869 roku ustanowili konstytucję przyznającą prawa polityczne wyłącznie katolikom. Zaostrzająca się rywalizacja między konserwatystami a liberałami doprowadziła do wojny domowej, trwającej w latach 1895–1896. Po zwycięstwie liberałów, przejęli oni władzę w Ekwadorze i sprawowali ją prawie nieprzerwanie do 1944. Dominującą wtedy rolę w gospodarce i polityce zaczęła odgrywać "Costa", zwłaszcza prowincja Guayaquil. Po otwarciu Kanału Panamskiego intensywnie zaczął rozwijać się handel zagraniczny, Ekwador stał się jednym z największych na świecie eksporterów kakao.
XX wiek.
W latach 20. XX wieku utworzona została junta wojskowa. W tym czasie zaczęły do Ekwadoru napływać obce kapitały (zwłaszcza brytyjski i amerykański) inwestowane w przemysł naftowy. Rosło uzależnienie Ekwadoru od USA. Rządzący od 1929 do 1931 roku Isidro Ayora próbował dokonać reformy państwa, co nie udało się ze względu na problemy ekonomiczne. Lata 30. to okres kryzysu gospodarczego (znaczne pogorszenie sytuacji ekonomicznej m.in. pod wpływem wielkiego kryzysu światowego) oraz destabilizacji politycznej wywołanej licznymi zamachami stanu. W latach 1931–1940 władzę sprawowało aż 18 prezydentów i żaden z nich nie dotrwał do końca kadencji. W 1941 wybuchła wojna z Peru o Amazonię, gdzie odkryto bogate zasoby ropy naftowej. Wojnę zakończyło porozumienie zawarte 1942 w Rio de Janeiro pod presją państw obu Ameryk (gwarantowane przez Argentynę, Brazylię, Chile i USA), niekorzystne dla Ekwadoru, który utracił ok. 40% swojego terytorium. W połowie II wojny światowej Ekwador opowiedział się po stronie aliantów i w 1942 roku wypowiedział wojnę Niemcom oraz Włochom. Dzięki temu otrzymał znaczną pomoc gospodarczą od USA, które zbudowały na ważnych pod względem strategicznym wyspach Galápagos bazę wojskową, dla ochrony Kanału Panamskiego.
Ekwador zostaje w 1945 członkiem ONZ. W okresie powojennym armia przejęła inicjatywę w życiu politycznym państwa i podjęła próby jego unowocześnienia. W 1944 roku, w wyniku zamachu stanu wojskowych, władzę przejął José María Velasco Ibarra, który przez ok. 30 lat wywierał wpływ na życie Ekwadoru, był prezydentem w latach 1944–1947, 1952–1956, 1960–1961 i 1968–1972. Jego plany reform, zmierzających do modernizacji zacofanego gospodarczo, rolniczego Ekwadoru, nie zostały zrealizowane. Prowadził niezależną politykę zagraniczną w stosunkach z USA i kwestionował, lecz bez rezultatu, układ graniczny z Peru zawarty po wojnie w 1942.
Wojskowi sprawujący (z przerwami) władzę w latach 1961–1979 deklarowali potrzebę reform strukturalnych, polityki rozwojowej i wzmocnienia kontroli państwa nad gospodarką. Próbowali także nacjonalizować niektóre jej dziedziny. W 1964 zadekretowali ograniczoną reformę agrarną, którą realizowano jeszcze w połowie lat 70., lecz nie wywarła ona większego wpływu na zmianę struktury rolniczej kraju, w ramach reformy udało znieść się "huasipungo", czyli quasi-pańszczyźniany system panujący w regionie Sierra. Od lat 70. ważnym elementem gospodarki Ekwadoru stała się ropa naftowa, której bogate złoża odkryto w 1967. W 1974 znacjonalizowano część mienia amerykańskiego koncernu "Texaco-Gulf" i zmniejszono tereny koncesyjne, w 1973 roku, po odkryciu dalszych bogatych złóż ropy, Ekwador przystąpił do OPEC. Eksport ropy poprawił sytuację gospodarczą Ekwadoru, dochody z niego nie służyły jednak tworzeniu trwałych podstaw do rozwoju kraju.
Na początku lat 80., po spadku cen ropy naftowej na rynkach światowych, sytuacja gospodarcza Ekwadoru ponownie się pogorszyła, jednocześnie odżyły konflikty graniczne z Peru i Kolumbią. Kolejne rządzące koalicje (1981–1988 i od 1992 centroprawicowe, 1988–1992 centrolewicowa) próbowały realizować całkowicie odmienne rozwiązania gospodarcze – neoliberalne i socjaldemokratyczne, co nie przyniosło pozytywnych i trwałych zmian w sytuacji społeczno-gospodarczej kraju. Przybyły też nowe problemy: wzrost roszczeń (m.in. społeczno-politycznych) ludności tubylczej (indiańsko-metyskiej) stanowiącej większość mieszkańców Ekwadoru, m.in. żądania zwrotu ziemi nadanej reformami z 1964 i 1973 i odebranej w 1994 (marsze na stolicę, blokady dróg itd.). Według raportów USA Ekwador ma coraz bardziej rosnący udział w nielegalnym tranzycie narkotyków.
W 1993 nowo wybrany prezydent Sixto Durán Ballén podjął decyzję o wystąpieniu Ekwadoru z OPEC. Krok ten był konsekwencją polityki sanacji, dotyczącej gospodarki prowadzonej przez nową ekipę rządzącą. Decyzję o wystąpieniu podjęto w związku z nieprzyznaniem żądanych, wyższych limitów na wydobycie ropy. Wprowadzone posunięcia oszczędnościowe, podwyżki cen, dewaluacja krajowej waluty spotkały się z protestami związków zawodowych i ludności. W 1994 roku na fali niezadowolenia powstała organizacja rebeliancka Grupa Ludowych Kombatantów, która przyjęła lewicową ideologię.
W 1998 prezydentem zostaje chrześcijański-demokrata Jamil Mahuad, doprowadza do nowelizacji konstytucji, poprzedzonej referendum, w kwestii możliwości reelekcji głowy państwa i prawa dwukrotnego wyboru deputowanych do parlamentu. W 1999 na skutek dużego spadku cen ropy na rynkach światowych kraj popada w duży kryzys ekonomiczny, inflacja osiąga poziom 60%, fala strajków i demonstracji (okupacja parlamentu przez 10 tys. Indian) zmusza prezydenta do ogłoszenia stanu wyjątkowego. Jednak już na początku 2000 nasilają się nowe demonstracje, wspomagane częściowo przez wojsko (nieudany wojskowy zamach stanu płk. Lucio Gutierreza), prowadzą do obalenia prezydenta Jamila Mahuada (21 stycznia 2000). Zostaje on zastąpiony przez ówczesnego wiceprezydenta Gustavo Noboa Berejano. 10 września 2000 zastąpiono narodową walutę sucre dolarem amerykańskim, z czego wynikła drastyczna podwyżka cen, która ostatecznie pogłębiła napięcie i trudną sytuację w kraju. Prezydent Gustavo Noboa Berejano wprowadza stan wyjątkowy w całym kraju.
XXI wiek.
W 2002 r. mają miejsce kolejne wybory prezydenckie, zwycięża Lucio Gutierrez, który stał na czele puczu z 2000. U progu XXI wieku rozwija się działalność rebeliantów z Grupy Ludowych Kombatantów, która dokonała kilku zamachów, a według doniesień otrzymała szkolenie militarne ze strony kolumbijskiej partyzantki. Działania te jednak miały znikomy wpływ. W marcu 2005 w wyniku demonstracji ulicznych parlament odsuwa od władzy prezydenta (prezydent otrzymuje azyl polityczny w Brazylii). Urząd prezydencki obejmuje dotychczasowy wiceprezydent Alfredo Palacio. W marcu tego roku mają miejsce protesty ludności indiańskiej wobec planowanej umowy o wolnym handlu z USA.
W 2006 roku wybory prezydenckie wygrał ekonomista Rafael Correa. Correa obiecał przed wyborami reformę przemysłu naftowego, mającą zapewnić większe dochody skarbowi państwa. Protestował przeciw dominacji i zaangażowaniu Stanów Zjednoczonych w sprawy latynoamerykańskie. Sprzeciwiał się podpisaniu porozumienia handlowego z USA i wprowadzeniu dolara amerykańskiego jako oficjalnej jednostki monetarnej w Ekwadorze. Obiecywał likwidację amerykańskiej bazy wojskowej w Mancie, liczącej 400 żołnierzy. 5 stycznia 2007 został zaprzysiężony na stanowisku prezydenta.
Rafael Correa w swoim przemówieniu inauguracyjnym 15 stycznia 2007 stwierdził, że część długu zagranicznego Ekwadoru jest „bezprawna”, ponieważ została zaciągnięta przez reżim wojskowy. W kolejnych dniach minister finansów ogłosił, że Ekwador byłby skłonny do spłacenia tylko 40% swego zadłużenia, wynoszącego w sumie 11 mld USD. Prezydent Correa opowiedział się za renegocjacją warunków spłaty długu oraz odrzucił zasady Konsensusu Waszyngtońskiego. Prezydent zagroził również zerwaniem współpracy z Bankiem Światowym oraz Międzynarodowym Funduszem Walutowym, a w kwietniu 2007 wydalił z Ekwadoru przedstawiciela Banku Światowego. 12 grudnia 2008 prezydent Correa ogłosił zawieszenie spłacania przez Ekwador zadłużenia zagranicznego, które raz jeszcze nazwał „bezprawnym”. W marcu 2008 w Ameryce Południowej doszło do wybuchu kryzysu dyplomatycznego między Ekwadorem a Kolumbią, spowodowanego wejściem kolumbijskich wojsk na terytorium Ekwadoru w pościgu za partyzantami FARC. Kolumbia oskarżyła prezydenta Correę o powiązania z partyzantami oraz udzielanie im wsparcia politycznego i militarnego. W lutym 2009 doszło do napięć w stosunkach Ekwadoru ze Stanami Zjednoczonymi. Prezydent Correa wydalił z Ekwadoru dwóch dyplomatów. Administrację amerykańską oskarżył o mieszanie w sprawy wewnętrzne kraju i wpływanie na decyzję o mianowaniu nowego szefa antynarkotykowej jednostki policji.
Demografia.
Ekwador liczy 17,08 mln mieszkańców (2018). Średnia gęstość zaludnienia wynosi 49 osób/km². W miastach zamieszkuje około 62% ludności. 7% ludności to analfabeci. Przeciętna długość życia mężczyzn to 75 lat, kobiet – 80 lat.
Struktura etniczna.
Społeczeństwo Ekwadoru to w większości ludność mieszana pochodzenia indiańsko-europejskiego. 71.9% stanowią Metysi (potomkowie białych i Indian), Montubios (potomkowie czarnych i metysów) 7,4%, Afro-Ekwadorczycy 7,2%, Indianie (głównie Keczua) 7%, biali 6,1%, pozostałe grupy etniczne zajmują 0,4% populacji.
Religia.
Według badania Pew Research Center z 2014 roku, 79% populacji stanowili katolicy (95% w 1970 r.), 13% protestanci, 5% niestowarzyszeni i 3% wyznawało inne religie. 
76% ogółu społeczeństwa (w tym 79% katolików i 82% protestantów) twierdzi, że religia jest bardzo ważna w ich życiu. 38% ogółu społeczeństwa (34% katolików i 67% protestantów) uczestniczy w nabożeństwach przynajmniej raz w tygodniu. 
55% ekwadorskich protestantów to zielonoświątkowcy, podczas gdy 40% katolików przyznało, że są związani z ruchem charyzmatycznym.
Obok ewangelikalnych protestantów sukces w Ekwadorze odnieśli także mormoni, adwentyści dnia siódmego i świadkowie Jehowy, podczas gdy ich społeczności pozostają stosunkowo niewielkie.
Języki.
Językiem urzędowym jest hiszpański, w użyciu wśród miejscowej populacji Indian jest także język keczua, chibcha i inne.
"Analfabetyzm, dane szacunkowe na rok 2003":
Największe miasta.
Tabela poniższa przedstawia miasta w Ekwadorze mające powyżej 50 tys. mieszkańców.
Polityka.
Ustrój polityczny.
Obecna konstytucja, przyjęta w referendum w 2008 r., jest 20. konstytucją Ekwadoru. Głową państwa, a jednocześnie szefem rządu jest prezydent. Prezydent wraz z wiceprezydentem są wybierani z tej samej listy w powszechnych i bezpośrednich wyborach na czteroletnią kadencję (z możliwością jednokrotnej reelekcji). Członkowie rządu są mianowani przez prezydenta.
Władza ustawodawcza należy do Zgromadzenia Narodowego, które na mocy nowej konstytucji zastąpiło Kongres Narodowy, rozwiązany w 2007 przez Zgromadzenie Konstytucyjne z powodu zarzutów korupcyjnych wobec wielu jego członków. Zgromadzenie Narodowe liczy 124 członków wybieranych w prowincjach w bezpośrednich wyborach. Pierwsze wybory odbyły się 26 kwietnia 2009. Wygrała je Alianza PAIS.
Partie polityczne.
W Ekwadorze istnieje system wielopartyjny, cechuje go duża niestabilność i rozdrobnienie.
Główne partie:
W przeszłości większą rolę miały również:
Sytuacja międzynarodowa.
Ekwador jest członkiem ONZ od 1945 r. Jest także członkiem wielu regionalnych organizacji jak ALADI, CAN czy SELA.
Podział administracyjny.
Ekwador jest podzielony na 24 prowincje ("provincias") – jednostki administracyjne pierwszego rzędu. Prowincje dzielą się na 217 kantonów ("cantones"), a te z kolei na 1024 parafii (parroquias) dla odróżnienia od parafii kościelnych zwanymi także parafiami cywilnymi (parroquias civiles).
Poza tym istnieją trzy obszary, które nie zostały zaliczone do żadnej z prowincji i w ostatnim Spisie Ludności z 2010 roku zostały opisane jako „strefy o nieokreślonej przynależności”. Są to:
Siły zbrojne.
Ekwador dysponuje trzema rodzajami sił zbrojnych: wojskami lądowymi, marynarką wojenną oraz siłami powietrznymi. Uzbrojenie sił lądowych Ekwadoru składało się w 2014 roku z: 202 czołgów, 262 opancerzonych pojazdów bojowych, 12 dział samobieżnych, 102 zestawów artylerii holowanej oraz 18 wieloprowadnicowych wyrzutni rakietowych. Marynarka wojenna Ekwadoru dysponowała w 2014 roku trzema okrętami obrony przybrzeża, czterema fregatami, sześcioma korwetami oraz dwoma okrętami podwodnymi. Ekwadorskie siły powietrzne z kolei posiadały w 2014 roku uzbrojenie w postaci m.in. 20 myśliwców, 59 samolotów transportowych, 49 samolotów szkolno-bojowych oraz 44 śmigłowców.
Wojska ekwadorskie w 2014 roku liczyły 37,5 tys. żołnierzy zawodowych oraz 118,5 tys. rezerwistów. Według rankingu "Global Firepower" (2014) ekwadorskie siły zbrojne stanowią 75. siłę militarną na świecie, z rocznym budżetem na cele obronne w wysokości 2,4 mld dolarów (USD).
Gospodarka.
Gospodarka opiera się na rolnictwie i wydobyciu ropy naftowej (drugie na kontynencie zasoby, z eksportu ropy pochodzi 42% wpływów dewizowych). Po dość szybkim rozwoju przemysłu przetwórczego w latach 1970–1980 narosło zadłużenie zagraniczne (do 12 mld dolarów USA w 1991) oraz spadło średnie roczne tempo wzrostu produktu krajowego brutto, z 8,7% w 1965–1980 do 1,5% w 1980–1987. Programy stabilizacyjne wprowadzane pod kontrolą Międzynarodowego Funduszu Walutowego nie przyniosły oczekiwanych rezultatów.
Od 10 września 2000 r. obowiązującą walutą jest dolar amerykański, który dzieli się na 100 centów. Dawniej jednostką monetarną było "sucre" = 100 "centavos".
Struktura zatrudnienia: rolnictwo 8%, przemysł 24%, usługi i handel 68%. Dochód narodowy w 2004 wynosił 3700 USD na 1 mieszkańca. Inflacja w 2004 wyniosła 2%. Zadłużenie zagraniczne przekracza 16 mld USD (2004).
Podatki.
Podstawowa stawka VAT to 12% dla większości produktów i usług.
Występuje 0% stawka VAT na produkty żywnościowe, sprzęt rolniczy, leki, książki oraz prasa i produkty eksportowe. Dodatkowo usługi objęte zerową stawką VAT to: transport osobowy oraz towarowy, usługi medyczne, elektryczność, woda, wywóz śmieci, ścieki, edukacja, domy spokojnej starości, domy opieki społecznej, usługi religijne i pogrzebowe, druk książek, inne usługi poniżej 400$.
Rolnictwo.
Podstawę utrzymania 1/3 ludności stanowi rolnictwo rozwijające się dzięki dużym, wielkoobszarowym prywatnym majątkom ziemskim (duży udział w ogólnej powierzchni użytków rolnych). Ekwador jest jednym z największych w świecie producentów i eksporterów bananów. Z przeznaczeniem głównie na wywóz uprawia się także kawę i kakao. Na potrzeby wewnętrzne uprawia się: trzcinę cukrową, ryż, kukurydzę, pszenicę, jęczmień, ziemniaki, maniok jadalny, soję, drzewa cytrusowe (głównie pomarańcze) palmę oleistą oraz bawełnę. Prowadzi się tu także hodowlę bydła, trzody chlewnej, owiec, koni i kóz. Areał ziem uprawnych został znacznie powiększony w połowie lat 50. dzięki zakrojonemu na szeroką skalę karczowaniu lasów. Średnia wydajność pracy w rolnictwie jest czterokrotnie niższa niż w przemyśle. Istotnym elementem sektora rolno-spożywczego jest dość dobrze rozwinięte rybołówstwo zwłaszcza połów krewetek i tuńczyków. Ważną rolę odgrywa leśnictwo, eksploatujące cenne gatunki drzew występujące w wilgotnych lasach tropikalnych, we wschodniej części kraju (drzewo balsa, chinowiec, kauczukowiec i mahoniowiec).
Przemysł.
Przemysł Ekwadoru jest słabo rozwinięty. Podstawową gałęzią przemysłu przetwórczego jest rafinacja ropy naftowej i przetwórstwo gazu ziemnego oraz związany z ropą przemysł chemiczny (produkcja opon i nawozów sztucznych). Duże zakłady petrochemiczne funkcjonują w Guayaquil. Pieniądze pochodzące z sektora naftowego rząd stara się lokować w rozwój nowych gałęzi przemysłu, m.in. samochodowego i metalurgicznego. Ponadto w kraju działają zakłady branż tradycyjnych: przetwórstwa spożywczego, włókienniczej, cementowej i materiałów budowlanych. Istotną rolę w dalszym ciągu odgrywa ręczne rzemiosło (wyrób makaty, kilimy, poncz).
Handel zagraniczny.
Podstawowym towarem przeznaczonym na eksport jest ropa naftowa (47% wartości eksportu). Drugą ważną grupą towarową są produkty branży rolno-spożywczej, głównie banany i krewetki oraz ziarna kakao i kawy. Do kraju sprowadza się przede wszystkim surowce, dobra inwestycyjne oraz artykuły konsumpcyjne.
Głównymi partnerami handlowymi są: Stany Zjednoczone, Kolumbia i Wenezuela.
Obroty w handlu z zagranicą w 2004 wyniosły:
Obroty w handlu z zagranicą w 2005 wyniosły:
Nauka.
W Ekwadorze działa "Ekwadorska Akademia Literatury", założona w 1875, powiązana z "Hiszpańską Akademią Królewską" w Madrycie. Istnieje 10 uniwersytetów z których najstarszy i największy "Centralny Uniwersytet Ekwadoru w Quito" został założony w 1769. Poza tym "Politechnika Narodowa w Quito", założona w 1869.

</doc>
<doc id="13038" url="https://pl.wikipedia.org/wiki?curid=13038" title="Morfem zerowy">
Morfem zerowy

Morfem zerowy – morfem, któremu odpowiada pusty ciąg fonemów, wyrażający stosunki między morfemami pełnymi.
Morfem zerowy można wykryć, gdyż wpływa fonetycznie na sąsiednie (zwykle poprzedzający) morfemy. Zwykle odpowiadają mu jakieś fonemy w fonetyce głębokiej – na przykład brak końcówki, która zanikła, por. "on czyta" i rosyjskie .

</doc>
<doc id="13039" url="https://pl.wikipedia.org/wiki?curid=13039" title="Fonem">
Fonem

Fonem – podstawowa jednostka struktury fonologicznej mowy. Jest różnorodnie definiowany, ale zwykle o jego wyróżnianiu ma decydować rozróżnianie dzięki niemu znaczenia wyrazów. Fonem jest pojęciem abstrakcyjnym, realizowanym w rzeczywistej mowie przez głoski. Różne głoski będące realizacjami jednego fonemu to alofony.
W literaturze językoznawczej przyjęto konwencję, w której fonemy zapisywane są między tworzącymi nawias ukośnikami, np. /t/, a alofony, czyli rzeczywiste głoski w nawiasach kwadratowych, np. [t].
W różnych teoriach językoznawczych zarówno sam termin "fonem", jak i pojęcie podstawowej jednostki fonologicznej były definiowane w różny sposób. Rozbudowany system pojęć związanych z fonemem funkcjonował w strukturalizmie, podczas gdy w modelach generatywnych reprezentacja fonemiczna została zastąpiona przez reprezentację fonologiczną.
Jedno z ujęć przedstawia fonem jako grupę podobnych do siebie głosek, która jest odróżnialna od pozostałych grup. Za psychologicznym i abstrakcyjnym ujęciem fonemu przemawia fakt, że użytkownicy języka zwykle nie zdają sobie sprawy ze zróżnicowania allofonów, które wymawiają, i są przeświadczeni, że są to te same głoski. Jest to związane również z pismem alfabetycznym, gdzie zwykle jedna litera odpowiada kilku podobnym głoskom, z reguły będącym allofonami jednego fonemu. Przykładowo w polskim alfabecie istnieją odrębne litery dla fonemów /t/ i /d/, nie ma natomiast zróżnicowania w piśmie dla głoski "d" wymawianej zębowo czy dziąsłowo. Tymczasem fonemy intuicyjnie bywają kojarzone z grafemami. Cechy odróżniające od siebie fonemy nazywane są cechami dystynktywnymi, a różnica charakteryzująca te cechy nazywana jest opozycją.
Ponieważ fonem jest bytem abstrakcyjnym realizowanym przez zbiór allofonów, nie można go wymówić, gdyż wymagałoby to równoczesnego wymówienia wielu głosek naraz.
Oprócz zestawów fonemów typowych dla danego języka mogą pojawić się w nim, na skutek procesów fonostylistycznych fonemy rezerwowe (potencjalne). Za taki fonem w języku polskim może być w niektórych modelach fonologicznych uznana szwa, nieuznawana za fonem typowy dla tego języka, ale pojawiająca się w nim w mowie szybkiej. 
Historyczne ujęcia.
Samo słowo "fonem" ma źródłosłów grecki od słowa "φωνή", czyli ‘głos’, a ukuł je we francuskiej formie "phonème" Antoni Dufriche-Desgenettes około 1865 roku. Szerzej znane stało się, gdy wygłosił referat na konferencji językoznawczej w 1873 roku. U niego był to przekład funkcjonującego terminu niemieckiego "Sprachlaut" i oznaczało mniej więcej to, co głoska. Termin ten upowszechnił Louis Havet, a następnie, w 1879 roku, przejął Ferdinand de Saussure, zmieniając znaczenie na bardziej abstrakcyjne. Jego ujęcie było diachroniczne, związane z fonologiczną ewolucją języków, przy czym nie było w pełni konsekwentne.
W językoznawstwie utrwaliło się znaczenie synchroniczne, które pojęciu "fonem" nadał Mikołaj Kruszewski, ostatecznie odróżniając je od głoski w roku 1879 lub 1880 i rozpowszechnił Jan Baudouin de Courtenay. U tego ostatniego fonem oznacza najmniejszą jednostkę foniczną będącą podstawą regularnych alternacji, choć z czasem przyjął on podejście psychologistyczne. Zgodnie z nim fonem ma być psychologicznym ekwiwalentem głoski, czyli jej psychicznym wyobrażeniem, które może być realizowane przez różne głoski, w zależności od zmienności diachronicznej i synchronicznej języka. Obaj ci naukowcy byli przedstawicielami tzw. szkoły kazańskiej. Baudouin de Courtenay jest uważany za prekursora mentalizmu. W ich pracach podkreślono, że głoski mają pewne akustyczne cechy fizyczne, podczas gdy fonemy są bytami abstrakcyjnymi, które należy rozróżniać przez te cechy, które zmieniają znaczenie. 
Wraz z rozwojem fonologii i jej rozdziałem z fonetyką wzmocniło się powyższe podejście, przy jednoczesnym odrzuceniu roli psychologicznej na rzecz cech strukturalnych. Jeden z przedstawicieli szkoły praskiej, Roman Jakobson, zdefiniował fonem jako wiązkę cech dystynktywnych. W definiowaniu fonemu zatem zgodnie z tą szkołą należy zestawiać pary minimalne, takie jak "prać" i "brać", gdzie różnica między "p" a "b" przesądza o różnym znaczeniu całych słów. Różnice te to może być dźwięczność (jak w parze "kra" i "gra") czy miejsce artykulacji (jak w przypadku słów "pory", "tory" i "kory"). Nikołaj Trubieckoj jako trzy główne warunki wyróżniania fonemów podał:
Zatem w strukturalizmie przyjmowano definicję mówiącą, że fonem jest najmniejszą segmentalną (linearną) jednostką dystynktywną mowy. W świetle tego niektórzy przedstawiciele tego nurtu dyftongi, długie samogłoski i afrykaty traktowali jako zestawienia dwóch fonemów.
Powyższe ujęcie fonemu rodzi problemy interpretacyjne, gdy cecha dystynktywna między dwoma fonemami zanika w pewnym kontekście. Przykładowo, w słowie "chleb" fonem /b/ jest realizowany jako [p]. Zasada „raz fonemem – zawsze fonemem”, mówiąca, że coś, co jest fonemem w jednym przypadku, musi być fonemem w innych, jest typowa dla strukturalizmu. Skoro nie ma wątpliwości, że w języku polskim fonemy /p/ i /b/ są odrębne, w tym przypadku w strukturalizmie przyjmowano, że w tym słowie w istocie występuje fonem /p/. Aby uniknąć problemów wynikających z tego, że w słowie "chleb" fonem zapisywany przez literę „b” jest inny niż analogiczny fonem w słowie "chlebek", gdzie występuje fonem /b/, Trubieckoj wprowadził pojęcie "archifonem". W podanym przykładzie zgodnie z tą definicją występuje archifonem P charakteryzowany tylko przez dwie cechy – spółgłoska zwarta i spółgłoska wargowa. Archifonem taki reprezentuje neutralizację cechy dźwięczności, która tworzy kontrast między fonemami /p/ i /b/. Neutralizacja taka może zachodzić tylko wobec cech przybierających dwie wartości (np. dźwięczna – bezdźwięczna), natomiast nie wobec cech przybierających więcej wartości (np. wargowa, zębowa, welarna), zatem nie ma archifonemu łączącego fonemy /p/ i /k/.
Kolejnym pojęciem postulowanym przez szkołę praską jest morfofonem, czyli jednostka bardziej złożona, składająca się z fonemów podlegających alternacji w danym morfemie, wraz z ich kontekstami. Przykładowo, w morfemie "mrok" ostatnim fonemem może być [k], [k'] lub [č].
Inną próbą rozwiązania tego problemu na gruncie strukturalizmu było przyjęcie przez Bernarda Blocha koncepcji częściowego nakładania się fonemów. Co prawda, co do zasady allofon może reprezentować tylko jeden fonem, ale pewnych przypadkach dopuszczalne jest częściowe nakładanie się fonemów, tj. jeden z allofonów danego fonemu może być identyczny z jednym z allofonów innego, jeżeli występują w odmiennych kontekstach.
Stosunkowo podobne do mentalnego podejścia szkoły praskiej reprezentował Edward Sapir. W jego ujęciu również dany fonem ma podłoże w psychice i może być realizowany różnie w zależności od kontekstu. Zatem angielskie /t/ jest zwykle realizowane jako spółgłoska dziąsłowa (spółgłoska zwarta dziąsłowa bezdźwięczna), ale zawsze jest wymawiane jako spółgłoska zębowa przed frykatywami zębowymi (np. w słowie "eighth"), jako zadziąsłowa przed zadziąsłowymi (np. w "country") czy podniebienno-dziąsłowa przed podniebienno-dziąsłowymi (np. w zbitce "that chair"). Mimo to, zawsze są to allofony tego samego /t/, pojawiające się w ściśle określonych kontekstach, wzajemnie się wykluczających, a więc komplementarnych. Natomiast mogą wystąpić również allofony fakultatywne, w tym samym kontekście, co ma miejsce, gdy /t/ na końcu wyrazu może być wymawiane jako [t] lub [ʔ].
Odmienne od fonologicznego podejście przyjął Daniel Jones, dla którego o wyróżnianiu fonemu decydują podobieństwa fonetyczne dźwięków, a nie cechy fonologiczne (dystynktywne). W amerykańskim strukturalizmie ukształtowanym przez Leonarda Bloomfielda również przeważało podejście odrzucające mentalizm i definiujące fonemy na podstawie klas cech dźwiękowych, jednak także podkreślające abstrakcyjny ich charakter. Wyjątkiem były poglądy Sapira. Amerykańscy strukturaliści odrzucali również koncepcję archifonemu.
Podejście Jonesa było krytykowane przez innych strukturalistów, którzy twierdzili, że część z wyróżnianych przez niego fonemów to w istocie zbitki kilku fonemów, a za ich wyróżnianiem przemawia jedynie tradycja związana z pisownią. W tym modelu występuje hierarchia jednostek dystynktywnych: "fonem" – jednostka minimalna, "centrem" jednostka dystynktywna zbudowana z jednego lub kilku fonemów, tworząca centrum sylaby, "marginem" jednostka dystynktywna zbudowana z jednego lub kilku fonemów, tworząca margines sylaby, "sylabem" jednostka dystynktywna zbudowana z jednego lub kilku fonemów, tworząca całą sylabę. W tym systemie zaproponowane przez Jonesa i Gimsona 20 fonemów samogłoskowych "Received Pronunciation" to w istocie centremy.
Zupełnie odmienne podejście od językoznawstwa strukturalistycznego przyjęto w modelu generatywnym. W celu uniknięcia sprzecznych z intuicją wniosków, że pary polskich słów takie jak "grad" i "grat", będąc homofonami, mają dokładnie taką samą reprezentację fonemiczną, tj. /grat/, pojęcie to zastąpiono przez reprezentację fonologiczną. W tej reprezentacji słowa te wyglądają odmiennie: /grad/ i /grat/ i dopiero fonologiczna reguła ubezdźwięczniania spółgłosek przed pauzą powoduje, że reprezentacja fonetyczna w obu przypadkach wygląda tak samo: [grat]. W praktyce oznacza to, że fonemy w rozumieniu fonologii generatywnej często odpowiadają morfofonemom w rozumieniu szkoły praskiej.
W językoznawstwie kognitywnym niektórzy badacze postulują wyróżnianie dystynktywnych klas dla dźwięków zbliżonych do tradycyjnego pojęcia fonemu, podczas gdy inni twierdzą, że głoski podporządkowane są ich znaczeniu w całych słowach. Związane jest to z zacieraniem różnic między współczesną fonologią a fonetyką w takich modelach, jak "exemplar phonology", zatem skoro dźwięki mowy tworzą akustyczne kontinuum, zgodnie z tym podejściem również ich fonologiczne reprezentacje powinna charakteryzować ciągłość. Modele zachowujące wyróżnianie fonemów zakładają, że użytkownicy języka przechowują w umyśle fonemy jako abstrakcyjne, schematyczne reprezentacje wszystkich ich allofonów, przy czym w mowie są one modyfikowane przez kontekst fonetyczny. Taki wyabstrahowany od rzeczywistych głosek fonem jest prototypem, a poszczególne rzeczywiste allofony są do niego porównywane. W "exemplar phonology" zakładane jest, że fonem odpowiada najczęstszym zachowywanym w umyśle przykładom dźwięków.
Fonemy języka polskiego.
W zależności od przyjętych kryteriów w języku polskim liczba fonemów bywa określana od 31 do 42. Kontrowersje dotyczą głównie statusu spółgłosek wargowych miękkich, które mogą być uznawane za fonemy (np. /p’/) lub zbitki fonemów (np. /p/+/j/) i samogłosek nosowych, a nawet spółgłosek zwarto-szczelinowych. Od czasów Baudouina de Courtenay istnieje również spór, czy w języku polskim "i" oraz "y" są odrębnymi fonemami, czy też różnymi allofonami tego samego fonemu, a ich wymowa zależy od miękkości spółgłoski poprzedzającej.
Jan Baudouin de Courtenay wyróżniał następujące fonemy języka polskiego:
p, b, m, f, w, t, d, n, s, z, c, dz, ł, sz, ż, cz, dż, r, k, g, ch, j, p', b', m', f', w', (t'), (d'), ń, ś, ź, ć, dź, l, k', g', ch', u, o, ą wymawiane õ, a, ą wymawiane ã, i, e, ę, rz odróżniające się od ż lub sz tylko w gwarach.

</doc>
<doc id="13040" url="https://pl.wikipedia.org/wiki?curid=13040" title="Test jednostkowy">
Test jednostkowy

Test jednostkowy () – metoda testowania tworzonego oprogramowania poprzez wykonywanie testów weryfikujących poprawność działania pojedynczych elementów (jednostek) programu – np. metod lub obiektów w programowaniu obiektowym lub procedur w programowaniu proceduralnym. Testowany fragment programu poddawany jest testowi, który wykonuje go i porównuje wynik (np. zwrócone wartości, stan obiektu, zgłoszone wyjątki) z oczekiwanymi wynikami – tak pozytywnymi, jak i negatywnymi (niepowodzenie działania kodu w określonych sytuacjach również może podlegać testowaniu).
Zaletą testów jednostkowych jest możliwość wykonywania na bieżąco w pełni zautomatyzowanych testów na modyfikowanych elementach programu, co umożliwia często wychwycenie błędu natychmiast po jego pojawieniu się i szybką jego lokalizację zanim dojdzie do wprowadzenia błędnego fragmentu do programu. Testy jednostkowe są również formą specyfikacji. Z powyższych powodów są szczególnie popularne w programowaniu ekstremalnym.
Podział testów jednostkowych.
Testy można podzielić na następujące warianty:
Analiza ścieżek.
Podejście, w którym określamy punkt początkowy oraz punkt końcowy dla przeprowadzenia testów i badamy przebieg możliwych ścieżek pomiędzy nimi. Rozpatrywane możliwe ścieżki od punktu początkowego do punktu końcowego dzielimy na dwa podejścia:
Aby zapobiec niemożności sprawdzenia kodu z powodu pętli stosujemy dwie grupy testów:
Boundary Test: zwracane wartości to zero lub jedno przejście
Interior Test: zwracana wartość to dwa przejścia
Użycie klas równoważności.
Klasa równoważności jest to zbiór danych o podobnym sposobie przetwarzania, używanych do przeprowadzenia testu. Wykonanie testu z użyciem kilku elementów zbioru, powoduje uznanie całej klasy za poprawną i zwalnia nas od testowania wszystkich elementów w np. 1000-elementowym zbiorze.
Klasy równoważności dzielą się na:
Przykłady:
Testowanie wartości brzegowych.
Rozwinięciem testów z użyciem klas równoważności jest testowanie wartości brzegowych. Wartość brzegowa to wartość znajdująca się wewnątrz, pomiędzy lub tuż przy granicy danej klasy równoważności.
Przykłady:
Testowanie składniowe.
Podstawowym zadaniem testowania składniowego jest sprawdzenie poprawności wprowadzanych danych do systemu.
Błędy zależne od systemu i środowiska:
W testowaniu składniowym należy pamiętać o zasadzie "garbage in – garbage out", która zadziała gdy:
Przykładowe testy jednostkowe.
W przykładzie zostało przytoczone użycie środowiska JUnit wraz z dostarczonym mechanizmem testów jednostkowych.
Testy w przykładzie dotyczą niedeterministycznego automatu skończenie stanowego. W każdym teście,
oznaczonym adnotacją @Test tworzymy obiekt klasy DAUTAutomaton, następnie dodajemy stany 
automatu. Potem dodajemy przejścia wraz z etykietami, po których możemy udać się do określonego stanu.
Testy zaczynają się w momencie, gdy wywołujemy asercje dla żądanego napisu, aby sprawdzić czy napis jest akceptowany przez automat. Każda litera staje się etykietą przejścia od jednego stanu do drugiego i po przejrzeniu całego napisu musimy znaleźć się w tzw. stanie akceptującym.
 assertTrue(A.run("ab")); // sprawdza czy dla napisu "ab" automat zwróci prawdę
 assertTrue(A.run("abbbbb")); // sprawdza czy dla napisu "abbbbb" automat zwróci prawdę
 assertTrue(A.run("c")); // sprawdza czy dla napisu "c" automat zwróci prawdę
 assertFalse(A.run("a")); // sprawdza czy dla napisu "a" automat zwróci fałsz, czyli nie zaakceptuje tego napisu
 assertFalse(A.run("xxxxxxx")); // sprawdza czy dla napisu "xxxxxxx" automat zwróci fałsz, czyli nie zaakceptuje tego napisu
 assertFalse(A.run("ba")); // sprawdza czy dla napisu "ba" automat zwróci fałsz, czyli nie zaakceptuje tego napisu

</doc>
<doc id="13043" url="https://pl.wikipedia.org/wiki?curid=13043" title="Typowanie silne">
Typowanie silne

Silna typizacja – system typów w języku programowania, w którym każde wyrażenie ma ustalony typ i nie można go używać w kontekście przeznaczonym dla innych typów.
Przykład:
 int liczba = 1;
 if ("1" == liczba) { // błąd podczas kompilacji, ponieważ "1" to typ tekstowy (string), zatem nie jest liczbą (int)

</doc>
<doc id="13044" url="https://pl.wikipedia.org/wiki?curid=13044" title="Liczby zmiennoprzecinkowe">
Liczby zmiennoprzecinkowe



</doc>
<doc id="13045" url="https://pl.wikipedia.org/wiki?curid=13045" title="Typowanie słabe">
Typowanie słabe

Typowanie słabe – system typów, w którym typ wyrażenia może być automatycznie zmieniony, jeśli kontekst tego wymaga. Oznacza to m.in. automatyczne konwersje pomiędzy niektórymi typami.
Pewną zaletą słabego typowania w porównaniu z silnym typowaniem jest to, że wymaga ono mniejszego nakładu pracy programisty, ponieważ kompilator lub interpreter niejawnie wykonuje pewne konwersje. Jednakże, wadą może być to, że systemy ze słabym typowaniem wychwytują mniej błędów na etapie kompilacji i błędy te mogą pozostać niewykryte nawet po zakończeniu testowania. Na przykład w języku PHP łańcuchy "1000" i "1e3" dają przy porównaniu równość, ponieważ są niejawnie konwertowane do liczb zmiennopozycyjnych - mimo że jako łańcuchy znaków są różne. W językach JavaScript i PHP istnieje specjalny operator porównania (identyczność) === który sprawdza czy oba argumenty są tego samego typu i mają tę samą wartość.
Przykład w języku PHP:
$liczba = 1;
if ("1" == $liczba) {
 // mimo porównywania z tekstem, warunek jest prawdziwy, ponieważ liczba jest rzutowana na typ string

</doc>
<doc id="13047" url="https://pl.wikipedia.org/wiki?curid=13047" title="Liczby zmiennopozycyjne">
Liczby zmiennopozycyjne



</doc>
<doc id="13048" url="https://pl.wikipedia.org/wiki?curid=13048" title="System typów">
System typów

System typów – system klasyfikacji wyrażeń w zależności od rodzajów wartości, jakie one generują. Każdej obliczonej wartości przypisywany jest pewien typ, który jednoznacznie definiuje, jakie operacje można na niej wykonać. Śledząc przepływ wartości, system typów stara się udowodnić, że w programie występuje poprawne typowanie, tzn. nie dochodzi do sytuacji, w której na wartości określonego typu próbujemy wykonać niedozwoloną operację.
Kompilator może posłużyć się informacją o typie do poprawnego określenia ilości pamięci niezbędnej na przechowanie wartości oraz wyboru najlepszych algorytmów. Na przykład wiele kompilatorów języka C zapisuje typ "float" na 32 bitach zgodnie z założeniami normy IEEE 754 dla liczb zmiennoprzecinkowych pojedynczej precyzji. Ponadto do przetwarzania wartości tego typu wybierane są instrukcje procesora oraz algorytmy zaprojektowane specjalnie dla nich.
"Typizacją" języka nazwiemy ilość ograniczeń nakładanych na typy oraz sposób ich obliczania. Teoria typów zajmuje się badaniami nad systemami typów, jednak rzeczywiste systemy typów stosowane w językach programowania wywodzą się przeważnie z praktycznych obserwacji oraz ograniczeń nakładanych przez architekturę sprzętową, budowę kompilatora i samego języka.

</doc>
<doc id="13049" url="https://pl.wikipedia.org/wiki?curid=13049" title="Talia">
Talia



</doc>
<doc id="13050" url="https://pl.wikipedia.org/wiki?curid=13050" title="System typów ML">
System typów ML

System typów ML – silny system typów stosowany w językach rodziny ML (Ocaml, Standard ML) oparty na inferencji.
Podstawowy system typów jest następujący: istnieją typy proste, takie jak string, int, bool, unit (typ pusty) itd. Z dowolnych typów można też generować typy złożone – przez krotki (typ1 * typ2, typ1 * typ2 * typ3 itd.), konstruktory typów (typ list, typ tree itd.) i funkcje (typ1 → typ2).
System próbuje nadać typy każdemu wyrażeniu języka, i nie licząc kilku rzadkich przypadków, udaje mu się to całkiem dobrze.
Generalnie system taki wyklucza polimorfizm (nie licząc typów polimorficznych), jednak w Standard ML stworzono specjalne reguły umożliwiające polimorfizm dla wyrażeń arytmetycznych.
System typów ML jest interesujący z teoretycznego punktu widzenia – wiele problemów ma bardzo wysoką złożoność, jednak w praktyce inferencja zachodzi bardzo szybko – typy, które są rzeczywiście używane, są zwykle bardzo proste – rzadko używa się funkcji rzędów wyższych niż trzeci-czwarty, oraz liczby argumentów większej niż kilkanaście.
W rzeczywistych implementacjach dochodzą do tego bardziej złożone problemy typizacji obiektów, modułów itd.

</doc>
<doc id="13051" url="https://pl.wikipedia.org/wiki?curid=13051" title="Pusty typ danych">
Pusty typ danych

Pusty typ danych () – typ danych, którego zmienna niesie zerową informację, czyli, zgodnie z teorią informacji, matematyczna klasa wszystkich wartości zmiennych tego typu zawiera dokładnie jeden element. Wprowadzenie takiego typu do systemu typów języka programowania umożliwia pewne rodzaje uogólnień - nie trzeba rozróżniać funkcji, które zwracają wartość, od tych, które jej nie zwracają (czyli zwracają wartość typu pustego), oraz funkcji, które pobierają jakiś argument, od tych, które tego nie robią.
Typ pusty stosowany jest głównie do:
Przykłady.
Definiowanie funkcji niezwracającej wyniku.
void 
wypisz_liczbe(int liczba)
 printf("%d\n", liczba);
W przykładzie tym (napisanym w języku C lub C++) słowo kluczowe codice_3 
wskazuje, że funkcja codice_4 nie zwraca wartości.
Definiowanie funkcji bezargumentowych.
int
powitanie(void)
 printf("Witaj!\n");
 return 0;
W przykładzie tym (napisanym w języku C) słowo kluczowe codice_3 wskazuje, że funkcja codice_6 nie pobiera żadnych argumentów.
W języku C++ taka konstrukcja także jest dopuszczalna. Jednak taki sam rezultat da pozostawienie nawiasu pustego − w języku C oznaczałoby to, że funkcja przyjmuje nieokreśloną liczbę argumentów.
Definiowanie wskaźników do danych nieokreślonego typu.
int n = 10;
void *p = &amp;n;
int *pn = (int *) p;
printf("n = %d\n", *pn); 
W przykładzie tym zdefiniowano wskaźnik codice_7 i przypisano mu adres 
zmiennej całkowitej codice_8. Ponieważ kompilator nie ma żadnej informacji 
o typie danych wskazywanych przez codice_7, nie wolno bezpośrednio wyłuskiwać danych wskazywanych przez codice_7. Aby uzyskać dostęp do tych danych, należy jawnie wskazać ich typ:
Przykład zaawansowany (qsort).
W standardowej bibliotece języka C występuje funkcja sortujaca codice_11 o następującym prototypie:
void 
qsort (void *array, size_t count, size_t size, int (*compare_fun) (const void *a, const void *b))
Uwagi.
int
powitanie()
 printf("Witaj!\n");
 return 0;
Ta sama konstrukcja w języku C interpretowana jest jako definicja funkcji o nieokreślonej (dowolnej) liczbie argumentów.

</doc>
<doc id="13052" url="https://pl.wikipedia.org/wiki?curid=13052" title="Typ polimorficzny">
Typ polimorficzny



</doc>
<doc id="13053" url="https://pl.wikipedia.org/wiki?curid=13053" title="Krotka">
Krotka



</doc>
<doc id="13054" url="https://pl.wikipedia.org/wiki?curid=13054" title="STL">
STL

Akronim STL może oznaczać:

</doc>
<doc id="13055" url="https://pl.wikipedia.org/wiki?curid=13055" title="Konsul">
Konsul

Konsul (łac. "consul")

</doc>
<doc id="13056" url="https://pl.wikipedia.org/wiki?curid=13056" title="Zmienna typowa">
Zmienna typowa

Zmienna typowa – zmienna której wartościami mogą być typy – zwykle istnieje tylko na potrzeby kompilacji,
nie jest natomiast typową zmienną zajmującą pamięć i modyfikowalną w trakcie uruchamiania programu.
Np. w poniższym fragmencie C++ T jest zmienną typową:

</doc>
<doc id="13057" url="https://pl.wikipedia.org/wiki?curid=13057" title="Kendo">
Kendo

 – sport walki wywodzący się z szermierki japońskich samurajów.
Kendo dzisiaj.
Kendo – jako sport, sposób rekreacji czy sztukę walki – uprawia na świecie około 7 mln ludzi. Co trzy lata odbywają się mistrzostwa świata, w pozostałych latach mają miejsce mistrzostwa Europy. Od 1969 r. działa EKF Europejska Federacja Kendo, a od 1970 IKF Międzynarodowa Federacja Kendo, do której należy obecnie ponad 40 państw. Obydwie te organizacje nadzorują m.in. nadawanie stopni mistrzowskich dan.
Kwalifikacje zawodników kendo, podobnie jak w innych dalekowschodnich sportach walki, wyraża się stopniami uczniowskimi kyū oraz stopniami mistrzowskimi dan. Jednakże w odróżnieniu od judo czy karate, stopień w kendo nie jest w żaden sposób uwidaczniany.
W Polsce kendo jest uprawiane od roku 1973. Obecnie ćwiczy je około 500 zawodników ("kendoka") w 23 klubach (dojo), zrzeszonych w Polskim Związku Kendo. Największym dotychczasowym sukcesem sportowym Polaków w kendo był brązowy medal drużynowy, wywalczony na mistrzostwach Europy w Amsterdamie w roku 1989, a w 2005 roku na Mistrzostwach Europy w Bernie Polacy zdobyli srebrny medal w kategorii Juniorów oraz brązowy w zawodach drużynowych kobiet. Polskie zawodniczki w 2007 roku na Mistrzostwach Europy w Lizbonie zdobyły srebrny medal w zawodach drużynowych kobiet.
Na Mistrzostwach Europy w Kendo w 2016 reprezentacja Polski wywalczyła drużynowe srebro i indywidualny brąz (Krzysztof Bosak). Ponadto reprezentanci Polski Maciej Wierzbowski (za turniej męski indywidualny) oraz dwukrotnie Alina Gdeczyk (za turnieje kobiece indywidualny i drużynowy) zdobyli tradycyjną nagrodę kantosho (za ducha walki). Kobieca reprezentacja Polski na tych mistrzostwach doszła do ćwierćfinału i po nieznacznej porażce zajęła ósme miejsce. Był to najlepszy w historii wynik polskiej reprezentacji w kendo.

</doc>
<doc id="13058" url="https://pl.wikipedia.org/wiki?curid=13058" title="Standard Template Library">
Standard Template Library

Standard Template Library, STL – biblioteka C++ zawierająca algorytmy, kontenery, iteratory oraz inne konstrukcje w formie szablonów, gotowe do użycia w programach.
Historia.
Osobą w dużej mierze odpowiedzialną za architekturę tej biblioteki jest Alexander Stepanov. STL początkowo powstawała jako niezależna biblioteka rozwijana przez firmę Hewlett Packard, później większość przyjętych tam rozwiązań przeszła do biblioteki standardowej C++.
Opis.
STL jest to tzw. biblioteka generyczna, oznacza to, że jej komponenty są parametryzowane, niemal każdy z nich jest szablonem. Umożliwia to równie dobrą współpracę z typami wbudowanymi w język, z typami wbudowanymi w bibliotekę, co z typami zdefiniowanymi przez użytkownika, pod warunkiem, że spełniają pewne określone warunki.
Jedną z najważniejszych rzeczy wprowadzonych przez STL, są kontenery, czyli obiekty zbiorcze. Jest ich kilka rodzajów, różnią się konstrukcją i tym samym wydajnością poszczególnych operacji. Np. kontener typu "vector" trzyma obiekty w liniowym obszarze pamięci, co umożliwia swobodny dostęp (ang. "random access") do wszystkich elementów – można ten zbiornik indeksować liczbą całkowitą, podobnie jak robi to się ze zwykłymi tablicami. Niestety, wstawienie nowego elementu gdziekolwiek indziej, niż na końcu jest operacją liniowego czasu, gdyż trzeba "odsunąć" elementy, żeby zrobić miejsce na nowy. Z kolei, w kontenerze typu "list", wstawianie i usuwanie elementów jest operacją o stałym czasie wykonania, ale nie jest możliwe indeksowanie.
Koncept określa podstawowe warunki, jakie powinien spełniać typ, aby móc być zaliczonym do odpowiedniej kategorii i tym samym obsługiwanym przez odpowiednie elementy biblioteki. Określa też możliwości, jakie udostępnia dany typ. Np. "list" jest zbiornikiem dwukierunkowym, co oznacza, że można się po nim poruszać jedynie krokowo w obu kierunkach. Natomiast "vector" jest zbiornikiem swobodnego dostępu i umożliwia poza tym jeszcze indeksowanie elementów wewnątrz zbiornika. Inny model z kolei prezentują sortowane zbiorniki asocjacyjne, jak "set" i "map". Elementy wewnątrz nich są posortowane i wyszukiwanie elementu jest podobne do wyszukiwania binarnego, które posiada logarytmiczną złożoność czasową. Zbiornik "set" jest zwykłym zbiornikiem asocjacyjnym i zawiera tylko elementy kluczowe (służy tylko do tego, żeby można było w nim łatwo dany element wyszukać), natomiast "map" jest parowym zbiornikiem asocjacyjnym i zawiera pary klucz-wartość.
Istnieją też koncepty stanowiące wymagania dla typów użytkownika. Np. "przypisywalny" oznacza, że obiekt ma mieć możliwość przypisania do niego wartości, a "domyślnie konstruowalny" oznacza, że typ musi posiadać konstruktor domyślny. Zbiorniki "list" i "vector" stawiają takie wymagania, gdyż implementacja zakłada tworzenie takich obiektów "bez podania przyczyny" (lista ma jeden element nieużywany, który stanowi węzeł łączący początek z końcem i jest używany do określania tzw. za-końca).
Jednym z elementów biblioteki są tzw. alokatory.
Iteratory.
Po kontenerach można się poruszać za pomocą "iteratorów". Są to specjalne obiekty przeznaczone do takich właśnie operacji. Iterator, podobnie jak wszystko w STL-u, musi podpadać pod określony koncept. Koncept iteratora spełnia np. wskaźnik, gdyż można na nim wykonać operacje wymagane dla iteratora; co więcej, jest to iterator swobodnego dostępu, gdyż udostępnia zarówno operatory ++ i --, jak też operację awansu (+= i -=) i dystansu (-).
Algorytmy.
Oprócz tego w STL definiuje się też algorytmy, czyli odpowiednie wzorce funkcji, które mają wykonać pewne abstrakcyjne zadania na określonym kontenerze. Przykładowym algorytmem jest "for_each", który ma wywołać podany funktor na określonym zakresie elementów. Innymi przykładami algorytmów są "reverse", który odwraca kolejność elementów w zbiorniku, "find", który wyszukuje określoną wartość w zbiorniku, czy "find_if", który wyszukuje element spełniający warunek określony podanym funktorem.
W STL każdy algorytm może pracować na każdym zbiorniku specjalizowanym każdym możliwym typem. Choć nie każda kombinacja algorytmu i zbiornika ma sens, np. nie ma sensu wywoływać algorytmu "sort" na zbiorniku takim jak "set". Taki sposób zaprogramowania tej biblioteki zapewnił jej szerokie zastosowanie oraz generyczność, czyli możliwość adaptowania się do elementów nieznanych w momencie jej opracowywania.
Ponieważ szablony C++ są bardzo efektywne, STL jest o wiele popularniejszy niż podobne biblioteki pisane dla C, w przypadku których wydajność była istotnie niższa od ręcznie programowanych rozwiązań.

</doc>
<doc id="13059" url="https://pl.wikipedia.org/wiki?curid=13059" title="Lista">
Lista

Lista – struktura danych służąca do reprezentacji zbiorów dynamicznych, w której elementy ułożone są w liniowym porządku. Rozróżniane są dwa podstawowe rodzaje list: lista jednokierunkowa w której z każdego elementu możliwe jest przejście do jego następnika oraz lista dwukierunkowa w której z każdego elementu możliwe jest przejście do jego poprzednika i następnika.
Implementacja listy.
Każdy element listy składa się z co najmniej dwóch pól: klucza oraz pola wskazującego na następny element listy. W przypadku list dwukierunkowych każdy element listy zawiera także pole wskazujące na poprzedni element listy. Pole wskazujące poprzedni i następny element listy są najczęściej wskaźnikami.
Dopisanie elementu (dla prostej listy jednostronnej):
Usunięcie elementu jest odwrotne do wstawiania: w pewnym miejscu zapisuje się wskaźnik do usuwanego elementu (aby nie „zgubić” jego adresu), następnie wskaźnik wiążący poprzednika przestawia się na następnik. Dopiero w tym momencie zwalnia się pamięć po obiekcie usuwanym (do tego potrzebny jest ten wskaźnik tymczasowy).
Zalety i wady listy są komplementarne w stosunku do tablicy (patrz porównanie niżej).
Wgłębiając się w szczegóły implementacji listy można wyróżnić następujące rodzaje list:
Powyższe cechy można prawie dowolnie łączyć, co daje możliwość stworzenia wielu różnych implementacji listy, zależnie od potrzeb.
Jednokierunkowe listy są bardzo popularną podstawową strukturą danych w funkcyjnych językach programowania.
Lista dwukierunkowa z jednym wskaźnikiem.
Istnieje możliwość realizacji takiej listy, wtedy gdy:
Wówczas pojedynczy wskaźnik zawiera różnicę symetryczną (xor) wartości liczbowej wskaźników na poprzedni i następny element listy. Podczas przechodzenia listy pamiętany jest rzeczywisty wskaźnik uprzednio odwiedzonego elementu i dzięki własności formula_1 można z zakodowanej liczby odtworzyć albo poprzedni albo następny element, w zależności od kierunku przeglądania listy. Warunek 2. gwarantuje, że wskaźniki na pierwszej i ostatniej pozycji można odkodować natychmiast.
Zaletą takiej reprezentacji jest oszczędność pamięci (jeden wskaźnik, zamiast dwóch), wadą natomiast utrudnione przeglądanie – jeśli nie rozpoczyna się od pierwszego lub ostatniego elementu, potrzeba znać co najmniej dwa wskaźniki w celu odkodowania rzeczywistych wartości.
Porównanie z tablicą.
Tablica to alternatywa dla listy.
Dopisanie elementu do listy to wstawienie elementu do tablicy:
Usunięcie elementu znajdującego się pod danym indeksem tablicy to przesunięcie o jedno pole w lewo wszystkich elementów o indeksie wyższym.
Zalety tej implementacji: prosta nawigacja wewnątrz listy, korzystanie z gotowej struktury tablicy, szybki dostęp do elementu o konkretnym numerze, większa odporność na błędy.
Wady: niska elastyczność, szczególnie dotycząca rozmiaru tablicy, liniowa złożoność operacji wstawiania i usuwania.
Implementację tablicową stosuje się tam, gdzie elastyczność nie odgrywa istotnej roli, a wymagana jest szybka i prosta nawigacja.

</doc>
<doc id="13061" url="https://pl.wikipedia.org/wiki?curid=13061" title="Szablon">
Szablon



</doc>
<doc id="13062" url="https://pl.wikipedia.org/wiki?curid=13062" title="Tablica asocjacyjna">
Tablica asocjacyjna

Tablica asocjacyjna, tablica skojarzeniowa, mapa, słownik (ang. "associative array", "map", "dictionary") – nazwa dla powszechnie stosowanego w informatyce abstrakcyjnego typu danych, który przechowuje pary ("unikatowy klucz", "wartość") i umożliwia dostęp do wartości poprzez podanie klucza.
Formalnie typ tablicy asocjacyjnej odpowiada zbiorowi skończonych funkcji częściowych z typu klucza tablicy w typ wartości tablicy. Wiele złożonych danych jest naturalnie reprezentowanych przez tego typu tablice – np. drzewa plików, nagłówki poczty, a nawet wszystkie atrybuty obiektu czy przestrzeń nazw zmiennych.
Tablice asocjacyjne realizowane są jako drzewa poszukiwań (BST, AVL, trie itp.) lub tablice mieszające. Typ danych klucza może być praktycznie dowolny. Najczęściej są to łańcuchy znaków (napisy), ale także liczby (całkowite, zmiennoprzecinkowe, zespolone), krotki itp.
Cechy tablic asocjacyjnych.
Istniejące implementacje tablic asocjacyjnych, bądź to dostępne bezpośrednio w danym języku programowania, bądź jako oddzielna biblioteka programistyczna na ogół oferują większą funkcjonalność niż tylko przypisanie wartości do klucza i pobranie wartości. Może ona obejmować następujące operacje:
Tablice asocjacyjne w różnych językach programowania.
AWK.
W języku AWK tablica asocjacyjna nazywana jest tablicą ("array"). Kluczem może być pojedyncze wyrażenie (zamieniane zawsze na łańcuch znaków), albo lista wyrażeń, które są sklejane razem, a ciąg je separujący jest określony przez zmienną SUBSEP.
 tablica["Wikipedia"] = "Wolna encyklopedia";
 tablica[10, 12, 2006] = "środa";
 tablica[255] = 0xff;
 if ("Wikipedia" in tablica)
 print tablica["Wikipedia"];
C++.
W standardowej bibliotece języka C++ istnieje szablon map, który przyjmuje jako parametry dwa typy danych: typ klucza i typ wartości.
using namespace std;
map&lt;string, int&gt; liczba_dni; // klucze typu string, wartości typu int
liczba_dni["styczeń"] = 31; // wstawienie pary klucz, wartość
liczba_dni["luty"] = 28;
liczba_dni["marzec"] = 31;
if (rok_przestępny)
 liczba_dni["luty"] = 29; // zmiana wartości związanej z kluczem "luty"
// wyszukanie wartości klucza metodą 'find'
if (liczba_dni.find("marzec") == liczba_dni.end())
 cout « "klucz 'marzec' nie występuje w tablicy";
else
 cout « "liczba dni w marcu = " « liczba_dni["marzec"];
PHP.
$tablica = array("klucz" =&gt; "wartosc",
 "nowy_klucz" =&gt; 2);
// lub też:
$tablica["klucz"] = "wartosc";
$tablica["nowy_klucz"] = 2;
//od PHP 5.4
$tablica = ["klucz" =&gt; "wartosc", "inny_klucz" =&gt; 1];
Perl.
%kolejna_tablica_asocjacyjna = (apple =&gt; "red", banana =&gt; "yellow", );
JavaScript.
W języku JavaScript każdy obiekt jest tablicą asocjacyjną.
var tab_asoc = {};
tab_asoc["klucz"]="wartość";
//co jest równoważne
tab_asoc.klucz="wartość";
Python.
W języku Python tablice są nazywane słownikami ("dictionary", dict). Kluczem może być dowolny obiekt, która posiada metodę __hash__. Jeśli chodzi o typy wbudowane, jako klucze mogą służyć liczby całkowite, zmiennoprzecinkowe, zespolone, łańcuchy znaków (zwykłe i unikodowe), niemodyfikowalne zbiory ("immutable sets"), krotki, a nawet funkcje. Natomiast listy, modyfikowalne zbiory ani słowniki nie mogą być kluczami.
tablica = {"Wikipedia": "Wolna encyklopedia",
 (10, 12, 2006): "środa",
for klucz in tablica:
 print(klucz)
for wartosc in tablica.values():
 print(wartosc)
for klucz, wartosc in tablica.items():
 print(klucz, '=&gt;', wartosc)
if "Wikipedia" in tablica:
 print(tablica["Wikipedia"])
print(tablica.get("Wikipedia", "brak klucza 'Wikipedia'"))
Lua.
tablica = {
 klucz = 'wartość',
 innyklucz = 'innawartosc'
-- w przypadku kiedy klucz ma więcej niż jeden wyraz lub jest liczbą
tablica = {
 ['klucz numer 1'] = 'wartosc',
 ['2'] = 'innawartosc'
-- lub inny zapis:
tablica["klucz"] = "wartosc"
-- lub
tablica.klucz = 'wartosc'
Object Pascal.
W bibliotece VCL środowiska Delphi istnieje klasa generyczna TDictionary, która przyjmuje dwa typy danych jako parametry: typ klucza i typ wartości. Poniższy kod kompiluje się od wersji Delphi XE3, ponieważ użyto w nim rekordów pomocników (record helpers).
program LiczbaDniRoku;
uses
 System.SysUtils, System.Generics.Collections, System.DateUtils;
var
 LiczbaDni: TDictionary&lt;String, Integer&gt;; // klucze typu String, wartości typu Integer
begin
 // utworzenie słownika
 LiczbaDni := TDictionary&lt;String, Integer&gt;.Create;
 LiczbaDni.Add('styczeń', 31); // wstawienie pary: klucz, wartość
 LiczbaDni.Add('luty', 28);
 LiczbaDni.Add('marzec', 31);
 // podaje liczbę kluczy przechowywaną w słowniku
 Writeln('liczba dodanych miesiecy: ', LiczbaDni.Keys.Count.ToString);
 // korekta liczby dni 'lutego', gdy rok jest przestępny
 if DaysInAYear(2000) = 366
 then LiczbaDni['luty'] := 29; // zmiana wartości związanej z kluczem "luty"
 // wyszukanie wartości klucza w słowniku
 if LiczbaDni.ContainsKey('marzec')
 then Write('liczba dni w marcu = ', LiczbaDni['marzec'])
 else Write('klucz "marzec" nie występuje w słowniku');
 // usunięcie słownika
 LiczbaDni.Free;
 // zatrzymanie okna konsoli
 Readln;
end.
W bibliotece FCL środowiska Lazarus, które używa kompilatora FPC, istnieje klasa generyczna TFPGMap. Przyjmuje ona dwa typy danych jako parametry: typ klucza i typ wartości. W środowisku Lazarus można też korzystać z klasy TDictionary, która jest dostępna w module Generics.Collections i działa podobnie jak ta z biblioteki VCL. Poniższy kod kompiluje się od wersji 2.6 kompilatora FPC, ponieważ użyto w nim rekordów pomocników (record helpers).
program LiczbaDniRoku;
uses
 SysUtils, DateUtils, Fgl;
var
 LiczbaDni: specialize TFPGMap&lt;String, Integer&gt;; // klucze typu String, wartości typu Integer
begin
 // utworzenie słownika
 LiczbaDni := specialize TFPGMap&lt;String, Integer&gt;.Create;
 LiczbaDni.Add('styczeń', 31); // wstawienie pary: klucz, wartość
 LiczbaDni.Add('luty', 28);
 LiczbaDni.Add('marzec', 31);
 // podaje liczbę kluczy przechowywaną w słowniku
 Writeln('liczba dodanych miesiecy: ', LiczbaDni.Count.ToString);
 // korekta liczby dni 'lutego', gdy rok jest przestępny
 if DaysInAYear(2000) = 366
 then LiczbaDni['luty'] := 29; // zmiana wartości związanej z kluczem "luty"
 // wyszukanie wartości klucza w słowniku
 if LiczbaDni.IndexOf('marzec') &gt; -1
 then Write('liczba dni w marcu: ', LiczbaDni['marzec'])
 else Write('klucz "marzec" nie występuje w słowniku');
 // usunięcie słownika
 LiczbaDni.Free;
 // zatrzymanie okna konsoli
 Readln;
end.

</doc>
<doc id="13063" url="https://pl.wikipedia.org/wiki?curid=13063" title="Tablica">
Tablica



</doc>
<doc id="13064" url="https://pl.wikipedia.org/wiki?curid=13064" title="Wyjątek">
Wyjątek

Wyjątek () - mechanizm przepływu sterowania używany w procesorach oraz współczesnych językach programowania do obsługi zdarzeń wyjątkowych, a w szczególności błędów, których wystąpienie zmienia prawidłowy przebieg wykonywania programu.
W momencie zajścia niespodziewanego zdarzenia generowany jest wyjątek, który musi zostać "obsłużony" poprzez zapamiętanie bieżącego stanu programu i przejście do procedury jego obsługi.
W niektórych sytuacjach po obsłużeniu wyjątku można powrócić do wykonywania przerwanego kodu, korzystając z zapamiętanych informacji stanu. Przykładowo obsługa błędu braku strony pamięci polega najczęściej na pobraniu brakującej strony z pliku wymiany, co umożliwia kontynuowanie pracy programu, natomiast błąd dzielenia przez zero powoduje, że wykonywanie dalszych obliczeń nie ma sensu i musi zostać definitywnie przerwane.
Wyjątki w procesorach.
Wyjątki w procesorach są zdarzeniami, których wynikiem jest przerwanie wykonania bieżącego strumienia instrukcji i przekazanie sterowania do oprogramowania systemowego w celu programowej reakcji na zdarzenie.
Wyjątki dzielą się na synchroniczne, obsługiwane bezpośrednio po wystąpieniu, oraz asynchroniczne, których obsługa może, w zależności od bieżącego priorytetu procesora, zostać opóźniona.
Do wyjątków asynchronicznych należą przerwania. Wyjątki synchroniczne - to pułapki (traps) i błędy (faults, aborts, errors).
Przerwania mogą być generowane sprzętowo przez sterowniki urządzeń zewnętrznych oraz - w nowocześniejszych architekturach (np. ARM) - programowo przez procesor.
Pułapki są generowane przez jednostkę wykonawczą procesora w wyniku wykonania instrukcji, na końcu jej wykonania. Pułapki służą do trzech celów:
Przy wystąpieniu pułapki wykonanie instrukcji, która ją spowodowała, zostaje normalnie zakończone.
Błędy mogą być generowane przez procesor lub jego otoczenie. Charakterystyczną cechą błędów jest to, że uniemożliwiają one zakończenie wykonania instrukcji, podczas której wystąpiły. Są to np:
Wyjątki w językach programowania.
W językach programowania wsparcie dla wyjątków realizowane jest na poziomie składni i semantyki danego języka. Zgłoszenie sytuacji wyjątkowej możliwe jest w dowolnym miejscu kodu poprzez instrukcje zwane raise lub throw. Od ich angielskich nazw w języku polskim proces ten nazywany jest "podnoszeniem" lub "rzucaniem wyjątku". Dla dowolnej partii kodu możliwe jest zdefiniowanie bloku obsługi, który "przechwytuje" (ang. "catch") określone rodzaje wyjątków. Poniżej widoczna jest typowa realizacja w pseudokodzie:
 operacje programu
 try
 operacje programu
 jeśli wystąpiła sytuacja wyjątkowa:
 throw "wyjątek"
 operacje programu
 catch "wyjątek"
 obsłuż "wyjątek"
 end
 operacje programu
W momencie wykonania instrukcji throw sterowanie przekazywane jest do bloku catch, w którym powinien być zawarty kod obsługi danego rodzaju wyjątku. Po obsłużeniu, sterowanie nie powraca już do bloku try – program wykonuje się dalej od instrukcji end, zatem dalsze operacje wewnątrz tego bloku nie będą wykonywane. Zezwala się na rzucanie wyjątków z wnętrza funkcji, a także na zagnieżdżanie bloków try. W momencie wystąpienia wyjątku sterowanie jest przekazywane do pierwszego z nich, który potrafi go obsłużyć.
Blok finally.
Istotnym problemem w obsłudze wyjątków jest to, że wewnątrz bloku try mogły zostać tymczasowo zaalokowane jakieś zasoby, które po zakończeniu wykonywania powinny zostać zwolnione. Jeśli rzucanie i przechwytywanie wyjątku zachodzi w obrębie tej samej funkcji, odpowiedni kod można umieścić za sekcją try ... catch, lecz funkcja rzuca wyjątek, który powinien przechwycić kod wywołujący, programista sam musi zadbać, by zwolnić wszystkie tymczasowe zasoby przed jego rzuceniem. Dlatego w niektórych językach wprowadzony jest dodatkowy, opcjonalny blok finally, który musi się wykonać niezależnie od tego, czy wewnątrz try został rzucony wyjątek, czy nie. Poniżej przedstawiony jest przykład w pseudokodzie ilustrujący zagadnienie:
 procedura "foo()"
 try
 zaalokuj zasób "X"
 operacje programu
 jeśli wystąpiła sytuacja wyjątkowa:
 throw "wyjątek"
 operacje programu
 finally
 zwolnij zasób "X"
 end
 koniec
 try
 wywołaj "foo()"
 catch "wyjątek"
 obsłuż "wyjątek"
 end
Na samym początku procedury codice_1 alokujemy pewien zasób "X", który musi zostać zwolniony przed zakończeniem jej wykonywania. Jednak w międzyczasie może zostać rzucony wyjątek, który w normalnych okolicznościach spowodowałby opuszczenie procedury i pojawienie się wycieku pamięci. Dlatego kod procedury zostaje objęty blokiem try z dołączoną klauzulą finally opisującą zwolnienie zasobów. Język programowania gwarantuje nam, że zostanie ona wykonana zarówno wtedy, gdy procedura zakończy się normalnie, jak i gdy zostanie rzucony wyjątek, który obsługiwany jest przez kod ją wywołujący.
Typy wyjątków.
Reprezentacja wyjątków jest zależna od konkretnego języka programowania. Przykładowo, w C++ wyjątkiem może być wartość dowolnego typu:
try
 throw 20;
catch(int x)
 cout « "Wystąpił wyjątek o kodzie " « x;
W Javie wyjątki mogą być wyłącznie obiektami klas rozszerzających klasę codice_2:
try
 throw new Exception("Informacja o błędzie");
catch(Exception x)
 System.err.println(x.getMessage());
Bezpieczna obsługa wyjątków.
Skuteczność obsługi błędów zależy od przyjętej strategii obsługi wyjątków. Jednym z największych wyzwań jest konieczność przekazywania informacji o wyjątkach między systemami. Aplikacje biznesowe mogą składać się z wielu niewielkich programów oraz być rozproszone pomiędzy kilka maszyn, co wymaga podjęcia decyzji czy dany wyjątek powinien być obsługiwany w ramach aktualnego procesu czy przekazany do innej części systemu.
Odporność na wyjątki.
O kodzie powiemy, że jest bezpieczny dla wyjątków (ang. "exception-safe"), jeśli rzucenie wyjątku w jego obrębie nie produkuje niepożądanych skutków ubocznych takich, jak wycieki pamięci, generowanie nieprawidłowego wyniku czy pozostawienie systemu w stanie niespójnym. Kod bezpieczny dla wyjątków musi spełniać niezmienniki nawet w przypadku wystąpienia błędu. Wyróżniamy kilka poziomów bezpieczeństwa:

</doc>
<doc id="13065" url="https://pl.wikipedia.org/wiki?curid=13065" title="Patrylinearność">
Patrylinearność



</doc>
<doc id="13066" url="https://pl.wikipedia.org/wiki?curid=13066" title="Patrylinearny system pokrewieństwa">
Patrylinearny system pokrewieństwa

Patrylinearny system pokrewieństwa – w antropologii system pokrewieństwa faworyzujący ojca dziecka.
Patrylinearność zakłada automatyczne włączanie dzieci po urodzeniu do "grupy ojca" i pozostawanie jej członkami przez całe życie (zasada patrylinearności). Przekłada się to np. na dziedziczenie nazwisk, przywilejów, majątku itp. – po krewnym ze strony ojca, a nie matki (tj. nie tylko od samego ojca).
Na podstawie badań ponad pięciuset społeczeństw na całym świecie (zob. światowa próba etnograficzna) stwierdzono, że system patrylinearny występuje średnio trzy razy częściej niż matrylinearny system pokrewieństwa.
Współczesne społeczeństwa europejskie nie są patrylinearne – występuje obustronne dziedziczenie i ustalanie pokrewieństwa – ale mają tendencję do patrylinearyzmu (np. dziecko automatycznie otrzymuje nazwisko ojca, chyba że przedsięweźmie się odpowiednie formalności).

</doc>
<doc id="13067" url="https://pl.wikipedia.org/wiki?curid=13067" title="Naruszenie ochrony pamięci">
Naruszenie ochrony pamięci

Naruszenie ochrony pamięci – zdarzenie wykrywane przez sprzęt, polegające na korzystaniu przez program z pamięci poza zaalokowanym dla niego obszarem.
Zwykle wynika to z błędów, czasem jednak jest to świadome działanie programisty – np. program może zalokować mały stos i nie sprawdzać jego przepełnienia, za to kiedy ono nastąpi – i nastąpi naruszenie ochrony pamięci – przechwycić ten sygnał i rozszerzyć stos. Jest to o wiele bardziej efektywne od ciągłego sprawdzania przepełnienia (co musi następować ogromną liczbę razy), oraz od alokacji dużej ilości pamięci na stos (co marnuje pamięć).
Objawy błędu.
W systemie Linux w konsoli pojawia się napis „Segmentation fault” opcjonalnie z dodatkowymi informacjami, o ile sygnał SIGSEGV nie zostanie przechwycony przez aplikację.
W systemach Windows aplikacje często w tej sytuacji wyświetlają okno z błędem o treści „EAccess Violation”, „Access Violation” lub informacji o kodzie błędu 0xC0000005. Zdarzają się też przypadki zakończenia aplikacji bez wyświetlenia jakiegokolwiek komunikatu. 
Przykłady.
Zapis do obszaru pamięci przeznaczonego tylko do odczytu.
Zapis do obszaru pamięci, który przeznaczony jest tylko do odczytu powoduje zgłoszenie błędu naruszenia ochrony pamięci. Błąd ten wystąpi również przy próbie zapisu do obszaru, w którym znajduje się kod wykonywalny lub dane przeznaczone tylko do odczytu (np. tablice stałych) lub biblioteki systemowe (np. kernel32.dll).
Poniżej znajduje się fragment kodu napisanego w ANSI C, który powoduje błąd naruszenia ochrony pamięci na platformach, posiadających ochronę pamięci. Pamiętaj, że modyfikowanie stałych łańcuchów tekstowych nie jest zdefiniowane standardem ANSI C, ale większość kompilatorów nie zauważy błędu podczas kompilacji i nie zgłosi błędu ani ostrzeżenia. Uruchomiony program zakończy się błędem.
int main(void)
 char *s = "hello world";
 *s = 'H';
Gdy program jest kompilowany stała tekstowa „Hello World” umieszczana jest w sekcji rodata pliku wykonywalnego. Rodata jest częścią segmentu danych przeznaczoną tylko do odczytu. Do zmiennej „s” przypisywany jest wskaźnik na pierwszy znak tekstu „hello world”. Próba zmiany pierwszego znaku, na który wskazuje zmienna „s” kończy się wystąpieniem wyjątku. Uruchomienie programu na systemach Linux i Unix kończy się wyświetleniem poniższego komunikatu (lub podobnego zależnie od konfiguracji systemu):
$ gcc segfault.c -g -o segfault
$ ./segfault
Segmentation fault
Śledzenie wsteczne działania programu przy użyciu gdb zwróci:
Powyższy błąd w kodzie może być naprawiony poprzez użycie tablicy w miejsce wskaźnika do znaku (codice_1). Spowoduje to za-alokowanie tablicy na stosie oraz przepisanie w ten obszar łańcucha znaków. 
char s[] = "hello world";
s[0] = 'H'; // lub również poprawnie: *s = 'H';
Z uwagi, że w C++ łańcuchy znaków są typu codice_2 kompilatory powinny wykrywać próbę niejawnej konwersji zmiennej codice_2 do typu codice_1 i zgłosić uwagę podczas kompilacji. 
Odwołanie do zerowego adresu pamięci.
Ponieważ dosyć częstym błędem jest próba zapisu/odczytu spod zerowego adresu pamięci (wskaźnik zainicjowany wartością NULL – oznaczającą brak obiektu), większość systemów operacyjnych nie alokuje adresu zerowego dla jakichkolwiek danych do odczytu lub zapisu. W systemach tych próba zapisu lub odczytu danych oraz wykonania instrukcji znajdujących się pod adresem zerowym kończy się zgłoszeniem błędu naruszenia ochrony pamięci.
int *ptr = NULL;
printf("%d", *ptr);
Powyższy kod tworzy zerowy wskaźnik i próbuje przeczytać dane, do których on wskazuje. Wykonanie tego kodu spowoduje naruszenie ochrony pamięci na systemach wspierających ochronę pamięci. Podobnie zakończy się próba zapisu z poniższego kodu:
int *ptr = NULL;
Przepełnienie stosu.
Kolejnym przykładem błędu mogącego doprowadzić do błędu naruszenia ochrony pamięci jest przepełnienie stosu, które można uzyskać rekurencyjnym wywołaniem funkcji nie posiadającym warunku zakończenia:
 int main(void)
 main();
 return 0;
Powyższy kod z uwagi na włączoną optymalizację w kompilatorze może prowadzić do różnych zachowań w powyższym fragmencie: Wynikowy program wykonywalny może:

</doc>
<doc id="13068" url="https://pl.wikipedia.org/wiki?curid=13068" title="22. ceremonia wręczenia Oscarów">
22. ceremonia wręczenia Oscarów

22. ceremonia rozdania Oscarów odbyła się 23 marca 1950 roku w RKO Pantages Theatre w Los Angeles.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii, napisano ich pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).

</doc>
<doc id="13074" url="https://pl.wikipedia.org/wiki?curid=13074" title="ISO 8859">
ISO 8859

ISO/IEC 8859 – zestaw standardów służących do kodowania znaków za pomocą 8 bitów. Standardy te zostały utworzone przez European Computer Manufacturers Association w połowie lat osiemdziesiątych, po czym zostały uznane przez Międzynarodową Organizacją Normalizacyjną.
Wszystkie zestawy ISO 8859 mają znaki 0-127 (hex 00-7F) identyczne jak w kodzie ASCII, zaś pozycjom 128-159 (hex 80-9F) przypisane są dodatkowe kody sterujące, tzw. C1 (faktycznie są nieużywane).
Polskie litery są obecne w ISO-8859-2, ISO-8859-13 i ISO-8859-16. Tylko ISO-8859-13 i ISO-8859-16 zawierają prawidłowe cudzysłowy stosowane w języku polskim zgodnie z normą PN-83/P-55366 („ i ”), których brak jest w ISO-8859-2. Litery Ą, ą, Ę, i ę istnieją również w ISO-8859-4 i ISO-8859-10 (w tym ostatnim obecne są również Ó i ó).
Porównanie standardów ISO 8859.
Na pozycji 0xA0 zawsze występuje spacja niełamliwa, a na 0xAD w większości zestawów występuje znak warunkowego przełamania tekstu (program może w tym miejscu przenieść zbyt długie słowo do nowej linii wstawiając dywiz), czyli miękki dywiz (ang. "soft hyphen)". Wszystkie pozostałe puste pola oznaczają, że kod został nieprzypisany lub zastosowany system nie jest w stanie go wyświetlić.
Kolorem żółtym oznaczono dodatki dla wersji ISO/IEC 8859-7:2003 i ISO/IEC 8859-8:1999.

</doc>
<doc id="13075" url="https://pl.wikipedia.org/wiki?curid=13075" title="23. ceremonia wręczenia Oscarów">
23. ceremonia wręczenia Oscarów

23. ceremonia rozdania Oscarów odbyła się 29 marca 1951 w RKO Pantages Theatre w Los Angeles.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii, napisano ich pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).

</doc>
<doc id="13076" url="https://pl.wikipedia.org/wiki?curid=13076" title="24. ceremonia wręczenia Oscarów">
24. ceremonia wręczenia Oscarów

24. ceremonia rozdania Oscarów odbyła się 20 marca 1952 roku w RKO Pantages Theatre w Los Angeles.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii, napisano ich pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).
Najlepszy Film.
Jest to pierwsza ceremonia podczas której nagrodę i nominację w tej kategorii otrzymuje producent, a nie wytwórnia.

</doc>
<doc id="13077" url="https://pl.wikipedia.org/wiki?curid=13077" title="25. ceremonia wręczenia Oscarów">
25. ceremonia wręczenia Oscarów

25. ceremonia rozdania Oscarów odbyła się 19 marca 1953 roku w RKO Pantages Theatre w Los Angeles i NBC International Theatre w Nowym Jorku. Była to pierwsza ceremonia transmitowana w telewizji.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii, napisano ich pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).

</doc>
<doc id="13078" url="https://pl.wikipedia.org/wiki?curid=13078" title="26. ceremonia wręczenia Oscarów">
26. ceremonia wręczenia Oscarów

26. ceremonia rozdania Oscarów odbyła się 25 marca 1954 roku w RKO Pantages Theatre w Los Angeles i w USA NBC Century Theatre w Nowym Jorku.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii, napisano ich pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).

</doc>
<doc id="13079" url="https://pl.wikipedia.org/wiki?curid=13079" title="27. ceremonia wręczenia Oscarów">
27. ceremonia wręczenia Oscarów

27. ceremonia rozdania Oscarów odbyła się 30 marca 1955 roku w RKO Pantages Theatre w Los Angeles oraz w NBC Century Theatre w Nowym Jorku.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii, napisano ich pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).

</doc>
<doc id="13080" url="https://pl.wikipedia.org/wiki?curid=13080" title="28. ceremonia wręczenia Oscarów">
28. ceremonia wręczenia Oscarów

28. ceremonia rozdania Oscarów odbyła się 21 marca 1956 roku w RKO Pantages Theatre w Los Angeles oraz NBC Century Theatre w Nowym Jorku.
Laureaci i nominowani.
Dla wyróżnienia zwycięzców poszczególnych kategorii, napisano ich pogrubioną czcionką oraz umieszczono na przedzie (tj. poza kolejnością nominacji na oficjalnych listach).

</doc>
<doc id="13081" url="https://pl.wikipedia.org/wiki?curid=13081" title="29. ceremonia wręczenia Oscarów">
29. ceremonia wręczenia Oscarów

29. ceremonia rozdania Oscarów odbyła się 27 marca 1957 roku w RKO Pantages Theatre w Los Angeles oraz w NBC Century Theatre, Nowy Jork. Była to ostatnia ceremonia transmitowana oddzielnie na dwóch wybrzeżach Stanów Zjednoczonych.

</doc>
<doc id="13082" url="https://pl.wikipedia.org/wiki?curid=13082" title="30. ceremonia wręczenia Oscarów">
30. ceremonia wręczenia Oscarów

30. ceremonia rozdania Oscarów odbyła się 26 marca 1958 roku w RKO Pantages Theatre w Los Angeles.

</doc>
<doc id="13083" url="https://pl.wikipedia.org/wiki?curid=13083" title="31. ceremonia wręczenia Oscarów">
31. ceremonia wręczenia Oscarów

31. ceremonia rozdania Oscarów odbyła się 6 kwietnia 1959 roku w RKO Pantages Theatre w Los Angeles.
Laureaci i nominowani.
Laureaci nagród wyróżnieni są wytłuszczeniem

</doc>
<doc id="13084" url="https://pl.wikipedia.org/wiki?curid=13084" title="32. ceremonia wręczenia Oscarów">
32. ceremonia wręczenia Oscarów

32. ceremonia rozdania Oscarów odbyła się 4 kwietnia 1960 roku w RKO Pantages Theatre w Los Angeles.

</doc>
<doc id="13085" url="https://pl.wikipedia.org/wiki?curid=13085" title="John Tyler">
John Tyler

John Tyler (ur. 29 marca 1790 w hrabstwie Charles City, zm. 18 stycznia 1862 w Richmond) – amerykański prawnik i polityk, dziesiąty prezydent USA.
Młodość i edukacja.
John Tyler urodził się 29 marca 1790 roku w hrabstwie Charles City. Pochodził z wielodzietnej rodziny sędziego – Johna Tylera seniora. W 1802 rozpoczął studia prawnicze na College of William &amp; Mary, które ukończył po pięciu latach. Po odbyciu dwuletniej praktyki uzyskał prawo do prowadzenia samodzielnej praktyki prawniczej.
Kariera polityczna.
Swoją karierę polityczną rozpoczął w wieku 21 lat, kiedy to został członkiem legislatury stanu Wirginia, pełniąc tę rolę do 1816 roku. Od 16 grudnia 1817 do 3 marca 1821 był członkiem Izby Reprezentantów jako przedstawiciel Partii Demokratyczno-Republikańskiej. Po zakończeniu kadencji na kilka lat zawiesił działalność polityczną, ze względu na zły stan zdrowia, jednak od 1823 roku powrócił do legislatury stanowej, a w latach 1825-1827 był gubernatorem Wirginii. Przyczynił się wówczas do znacznej poprawy infrastruktury stanu. W 1827 roku został członkiem Senatu i pełnił tę funkcję do 1836, a w ostatnim roku swojej kadencji był także przewodniczącym pro tempore. W okresie sprawowania mandatu senatora, zaczęły się uwidaczniać jego konflikty z Partią Demokratyczną, z której odszedł w 1830. Następnie związał się z nowo powstałą Partią Wigów.
Po rezygnacji z mandatu senatorskiego postanowił ubiegać się o nominację swojej partii na kandydata na wiceprezydenta. Nie udało mu się osiągnąć tego celu, w związku z czym powrócił do działalności politycznej na szczeblu lokalnym. W wyborach w 1840 roku ponownie ubiegał się o nominację na wiceprezydenta i tym razem mu się powiodło. Wybory prezydenckie wygrał William Henry Harrison, a Tyler został wiceprezydentem. Po miesiącu urzędowania dowiedział się, że prezydent zmarł. Tyler został zaprzysiężony 6 kwietnia 1841 roku.
Prezydentura.
Po objęciu przez Tylera fotela prezydenckiego, w Partii Wigów obawiano się, czy styl jego prezydentury będzie taki sam, jak jego poprzednika. Nowy prezydent zapowiedział, że będzie rządził silną ręką, nie patrząc na interesy partii. Lider wigów, Henry Clay, który miał aspiracje prezydenckie, zaczął wówczas budować swoją pozycję i poparcie partii, jednocześnie konfliktując się z Tylerem. Kiedy prezydent odmówił podpisania ustaw ekspansjonistycznych, przedstawionych przez Claya, wszyscy członkowie gabinetu, z wyjątkiem Daniela Webstera podali się do dymisji, a Tylerowi okazywano ostracyzm polityczny, zarówno w partii, jak i w Kongresie (gdzie dyskutowano nawet o impeachmencie).
Prezydent nie wykazywał zbyt wielu inicjatyw w zakresie polityki wewnętrznej. Jednym z nielicznych było doprowadzenie do zakończenia siedmioletniej wojny z Seminolami, których skłonił do przeprowadzki na zachód Stanów Zjednoczonych.
Więcej inicjatywy wykazywał w dziedzinie polityki zagranicznej. Widząc narastające konflikty graniczne pomiędzy Maine a Nowym Brunszwikiem, Tyler zdecydował się wznowić rozmowy pomiędzy Stanami Zjednoczonymi a Wielką Brytanią, do których desygnował swojego sekretarza stanu – Daniela Webstera. Stronę brytyjską reprezentował akredytowany poseł Alexander Baring, który wysunął propozycję, by granica przebiegała od źródła rzeki St. Croix do rzeki St. John. Pomimo że Webster był skłonny przystać na tę propozycję, stan Maine nie zgodził się oddawać osady Madawaska. Wówczas gabinet Tylera wypłacił obu stronom po 150 tysięcy dolarów odszkodowań, co skłoniło je do podpisania traktatu. Układ został przedłożony 27 lipca 1842 i regulował granice amerykańsko-brytyjskie, a także prawa wzajemnej żeglugi. Rzeki: St. Clair, Detroit, św. Wawrzyńca i jezioro St. Clair były przeznaczone dla obu stron, natomiast teren stanu Minnesota miał przypaść Stanom Zjednoczonym. Zawarto także regulację o nienaruszalności terytorium i zakazie nielegalnego przekraczania granicy, jakie miało miejsce w czasie powstania w Kanadzie w 1837. Układ został sygnowany 9 sierpnia 1842. Pomimo początkowych sprzeciwów, jedenaście dni później Senat przegłosował go stosunkiem głosów 39:9, natomiast prezydent ratyfikował go 13 października.
Drugim głównym elementem polityki Tylera był ekspansjonizm, który objawiał się zainteresowaniem dokonania aneksji Teksasu. Początkowo prezydent nie czynił starań, by doprowadzić do rozszerzenia terytorium USA, gdyż uważał, że nie ma szans by przegłosować tę ustawę w Senacie. Z uwagi na fakt, iż Meksyk, Wielka Brytania i Francja także były zainteresowane tym obszarem, w 1843, Tyler zobowiązał sekretarza stanu, Abla Upshura, by rozpoczął negocjacje z prezydentem Republiki Teksasu. Sam Houston obawiał się, że przyłączenie do Unii, rozgniewa władze Meksyku, więc zażądał, by Tyler zmobilizował wojska amerykańskie, które przyjdą z pomocą Teksańczykom, jeśli zajdzie potrzeba. Po śmierci Upshura na statku „Princeton”, sekretarzem stanu został John C. Calhoun, który kontynuował negocjacje. Układ został podpisany 12 kwietnia 1844 jednak został odrzucony w głosowaniu senackim stosunkiem głosów 16:35. W grudniu 1844 prezydent Tyler zaproponował, by aneksję uchwaliły połączone Izby Kongresu, zwykłą większością głosów. Izba Reprezentantów przyjęła traktat, natomiast Senat wprowadził poprawki i przegłosował go 27:25. Akt aneksji został podpisany przez prezydenta 1 marca 1845 roku. Republika Teksasu opowiedziała się za ratyfikowaniem traktatu w drodze referendum 13 października 1845. Dwa miesiące później, 29 grudnia, stan został przyłączony do Unii. Tyler podejmował także próby negocjacji kupna Kalifornii, jednak bezskutecznie.
Kwestia głosowania ws. aneksji Teksasu była przedmiotem kampanii prezydenckiej przed wyborami w 1844. Po porażce Wigów w wyborach do Izby Reprezentantów, Tyler zebrał swoich zwolenników i starał się utworzyć nowe stronnictwo polityczne. Dzielenie stanowisk politycznych, spowodowało, że zaufany współpracownik Tylera, Daniel Webster zrezygnował ze swojej posady w rządzie, choć nadal popierał prezydenta. Partia Demokratyczna wysunęła kandydaturę Jamesa Polka. Zdając sobie sprawę, że nie ma żadnych szans na wygranie wyborów, Tyler zrezygnował z ubiegania się o reelekcję i udzielił swojego poparcia Polkowi.
Emerytura i śmierć.
Po opuszczeniu Białego Domu Tyler powrócił na swoją plantację do Wirginii. W 1859 ponownie został rektorem William and Mary’s College. Kiedy nad Stanami Zjednoczonymi zawisła groźba wojny domowej, Tyler opowiedział się za secesją stanów południowych i od 1861 był członkiem Izby Reprezentantów Skonfederowanych Stanów Ameryki. 12 stycznia 1862 roku w Richmond doznał udaru serca i zmarł sześć dni później.
Życie prywatne.
John Tyler poślubił swoją pierwszą żonę, Letitię Christian, w 1813 roku. Z tego związku miał ośmioro dzieci: trzy córki i pięciu synów. Letitia Christian zmarła w czasie prezydentury męża, w 1842 roku.
Dwa lata po tym jak został wdowcem, Tyler ożenił się z Julią Gardiner – córką nowojorskiego senatora. Z tego małżeństwa urodziło się siedmioro dzieci.

</doc>
<doc id="13086" url="https://pl.wikipedia.org/wiki?curid=13086" title="Absalom">
Absalom



</doc>
<doc id="13088" url="https://pl.wikipedia.org/wiki?curid=13088" title="Bies">
Bies

Bies – w przedchrześcijańskich wierzeniach Słowian personifikacja bliżej nieokreślonego złego ducha, demona zła. Nazwa "bies" wywodzi się z prasłowiańskiego "*bĕsъ", od praindoeuropejskiego "*bhoidh-", oznaczającego „powodujący strach, przerażenie”.
Biesy mogły wnikać w poszczególne osoby i kierować ich działaniami (stąd określenie „zbiesiony”), przypisywano im też pilnowanie skarbów ukrytych w ziemi. Bytowały w lasach, bagnach i w głębinach wodnych.
Po chrystianizacji Słowiańszczyzny określenia bies zaczęto używać jako synonimu pojęcia diabeł.

</doc>
<doc id="13089" url="https://pl.wikipedia.org/wiki?curid=13089" title="Arabowie">
Arabowie

Arabowie ( "’Arab", w pierwotnym znaczeniu: „koczownik”) – grupa ludów pochodzenia semickiego zamieszkująca od czasów starożytnych Półwysep Arabski. Arabowie to ludzie biali. W Afryce można też spotkać zarabizowanych Chamitów o negroidalnym wyglądzie.
Pierwsze wzmianki o Arabach pojawiają się w Biblii już ok. 1000 r. p.n.e., a w kronikach asyryjskich ok. VII wieku p.n.e. – przez ok. 1600 lat zamieszkiwali głównie rejon Półwyspu Arabskiego, aby w VII wieku n.e. rozpocząć ekspansję i zmieszać się z ludnością mieszkającą na zajętych przez nich terenach, która uległa w znacznej części arabizacji. Najczęstszym wyznaniem wśród Arabów jest islam sunnicki, ale jest również wielu szyitów (głównie w Iranie, Jemenie, Syrii i Libanie) oraz chrześcijan (głównie w Libanie, Syrii i Egipcie).
Często uznaje się Arabów nie za jeden naród, ale za wspólnotę kulturową. Pogląd ten jest spowodowany tym, że większość Arabów jest potomkami ludów podbitych w trakcie arabskich podbojów (m.in. Aramejczyków, Egipcjan, Wandalów, Berberów, zhellenizowanych mieszkańców Bliskiego Wschodu i zromanizowanych mieszkańców północnej Afryki).
Krajami i terytoriami zdominowanymi przez ludność arabską są: Maroko, Mauretania, Sahara Zachodnia, Algieria, Tunezja, Libia, Egipt, Sudan, Arabia Saudyjska, Palestyna (Zachodni Brzeg i Strefa Gazy), Jordania, Liban, Syria, Irak, Kuwejt, Jemen, Katar, Bahrajn, Zjednoczone Emiraty Arabskie oraz Oman. Ocenia się, że obecnie żyje na świecie ponad 500 milionów Arabów, z czego najwięcej w Egipcie (66,8 miliona w 2001 roku). Duża emigracja arabska istnieje m.in. w Stanach Zjednoczonych, Francji, Niemczech i Wenezueli.
Wśród Arabów istnieje podział na Fellahów (ludność osiadłą) i Beduinów (koczowników). Grupy te różnią się między sobą nie tylko stylem życia, ale także obyczajami, a nawet sposobem mówienia.
Historia.
Według przekazów Biblii i Koranu, Arabowie są potomkami Sema. Praojcami tego ludu, według średniowiecznych historyków, byli Kahtan (biblijny Joktan), od którego wywodzą się "al-’Arab al-’ariba" – mieszkańcy południowej części Półwyspu Arabskiego, posługujący się językiem południowoarabskim – i Adnan, od którego wywodzą się północni Arabowie ("musta’riba"), pod względem antropologicznym i językowym bardziej zbliżeni do północnych Semitów takich jak Żydzi i Fenicjanie. Migracje Kahtanitów na północ doprowadziły do zlania się obu grup etnicznych w jedną.
Już od początków II tysiąclecia p.n.e. Arabowie tworzyli rozwinięte cywilizacje na względnie bogatym w wodę południowym zachodzie Półwyspu Arabskiego (np. Irem, Saba). Nie ma jednak ciągłości kulturowej między nimi a współczesnymi Arabami, gdyż państwa te upadły pod koniec I tysiąclecia p.n.e. ze względu na zmianę szlaków handlowych z Rzymu do Indii. Także północne obszary, częściowo pod wpływem rozwiniętych kultur Mezopotamii, wytworzyły handlowe państwa (Nabatejczycy, Petra, Gassanidzi). Obszary pustynne zamieszkiwane były natomiast przez pasterskie ludy beduińskie, żyjące bez organizacji państwowej w stanie określanym później jako "dżahilijja" (okres niewiedzy, ciemności). Struktura społeczna tych ludów opierała się o więzi rodowe ("asabijja"). Rody prowadziły ze sobą ciągłe wojny. Religia Arabów w tym okresie cechowała się politeizmem, w którym obok najwyższego boga Allaha czczono ciała niebieskie.
Przełomem w rozwoju kultury arabskiej było powstanie islamu i zjednoczenie Półwyspu Arabskiego przez Mahometa. Posługując się często zwyczajami okolic handlowych miast Mekki i Medyny i Koranem (według muzułmanów zesłanym mu przez Allaha) Mahomet zintegrował arabskie prawo i zwyczaje.
Wkrótce po śmierci Mahometa Arabowie pod panowaniem kalifów podbili rozległe regiony – całą Afrykę Północną, Lewant, Mezopotamię, Persję, Turkiestan, część Anatolii, Hiszpanię, Sycylię i Sardynię. Rozpowszechnili swoją kulturę, pismo i język na wszystkie te obszary. Islam jako religia państwa i prawa regulował całe życie społeczne, było jednak wiele znaczących ruchów próbujących zachwiać tymi regułami. Przejęli wiele elementów kultur obcych – szczególnie bizantyjskiej, perskiej i indyjskiej oraz lokalnych wspólnot chrześcijańskich. Chrześcijańscy Arabowie i arabskojęzyczni Żydzi utworzyli własne kultury w obrębie kultury arabskiej. Jednocześnie wystąpiły antagonizmy między rolniczo-miejską a koczowniczą kulturą Arabów.
Państwo kalifów dość szybko (już w X wieku) rozpadło się na wiele wciąż dzielących się części. Pod koniec średniowiecza kultura arabska podupadła, na skutek najazdów tureckich i mongolskich oraz rozwoju ruchów dążących do ściślejszej dominacji religii nad wszystkimi aspektami życia. Arabowie przez wieki znajdowali się w większości pod panowaniem tureckim. Po wyzwoleniu spod niego większość regionów zamieszkanych przez Arabów uległa kolonizacji europejskiej, zwłaszcza francuskiej i angielskiej.
Na przełomie XIX i XX stulecia nastąpiło odrodzenie kultury arabskiej, zwane jako an-nahda. An-Nahda zaczęła się w Egipcie i w Libanie, później przenosząc się również do Iraku i Syrii, podczas gdy kraje Maghrebu i Półwyspu Arabskiego długo pozostały zacofane. Intelektualiści arabscy zapoznali się z osiągnięciami kultury i techniki europejskiej, co doprowadziło do rozkwitu nowatorskiej myśli. Odrzucono opartą na wzorcach starożytnych sformalizowaną poezję. Postulowano również stworzenie świeckich państw na wzór zachodni i ograniczenie roli religii w życiu publicznym.
W I połowie XX wieku powstały znane obecnie państwa arabskie. W większości z nich, zwłaszcza rządzący, kierowali się ideologiami nacjonalizmu i socjalizmu. Powstanie Izraela w 1948 roku było odebrane przez Arabów jako klęska, co przyczyniło się do wzrostu nastrojów panarabskich i skłoniło niektóre rządy do sojuszu z ZSRR, postrzeganego jako przeciwwaga dla wsparcia Stanów Zjednoczonych dla Żydów. W II połowie stulecia w wielu krajach arabskich rozpoczęto wydobycie ropy naftowej, co przyczyniło się do rozwoju ekonomicznego i wzrostu prestiżu tych państw na arenie światowej.
Na początku XXI wieku największym problemem z jakim borykają się Arabowie jest działalność organizacji terrorystycznych, opartych na radykalnych ruchach religijnych takich jak wahhabizm, które zyskały na popularności za sprawą rozczarowania Arabów niedemokratycznymi rządami zlaicyzowanych elit.
Kultura.
Arabowie, jak wszystkie ludy Bliskiego Wschodu, są kulturą patriarchalną. Gościnność i odwaga są w tej kulturze dwiema największymi zaletami człowieka. Od czasów Mahometa nieodłącznym elementem tej kultury jest również islam.
Już w czasach przed islamem Arabowie chętnie tworzyli literaturę, choć ze względu na małe upowszechnienie pisma była to głównie twórczość ustna. Plemiona arabskie rozwinęły skomplikowaną, sformalizowaną poezję, w której z reguły opisywano trzy tematy: pustynię, kobietę i wielbłąda. Istniało 16 gatunków poetyckich, znanych jako "bihaar" (dosłownie ‘morza’; rytm wiersza porównywano do pływów morskich). Najbardziej cenionym gatunkiem była kasyda i rubajjat. Szczytowym osiągnięciem pogańskiej kultury arabskiej są niewątpliwie muallaki – poematy autorów takich jak Imru al-Kajs, Labid ibn Rabia i Antara ibn Szaddad, wyhaftowane złotem na jedwabiu i zawieszone w świątyni Kaaba. Proza cieszyła się mniejszym powodzeniem, choć należy wymienić dzieło historyczne "Dni Arabów". Ze względu na koczowniczy styl życia sztuki plastyczne nie były uprawiane na większą skalę.
Średniowiecze było okresem największego rozkwitu kultury arabskiej. Arabowie zdołali przyswoić sobie, rozwinąć i pogodzić z islamem większość osiągnięć kultury hellenistycznej dominującej na podbijanych przez nich obszarach. Zarazem przyswoili sobie wiele osiągnięć kultury indyjskiej. Stworzyli wysoce rozwiniętą filozofię i logikę oraz bogatą literaturę (często opartą na formach beduińskich). Zaczęli też uprawiać naukę – zwłaszcza alchemię, matematykę (za pośrednictwem Arabów Europejczycy zapożyczyli indyjskie tzw. cyfry arabskie) i medycynę. Przyswoili sobie dziedzictwo Platona i Arystotelesa, które między innymi dzięki nim przedostało się z powrotem do Europy zachodniej.
Rozwój malarstwa i rzeźby został zahamowany przez czynniki religijne. Islam uważa bowiem, iż wszelkie próby artystycznego przedstawiania postaci ludzkich i zwierzęcych stanowią naigrywanie się z dzieła Allaha i prowadzą do bałwochwalstwa. Teksty szariackie uważają także za grzeszną muzykę, zakaz ten nie był jednak nigdy powszechnie przestrzegany. Na muzykę arabską silnie wpłynęły dwie starożytne kultury: perska i akadyjska. Arabowie słyną z pięknej architektury, ozdabianej motywami geometrycznymi i roślinnymi, oraz wszechobecnej w ich świecie kaligrafii.
Za sprawą uniwersalizmu islamu kultura arabska silnie wpłynęła na kultury Afryki Północnej, Bliskiego Wschodu, Azji Środkowej i Kaukazu.

</doc>
<doc id="13090" url="https://pl.wikipedia.org/wiki?curid=13090" title="Korybanci">
Korybanci

Korybanci (gr. "korýbantes", lp. "korýbas"; łac. "corybantes", lp. "corybant") – bóstwa demoniczne oraz uczestnicy kultu frygijskiej bogini Kybele.
W mitologii.
Początkowo demony pochodzenia frygijskiego towarzyszące Kybele. Grecy uważali ich za synów Kronosa i Rei (utożsamianej przez nich później z Kybele), przypisując im wynalezienie ekstatycznego tańca ("korybas") z odpowiednimi instrumentami akompaniującymi (flet, tympanon). Wierzono, iż mają moc wywoływania, ale i leczenia szaleństwa. Według innej tradycji mieli być synami Zeusa, który zapłodnił ziemię pod postacią deszczu, według jeszcze innych podań – potomstwem muzy Talii i Apollina lub nawet Heliosa i Kybele; występowali zawsze w liczbie dziewięciu. 
W obrzędowości.
Nazwę tę potem odnoszono również do uczestników kultu małoazjatyckiej bogini, wykonujących podczas jej świąt orgiastyczne tańce przy wtórze bębnów, fletów i cymbałów, stanowiące część praktykowanych obrzędów kultowych. Wyposażeni we włócznie i tarcze, korybanci nosili też hełmy z potrójnym obrzeżeniem (dlatego zwano ich „trójhełmiastymi”). Ich rytuał obejmował gorszące praktyki (m.in. samookaleczenia na cześć bóstwa), co nie zjednywało im sympatii u Rzymian. Szczególne znaczenie mieli korybanci na Eubei i Samotrace, uczestniczący w tamtejszych misteriach. 
Dość wcześnie przyswojeni w Atenach i wspominani w literaturze przez Sofoklesa, Eurypidesa, Arystofanesa, Platona. Później nierzadko utożsamiani z kreteńskimi kuretami, samotrackimi kabirami i frygijskimi daktylami ("daktyloi"), których pierwowzoru także upatrywano w lokalnych bóstwach demoniczno-opiekuńczych.

</doc>
<doc id="13091" url="https://pl.wikipedia.org/wiki?curid=13091" title="Kybele">
Kybele

Kybele (hetyckie "Kubaba", gr. "Kybele" lub "Kybebe", łac. "Cybele" lub "Cybebe") – frygijska bogini płodności, urodzaju, wiosny i miast obronnych, strażniczka zmarłych. W mitologii frygijskiej jej młodym kochankiem był Attis. Czczona od tysiącleci w całej Azji Mniejszej jako Magna Mater; 
Azja Mniejsza.
W III w. p.n.e. najważniejsze sanktuarium Kybele znajdowało się we Frygii, w Pessinunte (Pessinus, Pesynunt), nad rzeką Sangarius (obecnie Sakarya), u stóp góry Didymus, która była jej świętą górą (dlatego nosiła przydomek "Meter Didymene"). W sanktuarium znajdował się czarny kamień, niebędący tradycyjnym posągiem wyobrażającym bóstwo, lecz raczej jego archaicznym symbolem. Według podania spadł z nieba – najprawdopodobniej był to oprawiony w srebro meteoryt w kształcie figury kobiecej. W Troadzie czczono Kybele pod imieniem Matki Idajskiej ("Mater Idaea"); nazwa ta pochodziła od poświęconej jej góry Ida w pobliżu Troi. Czczono ją jeszcze w innych miastach Troady, w Lampsakos i Andeirze.
Inne ośrodki jej kultu stwierdzono we Frygii nad rzeką Penkelas, w grocie zwanej Steunos, w Myzji, w Kyzikos i Pergamonie, na wyspie Prokonessos i pod górą Didyma znajdującą się nieopodal Kyzikos. W Lidii była czczona na górze Sipylos, w Sardes i Magnezji, zaś w Karii w Laryssie.
Grecja.
W VII i VI w. p.n.e. kult Kybele dotarł do Grecji, gdzie identyfikowano ją z Reą i Demeter. Tam zwano ją także Matką Bogów ("Meter Theôn"). Czczono ją również na Krecie, gdzie była jej poświęcona góra Ida, a na jej cześć odbywali misteria kureci identyfikowani z korybantami. W V w. p.n.e. kult Kybele dotarł do Aten.
Okres rzymski.
W roku 205 p.n.e. w czasie II wojny punickiej senat wezwał kolegium kapłanów, aby odwołali się do Księgi Sybilli w kwestii wyniku toczącej się wojny. Kapłani wydali werdykt, że jedynym ratunkiem może być sprowadzenie do Rzymu nowej bogini, czczonej przez pradawnych przodków Rzymian. Liwiusz w "Ab Urbe condita" ujął to w słowach: „Kiedy obcy wróg wyda wojnę ziemi italskiej, będzie go można wypędzić z Italii i pokonać, jeżeli do Rzymu sprowadzi się z Pesynuntu Matkę Idajską” ("pelli Italia alienigenam hostem posse, si mater Idaea deportata Romam esset").
Rzymianie wierzyli, że są potomkami uciekinierów z Troi, których wyprowadził z palącego się grodu Eneasz, po długiej tułaczce doprowadził do Italii i osiedlił na wybrzeżu Lacjum. W obliczu wielkiego niebezpieczeństwa zdecydowali się więc oddać pod opiekę największej bogini Troady – Matki Idajskiej. Pesynunt wówczas podlegał jurysdykcji króla Pergamonu Attalosa I Sotera i do niego zwrócili się Rzymianie. Będący sprzymierzeńcem Rzymu władca wyraził zgodę: statuę bogini załadowano na okręt, a wraz z nią kapłanki i kapłanów znających szczegóły kultu i obrzędy.
6 kwietnia 204 roku p.n.e., okręt dobił do Ostii, w porcie czekała na niego delegacja złożona z senatorów, wybitnych i cnotliwych obywateli oraz wiwatującego tłumu zaciekawionego przybyciem tej, co miała uratować Italię przed Hannibalem. Matrony rzymskie przybyły licznie, a Claudia Quinta osobiście powitała orszak bogini, ciągnąc własnoręcznie okręt na linie i wykazując się nadludzką siłą. Zdarzenie to uznano za cudowne i świadczące o przychylności bóstwa.
W Rzymie przygotowano dla Matki Bogów (łac. "Mater Deum") tymczasową siedzibę w świątyni Wiktorii na Palatynie. Miejsce to przypominało o najstarszych tradycjach związanych z założeniem miasta i najstarszymi kultami Penatów i Westy mającej świątynię opodal. Ta lokacja miała symbolizować powiązanie Wielkiej Bogini z najodleglejszymi początkami Rzymu. Senatorzy Marek Liwiusz Salinator i Gajusz Klaudiusz Neron rozpoczęli prace nad planem odpowiedniej świątyni i w tym samym roku kult nowej bogini został zatwierdzony przez senat – "Magna Mater Cybele" ogłoszono Świętą Opiekunką Miasta. Budowa świątyni przy Via Sacra trwała trzynaście lat, ukończono ją w 191 roku p.n.e. (prace uległy opóźnieniu ze względu na kryzys finansowy będący rezultatem wojen punickich).
Kult.
W kulcie bogini istnieją dwa odrębne aspekty: urzędowy oraz orgiastyczny, gwałtowny i krzykliwy. Jej kapłani, zwani „archigalli”, musieli się poddać kastracji, nim dostąpili zaszczytu kapłaństwa, nawiązując do samookaleczenia się Attisa. Ceremonia polegała na wykonywaniu tańca kultowego przy akompaniamencie bębnów. Jego charakterystyczną cechą było to, że rytm zmieniał się w coraz bardziej porywający, a skoczny taniec kończył się wirowaniem aż do osiągnięcia ekstazy, co oznaczało, że bóstwo zawładnęło kapłanem: w tym stanie mógł on wygłaszać przepowiednie i wróżby, a w transie dopuszczał się często samookaleczenia.
Senat rzymski zakazał swym obywatelom uczestniczyć w tych praktykach, wyłącznie kapłani bogini mogli sprawować kult.
Kybele przedstawia się jako "divinitas salutaris" – opiekuńcze bóstwo Rzymu, wyobrażane w koronie z muru i wież. Pod koniec II w. p.n.e. Batrakes, wielki kapłan bogini przepowiedział zwycięstwo Mariusza nad Teutonami, i w 98 roku p.n.e. Mariusz udał się do Azji Mniejszej dla złożenia przyrzeczonych wotów dziękczynnych.
Pod rządami Augusta, a przede wszystkim Klaudiusza, dotychczasowe ograniczenia kultu zniesiono. August podkreślił charakter bogini jako opiekunki Rzymu, dodając ją do grona bóstw opiekuńczych rodziny cesarskiej, odbudował też jej świątynię na Palatynie, poprzednio zniszczoną przez pożar.
W roku 111 p.n.e. świątynię podpalono, a edyl Kwintus Memmiusz przywłaszczył sobie czarny kamień. Kult przywrócono, zaś Metellus Numidyjski odbudował świątynię. Z tego okresu pochodzi ogromny basen kultowy o wymiarach 16,5 × 3 m.
Święto Kybele – Ludi Megalenses (Megalesia), trwało od 4 do 10 kwietnia i obejmowało również widowiska oraz wyścigi konne w Circus Maximus. Składano wówczas ofiary zwane "moretum", a w domach urządzano uczty, na które zapraszano przyjaciół i znajomych. W II wieku wprowadzono rytuał "taurobolium", tj. oczyszczenia z grzechów poprzez oblewanie krwią byka (przypominające obrzęd z mitraizmu). Kult Kybele przetrwał do IV wieku n.e.

</doc>
<doc id="13092" url="https://pl.wikipedia.org/wiki?curid=13092" title="Kraje arabskie">
Kraje arabskie

Kraje arabskie – kraje, w których znaczącą część ludności stanowią Arabowie lub które są ściśle związane z Arabami. Pojęcie kraju „arabskiego” nie jest ściśle zdefiniowane. Wyznaczają go zachodzące na siebie kryteria językowe, historyczne, kulturowe i polityczne. W krajach Maghrebu znaczną rolę odgrywają Berberowie, na tyle silnie zarabizowani, że krajów tych nie wyłącza się z grupy krajów arabskich.
Geografia.
Kraje arabskie położone są w obrębie Afryki Północnej oraz Bliskiego Wschodu. Granice Afryki północnej nie są dobrze zaznaczone. Zależnie od przyjętej definicji, za takową można uznać obszar od Maroka po Morze Czerwone lub tylko kraje Maghrebu. Maroko, Algierię i Tunezję na północy przecinają góry Atlas (góry), każde z tych państw obejmuje również fragment Sahary. W Libii jedynie północno-wschodnie i północno-zachodnie obszary kraju leżą poza pustynią – są to krainy zwane dawniej Cyrenajką i Trypolitanią. Klimat tych regionów nie zawsze był pustynny. Ostatni okres intensywnych opadów miał miejsce około 6 tys. lat p.n.e., na początku neolitu. Dawniej w Afryce Północnej występowała również fauna charakterystyczna dziś dla Czarnej Afryki (Afryki subsaharyjskiej). Główna trasa, którą mieszkańcy basenu Morza Śródziemnego mogli komunikować się z subsaharyjską Afryką biegła od pasma Ahaggar do Tibesti. Kraje arabskie północnej Afryki mają w większości nieprzyjazną dla żeglugi linię brzegową (wyjątek: północno-wschodnia Tunezja). Możliwości dla żeglugi nie stwarzają także główne rzeki tego regionu, jak Wadi Madżarda i Wadi asz-Szalif.
Pozostała część krajów arabskich położona jest w obrębie Bliskiego Wschodu oraz Środkowego Wschodu – definicje tych pojęć bywają rozbieżne. Obejmują obszary od Maroko przez Półwysep Arabski po Iran, w tym tereny położone u wschodnich wybrzeży Morza Śródziemnego. Bardziej znaczącą formacją tego obszary jest Półwysep Arabski, mający formę wyniesionej platformy. Niegdyś pokrywające ją morskie piaski i osady obecnie są rozległą pustynią. Na jego obszarze występują kenozoiczne płaskowyże z zastygłej lawy, równiny o budowie wartwowej i kuesty. Część państw arabskich, znana jako Lewant, leży u wschodniego wybrzeża Morza Śródziemnego. Stąd występuje tu klimat śródziemnomorski i podobna roślinność – makia, "shiblyak" i frygana. Pod tymi formacjami przeważają gleby brązowe, bogate w żelazo. Frygana pospolicie porasta zachodnioacjatyckie wyżyny.
Kultura i społeczeństwo.
Krajów arabskich nie można utożsamiać z ogółem krajów islamskich – są one wyodrębnione ze względu na istnienie kulturowej i językowej wspólnoty. Większość muzułmanów – według PEW Research Center aż 62% w 2017 roku – zamieszkuje region Indo-Pacyfiku, choć religia ta stanowi w podanym obszarze 24%. W 2017 roku około 93% spośród mieszkańców (341 mln) krajów arabskich wyznawało islam. Do 10 krajów z największą populacją muzułmanów wśród krajów arabskich zaliczyły się jednak jedynie Egipt, Algieria i Maroko. Krajem o największej populacji muzułmanów na świecie jest Indonezja – kraj niearabski, zawierający liczną (4–5 mln w 2013) diasporę arabską – w 2017 roku muzułmanami było 87,2% populacji tego kraju, około 209 mln osób. Tuż po niej na liście plasują się kraje spoza świata arabskiego: Pakistan i Indie. Rozprzestrzenienie się Arabów i ich kultury na inne kraje nastąpiło podczas ich migracji do Azji Południowo-Zachodniej, trwającej od VI do XVI wieku n.e.
Kraje arabskie mają własną organizację o nazwie Liga Państw Arabskich. Państwami założycielskimi były: Egipt, Syria, Liban, Irak, Jordania (wówczas, w 1943, jeszcze Transjordania), Arabia Saudyjska oraz Jemen. Kraje arabskie w 2015 zamieszkiwało około 387,6 mln ludzi. Krajem o największej liczbie ludności był wówczas Egipt (91,5 mln – blisko 23,6% ludności całego regionu). Wskaźnik rozwoju społecznego w krajach arabskich w 2015 wynosił średnio 0,687. Znaczące w tym regionie są nierówności płciowe – ich wskaźnik (GII) w 2015 wynosił według Programu Narodów Zjednoczonych ds. Rozwoju 0,535; wyższy wynik osiągnęły jedynie państwa Czarnej Afryki.
Do krajów arabskich nie wlicza się także tych, w których Arabowie stanowią po prostu dużą mniejszość etniczną (np. Iran, Turcja) lub których kultury i dzieje kształtowali, lecz obecnie nie odgrywają w nich większej roli, jak również do krajów arabskich nie jest zaliczana Malta, choć język maltański wyrósł z języka arabskiego. Wlicza się do nich natomiast niekiedy kraje niezamieszkane w większości przez etnicznych Arabów, w których jednak wpływy arabskiej kultury są silne i które wykazują dążenia do integracji ze światem arabskim (np. Dżibuti, Komory, Somalia – również członkowie Ligi Państw Arabskich).
Kraje arabskie są niezwykle zróżnicowane pod względem kulturowym. Na Listę światowego dziedzictwa UNESCO wpisane są (2018) 82 obiekty, z tego 74 kulturalne – od powstałych w czasach antycznych po współczesne (Rabat).
Lista krajów arabskich.
UNESCO uznaje przynależność następujących państw i terytoriów do krajów arabskich:

</doc>
<doc id="13093" url="https://pl.wikipedia.org/wiki?curid=13093" title="Attis">
Attis

Attis (także Attys, Atys, ) – starożytne bóstwo wegetacji, mityczny towarzysz i kochanek bogini Kybele przedstawiany w postaci młodego pasterza.
W mitologii.
W wierzeniach starożytnych był synem nimfy Nany, która urodziła go po spożyciu owoców migdałowca. Pauzaniasz w swym dziele przytacza opartą na podaniach frygijskich, znacznie poszerzoną wersję mitologiczną, według której faktycznym rodzicem Attisa miał być dwupłciowy demon (hermafrodyta) Agdistis; obawiający się go bogowie podstępem we śnie pozbawili męskich genitaliów – w miejscu, gdzie upadły, wyrósł migdałowiec, którego owoc spożyła przypadkiem Nana, córka boga rzeki Sangarios (łac. Sangarius). Urodziła dziecko, które porzuciła i którym zaopiekował się kozioł, a później zajęli się przybrani rodzice. Kiedy Attis dorósł, jego boska uroda zwróciła uwagę Agdistisa, który jako Kybele zakochał się w pięknowłosym młodzieńcu. Wówczas jego przybrani rodzice wysłali go do pobliskiego Pesynuntu, gdzie poślubić miał córkę króla (według niektórych podań był nim Midas). W momencie gdy zabrzmiała pieśń godowa, niespodzianie pojawiła się Kybele-Agdistis i zesłała na oblubieńca obłęd, wskutek czego Attis pozbawił się męskości pod drzewem sosny. Z krwi jego wyrosły kwiaty (inna wersja mówi o zamienieniu się w drzewo figowe), lecz bogini ubłagała Zeusa, by ciało Attysa nigdy nie ulegało rozkładowi, później zaś wskrzesiła go, ażeby odtąd jako jej małżonek (lub kochanek) stał się symbolem wiecznie odradzającej się przyrody.
Ten prawdopodobnie pierwotny mit został w okresie rozwiniętego już kultu w świecie grecko-rzymskim zastąpiony złagodzoną i uszlachetnioną wersją, zgodnie z którą Kybele zakochała się w pięknym pasterzu, wybierając go na swego kapłana i wymuszając na nim śluby czystości. Kiedy jednak jej wybrany zakochał się w nimfie rzecznej, dotknęła go szaleństwem i wówczas dokonał samookaleczenia (kastracji). Odzyskawszy świadomość zapragnął popełnić samobójstwo, ale litościwa bogini zamieniła go w sosnę (lub jodłę).
Po opanowaniu Frygii przez Lidów na rodzimą warstwę mitologiczną nałożył się dodatkowo kontekst lidyjski, znany z przekazu Arnobiusza z Sikki. Wedle niego Attys jako syn frygijskiego króla Kalaosa, sam będąc eunuchem wprowadził kult Kybele w Lidii i nauczył jej mieszkańców orgiastycznych obrzędów, co zjednało mu szczególne łaski bogini. Wzbudziło to zazdrość i gniew Zeusa, który zesłał dzika niszczącego zasiewy – w końcu uśmiercił on wielu Lidów wraz z Attysem, z którego krwi zrodziły się fiołki. Herodot zaś przytacza już zhistoryzowaną wersję tego mitu, która czyni z Attysa syna lidyjskiego Krezusa, zabitego przypadkowo przez Adrasta podczas polowania na dzika.
Pochodzenie.
Nazwę bóstwa wywodzi się z frygijskiego "attis" (piękny młodzieniec, piękniś) bądź też od słowa "attagus" (kozioł). Podobnie jak Wielka Macierz Bogów Kybele, Attis przypuszczalnie był miejscowym bóstwem małoazjatyckim, przejętym przez najeźdźczych Frygów z nadaniem mu własnych cech mitologicznych. Za pierwotne miejsce jego kultu uznaje się górę Dindymon, skąd oddziaływał on na leżące pod jej osłoną duże frygijskie miasto handlowe Pesynunt (Pessinus, Pessinunte) – według świadectwa Strabona znane dobrze z kultu Kybele. Również samą górę, nazywaną też Agdistis i uważaną za swoiste uosobienie, w starożytności utożsamiano z istotą demoniczną kojarzoną właśnie z Wielką Macierzą.
W szerszym kontekście religioznawczym mit o Attisie i Kybele należy do najstarszych i najbardziej rozpowszechnionych na Bliskim Wschodzie, wykazując bezsprzeczne podobieństwa z tamtejszymi mitami o Tammuzie i Isztar, Dumuzi i Inanie, Adonisie i Afrodycie, a nawet o hetyckim Telepinu. Bogowie umierający i cudownie powracający do życia związani byli w tamtejszych kulturach z wegetacją, płodnością i żniwami. Wiara w coroczny powrót sił przemagających śmierć i moce ciemności dawała ufność co do urodzajności kolejnego roku, a świeże pędy roślin kojarzono z wieczną młodością bóstwa wynurzającego się ze świata podziemnego. Okazując mu cześć wyznawcy wyrażali też potrzebę upewnienia się, iż po letniej suszy niszczącej urodzaj, zapewnią sobie plony w kolejnej porze zbiorów. Ponadto mity te łudziły wyznawców obietnicą szczęśliwego życia pozagrobowego, wymownie ukazując możliwość odniesienia zwycięstwa nad śmiercią i dając nadzieję na trwanie rodzaju ludzkiego w przyszłych pokoleniach.
Kult.
Początki czci oddawanej Attisowi w rejonie góry Dindymon stwierdzono już ok. 1250 r. p.n.e. Poprzez Lidię (a przede wszystkim przez Pergamon w Myzji) kult przeniknął w VII wieku p.n.e. do greckich kolonii w Azji Mniejszej, a stamtąd dalej na zachód. W IV wieku p.n.e. był już utrwalony w świecie greckim, szczególnie zaś popularny w Macedonii. Pod koniec III w. p.n.e. dotarł do Rzymu, gdzie z porady ksiąg Sybillińskich wkrótce został oficjalnie przyjęty. W początkach cesarstwa korzystał z protekcji panujących, zwłaszcza Kaliguli i Klaudiusza. Różnorodne znaleziska z Herkulanum pozwalają przypuszczać, iż kult bóstwa cieszył się tam znaczną popularnością już podczas katastrofalnego wybuchu Wezuwiusza w 79 roku. W II stuleciu n.e. Attis był w cesarstwie ogólnie uznanym bóstwem solarnym, którego święto zawsze połączone było ze świętem bogini.
Znacznie silniejsze podstawy niż w kojarzeniu z Mitrą miało łączenie Attysa z innym frygijskim bóstwem – lunarnym Menem, również mającym wpływ na wegetację. Potwierdzałaby to nie tylko inskrypcja z Ostii, nazywająca go "Attis Menotyrannus", lecz i neofrygijskie napisy nagrobne mówiące o obecności Attysa w świecie podziemnym w roli pana i sędziego – przypisywanej też Menowi. Na gruncie małoazjatyckim religioznawcy dopatrują się także powiązań Attysa z czczonym w Tarsie cylicyjskim Sandanem.
Święta.
Każdej wiosny obchodzono sześciodniowe uroczystości ku czci bóstwa, uosabiającego płody ziemi, które giną z nastaniem zimy i odradzają się wiosną. Wystawiano wówczas dramat śmierci i wskrzeszenia Attisa. W obchodach tych, oprócz tłumów wiernych, uczestniczyli kapłani bóstwa – gallowie, oraz towarzyszący im dendroforowie i korybanci. 
W sto lat po dekretach Klaudiusza dotyczących tych obchodów kult uświetniono dodatkowym obrzędem, zwanym "taurobolium", symbolizującym oczyszczenie z grzechów poprzez skrapianie krwią zabitego byka (podobnie jak w kulcie Mitry).
Ikonografia.
W sztuce przedstawiano go na ogół jako młodzieńca w charakterystycznej czapce frygijskiej i spodniach albo w perskich nogawicach zwanych "anaxyrides", otwartych z przodu tak, by odsłaniały jego okaleczenie. Rzymianie często wyobrażali go jako pasterza, z laską w ręku, czasem niosącego na ramionach jagnię, niekiedy grającego na fujarce lub syrindze, nierzadko z bębenkiem (tympanon). Wystające spod czapki promienie słoneczne (względnie kłosy zboża) symbolizowały go jako bóstwo wiosennej wegetacji i odradzającego się życia. Spośród atrybutów zwierzęcych zazwyczaj towarzyszył mu kogut ("gallus") albo lew typowy dla kultu Kybele jako zwierzę ciągnące jej rydwan.
W sztuce rzymskiej nierzadkie są wyobrażenia Attisa swobodnie stojącego (bądź opartego o kolumnę) z założonymi rękami i skrzyżowanymi nogami. Przedstawienie takie, pochodzące z połowy II w. n.e., znajduje się również w zbiorach warszawskiego Muzeum Narodowego (nr inw. MNW 199337). W rzymskiej sztuce prowincjonalnej (Germania, Galia) jego wyobrażenia przybierały niekiedy formy groteskowe.
W twórczości epok.
Temat tragedii i ofiary bóstwa obficie wykorzystywano literacko już w epoce antyku. Katullus wśród swych pieśni poświęcił mu osobny epyllion zatytułowany "Attis" (Pieśń LXIII). Do postaci tej sięgali również inni autorzy, np. Owidiusz w "Kalendarzu" ("Fasti" IV, 221-246) i w "Przemianach" (X, 103), czy później Nonnos z Panopolis w obszernym eposie "Dionysiaca" ("Historia Dionizosa" XXV, 311 nn.) oraz – w ujęciu filozoficznym – cesarz Julian Apostata. W weneckim Pałacu Dożów znajduje się sarkofag z Attisem i Kybele dekorowany znaną płaskorzeźbą. W sztuce XV-wiecznej uwiecznił go Donatello rzeźbą w brązie, wyobrażając uskrzydlonego, w dwojakiej postaci jako Amora-Attisa.

</doc>
<doc id="13094" url="https://pl.wikipedia.org/wiki?curid=13094" title="Kureci">
Kureci

Kureci (gr. "kourē̂tes", l. poj. "kourḗtē", łac. "curetes", l. poj. "curete") – w mitologii greckiej bóstwa opiekuńcze, później także kapłani kultu. 
Dziewięciu kapłanów Rei chroniących na Krecie Zeusa przed jego ojcem Kronosem, by nie dowiedział się o miejscu ukrycia nowo narodzonego. Swymi hałaśliwymi tańcami, m.in. uderzając włóczniami o tarcze, zagłuszali płacz niemowlęcia. W późniejszym czasie nazywano tak również kapłanów kultu, utożsamianych z frygijskimi korybantami lub daktylami.

</doc>
<doc id="13095" url="https://pl.wikipedia.org/wiki?curid=13095" title="Menady">
Menady

Menady (także bakchantki, bachantki, gr. "Mainádes" ‘szalejące’, gr. "Bákchai", łac. "Maenades", "Bacchae") – 1. w mitologii greckiej towarzyszki Dionizosa; 2. czcicielki Dionizosa (Bachusa).
Wedle mitu menady zabiły Orfeusza, który, pogrążony w rozpaczy po utracie Eurydyki, odmówił wzięcia udziału w Bachanaliach. 
Nazwa "bachantki" wiąże się z imieniem Bachus (bądź Bakchos – stąd bakchantki), którym również określano boga – Dionizosa.
Trackie bachantki, które odziane w skóry jeleni, wymachując owiniętymi winną latoroślą tyrsami i śpiewając dzikie, szalone pieśni, tworzyły orszak Dionizosa, podczas jego podróży z Lidii, przez cały antyczny świat do Grecji.
W Atenach uważano Traków za barbarzyńców, których cechowało zachowanie gwałtowne i nieopanowane. Rytualne misteria dionizyjskie (Dionizje) stwarzały okazję bachantkom do podobnie nieprzyzwoitego zachowania, krzyków i dzikich tańców graniczących z wyuzdaniem.

</doc>
<doc id="13098" url="https://pl.wikipedia.org/wiki?curid=13098" title="Amin (imię)">
Amin (imię)

Amin — imię męskie pochodzenia arabskiego. Oznacza „godny zaufania” lub „prawdomówny”. Nosił je szósty kalif abbasydzki.
Amin imieniny obchodzi 2 czerwca.
Znane osoby noszące imię Amin:

</doc>
<doc id="13099" url="https://pl.wikipedia.org/wiki?curid=13099" title="Amon (imię)">
Amon (imię)

Amon – imię męskie pochodzenia egipskiego. Wywodzi się od greckiej wersji imienia egipskiego boga "Amona". Oznacza: „ożywiający powiew”. Znanych jest około dziesięciu świętych katolickich o tym imieniu.
Amon imieniny obchodzi , 20 grudnia.
Odpowiedniki w innych językach:
Zobacz też:

</doc>
<doc id="13102" url="https://pl.wikipedia.org/wiki?curid=13102" title="Amos">
Amos

Amos — imię męskie pochodzenia biblijnego. Wywodzi się od hebr. עמוס "amos" — „mocny, dźwigający ciężary”. Patronem tego imienia jest Amos, jeden z dwunastu proroków mniejszych, którego imieniem nazwana jest jedna z ksiąg biblijnych — Księga Amosa. Obchodzi imieniny 31 marca.
Amos w innych językach:
Znane osoby noszące to imię:

</doc>
<doc id="13103" url="https://pl.wikipedia.org/wiki?curid=13103" title="Ananiasz">
Ananiasz

Ananiasz – imię męskie pochodzenia biblijnego. Grecka forma hebrajskiego "Hananiah" – „Jahwe jest łaskawy”. Jednym z patronów tego imienia jest św. Ananiasz z Damaszku.
Ananiasz imieniny obchodzi 25 stycznia, 1 grudnia i 16 grudnia.
Ananiasz w innych językach: 

</doc>
<doc id="13104" url="https://pl.wikipedia.org/wiki?curid=13104" title="Baszta">
Baszta

Baszta – budowla obronna, stanowiąca element starożytnego i średniowiecznego muru obronnego w postaci wysunięcia jego fragmentu przed lico i wzniesienia ponad jego poziom. Baszta może być w stosunku do wnętrza obwodu obronnego zamknięta, dostępna z chodnika straży, otwarta częściowo (arkadą) lub całkowicie jako wykusz.
Janusz Bogdanowski w swoich książkach jako element odróżniający basztę od wieży podkreśla zmianę sposobu obrony: odejście od biernej roli murów na rzecz obrony skrzydłowej wobec rozwoju broni palnej. Stąd baszty wysuwają się przed narys murów i opatrzone zostają przez możliwie dużą liczbę strzelnic zamiast gładkich ścian średniowiecznej wieży.
Baszty były budowane na planie koła, prostokąta lub wielokąta. Stanowiły miejsce, skąd możliwa była obrona odcinków muru między nimi. Wznoszono je początkowo z drewna, a następnie z kamienia i cegły. Zazwyczaj były zwieńczone blankami z hurdycjami lub machikułami.
Wnętrze baszty podzielone było na kilka kondygnacji, połączonych ze sobą schodami lub drabinami. Na poszczególnych kondygnacjach umieszczano otwory strzelnicze. Najniższa, podziemna kondygnacja była zazwyczaj przeznaczona na więzienie.
Baszty jako element obronny straciły rolę po wynalezieniu broni palnej i zostały zastąpione bastejami i bastionami.
Najwyższymi basztami w Polsce są: mierząca 34 m Baszta Morze Czerwone w Stargardzie i podobnej wysokości Baszta Jacek w Gdańsku oraz Brama Floriańska w Krakowie.
Określenie "baszta" odnosi się także do:

</doc>
<doc id="13106" url="https://pl.wikipedia.org/wiki?curid=13106" title="Bakchantki">
Bakchantki



</doc>
<doc id="13109" url="https://pl.wikipedia.org/wiki?curid=13109" title="Teoria (logika)">
Teoria (logika)

Teoria – niesprzeczny zbiór zdań. 
Definicja formalna.
Niech T będzie zbiorem zdań zapisanych w pewnym języku L. Wtedy T jest teorią, jeśli nie istnieje zdanie napisane w języku L takie że T dowodzi zarówno tego zdania, jak i jego zaprzeczenia. Zbiór zdań T dowodzi zdania X, jeśli można przeprowadzić formalny dowód zdania X przy użyciu zdań ze zbioru T oraz aksjomatów i reguł dowodzenia klasycznego rachunku logicznego.
Czasami w definicji teorii dodatkowo zakłada się, że jest ona zamknięta ze względu na operację brania konsekwencji logicznej. Oznacza to, że jeśli teoria T dowodzi jakiegoś zdania X, to zdanie X musi należeć do T.
Własności.
Twierdzenie o zwartości mówi, że zbiór zdań jest niesprzeczny, jeśli każdy jego skończony fragment jest niesprzeczny. W świetle powyższej definicji niesprzeczności wydaje się to oczywiste, bo jeśli z danego zbioru zdań możemy udowodnić zarówno jakieś zdanie, jak i jego zaprzeczenie, to możemy też przeprowadzić ten sam dowód korzystając tylko ze skończenie wielu zdań z tego zbioru. Jeśli jednak badamy to zagadnienie z punktu widzenia semantyki, a nie syntaktyki, to potrzebujemy twierdzenia o istnieniu modelu, które w 1931 roku udowodnił austriacki logik i matematyk Kurt Gödel. Mówi ono, że każda spójna teoria (tzn. taka w której nie istnieje dowód sprzeczności) ma model i umożliwia badanie własności dowolnej teorii przy użyciu metod teorii modeli.
Teoria T w języku L jest zupełna, jeśli dla każdego zdania X napisanego w języku L w teorii T można dowieść zdania X lub jego zaprzeczenia (tj.: suma domknięcia T ze względu na wyprowadzanie oraz jego negacji jest równa zbiorowi wszystkich zdań w L). Przy użyciu zakładanego zwykle przez matematyków aksjomatu wyboru można wykazać, że każdą teorię w jakimś języku L można rozszerzyć do teorii zupełnej w tym języku.
Teoria T w języku L jest rozstrzygalna, jeśli istnieje algorytm, który dla każdego zdania X napisanego w języku L rozstrzyga, czy T dowodzi X.
Teoria T jest kategoryczna, jeśli T ma dokładnie jeden model z dokładnością do izomorfizmu. Jest to raczej rzadkie zjawisko, bo kategoryczne są tylko te teorie, które są zupełne i mają model skończony. Dlatego osłabia się tę definicję i mówi, że teoria T jest kategoryczna w mocy m, jeśli T ma dokładnie jeden model mocy m z dokładnością do izomorfizmu.

</doc>
<doc id="13110" url="https://pl.wikipedia.org/wiki?curid=13110" title="Andronik">
Andronik

Andronik — imię męskie pochodzenia greckiego. Pochodzi od starogreckiego imienia "Andronikos" wywodzącego się od słów "andros" (człowiek) i "nike" (zwycięstwo), które w złożeniu znaczą „zwycięzca”.
Andronik imieniny obchodzi 30 maja i 11 października.
Andronik w innych językach:
Osoby o tym imieniu:

</doc>
<doc id="13111" url="https://pl.wikipedia.org/wiki?curid=13111" title="Andromeda">
Andromeda



</doc>
<doc id="13112" url="https://pl.wikipedia.org/wiki?curid=13112" title="Krążownik pomocniczy">
Krążownik pomocniczy

Krążownik pomocniczy (, ) – historyczna klasa okrętów powstałych przez przebudowę i uzbrojenie dużych lub średnich statków cywilnych, używana głównie w okresie I i II wojny światowej.
Krążowniki pomocnicze powstawały poprzez przebudowanie i uzbrojenie większych statków pasażerskich, a nawet towarowych, o mocniejszych kadłubach. Tak powstałe okręty były często używane jako tzw. rajdery, czyli okręty używane do działania na liniach komunikacyjnych nieprzyjaciela i zwalczania jego żeglugi. Dominującym przeznaczeniem była jednak patrolowanie i ochrona własnych konwojów i linii komunikacyjnych przed wrogimi rajderami, gdy nie było wystarczającej liczby okrętów eskortowych lub krążowników. Wykorzystanie krążowników pomocniczych zależało od specyfiki doktryny wojny morskiej danego państwa: Wielka Brytania, używająca największej liczby krążowników pomocniczych, wykorzystywała je do patrolowania i ochrony własnych rozległych linii żeglugowych, natomiast Niemcy używały ich podczas obu wojen światowych do zwalczania żeglugi. Na krążowniki pomocnicze przebudowywano głównie statki pasażerskie (brytyjskie oraz sześć niemieckich podczas I wojny światowej), rzadziej towarowe (niemieckie podczas obu wojen światowych).
Charakterystyka.
Mimo nazwy krążowniki pomocnicze nie zaliczały się do klasy krążowników i nie miały z nimi nic wspólnego, z wyjątkiem wielkości, uzbrojenia (porównywalnego z mniejszymi krążownikami lekkimi) i dużego zasięgu pływania. Zostały tak nazwane z uwagi na wypełnianie tradycyjnie rozumianych zadań „krążowniczych” w postaci odbywania dalekich rejsów patrolowych, w celu ochrony lub zwalczania komunikacji morskiej. Nie były one opancerzone, a z uwagi na użycie do ich przebudowy statków cywilnych, charakteryzowały się znacznie mniejszą odpornością na uszkodzenia, zwłaszcza wybuchy podwodne i pożary, od specjalnie budowanych okrętów. Stosowano jedynie doraźne ulepszenia zwiększające niezatapialność, typu wypełnienia ładowni pustymi beczkami lub korkiem.
Podstawowymi parametrami charakteryzującymi siłę bojową krążowników pomocniczych były: wielkość, prędkość, zasięg rozumiany szerzej jako autonomiczność i uzbrojenie, a w wielu przypadkach także maskowanie.
Trudno mówić o średnich wartościach czy przeciętnej wielkości, były to bez wyjątku okręty przystosowane "ad hoc" i od tego, jakiej wielkości był statek bazowy, zależała wyporność powstałego z niego krążownika pomocniczego. Można natomiast mówić o pewnych pułapach wielkości. Okręty te, jako przebudowywane ze statków, miały wyporność od 3000 ton do nawet 19 000 ton (np. niemiecki „Kormoran”). Często do opisu wielkości krążowników pomocniczych zamiast wyporności używa się parametrów stosowanych wobec bazowych jednostek cywilnych, jak nośność statku lub pojemność brutto (BRT).
Prędkość nie była zasadniczym atutem tej klasy; przebudowywane ze statków nie przechodziły remontów czy udoskonaleń w maszynowniach i prędkość pozostawała taka sama jak poprzednio, rzadko kiedy przekraczała 20-25 węzłów, zwykle było to ok. 15-17 w. W zasadzie wystarczała, żeby zatopić z zaskoczenia statek handlowy lub ewentualnie przez krótki okres ścigać go.
Zasięg był jednym z parametrów, który był ważny ze względu na specyfikę działań. Rajdery musiały krążyć po morzach aby natrafić na swoją „ofiarę”, przy tym możliwości ich zawijania do portów były ograniczone. Duży zasięg, wynoszący nierzadko 15000 mil morskich, okazywał się często zbyt mały, w związku z czym zachodziła potrzeba wysyłania okrętów zaopatrzeniowych mających zaopatrywać je nie tylko w paliwo, ale i we wszelkie środki do życia dla załogi i amunicję. Statki te odbierały także wzięte do niewoli załogi zatopionych przez krążowniki statków.
Z zasięgiem powiązany jest jeszcze inny parametr mający duży wpływ na siłę bojową krążowników pomocniczych, a mianowicie autonomiczność, czyli zdolność do długotrwałego działania bez uzupełniania zapasów. Ten parametr był wysoki, liczba dni, jakie te okręty potrafiły spędzać bez uzupełniania zapasów, była bardzo duża, nawet jak na standardy przyjęte dla „regularnych” okrętów. Najdłuższe rejsy bojowe niemieckich rajderów, przy uzupełnianiu zaopatrzenia na morzu, trwały ponad 16 miesięcy. Oprócz załogi, korsarskie okręty tej klasy musiały jeszcze pomieścić jeńców z zatopionych statków. Z kolei krążowniki pomocnicze przebudowane ze statków pasażerskich często służyły także jako transportowce wojska.
Uzbrojenie montowano różne: najczęściej stosowano kilka pojedynczych dział kalibru 120–150 mm, wspomagane dodatkowymi np. 76 mm i ewentualną lekką artylerią przeciwlotniczą. Część okrętów, zwłaszcza te przeznaczone do zwalczania wrogiej żeglugi, miała wyrzutnie torpedowe i miny, a nawet przenosiła małe kutry torpedowe. Niektóre wyposażone były też w wodnosamoloty rozpoznawcze. Przykładem może być niemiecki „Kormoran” mający 6 dział kalibru 150 mm, kilka działek przeciwlotniczych, 6 wyrzutni torpedowych kalibru 533 mm, dwa wodnosamoloty i kuter torpedowy.
Ostatnim elementem mającym wpływ na siłę bojową tej klasy okrętów jest maskowanie, jednak miało ono znaczenie jedynie w przypadku okrętów korsarskich. Na maskowanie może składać się wiele elementów: niemieckie krążowniki pomocnicze miały wiele elementów ruchomych pozwalających się składać lub rozwijać, w zależności od potrzeb; ruchome sztuczne kominy oraz odkrywane na czas strzelania i niewidoczne normalnie działa. Maskowanie obejmowało podawania fałszywej nazwy okrętu oraz kraju pochodzenia. Należy jednak zdawać sobie sprawę, że użycie takie maskowania podczas walki, zwłaszcza cudzej bandery, mogło być sprzeczne z prawem wojennym.
Warto wspomnieć, że podobne do zamaskowanych krążowników pomocniczych, lecz mniejsze i o innym przeznaczeniu, były statki-pułapki z I wojny św., służące do walki z okrętami podwodnymi.
Oprócz krążowników pomocniczych i statków-pułapek, mniejsze uzbrojone statki handlowe były także używane jako pomocnicze patrolowce. Marynarka brytyjska podczas II wojny światowej używała także 8 pomocniczych krążowników przeciwlotniczych, służących do ochrony konwojów przed lotnictwem.
Historia.
Jednymi z pierwszych okrętów, odpowiadającymi charakterystyką i zastosowaniem krążownikom pomocniczym, były okręty przebudowane ze statków handlowych, używane podczas wojny secesyjnej w Ameryce Północnej (1861-1865) przez konfederatów do zwalczania żeglugi Unii. Mimo że były one określane w języku angielskim wprost jako krążowniki ("cruiser"), niemniej w tym okresie klasa krążowników jeszcze nie istniała i oznaczało to jedynie ich rolę. Z uwagi na przystosowanie jednostek cywilnych, konfederackie krążowniki można uznać za protoplastów krążowników pomocniczych. W tym okresie jednak różnice konstrukcyjne między statkami a okrętami nie były jeszcze znaczne. Najbardziej znanymi z nich były CSS „Sumter” i CSS „Alabama”, o napędzie żaglowo-parowym, uzbrojone odpowiednio w 5 i 8 dział.
Krążowniki pomocnicze były następnie używane przez Rosję podczas wojny rosyjsko-japońskiej (1904-1905), lecz bez większych efektów.
I wojna światowa.
Duże zaangażowanie krążowników pomocniczych miało miejsce podczas I wojny światowej. Niemcy używali wówczas do działań rajderskich 16 okrętów tego typu, rozmaitych rozmiarów i typu, od małego transportowca „Meteor” (wyporność 3640 t) do transatlantyków „Kaiser Wilhelm der Große” i „Kronprinz Wilhelm” (24 300 t), włącznie z żaglowcem „Seeadler”. Łącznie sześć było przebudowanych ze statków pasażerskich, a pozostałe z innych handlowych. Jedynie kilka z nich odniosło większe sukcesy. Największym było zatopienie na minie postawionej przez krążownik pomocniczy „Berlin” brytyjskiego pancernika HMS „Audacious”. Wielka Brytania z kolei używała krążowników pomocniczych do ochrony własnych linii żeglugowych. Ciekawszymi epizodami była m.in. bitwa pod Trindade zakończona zatopieniem niemieckiego krążownika pomocniczego „Cap Trafalgar” przez brytyjski „Carmania” 14 września 1914 oraz walka między niemieckim krążownikiem pomocniczym „Greif” i brytyjskim 29 lutego 1916, zakończona zatopieniem obu okrętów.
Podczas I wojny światowej Wielka Brytania używała 62 krążowników pomocniczych, z których utracono 20 (w tym 12 zatopionych przez okręty podwodne, 1 zatopiony i 1 zdobyty przez niemiecki krążownik pomocniczy).
II wojna światowa.
Najbardziej znane użycie krążowników pomocniczych miało miejsce podczas II wojny światowej. Niemcy użyli wówczas jako rajdery 11 krążowników pomocniczych przebudowanych ze statków handlowych, a Brytyjczycy używali licznych okrętów tego typu (zazwyczaj przebudowanych ze statków pasażerskich) do patrolowania i ochrony konwojów. Z reguły krążowniki pomocnicze nie miały szans w starciu z dużymi okrętami nawodnymi; ewenementem było starcie niemieckiego rajdera „Kormoran” z lekkim krążownikiem , który zatopił atakiem z zaskoczenia z małej odległości, sam jednak również tonąc. Niemieckie krążowniki pomocnicze nie nosiły bandery i udawały statki handlowe krajów neutralnych.
Brytyjski krążownik pomocniczy , uzbrojony w 5 dział kalibru 152 mm, był w stanie przez pewien czas odciągać niemiecki pancernik kieszonkowy „Admiral Scheer” od ochranianego konwoju, angażując go w walce. Brytyjski okręt został zatopiony, lecz dzięki jego poświęceniu, znikoma część statków konwoju została zatopiona. Szczególnie ciekawa była służba niemieckiego rajdera „Thor”, który aż trzykrotnie walczył z brytyjskimi krążownikami pomocniczymi, z czego dwa pojedynki zostały zakończone uszkodzeniem okrętów brytyjskich, a trzeci zatopieniem HMS „Voltaire”. O wrażliwości krążowników pomocniczych na uszkodzenia, podobnej jak zwykłych statków, świadczy jednak fakt, że niemiecki krążownik pomocniczy „Stier” został zatopiony w pojedynku ze słabo uzbrojonym frachtowcem SS „Stephen Hopkins”, który również zatonął.
Podczas II wojny światowej państwa Brytyjskiej Wspólnoty Narodów używały 56 krążowników pomocniczych, w tym Wielka Brytania – 49. Utracono 14 z nich (dalsze 4 po przebudowie na transportowce wojska), z tego 10 zatopiły okręty podwodne.
Krążowników pomocniczych używały też inne państwa, przede wszystkim Japonia, Włochy i Francja, lecz na mniejszą skalę. Japońskie próby wykorzystywania krążowników pomocniczych do działań rajderskich zakończyły się po starciu okrętów „Aikoku Maru” i „Hokoku Maru” z indyjską korwetą HMIS „Bengal” i zbiornikowcem MV „Ondina” 11 listopada 1942 roku, którego efektem było zatopienie „Hokoku Maru” po trafieniu w jego wyrzutnię torped. Znanym epizodem było też zatopienie włoskiego rajdera „Ramb I” przez krążownik HMNZS „Leander” 27 lutego 1941 roku.

</doc>
<doc id="13113" url="https://pl.wikipedia.org/wiki?curid=13113" title="Rajder">
Rajder

Rajder – określenie okrętów używanych w trakcie wojny jako korsarskie, do zwalczania i dezorganizowania żeglugi nieprzyjaciela na jego liniach komunikacyjnych (działania rajderskie lub krążownicze). Nie można w tym wypadku mówić o jakiejś klasie okrętów. Słowo „rajder” określa przeznaczenie okrętu w danej chwili i nie determinuje żadnego z parametrów bojowych okrętu.
Rajdery znane były od dawnych czasów, lecz nazwa ta zaczęła być używana w okresie I wojny światowej, gdy cesarska flota niemiecka (Kaiserliche Marine) wystawiła do służby okręty nawodne mające za zadanie zwalczanie brytyjskiej żeglugi (z niem. "Raider").
Koncepcja wojny rajderskiej została opracowana pod koniec XIX wieku przez francuską „młodą szkołę”, jako środek do wyrównania przewagi floty brytyjskiej w ewentualnej wojnie. Zamiast stawiać czoła silnej flocie brytyjskiej w walnej bitwie, koncepcja ta zakładała odcięcie Imperium Brytyjskiego od zaopatrzenia w surowce oraz przecięcie jego szlaków komunikacyjnych z koloniami przez okręty – rajdery. W tym celu też opracowano koncepcję krążownika pancernego, jako szybkiego okrętu o dużym zasięgu, służącego do takich działań.
Intensywnie rajdery zaczęły być używane podczas wojny rosyjsko-japońskiej 1904, w czasie której władywostocki zespół krążowników prowadził działania przeciw żegludze japońskiej na Morzu Japońskim (bitwa pod Ulsan).
W okresie I wojny światowej działania rajderskie prowadzili Niemcy. Do zwalczania żeglugi używali okrętów klasycznych oraz krążowników pomocniczych, czyli kilkunastu odpowiednio przebudowanych statków pasażerskich lub statków handlowych, które uzbrojono i dano im odpowiednie maskowanie. Miały za zadanie uzupełniać U-booty w ich działaniach, nie odniosły jednak wielkich sukcesów. Nietypowym, lecz skutecznym rajderem był żaglowiec SMS Seeadler, który w czasie jedynego rejsu zatopił 14 statków.
Najbardziej znane rajdery I wojny spośród okrętów wojennych to krążowniki lekkie: , który w ciągu swojej niedługiej kariery na Oceanie Indyjskim zatopił lub zdobył 23 statki, a zatopiony został 9 listopada 1914 przez krążownik HMAS Sydney, oraz krążownik SMS „Dresden”.
Największy rozmach w działaniach rajderów przypada na okres II wojny światowej. Kriegsmarine, za pomysłem wielkiego admirała Ericha Raedera, wystawiła do działań korsarskich nie tylko kilkanaście krążowników pomocniczych, ale i klasyczne duże okręty. Jako rajdery Niemcy wykorzystali pancerniki kieszonkowe – przykładem jest rajd „Admirala Grafa Spee” na Oceanie Atlantyckim, zakończony jego samozatopieniem po bitwie u ujścia La Platy z angielskimi krążownikami. Były też rajdy bardziej udane, jak rajd pancernika kieszonkowego „Admiral Scheer”, czy zespołu pancerników „Scharnhorst” i „Gneisenau”.
Najbardziej znanym jest jednak nieudany wypad niemieckiego pancernika „Bismarck”, zakończony jego zatopieniem przez ścigające go okręty brytyjskie.

</doc>
<doc id="13114" url="https://pl.wikipedia.org/wiki?curid=13114" title="Kamikaze">
Kamikaze

 – specjalne japońskie oddziały wojskowe okresu II wojny światowej, należące do armii (w tym do jednostek lotniczych) i marynarki japońskiej. 
Żołnierze kamikaze poświęcali swoje życie w ataku na nieprzyjaciela, pilotując specjalnie przystosowane do tego celu samoloty lub jednostki wodne. Ataki kamikaze określane są czasami jako „ataki samobójcze”, choć samobójcza śmierć nie była celem samym w sobie. Celem kamikaze było zadanie jak największych strat nieprzyjacielowi; śmierć atakującego stawała się konsekwencją takiego ataku, a nie jego podstawowym założeniem.
Etymologia nazwy.
Nazwa 神風 ("kamikaze", "kamukaze", w sinojapońskim czytaniu "shinpū"), czyli „boski wiatr” ("kami" – bóg, boski, "kaze" – wiatr), odnosi się do tajfunów, które dwukrotnie – w latach 1274 i 1281 – zniszczyły inwazyjne floty mongolskie, atakujące Japonię. Japończycy uznali to za dowód opieki bogów ("kami") i nazwali tajfun „Boskim Wiatrem”.
Pełna, oficjalna nazwa jednostek specjalnych brzmiała: Shinpū Tokubetsu Kōgekitai () – w wolnym tłumaczeniu: Specjalny Korpus Uderzeniowy Boski Wiatr lub Oddziały Boskiego Wiatru do Ataków Specjalnych. Japońskie znaki w słowie "shinpū" mogą być także czytane jako "kamikaze". Związane to jest z różnicami w czytaniu japońskim i sinojapońskim chińskich ideogramów. Sami żołnierze jednostek specjalnych, jak i inni żołnierze należący do armii i marynarki japońskiej, zazwyczaj skracali nazwę do Shinpū-tokkōtai (神風特攻隊) lub Tokkōtai.
Przyczyny powstania jednostki.
Przyczyną zastosowania tak radykalnej metody ataku były coraz większe straty zadawane lotnictwu japońskiemu przez Amerykanów. Po pierwszej bitwie na Morzu Filipińskim, stoczonej przez floty obu krajów w dniach 19–20 czerwca 1944 roku, Japończycy ponieśli bardzo duże straty. Nie zatopili żadnego z okrętów amerykańskich, a sami stracili trzy lotniskowce – Shōkaku, Taihō i Hiyō. Straty w samolotach były ogromne i dużo większe od amerykańskich, wyniosły ponad 400 maszyn wobec nieco ponad setki amerykańskich. Walkę tę nazwano „strzelaniem do indyków nad Marianami”. Po tym wydarzeniu, w dniu 20 lipca, komandor Ei’ichirō Jō (dawna transkrypcja nazwiska spotykana w literaturze to: Eiychiro Jyo lub Eiichiro Jyo) wystosował memoriał do dowództwa marynarki „O wnioskach z przebiegu bitwy na Morzu Filipińskim”. Postulował w tym memoriale utworzenie specjalnych jednostek szturmowych, mających atakować nową i skuteczniejszą metodą. W sytuacji, gdy klasycznie walczące samoloty nie były w stanie zaszkodzić amerykańskim lotniskowcom, uznano, że atak samobójczy może być skuteczniejszy.
Sama idea ataku samobójczego w celu zniszczenia wrogich jednostek nie była nowa. Przykłady poświęcania się żołnierzy w atakach pozbawionych szansy na przeżycie są znane od początku historii wojen. Postęp techniczny w XX wieku spowodował powstanie nowych środków bojowych, za pomocą których można było dokonywać takich ataków, szczególnie samolotu, który zapewniał szybkie i łatwe dotarcie do wrogich celów. Często samobójcza śmierć, poprzez uderzenie (taranowanie) w samolot, okręt lub inne jednostki wroga, była wybierana dobrowolnie przez lotników różnych narodowości w przypadku zranienia lotnika lub uszkodzenia samolotu. Idea tworzenia specjalnych oddziałów samobójczych, używających przystosowanych do tego celu samolotów lub jednostek pływających (np. torped), postulowana była w momentach zagrożenia przez ideologów z różnych krajów. Nawet w Polsce w okresie bezpośrednio poprzedzającym II wojnę światową powstała idea społeczna zapisywania się ochotników na „żywe torpedy”. Jednakże Japonia była jedynym krajem, w którym jednostki samobójcze faktycznie utworzono.
Istotną przyczyną wyboru takiego środka walki był zamiar zwiększenia prawdopodobieństwa uderzenia w cel, niż np. przy bombardowaniu, gdyż aż do uderzenia w cel tor lotu samobójczego samolotu był korygowany przez człowieka. Podczas II wojny światowej broń kierowana przez aparaturę elektryczną znajdowała się dopiero w stadium rozwojowym w najbardziej rozwiniętych państwach, przy tym aparatura ta była droga i zawodna. Dlatego kierowanie bronią przez człowieka było najprostszym i „najtańszym” sposobem.
Historia jednostki.
Jednostkę utworzono w październiku 1944 roku. Pomysłodawcą i organizatorem był wiceadmirał Takijirō Ōnishi. Zadanie sformowania pierwszej jednostki samobójczej powierzono chorążemu Tadashiemu Nakajimie i porucznikowi Rikihei Inoguchiemu. Udali się oni do Mabalacat – bazy 201. Dywizjonu – i wybrali kilku spośród zgłaszających się do tego zadania ochotników. Jako dowódcę pierwszej grupy wyznaczono kapitana Yukio Seki. Pilot ten posiadał doświadczenie bojowe i umiejętności rzadko spotykane w szeregach japońskich pod koniec 1944 roku.
Według założeń admirała Ōnishi, pierwsze ataki kamikaze miały być desperacką próbą wsparcia japońskiej floty w walce z flotą amerykańską, która właśnie zaatakowała Filipiny.
Pierwszy atak pilotów samobójców miał miejsce 25 października 1944 roku. . Trzy inne okręty otrzymały trafienia i zostały uszkodzone, najpoważniej USS Sante.
Po ataku utworzono cztery jednostki kamikaze: „Shikishima”, „Yamato”, „Asahi” i „Yamazakura”. Wszystkie były organizacyjnie podporządkowane dowództwu Cesarskiej Marynarki Wojennej, gdyż to właśnie marynarka poleciła je utworzyć.
Kamikaze walczyli do końca wojny. Największa ich liczba wzięła udział w walkach o Okinawę w kwietniu 1945 roku, gdy do akcji bojowych wysłano około 1900 maszyn bojowych. Łącznie wykonano 2314 lotów bojowych na klasycznych samolotach, z tej liczby 1086 zakończyło się powrotem. Największą liczbę lotów wykonano na wodach Okinawy; wtedy do lotów samobójczych wystartowało 1809 maszyn, 879 z nich powróciło.
Oprócz zwykłych samolotów różnych typów, wprowadzono pod koniec wojny także specjalne samoloty samobójcze o napędzie rakietowym Ōka (jap. "Kwiat Wiśni"), nazywanych przez Amerykanów z jap. "baka" lub z ang. "screwball", czyli "świr", "narwaniec". Miały one bardzo mały zasięg i z tego powodu do miejsca ataku musiały być przenoszone pod kadłubem średnich bombowców Mitsubishi G4M3 Betty. Samoloty te stawały się wtedy mało zwrotne i przez to bardziej podatne na przechwycenie i zestrzelenie, co znacznie ograniczało zastosowanie tej broni. Łącznie wyprodukowano 755 tych samolotów-pocisków, z czego większość użyto bojowo. Atutem "Ōka" była bardzo duża prędkość nurkowania w kierunku celu, uzyskana dzięki dużemu obciążeniu powierzchni nośnej. 
Straty zadane Amerykanom przez lotnicze formacje samobójcze w latach 1944 i 1945 to 56 zniszczonych i 273 uszkodzonych jednostek nawodnych, kosztem życia 3913 pilotów lotnictwa japońskiego.
Oprócz jednostek lotniczych, w użyciu były też samobójcze jednostki morskie, tak zwane „żywe torpedy”, o nazwie "kaiten". Do końca wojny zbudowano 419 sztuk i użyto bojowo z miernym skutkiem. Udało im się bowiem zatopić tylko jeden zbiornikowiec (USS Mississinewa), jeden niszczyciel (USS Underhill) oraz uszkodzić 2 niszczyciele i 2 transportowce. Jednostki te nie były nazywane kamikaze.
Większość załóg samobójczych stanowili ochotnicy. Pod koniec wojny zdarzały się jednak przypadki wydawania rozkazów zwykłym pilotom do wzięcia udziału w takiej misji.
Strona moralna.
Dwie postaci lotników japońskich walczących we wcześniejszym etapie wojny nieświadomie dały swoją postawą przykład pilotom kamikaze – byli to kapitanowie: Tomonaga i Murata. Pierwszy zginął w trakcie bitwy pod Midway. Po powrocie z porannego nalotu na wyspę okazało się, że lewoskrzydłowy zbiornik jego samolotu jest uszkodzony, mimo to polecił zatankować drugi i wystartował do ataku na okręty amerykańskie. Nie został zestrzelony, ale nie starczyło mu paliwa na powrót. Runął do wody i zginął.
Murata z kolei w trakcie bitwy pod Santa Cruz po poważnym uszkodzeniu swojego samolotu uderzył w nieprzyjacielski lotniskowiec USS Hornet. Wiceadmirał Ōnishi wymieniał obu w motto dla kamikaze: "Wystartować do lotu w jedną tylko stronę jak Tomonaga i rozbić się o wrogi okręt jak Murata".
Oficerowie japońscy zbierali pilotów mających wyruszyć z samobójczą misją w specjalnej sali. Tam odczytywano im podstawowe założenia kodeksu Bushidō i wiersze haiku, pozostawione przez lotników, którzy już ponieśli śmierć. Miały one służyć podbudowaniu patriotyzmu i przypomnieniu samurajskich wzorów.
Następnie piloci składali przysięgę, przebierali się w specjalne mundury, odbierali samurajskie miecze i w końcu zasiadali do stołu z oficerem prowadzącym, wznosili toast czarką sake i owijali głowy opaskami hachimaki, z tarczą wschodzącego słońca i napisami: „pewne zwycięstwo” czy „poświęcenie dla kraju”. Po wyjściu na lotnisko żegnali się z przyjaciółmi, dostawali od nich drobne upominki. W końcu wsiadali do samolotów i startowali pośród pieśni patriotycznych, śpiewanych przez obsługę lotniczą. Samoloty były u szczytu sprawności technicznej i nieskazitelnie czyste. Tłumaczono to tym, iż samolot będzie trumną pilota, a wszystkie trumny są czyste.
Spadając na cel, kamikaze wykrzykiwali głośno: „Banzai” („Niech Cesarz żyje 10 tys. lat!”) lub „Hissatsu” („Pewna śmierć”).
Wyposażenie.
Najpopularniejszym samolotem wykorzystywanym przez kamikaze był Mitsubishi A6M. Pod koniec wojny, gdy tego typu myśliwców zaczęło brakować, kamikaze latali także na: Yokosuka D4Y, Nakajima B5N, Kugisho Ohka Model 11 i Mitsubishi G4M. Ich ubiór stanowiły – jak w przypadku zwykłego pilota – spodnie i kurtka ocieplane puchem, czapka uszanka i skórzane buty. Broń podręczną stanowił pistolet Nambu wz. 14 lub wz. 94. Oprócz niego kamikaze nosili przy sobie nóż, którym podcinali sobie żyły na wypadek, gdyby np. nie trafili w cel i przeżyli uderzenie w wodę. Zwykle nosili też przy sobie miecz samurajski, przekazywany z pokolenia na pokolenie, który umieszczali w ekskluzywnej pochwie. Piloci ci często zabierali ze sobą zdjęcia swoich bliskich oraz portrety z wyobrażeniem swoich przodków.
Wykaz formacji i jednostek samobójczych.
Pozostałe jednostki
Oprócz wymienionych wyżej jednostek istniało wiele innych nieformalnych grup, które powstały samorzutnie w różnych bazach lotniczych, w zależności od zaistniałej sytuacji.
Wszystkie te i inne podobne jednostki powstawały na podstawie tajnych rozkazów, bez wprowadzania zapisów do raportów dowództwa lotnictwa morskiego.

</doc>
<doc id="13115" url="https://pl.wikipedia.org/wiki?curid=13115" title="Język (logika)">
Język (logika)

Język – pewien zbiór symboli, przy użyciu których można tworzyć bardziej złożone wyrażenia (na przykład formuły, zdania matematyczne) według ściśle określonych reguł syntaktycznych. Przyjmuje się, że w danym języku L mogą występować (w dowolnej liczbie) symbole funkcyjne, relacyjne oraz symbole stałych. Zdania napisane przy użyciu języków tego typu wystarczają do opisu większości własności dowolnych struktur matematycznych oraz do wyrażenia twierdzeń mówiących o tych strukturach.
Język a syntaktyka.
Wyrażenia języka L to termy oraz formuły. Są to ciągi symboli, które powstają według ściśle określonych reguł z symboli języka L, symboli logicznych (takich jak spójnik koniunkcji czy alternatywy), zmiennych oraz kwantyfikatorów.
Zbiór termów języka L to najmniejszy zbiór T o własnościach:
Zbiór formuł języka L to najmniejszy zbiór F o własnościach:
Zdanie to formuła języka L, w której nie występują zmienne wolne. Ze zdań możemy budować teorie, a następnie badać różne własności tych teorii (na przykład takie jak zupełność, rozstrzygalność czy kategoryczność).
Język a semantyka.
Mówimy, że M jest strukturą (modelem) dla języka L, jeśli M jest zbiorem, w którym zinterpretowane zostały wszystkie symbole z języka L. Oznacza to, że:
Jeśli M jest modelem dla języka L, to możemy określić, które zdania napisane w języku L są prawdziwe w modelu M lub – inaczej mówiąc – spełniane przez model M.
Definicję spełniania zdania przez model jako pierwszy podał polski logik i matematyk Alfred Tarski, powszechnie uważany za twórcę semantyki logicznej (utożsamianej zwykle z teorią modeli).
Zbiór tych wszystkich zdań napisanych w języku L, które są prawdziwe w modelu M dla języka L, tworzy teorię modelu M w języku L. Teoria ta jest teorią zupełną. Badanie zależności między modelami i ich teoriami to główny przedmiot badań obszernego działu logiki matematycznej jakim jest teoria modeli.

</doc>
<doc id="13117" url="https://pl.wikipedia.org/wiki?curid=13117" title="Bitwa pod Midway">
Bitwa pod Midway

Bitwa pod Midway – bitwa lotniczo-morska w czasie II wojny światowej, stoczona w dniach 4–7 czerwca 1942 pomiędzy siłami japońskimi a amerykańskimi, w pobliżu atolu Midway na Oceanie Spokojnym, zakończona taktycznym i strategicznym zwycięstwem amerykańskim. Uznawana jest umownie za punkt zwrotny w wojnie na Pacyfiku, ponieważ inicjatywa działań militarnych przeszła na stronę amerykańską.
Geneza i cele starcia.
7 grudnia 1941 roku japońska "Kidō-Butai" (siły mobilne, siły uderzeniowe) przeprowadziła atak lotniczy na amerykańskie bazy lotnicze i morskie na Hawajach ("Hawaii sakusen").
Niemal równocześnie przeprowadzili symultaniczne operacje zajęcia Guam i Wake, wkrótce potem dokonali inwazji na Hongkong, a następnie wylądowali na Półwyspie Malajskim oraz na Filipinach, pod Kuantanem zaś zatopili HMS „Prince of Wales” i „Repulse”, rozpoczynając marsz w kierunku Singapuru. Sukces tych przeprowadzonych w ciągu kilku dni operacji, spowodował przyśpieszenie ich drugiej serii, które skutkowały zająciem Rabaul w Archipelagu Bismarcka, serią bitew na Morzu Jawajskim i rajdem na Darwin w Północnej Australii. W połowie lutego 1942 roku upadł Singapur i na przełomie lutego i marca, było oczywiste, iż Japonia osiągnie wszystkie swoje ekonomiczne cele wojny. Dotychczasowe zdobycze terytorialne zapewniały bowiem Japonii swobodny dostęp do ropy naftowej, kauczuku i innych surowców naturalnych. Z polityczno-ekonomiczno-ideologicznego punktu widzenia, Japończycy byli na najlepszej drodze do zniszczenia „białego kolonializmu” na obszarze ich operacji. Japońskie dowództwo wojskowe zaczęło wówczas rozważać dalsze kroki, rozważając różnorakie operacje zastanawiano się nad inwazją na Australię, skierowaniem się na obszar Oceanu Indyjskiego, uderzenia na południe – na Wyspy Salomona w kierunku Fiji i Samoa, celem odcięcia od zaopatrzenia Australii. W japońskich kręgach wojskowo-politycznych, w styczniu 1942 roku ścierały się jednak różne opcje. 
Dowódca Połączonej Floty admirał Isoroku Yamamoto nie był najwyższym dowódcą japońskiej floty – podlegał sztabowi generalnemu marynarki i jego szefowi admirałowi Osami Nagano. Już przed wybuchem wojny, wbrew stanowisku swojego przełożonego, adm. Nagano, Yamamoto forsował ideę ataku na Pearl Harbor, i uzyskał zgodę na rozpoczęcie wojny ze Stanami Zjednoczonymi oraz atak na amerykańską bazę, szantażując ustąpieniem ze stanowiska, swoim, i całego sztabu Połączonej Floty.
Poczytywany za sukces atak na Pearl Harbor i następujący po nim ciąg sukcesów marynarki, znacznie wzmocniły jego pozycję i prestiż, został narodowym bohaterem, w konsekwencji uzyskał bezprecedensową nieformalną władzę w zakresie kształtowania strategii „Drugiej Fazy Operacyjnej”.
Mimo wielkiej publicznej celebracji zwycięstwa w Pearl Harbor, sam Yamamoto był rozczarowany, że adm. Nagumo nie pozostawał w morzu wystarczająco długo, aby całkowicie zniszczyć amerykańską bazę i znaleźć oraz zatopić amerykańskie lotniskowce.
Sytuacja Stanów Zjednoczonych.
Po 7 grudnia, sytuacja Stanów Zjednoczonych na obszarze Pacyfiku jeszcze bardziej pogarszała się. Amerykańska flota pancerna, która przez dekady była trzonem amerykańskiej potęgi morskiej została sparaliżowana, co zniweczyło wszelkie nadzieje na obronę Filipin. Amerykanie nie byli też w stanie wysłać więcej niż symbolicznych sił do obrony Jawy i Sumatry. W rezultacie Stany Zjednoczone mogły tylko przyglądać się rozwojowi japońskiej ofensywy z prowadzonej z niewyobrażalną wcześniej prędkością i precyzją. Do kwietnia 1942 roku strategiczne pozycje aliantów na Pacyfiku obrócone zostały w pobojowisko – Jawa i Sumatra padły, cała amerykańska Flota Azjatycka przestała istnieć, a Japończycy znaleźli się w sytuacji, w której mogli bezpośrednio zagrozić Australii.
Filipiny były całkowicie izolowane, zaś walczące tam siły generała Douglasa MacArthura ostatecznie skapitulowały 9 kwietnia. Po upadku Birmy i Malajów, Brytyjczycy zaczęli odczuwać zagrożenie nawet dla Indii, zaś Royal Navy została unicestwiona do tego stopnia, że nie była w stanie opuścić Oceanu Indyjskiego nawet w bezpośredniej obronie Australii i Nowej Zelandii. Australia i Nowa Zelandia zaś, mimo wysokiej jakości ich sił zbrojnych, nie miały potencjału ekonomicznego i ludnościowego do samoobrony, nie mówiąc o prowadzeniu wojny z Japonią. Na dodatek doborowe oddziały australijskie zaangażowane były w tym czasie na Bliskim Wschodzie u boku armii brytyjskiej.
Z amerykańskiego punktu widzenia, kluczowa była obrona Hawajów oraz Kanału Panamskiego. Zagrożenie dla tego ostatniego nie było z uwagi na odległość realne, ich ewentualna utrata mogła jednak oznaczać katastrofę dla Stanów Zjednoczonych. Prowadzenie wojny z Japonią, oznaczało też konieczność obrony Australii, toteż USA zaczęły wzmacniać siły alianckie na tym kontynencie, co jednak wymagało zapewnienia bezpieczeństwa dostaw, w tym przede wszystkim przez utrzymanie w rękach alianckich wysp Fidżi, Nowa Kaledonia i Samoa. Ich utrata na rzecz Japonii, oznaczałaby bowiem praktycznie odcięcie Australii od zaopatrzenia ze Stanów Zjednoczonych.
Wojna na Pacyfiku wymagała więc dużego wysiłku, także gospodarczego – w sytuacji, gdy amerykańska gospodarka nie wyszła jeszcze wówczas w pełni z Wielkiego Kryzysu, którego skutki w postaci braków w zaopatrzeniu amerykańscy żołnierze odczuwali jeszcze nawet pod koniec 1942 roku, podczas walk na wyspach Salomona. Tymczasem oficjalnym priorytetem dla USA była Europa i obowiązująca doktryna „Germany First”, która zmuszała USA do kierowania większości sił i środków do działań na europejskim teatrze wojennym.
Po klęsce w Pearl Harbor, dowództwo amerykańskiej Floty Pacyfiku po zdymisjonowanym adm. Husbandzie Kimmelu objął admirał Chester Nimitz, który zamiast pozbyć się całego sztabu Kimmela, zachował większość jego członków, czym podbudował upadłe po 7 grudnia morale dowództwa. Będąc w United States Navy odpowiednikiem admirała Yamamoto, musiał reagować na działania dowódcy Połączonej Floty, nie mając jeszcze materialnej przewagi potrzebnej do wygrania wojny. W zakresie floty pancerników, Japonia dysponowała wówczas miażdżącą przewagą nad Flotą Pacyfiku, miała też więcej krążowników, więcej niszczycieli, i więcej okrętów podwodnych, zaś większość japońskiego sprzętu wojennego była nowocześniejsza od wyposażenia amerykańskiego. Na dodatek, wzmocnienie Floty Pacyfiku w marcu 1942 roku przez przejście na Ocean Spokojny „Horneta”, zostało zniweczone koniecznością wielomiesięcznego remontu „Saratogi” po jej storpedowaniu 11 stycznia przez japoński okręt podwodny I-6.
Amerykańskie rajdy 1. połowy roku.
Konsekwencje nie zniszczenia amerykańskich lotniskowców zostały dobitnie zademonstrowane przez amerykańskie rajdy na wyspy Marshalla i Gilberta, na atol Wake oraz na Salamaua i Lae. Nie mogąc frontalnie przeciwstawić się Połączonej Flocie, w pierwszej połowie 1942 roku Nimitz zaangażował swoje lotniskowce w serię rajdów na wysunięte japońskie posterunki na Oceanie Spokojnym, które choć przynosiły Japonii znikome straty materialne i wojskowe, stanowiły znakomity poligon dla niedoświadczonych amerykańskich pilotów i załóg okrętów, dając im doświadczenie i zahartowanie bojowe niezbędne w przyszłych bitwach. W japońskim dowództwie wzmagały zaś poczucie zagrożenia ze strony amerykańskich lotniskowców. Przeprowadzony 4 marca rajd na wyspę Marcus był kolejnym już atakiem lotnictwa pokładowego na japońskie wysunięte bazy w ciągu zaledwie dwóch miesięcy. Co więcej, atak na znajdującą się 600 mil od Japonii i 1000 mil od Tokio wyspę Marcus wzmógł japońskie obawy, że United States Navy zaatakuje samą stolicę imperium. Spowodował, że dowódca Połączonej Floty admirał Isoroku Yamamoto wznowił przygotowania do operacji zniszczenia amerykańskich lotniskowców przez zwabienie ich do walnej bitwy, czemu służyć miała operacja desantu na Midway. Rajdy te spowodowały, że Yamamoto był prześladowany przez myśl, że amerykańskie lotniskowce stanowią zagrożenie dla Japonii, w tym jej terytoriów macierzystych. Według zachowanych notatek szefa sztabu adm. Yamamoto, kadm. Matome Ugakiego, „obrona Tokio przed rajdami lotnictwa, była uważana przez admirała, za jego najważniejszą powinność”.
Sam Yamamoto ujawnił publicznie swoje obawy mówiąc, iż „nie można wykluczyć możliwości, że wróg ośmieli się zaatakować naszą ojczyznę, aby spalić naszą stolicę i inne miasta”, w czasie gdy japońskie lotniskowce znajdują się na Oceanie Indyjskim. Przeprowadzony na początku marca 1942 roku amerykański rajd na wyspę Marcus, zaledwie 1000 mil od Tokio, był drastycznym potwierdzeniem takiej ewentualności. Z tego powodu rozkazał utworzyć złożoną z małych jednostek linię dozoru w odległości 700 mil morskich od japońskich brzegów, stawiającą wyspy japońskie daleko poza zasięgiem amerykańskich bombowców pokładowych. Dlatego w momencie powrotu japońskich okrętów lotniczych z Oceanu Indyjskiego, Yamamoto skupiony był na zniszczeniu amerykańskich lotniskowców, nie zaś na ataku na Australię, Nową Gwineę, czy Aleuty.
Punktem kulminacyjnym amerykańskiej strategii w tym czasie był, przeprowadzony pod naciskiem prezydenta Roosevelta, bezpośredni atak na wyspy japońskie. 18 kwietnia 1942 roku 16 amerykańskich dwusilnikowych bombowców North American B-25 Mitchell zbombardowało Tokio, Nagoję, Kobe i Osakę. Należące nie do floty, lecz do United States Army samoloty płk. Jimmyego Doolittle'a, wystartowały z pokładu eskortowanego przez USS „Enterprise” (CV-6) lotniskowca USS „Hornet” (CV-8), który tak samo jak japońskie lotniskowce kilka miesięcy wcześniej niepostrzeżenie przeniknął bezmiar wód północnego Pacyfiku. Szkody materialne wyrządzone przez amerykańskie bombardowanie były niezauważalne, sam nalot miał jednak duży wpływ na morale amerykańskiego społeczeństwa, zaś reperkusje w Japonii miał wręcz gigantyczne. O ile bowiem przed rajdem na Tokio w japońskich dowództwach marynarki i armii istniały zastrzeżenia co do planu ataku na Midway admirała Yamamoto, amerykański nalot natychmiast je usunął.
Jeszcze zanim admirał Nagumo zdążył powrócić do Japonii po ataku na Pearl Harbor, Yamamoto rozkazał kadm. Ugakiemu opracowanie szkicu planu inwazji na Hawaje, jako sposobu na zwabienie amerykańskich lotniskowców do bitwy i zniszczenie ich. Z powodu całkowitego braku realizmu takiego planu – Japonia nie posiadała bowiem żadnych możliwości przeprowadzenia desantu na niezbędną do tego celu skalę – zarówno sztab generalny marynarki jak i dowództwo Armii stwierdziły, że taka operacja jest wykluczona. Według japońskich szacunków, zajęcie Hawajów wymagałoby przynajmniej 45 000 żołnierzy, trzy razy więcej niż kiedykolwiek przerzucili w jakiejś operacji desantu morskiego, które tym razem musieliby przerzucić na odległość 6500 kilometrów. Na taką odległość nie byliby również w stanie zaopatrywać tych wojsk.
Zamiarem Yamamoto był atak na cel wystarczająco ważny dla USA, aby celem jego obrony zmusić Stany Zjednoczone do zaangażowania większości lub nawet wszystkich lotniskowców, Głównodowodzący amerykańskiej floty adm. Ernest King był bardzo zaniepokojony możliwością japońskiej inwazji na Fiji i Samoa, co mogłoby odciąć amerykańskie dostawy do Australii, adm. Yamamoto nie uważał jednak tego celu za wystarczająco ważny, aby mógł sprowokować Amerykanów do reakcji. Sądził natomiast że ewentualne zajęcie Hawajów mogłoby zmusić Stany Zjednoczone do podjęcia negocjacji. Przy zdecydowanym jednak braku zgody sztabu generalnego na operację na Hawajach, zdecydował się na mniejszy cel, złożony z dwóch niewielkich wysp atol Midway. Zdaniem admirała Yamamoto, Midway było wystarczająco ważnym celem, aby atak na atol spowodował wysłanie amerykańskich lotniskowców z Oʻahu z zamiarem przeciwdziałania inwazji, co umożliwiłoby uderzenie na nie przez "Kidō-butai" i zatopienie ich.
Atol Midway.
Izolowany atol Midway znajdował się 1135 mile morskie na północny zachód od Pearl Harbor i 1185 mil morskich od wyspy Wake. Jak w przypadku każdego atolu na Pacyfiku okrągłokształtna rafa koralowa otacza małą lagunę. Na południowym brzegu laguny znajdują się dwie niewielkie piaszczyste wyspy – większa z nich o nazwie Sand Island ma nieco ponad 3 km długości, druga zaś – o nazwie Eastern Island – jest jeszcze mniejsza. Przez wieki jedynymi mieszkańcami atolu były albatrosy ciemnolice. Z uwagi na swe oddalenie od innych miejsc, oficjalnie atol został odkryty dopiero w 1859 roku, choć z całą pewnością też wcześniej zatrzymywali się tam wielorybnicy. Na początku XX wieku prezydent Theodore Roosevelt przekazał atol pod administrację departamentu marynarki, który utworzył tam stację telegraficzną łączącą go z Hawajami. W 1940 roku, w miarę narastania zagrożenia wojennego na Pacyfiku, marynarka ukończyła tam budowę kanału żeglugowego dającego swobodny dostęp do wnętrza laguny, co uczyniło z atolu wygodne chronione kotwicowisko dla wodnosamolotów i okrętów podwodnych. Rok później, cztery miesiące przed japońskim atakiem na Pearl Harbor, marynarka ukończyła budowę lotniska na Eastern Island, które uczyniło z atolu niezatapialny – choć nieruchomy – lotniskowiec. Izolacja atolu czyniła z Midway istotny punkt linii obrony Hawajów. Startując z chronionej laguny, wodnosamoloty Consolidated PBY Catalina mogły patrolować obszar o promieniu 1000 mil, amerykańska flota podwodna stąd właśnie mogła rozpoczynać patrole u brzegów Japonii, zaś z lotniska na Eastern Island amerykańskie bombowce i samoloty myśliwskie strzec mogły północnych podejść do Hawajów. Nic więc dziwnego, że w wewnętrznej komunikacji zarówno Nimitz jak i King podkreślali wagę „linii obrony Midway–Hawaje”.
Z drugiej strony, Midway znajdowało się wystarczająco blisko Hawajów, aby po zajęciu przez Japończyków stanowić istotne i stałe zagrożenie dla archipelagu, wystarczająco zaś daleko, aby znajdować się poza zasięgiem startujących z Oahu amerykańskich bombowców. Admirał Yamamoto założył więc, że waga Midway dla obrony archipelagu spowoduje reakcję dowództwa przeciwnika w razie japońskiego ataku na atol, które wyśle do jego obrony amerykańskie lotniskowce. Zdobycie atolu Midway nie było celem samym w sobie, atak na atol służyć miał jedynie do zastawienia pułapki na amerykańskie lotniskowce.
Japoński plan operacyjny.
W lutym 1942 roku Yamamoto rozkazał swojemu sztabowi opracowanie operacyjnego planu inwazji oraz okupacji Midway. Według ogólnego planu, podobnie jak w grudniu ubiegłego roku, "Kidō-Butai" podejść miała do atolu od północy i wykonać atak powietrzny na lotnisko, celem zniszczenia amerykańskich sił lotniczych na nim. Jednocześnie silna, lecz nie zanadto silna, grupa nawodna podejść miała do Midway od zachodu, celem zwrócenia na siebie uwagi Amerykanów, którzy – jak założył Yamamoto – wyślą lotniskowce w reakcji na bombardowanie atolu lub na pojawienie się w pobliżu umiarkowanie dużej grupy nawodnej. W drodze na Midway, okręty amerykańskie miały zostać zaatakowane przez rozstawione zawczasu japońskie okręty podwodne, które zadać im miały możliwie duże straty. W następnym kroku "Kidō-Butai" miała popłynąć na południe i przechwycić amerykańskie lotniskowce. Sześć dużych lotniskowców floty nie powinno mieć problemu ze zniszczeniem dwóch lub trzech lotniskowców amerykańskich, na wszelki wypadek jednak, w odległości 600 mil morskich na północ – między "Kidō-Butai", a zespołem nawodnym – płynąć miał silny zespół kilku ciężkich pancerników, z samym Yamamoto na pokładzie pancernika „Yamato”, który zniszczyć miał ocalałe po wcześniejszych atakach amerykańskie jednostki.
Siły japońskie.
Flota admirała Yamamoto składała się z 1 Zespołu Uderzeniowego Lotniskowców dowodzonego przez wiceadmirała Chūichi Nagumo, zespołu ubezpieczającego (sił głównych) pod dowództwem samego adm. Yamamoto, oraz mającego zająć Midway zespołu inwazyjnego wiceadm. Kondō. Osobne ugrupowanie stanowił Zespół operacji AL, mający zająć wyspy Attu, Adak i Kiska w archipelagu Aleutów. W jego skład wchodziły m.in. dwa lotniskowce 2 Zespołu Uderzeniowego Lotniskowców („Ryūjō” i „Jun'yō”).
Trzonem 1 Zespołu Uderzeniowego były 4 lotniskowce: tworzące 1. Dywizjon Lotniskowców „Akagi” i „Kaga”, 2. Dywizjon Lotniskowców „Hiryū” i „Sōryū”, a ponadto 2 szybkie pancerniki „Haruna” i „Kirishima”, 2 ciężkie krążowniki „Tone” i „Chikuma” oraz 12 niszczycieli i 5 zbiornikowców zaopatrzeniowych. W skład "Kido Butai" nie wszedł natomiast przewidziany do tej operacji 5. Dywizjon Lotniskowców w składzie „Shōkaku” i „Zuikaku”. Ten pierwszy bowiem został zbyt ciężko uszkodzony w bitwie na Morzu Koralowym aby mógł być naprawiony na czas, zupełnie nie uszkodzony natomiast „Zuikaku” stracił wówczas całą swoją grupę lotniczą, która wobec sztywności japońskich reguł, nie mogła być zastąpiona samolotami i ludźmi z innych okrętów. W przeciwieństwie bowiem do US Navy, w marynarce japońskiej eskadry lotnicze były na stałe przypisane do swoich okrętów – stanowiły ich immanentną część – i zgodnie z japońskimi procedurami nie mogły być przenoszone z jednej jednostki na drugą. Ostatecznie jednak, brak okrętów 5. Dywizjonu, zaważył na końcowym rezultacie bitwy, z jej przebiegu bowiem wynika, że niezależnie od dużej dozy towarzyszącego Amerykanom w tej bitwie szczęścia, ich zwycięstwo byłoby trudno wyobrażalne przy udziale w bitwie dwóch dodatkowych dużych lotniskowców.
W skład zespołu ubezpieczającego wchodziło 7 pancerników (w tym flagowy „Yamato”), 1 lekki lotniskowiec („Hōshō”), 2 transportowce wodnosamolotów, 2 lekkie krążowniki i 12 niszczycieli, z czego 4 pancerniki i 2 krążowniki zostały wydzielone do osłony operacji na Aleutach. Następnie zarówno one, jak i lotniskowce 2 Zespołu Uderzeniowego miały uczestniczyć w spodziewanej decydującej bitwie z interweniującą pod Midway Flotą Pacyfiku.
Zespół inwazyjny podzielony był na zespoły: osłony, wsparcia ogniowego, desantowy i pomocniczy. W jego skład oprócz okrętów transportowych wchodziły 2 szybkie pancerniki, 8 krążowników ciężkich i niszczyciele. Lotniskowce "Kido Butai" miały na swych pokładach 227 maszyn (plus dalszych 21 samolotów transportowanych dla przyszłych sił stacjonujących na zdobytej Midway).
Na przewidywanych kursach podejścia płynącej z Pearl Harbor ku Midway i Aleutom Floty Pacyfiku rozlokowano 14 okrętów podwodnych. 1 okręt podwodny (I-168) operował w rejonie Midway.
Siły amerykańskie.
Siły amerykańskie pod dowództwem kontradmirała Franka J. Fletchera dzieliły się na dwa zespoły uderzeniowe (ang. "Task Force").
Zespół TF-16, dowodzony przez kontradmirała Raymonda A. Spruance’a, składał się z lotniskowców USS „Enterprise” i USS „Hornet” oraz 5 ciężkich krążowników: USS „New Orleans”, USS „Minneapolis”, USS „Vincennes”, USS „Pensacola” i USS „Northampton”, krążownika przeciwlotniczego USS „Atlanta” i 9 niszczycieli (USS „Phelps” (DD-360), USS „Worden” (DD-352), USS „Monaghan” (DD-354), USS „Aylwin” (DD-355), USS „Balch” (DD-363), USS „Conyngham” (DD-371), USS „Benham” (DD-397), USS „Ellet” (DD-398) i USS „Maury” (DD-401)) oraz 4 tankowców (USS „Cimarron” (AO-22), USS „Platte” (AO-24), USS „Dewey” (DD-349), USS „Monssen” (DD-436)).
Drugi zespół, TF-17, pod dowództwem kontradmirała Fletchera, składał się z lotniskowca USS „Yorktown”, prowizorycznie naprawionego po uszkodzeniu w bitwie na Morzu Koralowym, 2 ciężkich krążowników USS „Astoria” i USS „Portland”, 6 niszczycieli: USS „Hammann” (DD-412), USS „Hughes” (DD-410), USS „Morris” (DD-417), USS „Anderson” (DD-411), USS „Russell” (DD-414) i USS „Gwin” (DD-433).
W sumie obie grupy bojowe dysponowały 233 samolotami.
Na Midway stacjonowało 17 ciężkich bombowców Boeing B-17 – "Latających Fortec", 6 samolotów bombowo-torpedowych Grumman TBF Avenger, 4 samoloty bombowo-torpedowe Martin B-26 Marauder, 19 bombowców nurkujących Douglas SBD Dauntless, 21 bombowców nurkujących Vought SB2U Vindicator, 21 myśliwców Brewster F2A Buffalo, 7 myśliwców Grumman F4F Wildcat i 31 rozpoznawczych łodzi latających Consolidated PBY Catalina (razem 126 maszyn).
Wyspy atolu zostały ufortyfikowane. Poza umocnieniami polowymi zbudowano schrony betonowe. Istniały przeszkody przeciwdesantowe, pola minowe i zasieki z drutu kolczastego. Garnizon Midway, tzn. 6 Batalion Obrony Wybrzeża (Marines) wzmocniły dwie kompanie raidersów Piechoty Morskiej oraz pluton lekkich czołgów M3 Stuart. Artyleria na Midway liczyła kilkadziesiąt dział (4 – 178 mm, 6 – 127 mm, 24 – 76 mm, ponadto wiele działek przeciwlotniczych 37 i 20 mm). Obrońcy dysponowali dużą ilością broni maszynowej (sam tylko 6 Batalion Obrony Wybrzeża miał 48 karabinów maszynowych 12,7 mm oraz 36 – 7,62 mm). Na Midway bazowało m.in. 8 kutrów torpedowych (a 2 dalsze jednostki tej klasy na pobliskim atolu Kure).
Od północnego zachodu, zachodu i południowego zachodu Midway osłaniał wachlarz 9 okrętów podwodnych. 2 okręty podwodne pozostawały w rezerwie na północ i południe od atolu, jeszcze 1 został wysunięty daleko na zachód. 7 okrętów podwodnych patrolowało na północ i zachód od głównych wysp Hawajów, jeszcze 7 znajdowało się kilkaset mil od Midway powracając z patroli.
HYPO.
W połowie lat 30. amerykańska marynarka zaczęła wysyłać oficerów do ambasady USA w Tokio, których jedynym zadaniem była intensywna nauka języka japońskiego. Część z przygotowanych w ten sposób osób została włączona w utworzoną w 1940 roku komórkę wywiadu elektronicznego HYPO z siedzibą na Hawajach. Kierowana przez Josepha Rocheforta HYPO, rozszyfrowując częściowo przychwytywaną na bieżąco japońską komunikację radiową, zdołała z dużą dokładnością ustalić cel ataku oznaczony w japońskich planach jako „AF”, datę i godzinę, a także pozycje i dokładny skład wszystkich trzech japońskich ugrupowań morskich. Dzięki Rochefortowi, admirał Chester Nimitz dysponował wiedzą dotyczącą miejsca i czasów wyjścia japońskich zespołów z własnych baz, planowanych miejsc japońskich uderzeń, znał także japońskie plany rekonesansu lotniczego Hawajów z wykorzystaniem łodzi latających mających tankować po drodze z okrętów podwodnych, znał również miejsce i czas spotkania japońskich zespołów morskich po spodziewanym przez adm. Yamamoto sukcesie operacji MI.
Mimo początkowej opozycji biura rozpoznania elektronicznego OP-20-G w Waszyngtonie, Rochefort wraz – z szefem wywiadu w sztabie dowódcy Floty Pacyfiku – Edwinem Laytonem, zdołał przekonać adm. Nimitza, że celem zbliżającego się japońskiego ataku ma być Midway, nie zaś kolejne wyspy na południowo-wschodnim Pacyfiku. Celem potwierdzenia stanowiska Hypo, iż oznaczony kryptonimem „AF” cel japońskiego ataku oznacza Midway, na polecenie HYPO 19 maja dowództwo wojsk na tym atolu wysłało „przypadkowo” niezakodowaną fałszywą wiadomość na Hawaje o awarii instalacji wodociągowej na wyspie. Przechwycona następnego dnia zarówno przez HYPO, jak i przez OP-20-G seria japońskich wiadomości o braku wody na „AF” ostatecznie potwierdziła stanowisko Rocheforta i Leytona.
Dokładna znajomość japońskiego planu ataku, pozwoliła Nimitzowi na skupienie na Midway i na północny wschód od atolu wszystkich dostępnych sił, w tym niemal całego będącego w jego dyspozycji lotnictwa, także przeniesionych tu z Hawajów bombowców wojsk lądowych, i opracowanie planu obrony z zastawieniem zasadzki na okręty Połączonej Floty.
Przed bitwą.
W dniach 26–28 maja japońskie siły wyszły w morze z baz. Według planu, rankiem 3 czerwca 1942 samoloty z lotniskowców miały jednocześnie zaatakować Dutch Harbor na Aleutach oraz Midway (zespół adm. Nagumo opuścił Japonię z jednodniowym opóźnieniem wobec harmonogramu operacji, wskutek czego data nalotu na Midway musiała zostać przesunięta).
6 czerwca, po bombardowaniu lotniczym i artyleryjskim Midway, atol miał zostać zajęty przez zespół inwazyjny. Zespół ubezpieczający pozostawał pomiędzy Midway a Aleutami w razie pojawienia się amerykańskich sił, głównie pancerników. Zadaniem zespołu uderzeniowego było natomiast najpierw zbombardowanie Midway, a ewentualnie później zniszczenie amerykańskich lotniskowców.
Amerykanie dowiedzieli się z wyprzedzeniem o zainteresowaniu Japończyków Midway, dzięki złamaniu szyfru japońskiej marynarki JN25b. Amerykańskie dowództwo, spodziewając się Japończyków, już w ostatnich dniach maja rozpoczęło loty rozpoznawcze, a flota zajęła pozycję ok. 300 mil na północny wschód od Midway. Aż do 3 czerwca loty zdawały się na nic, ponieważ Japończycy przemierzali Pacyfik pod osłoną złej pogody. Dopiero tego dnia rano rozpoznanie lotnicze zameldowało o dużej formacji okrętów w odległości 700 mil od wysp – japońskie okręty zespołu inwazyjnego zostały dostrzeżone na kilka minut przed planowanym zawróceniem samolotu.
Reakcją dowódcy Midway było wysłanie 9 „Latających Fortec” B-17, których atak nie przyniósł żadnych rezultatów, ponieważ został przeprowadzony z bardzo dużej jak na warunki morskie wysokości – 3 tysięcy metrów, a okręty japońskie z łatwością unikały bomb. Dopiero atak łodzi latających Catalina zaowocował uszkodzeniem jednego zbiornikowca.
Tymczasem 3 czerwca Japończycy zbliżyli się na odległość 400 mil do zespołu amerykańskiego, o którego obecności wciąż nie wiedzieli. Zgodnie ze wskazaniami komórki wywiadu elektromagnetycznego HYPO na Hawajach, Japończycy już następnego ranka mieli przeprowadzić atak lotniczy na wyspę. Na tę okoliczność adm. Nimitz, amerykański głównodowodzący Floty Pacyfiku, ustawił swoją flotę niespełna 200 mil na północny wschód od wyspy – blisko floty japońskiej, ale nie tracąc atutu zaskoczenia.
Bitwa.
Od godziny 4:30 nad ranem 4 czerwca, z japońskich lotniskowców wystartowało 108 samolotów – po 36 samolotów torpedowych, bombowych i myśliwskich, wysłanych w celu zbombardowania instalacji wojskowych na wyspie Midway. Japończycy byli pewni, że w pobliżu nie ma sił amerykańskich. Wysłali wprawdzie na patrol samoloty zwiadowcze, lecz użyli do tego celu niedostatecznej ich ilości, a samolot z krążownika „Chikuma” nie dostrzegł nieprzyjacielskich zespołów operacyjnych znajdujących się w sektorze jego poszukiwań.
Japończyków, po dotarciu do wyspy o 6:30, przywitał ogień artylerii przeciwlotniczej oraz 24 z myśliwców stacjonujących na wyspie. Rezultatem walk było zniszczenie 11 samolotów japońskich (14 było ciężko uszkodzonych), 15 amerykańskich myśliwców (13 Buffalo i 2 Wildcaty; 5 dalszych F2A i 2 F4F odniosły tak ciężkie uszkodzenia, że musiano je później złomować) oraz pewne straty w urządzeniach bazy. Choć jednak zniszczeniu uległa m.in. część zbiorników benzyny lotniczej i urządzenia do tankowania samolotów, sam pas startowy na Sand Island został uszkodzony nieznacznie, więc Amerykanie mogli go szybko naprawić. Obrona przeciwdesantowa atolu praktycznie nie ucierpiała. Gdy Japończycy walczyli nad Midway, ich własne okręty zostały zaatakowane kolejno przez kilka grup amerykańskich samolotów bombowo-torpedowych Avenger i Marauder oraz bombowców nurkujących Dauntless i Vindicator, wysłanych z Midway przed nalotem. Doświadczone załogi japońskich lotniskowców skutecznie manewrowały tak, że Amerykanie nie osiągnęli żadnych trafień. Atakujące bombowce torpedowe i nurkujące zostały zdziesiątkowane przez japońską osłonę myśliwską, która zestrzeliła 16 z nich. Także użycie ciężkich bombowców B-17 przeciw celom nawodnym okazało się zupełnie nieskuteczne.
Na dalszym przebiegu bitwy zaważył czynnik czasu i decyzje podejmowane przez adm. Nagumo. Po wysłaniu fali samolotów na Midway, zatrzymał on część samolotów torpedowych na lotniskowcach, przewidując, że w pobliżu może pojawić się amerykańska flota, zwabiona obecnością Japończyków. Tymczasem dowódca grupy samolotów atakujących Midway zgłosił konieczność przeprowadzenia drugiego nalotu, w celu zniszczenia lotniska na wyspie. Brak powtórnego nalotu był już błędem popełnionym przez Japończyków w Pearl Harbor. Nagumo zdecydował więc przezbroić oczekujące na lotniskowcach samoloty torpedowe w bomby i wysłać je nad Midway. Około godziny 7:30 pierwszy japoński samolot zwiadowczy dostrzegł amerykańskie okręty. Zaszła więc konieczność ponownego przezbrojenia samolotów w torpedy. W tym czasie zaczęły powracać na lotniskowce samoloty znad Midway, które należało przyjąć na pokłady, zatankować i uzbroić. Odwlekło to wysłanie samolotów uderzeniowych przeciw flocie amerykańskiej. Wówczas, około godziny 9:30, zaatakowały amerykańskie samoloty, które od godziny 7:00 zaczęły startować z lotniskowców amerykańskich.
Próba utworzenia jednolitej grupy uderzeniowej z samolotów zespołu TF-16 nie powiodła się. Eskadry bombowe i bombowo-rozpoznawcze wysłane z „Enterprise” (VB-6 i VS-6) oraz „Horneta” (VB-8 i VS-8 z osłoną myśliwców eskadry VF-8) obrały odmienne kursy (dowódca „Horneta” kontradmirał Mitscher błędnie założył, że japońskie lotniskowce podzielone są na dwa zespoły płynące w dużym oddaleniu od siebie i postanowił zaatakować drugi z nich). Eskadra samolotów torpedowych z „Horneta” (VT-8) pierwotnie towarzyszyła bombowcom, następnie jednak odłączyła od nich (z inicjatywy swego dowódcy komandora podporucznika J.C. Waldrona, który uważał, że nakazany kurs jest błędny i prawidłowo odgadł pozycję Japończyków). Eskadra torpedowa z „Enterprise” (VT-6) wystartowała z opóźnieniem. Myśliwce z „Enterprise” (z eskadry VF-6) podążyły za samolotami torpedowymi „Horneta”. Sprawnie za to przebiegł rozpoczęty o godzinie 08:38 start eskadr „Yorktowna” (bombowa VB-3, torpedowa VT-3, osłona myśliwska z VF-3). Tym razem amerykańskie samoloty uformowały połączoną grupę uderzeniową.
Jako pierwsze, o godzinie 09:20, zaatakowały samoloty torpedowe z „Horneta”. Towarzyszące im dotąd myśliwce z „Enterprise” przeoczyły moment rozpoczęcia nalotu przez VT-8 i nie zapewniły mu osłony. Wszystkie 15 samolotów torpedowych Douglas TBD-1 Devastator zostało zestrzelonych nad celem przez myśliwce i artylerię. Ocalał tylko jeden z pilotów – ppor. George Gay. Następnie (o godzinie 09:38) nadleciały samoloty torpedowe z „Enterprise” (VT-6, dowódca kmdr ppor. Eugene Lindsey). Również i one zostały zmasakrowane przez Japończyków – z 14 maszyn ocalały 4. Determinacja załóg tych dwóch eskadr torpedowych poszła w znacznym stopniu na marne. Niezgodny z prawdą jest powszechny pogląd, że związały japońską osłonę myśliwską, co ułatwiło atak bombowców nurkujących – ataki VT-6 i VT-8 miały miejsce na kilkadziesiąt minut przed przybyciem na pole walki amerykańskich nurkowców. Korzystny dla Amerykanów był jednak fakt, iż na zmuszonych do gwałtownych manewrów lotniskowcach japońskich uległy spowolnieniu przygotowania do startu bombowców. Ponadto część myśliwców japońskich patroli powietrznych musiała lądować celem uzupełnienia zapasu amunicji, a w tym czasie trzeba było zastępować je w powietrzu kolejnymi Zero.
Fatalny dla Amerykanów bilans zmienił się jednak, gdy nadleciały ich kolejne eskadry – grupa uderzeniowa z „Yorktowna” oraz bombowce nurkujące z „Enterprise”. Uwagę japońskich patroli powietrznych zaabsorbował rozpoczęty o godzinie 10.10 nalot samolotów torpedowych z lotniskowca „Yorktown” (kmdr ppor Lance Massey). Część Zero wdała się też w walkę powietrzną z amerykańskimi myśliwcami eskadry VF-3 z „Yorktowna” (pod dowództwem kmdra ppor J. S. Thacha, który podczas tego właśnie starcia po raz pierwszy zastosował w boju swoją słynną później taktykę walki z Zero, zwaną „Przeplatanką Thacha”). W tej sytuacji całkowicie niespodziewanym przez Japończyków i niemożliwym już dla nich do odparcia okazał się atak dwóch eskadr bombowców nurkujących Dauntless z lotniskowca „Enterprise” (VB-6 oraz VS-6) pod dowództwem komandora podporucznika Wade’a McClusky’ego. Zaskoczyły one lotniskowce o godzinie 10:25, z osłoną myśliwską zajętą zwalczaniem samolotów torpedowych „Yorktowna”, atakujących lotniskowiec „Hiryū”. VT-3 spotkał podobny los, co poprzednio atakujące eskadry torpedowe – z 12 samolotów tylko 2 przetrwały nalot, a i one musiały później wodować. Jednak bombowcom nurkującym Dauntless, nadlatującym z wysokości kilku kilometrów, udało się skutecznie zbombardować lotniskowce japońskie „Akagi” i „Kaga”.
Wbrew popularnemu poglądowi, pokłady japońskich lotniskowców nie były zastawione licznymi, gotowymi do startu i uzbrojonymi samolotami. Kapitan Richard Best zauważył jedynie 6 lub 7 Zer na pokładzie „Akagi”. Jeden z pilotów z „Kagi” – Takayoshi Morinaga, stwierdził, że jedynie dwa lub trzy samoloty były na pokładzie w momencie ataku. Oba okręty stanęły w płomieniach, podsycanych benzyną lotniczą i wybuchami uzbrojenia samolotów. W tym samym czasie trzeci japoński lotniskowiec – „Sōryū” – padł ofiarą ataku 17 bombowców nurkujących z „Yorktowna” (eskadra VB-3). Okręt został trafiony przez trzy bomby. Warto podkreślić, że dowódca samolotów z „Yorktowna” – kapitan Maxwell F. Leslie, stwierdził, że nie widział żadnych samolotów na pokładzie „Soryu” podczas ataku. Uzbrajane i tankowane samoloty znajdowały się jednak na pokładach hangarowych, co sprawiło, że skutki eksplozji bomb rzeczywiście okazały się zabójcze.
O godz. 14:00 „Kaga” został dodatkowo trafiony jedną torpedą wystrzeloną z okrętu podwodnego USS „Nautilus” (SS-168), lecz nieskutecznie, ponieważ torpeda nie eksplodowała. Podjęte przez Japończyków próby ratowania okrętu zakończyły się niepowodzeniem, i o godzinie 19:25 został zatopiony przez torpedy z niszczyciela „Hagikaze”. Nieco wcześniej, o 19:13, torpedy niszczyciela „Isokaze” zatopiły lotniskowiec „Soryu”. Również ciężko uszkodzony flagowy „Akagi” został zatopiony o 05:20 następnego dnia, trafiony torpedami wystrzelonymi z niszczycieli „Arashi”, „Nowaki”, „Hagikaze” i „Maikaze”.
Japoński kontratak.
Japończycy stracili w krótkim czasie 3 duże lotniskowce i został im tylko jeden – „Hiryū” (oznacza to dosłownie „latający smok”). Jego samoloty zaatakowały lotniskowiec USS „Yorktown”, którego załoga była jednak dobrze przygotowana do odparcia uderzenia. W asyście 12 myśliwców eskorty zestrzelili oni wprawdzie 11 z 18 bombowców, lecz pozostałe samoloty dowodzonej przez Michio Kobayashiego najlepszej eskadry pokładowej w całej flocie japońskiej, uzyskały 3 trafienia, ciężko uszkadzając „Yorktowna”. Dzięki błyskawicznej i sprawnej akcji ratowniczej, okręt tymczasowo uratowano, a powracające samoloty bezpiecznie przeniosły się na „Enterprise”. Jednakże kolejny atak na okręt przypuściły prowadzone przez Jōichiego Tomonagę japońskie samoloty torpedowe. Udało im się dwukrotnie trafić okręt torpedami, doprowadzając do 23-stopniowego przechyłu. Załoga opuściła okręt.
Uderzenie popołudniowe.
Po południu amerykańskie bombowce nurkujące startujące z „Enterprise” (w tym 10 maszyn z „Yorktowna”), zaatakowały szykujący się do kolejnego wypuszczenia samolotów „Hiryū”, zamieniając go w płonący wrak. „Hiryū” zatonął ok. 9:00 następnego dnia, dobity japońskimi torpedami, pociągając ze sobą kadm. Tamona Yamaguchiego, który pozostał na pokładzie.
Oznaczało to ostateczną porażkę japońskiej floty i w konsekwencji załamanie ofensywy. W nocy z 4 na 5 czerwca adm. Yamamoto zarządził odwrót. Porażkę pogłębiło zderzenie dwóch krążowników ciężkich, które dla jednego z nich – „Mikuma” – skończyło się tragicznie. W wyniku zderzenia zostały uszkodzone jego zbiorniki paliwa i okręt zostawiał za sobą widoczny ślad ropy, który umożliwił odnalezienie go przez lotnictwo amerykańskie i zatopienie, drugi „Mogami” został uszkodzony. 6 czerwca Amerykanie z powodu braku paliwa zaprzestali pogoni. Tego samego dnia ciężko uszkodzony „Yorktown” i towarzyszący mu niszczyciel „Hammann” zostały storpedowane przez japoński okręt podwodny I-168; „Hammann” zatonął natychmiast, a „Yorktown” następnego dnia rano o godzinie 05:01. 7 czerwca 1942 bitwa o Midway zakończyła się.
Po bitwie.
Bitwa o Midway okazała się pierwszą porażką floty japońskiej od 350 lat, tzn. od roku 1592, kiedy to koreański adm. Yi-Sun pobił Japończyków u wybrzeży Korei. Uważana jest umownie za punkt zwrotny w walkach na Pacyfiku, po którym Japończycy przeszli do defensywy.
Japończycy stracili trzon swych sił: 4 duże lotniskowce, krążownik „Mikuma” (łącznie około 100 tys. ton wyporności), 253 samoloty oraz 3 tys. ludzi na pokładach. W budowie wówczas znajdowały się tylko dwa lotniskowce o podobnej wielkości – „Taihō” i „Unryū”. Dla odrobienia strat rozkazano przerobić na lotniskowce kilka niedokończonych okrętów, m.in. „Shinano” – trzeci pancernik typu "Yamato". Straty amerykańskie zamknęły się w jednym lotniskowcu („Yorktown”), jednym niszczycielu, 150 samolotach i 300 ludziach. Lecz jeżeli porównać straty wśród personelu latającego obydwu stron, to okazuje się, że w bitwie poległo więcej lotników amerykańskich (194).
Dużą i trudną do nadrobienia stratą dla Japończyków była utrata wyszkolonego personelu lotniczego oraz pilotów. Wynikało to z japońskiego systemu szkoleniowego, w którym najlepsi i najbardziej doświadczeni piloci pozostawali w jednostkach liniowych do końca, aż nie polegną w walce. Owocowało to wysokim poziomem wyszkolenia Japończyków, ale system ów był zupełnie nieodporny na duże straty ludzkie. Amerykanie przenosili swoich asów do jednostek szkoleniowych, dzięki czemu utrzymywali stały, aczkolwiek często nie najwyższy, poziom wyszkolenia. Dzięki temu systemowi oraz dużym zasobom ludzkim dostarczenie posiłków nie stanowiło problemu.
Błędne jest jednak rozpowszechnione przekonanie, jakoby to właśnie pod Midway wyginęła większość japońskich wyszkolonych lotników. Straty wśród nich były stosunkowo niewielkie i wyniosły 121 ludzi („Akagi” – 7, „Kaga” – 21, „Soryu” – 10, „Hiryu” – 72, oprócz tego zginęło 11 lotników wodnosamolotów rozpoznawczych). Upadek japońskiego lotnictwa morskiego zapoczątkowały łączne straty poniesione podczas działań bojowych w 1942 r., szczególnie podczas przewlekłej kampanii o Guadalcanal.
Stratą największą i niepowetowaną okazała się śmierć wielu wyszkolonych specjalistów obsługi pokładowej. To oni stanowili większość japońskich ofiar bitwy (ok. 2600 z ok. 3000 poległych). Z tej liczby szczególnie bolesna okazała się śmierć 721 techników lotniczych. Utrata takiej liczby trudnego do zastąpienia wyspecjalizowanego personelu wpłynęła ujemnie na efektywność operacji japońskich lotniskowców w toku dalszych działań wojennych.
Straty japońskie wyniosły:
Razem: okręty o wyporności 120300 ton.
Amerykanie utracili:
Katastrofalna klęska w bitwie o Midway załamała japońską strategię wojny na Pacyfiku. Bez 4 utraconych lotniskowców Japończycy musieli zrezygnować ze swoich dalszych planów ofensywnych (zajęcia Nowych Hebrydów i Nowej Kaledonii, wysp Fidżi i Samoa oraz operacji przeciw Australii i Hawajom). Co więcej, strata tych bezcennych jednostek podważyła również plany defensywne Japonii – bowiem to lotniskowce miały stanowić ruchomy odwód strategiczny w spodziewanej fazie obronnej wojny z USA.
Zwycięstwo Stanów Zjednoczonych pod Midway umożliwiło im przejście do ofensywy na Pacyfiku jeszcze latem 1942, tzn. na kilkanaście miesięcy wcześniej, zanim nabierający dopiero rozmachu potencjał przemysłowy tego kraju zaczął rozstrzygająco wpływać na wynik wojny z Japonią.
Japończycy do końca wojny nie odzyskali już inicjatywy strategicznej. Klęska była tak wielka, że postanowiono ją zupełnie utajnić przed społeczeństwem.
Zbrodnie wojenne.
Podczas bitwy o Midway Japończycy dopuścili się zbrodni wojennych na kilku wziętych do niewoli lotnikach amerykańskich.
Chorąży Wesley Osmus, pilot strąconego samolotu torpedowego z lotniskowca „Yorktown” został wyłowiony z morza przez niszczyciel „Arashi”, dowodzony przez komandora porucznika Yasumasa Watanabe okręt flagowy 4 Dywizjonu Niszczycieli pod dowództwem komandora porucznika Kosaku Ariga. Na pokładzie Osmusa poddano przesłuchaniu, podczas którego był bity i zastraszany ścięciem mieczem. Następnie, na rozkaz dowódcy „Arashi”, japońscy marynarze wyrzucili lotnika za burtę okrętu. Amerykanin usiłował uczepić się relingu, lecz został zamordowany ciosem siekiery w tył głowy. Podobnie tragiczny los spotkał załogę jednego z bombowców nurkujących lotniskowca „Enterprise”: pilota Franka O’Flaherty’ego oraz jego strzelca pokładowego Bruno Gaido. Po tym, jak ich samolot wodował z braku paliwa, zostali podjęci na pokład niszczyciela „Makigumo” (dowodzonego przez komandora porucznika Isamu Fujitę). Po brutalnym przesłuchaniu Amerykanów wypchnięto za burtę, skrępowanych i z przywiązanym do ciał obciążeniem. Obydwaj utonęli. Mordercy Osmusa, O’Flaherty’ego i Gaido nie ponieśli odpowiedzialności karnej za swoje zbrodnie.
Pamięć o bitwie.
Bitwa o Midway trafiła do panteonu amerykańskich narodowych zwycięstw, wielokrotnie inspirując Amerykanów do jej upamiętniania.
4 czerwca (rocznica decydującego dnia bitwy) jest oficjalnym świętem Marynarki Wojennej Stanów Zjednoczonych (jako „Midway Day”).
W 1943 r. imieniem „Midway” ochrzczono lotniskowiec eskortowy typu "Casablanca" (CVE-63); w 1944 r. nazwę okrętu zmieniono na „St. Lo”.
W 1945 r. na cześć bitwy nazwano pierwszy z typu wielkich nowoczesnych lotniskowców US Navy, USS „Midway” (CV-41).
Już 14 września 1942 odbyła się premiera pierwszego filmu poświęconego bitwie – dokumentalnego obrazu pt. "Bitwa o Midway" w reżyserii Johna Forda. Ten wybitny amerykański reżyser osobiście kręcił część swego dramatycznego materiału filmowego i podczas japońskiego nalotu na Midway został kontuzjowany, częściowo tracąc słuch. W 1943 r. dzieło Forda zostało uhonorowane Oscarem za najlepszy film dokumentalny.
Z 1976 r. pochodzi fabularny film "Bitwa o Midway" wyreżyserowany przez Jacka Smighta. Jest to nakręcona z rozmachem (choć przy licznych niedoróbkach) hollywoodzka superprodukcja. Przedstawiony w niej obraz bitwy znacznie odbiega od historycznej rzeczywistości.
Bitwa zainspirowała również licznych twórców gier komputerowych, np. "" (gdzie prócz zmagań pod Midway gracz bierze udział także w innych operacjach drugiej wojny światowej na Pacyfiku).
Zostali uhonorowani także niektórzy z bohaterów bitwy. Np. w sierpniu 1942 nazwisko poległego w bitwie lotnika piechoty morskiej majora Loftona Hendersona otrzymało lotnisko na odbitej z rąk Japończyków wyspie Guadalcanal (Henderson Field). Obecnie nazwę Henderson Field nosi port lotniczy na Sand Island w atolu Midway. Na cześć Johna Waldrona, poległego dowódcy samolotów torpedowych z lotniskowca „Hornet” nazwano niszczyciel typu „Allen M. Sumner” (USS „Waldron”, DD-699) oraz pas startowy bazy lotniczej Corpus Christi w Teksasie (Waldron Field). Nazwiskiem Wesleya Osmusa, zamordowanego przez Japończyków pilota z lotniskowca „Yorktown”, ochrzczono w 1943 r. niszczyciel eskortowy typu „Buckley” – USS „Osmus” (DE-701). W ten sam sposób uczczono pamięć innego zamordowanego w niewoli lotnika, Franka W. O’Flaherty’ego z lotniskowca „Enterprise” – jego nazwisko nosił niszczyciel eskortowy USS „O’Flaherty” (DE-340) typu „John C. Butler”.
W 2010 roku zespół Sabaton nagrał piosenkę pt. „Midway”, która ukazała się w albumie „Coat of Arms”.
Siły.
Japonia.
Opisane tylko główne siły:
USA.
Źródło: Order of Battle: Battle of Midway and Aleutians 3-7 June 1942 w serwisie NavWeaps.com [dostęp 2010-05-20]

</doc>
<doc id="13118" url="https://pl.wikipedia.org/wiki?curid=13118" title="Midway">
Midway

Midway (haw. "Kuaihelani", także "Pihemanu") – atol leżący w archipelagu Hawajów, w grupie Północno-Zachodnich Wysp Hawajskich. Administracyjnie jest jedynym atolem archipelagu hawajskiego, który nie należy do stanu Hawaje, tylko stanowi odrębne terytorium nieinkorporowane Stanów Zjednoczonych. Wyspy obecnie zamieszkuje tylko personel United States Fish and Wildlife Service (brak stałych mieszkańców).
Geografia.
Midway to owalny atol, składający się z pierścienia rafy koralowej o średnicy ok. 8 km otaczającej lagunę o głębokości sięgającej 15 m w centralnej części. Większość rafy tworzy ciągłą barierę, szczególnie po stronie północnej i wschodniej. Od zachodu znajduje się wejście do laguny, w którym jest tylko kilka skrawków rafy. W południowej części atolu znajdują się trzy niewielkie, niskie wyspy: Sand Island (4,56 km²), Eastern Island (1,36 km²) i Spit Island (0,05 km²), łącznie mające powierzchnię 5,9 km². Jest największa powierzchnia lądowa w łańcuchu Północno-Zachodnich Wysp Hawajskich. Otaczające je rafy mają 356 km² powierzchni. Sand Island była pierwotnie pokryta prawie wyłącznie piaskiem, a jej najwyższe wzniesienie mierzyło 13 m n.p.m.; ludzie posadzili na niej trawy, krzewy i drzewa. Eastern Island to trójkątna wyspa zbudowana z bardziej zwartej gleby, która była porośnięta roślinami jeszcze przed odkryciem. Pomiędzy Sand Island a Spit i Eastern Island znajdowało się przejście w barierze rafy wystarczające dla łodzi, które zostało potem sztucznie powiększone.
Atol Midway jest oddalony o około na wschód od Kure i ok. od Pearl i Hermes. Od Honolulu dzieli go 482,7 km.
Koralowy atol narósł na szczycie dawnego wulkanu tarczowego, który wygasł wskutek przesunięcia się płyty pacyficznej sponad hawajskiej plamy gorąca, po czym uległ erozji. Datowanie metodą potasowo-argonową pozwoliło określić, że wulkan był aktywny 28,7 ± 0,6 miliona lat temu (oligocen).
Atol Midway stanowi część Papahānaumokuākea Marine National Monument. Na Sand Island istnieje port lotniczy Henderson Field, który stanowi awaryjne miejsce lądowania dla wszystkich samolotów przemierzających Pacyfik.
Klimat.
Klimat archipelagu Hawajów przez cały rok jest łagodny, o małej zmienności. Przeważają wiatry z północnego wschodu. Latem dominujący wpływ wywiera na niego wyż północnego Oceanu Spokojnego; zimą, szczególnie od listopada do stycznia, niż aleucki przemieszcza się na południe i może stać się dominujący w tym regionie. Temperatury powietrza na Midway zmieniają się w ciągu roku w zakresie . Najsilniejszy huragan zarejestrowany w tym regionie to huragan Patsy z 1959 roku, który przechodząc między Midway a Kure osiągał prędkość wiatru ponad .
Historia.
Nie ma archeologicznych świadectw bytności ludzi na Midway, ale w tradycji ustnej zachowały się opowieści świadczące o tym, że rdzenni Hawajczycy wiedzieli o istnieniu Północno-Zachodnich Wysp Hawajskich. Kulturowo były one uznawane za krainy przodków, nieprzeznaczone dla żyjących. Badacze kultury hawajskiej powiązali atol Midway z nazwą Kuaihelani, oznaczającą „kręgosłup nieba”; w mitach opisywano to miejsce jako wyspę unoszącą się na niebie. Może to być obrazowe przedstawienie tego, że otwarte wody lagun często odbijają obraz nieba, sprawiając wrażenie, jakby wyspy unosiły się w powietrzu. W mitach i pieśniach jest wiele odniesień do tego miejsca jako położonego w północno-zachodniej części archipelagu; to stamtąd bogowie ‘Au-kele-nui-‘aikū, Mo‘o-i-nānea, Pele, dziadkowie Kamapua‘a, Kea-nini-‘ula-ka-lani, i Ke-ao-melemele mieli wywędrować na główne wyspy Hawajów. To także miejsce, gdzie Kāne i Kanaloa piją kavę w towarzystwie duchów. Miejsce to pojawia się także w innych opowieściach. Późniejsza hawajska nazwa Pihemanu oznacza „głośny zgiełk ptaków” i nawiązuje do wielkiej liczebności ptaków morskich na atolu.
8 czerwca 1859 roku Midway odkrył N.C. Brooks z barku „Gambia” i nazwał je Middlebrook Islands. Brooks objął je w posiadanie w imieniu Stanów Zjednoczonych na mocy "Ustawy o wyspach z guanem". Zostało to sformalizowane w 1867, kiedy do wysp dopłynął okręt United States Navy USS „Lackawanna”. 28 sierpnia Stany Zjednoczone oficjalnie przyłączyły te wyspy (wówczas Brooks Island), jako pierwsze terytorium wyspiarskie. Na przełomie XIX i XX wieku wiele statków osiadło na rafach Midway, jako że wyspy są niskie i trudne do zobaczenia na morzu, szczególnie przy niesprzyjającej pogodzie. Jednym z nich był „Wandering Minstrel”, którego katastrofa z 1888 zainspirowała powieść "The Wrecker" Roberta Louisa Stevensona.
W 1870 amerykański slup wojenny USS „Saginaw” rozpoczął poszerzanie kanału żeglugowego między wyspami. W 1903 roku prezydent Theodore Roosevelt oddał Midway w zarząd United States Navy, aby zapobiec rzezi ptaków morskich przez kłusowników. W tym samym roku położono transoceaniczny kabel telegraficzny przez Pacyfik, wykorzystując centralne położenie Midway. W 1923 odbyła się ekspedycja USS „Tanager”, która jako pierwsza systematycznie badała zasoby naturalne Północno-Zachodnich Wysp Hawajskich. W 1935 roku linie lotnicze Pan American World Airways wykorzystywały Midway jako przystanek w pięciodniowych lotach przez Pacyfik i zbudowały na Sand Island hotel ze sklepami i własną elektrownią.
II wojna światowa.
W 1940 roku Stany Zjednoczone przygotowywały się do włączenia w działania II wojny światowej i rozpoczęły budowę placówki na Midway. Baza lotnicza marynarki wojennej została oddana w 1941 roku, a jej znaczenie strategiczne zostało uznane za niższe jedynie od bazy Pearl Harbor. Po przeprowadzeniu ataku na Pearl Harbor, dwa niszczyciele japońskiej marynarki wojennej ostrzeliwały Midway przez prawie dwie godziny. Następny japoński atak, w wyniku którego rozegrała się bitwa o Midway, okazał się przełomem w II wojnie światowej na Pacyfiku, po którym Cesarstwo Wielkiej Japonii nie odzyskało już inicjatywy. Początkowo mające przewagę siły japońskie zostały rozbite przez Amerykanów. Co najmniej 30 samolotów obu stron rozbiło się w wodach otaczających Midway i Kure; w 2000 roku sekretarz zasobów wewnętrznych Stanów Zjednoczonych ustanowił atol narodowym miejscem pamięci ("Battle of Midway National Memorial").
Zimna wojna.
Także po wojnie centralne położenie Midway na Pacyfiku sprawiało, że atol nie stracił strategicznego znaczenia. W 1952 spółka zarządzająca połączeniem telegraficznym powierzyła marynarce wszystkie budynki i sprzęt. Rok później marynarka reaktywowała bazę sił powietrznych i rozpoczęła nasłuch radarowy potencjalnych działań sił radzieckich. Do lat 1980. prowadzono tu nasłuch ruchu okrętów podwodnych. W czasie wojny koreańskiej i wojny wietnamskiej przez Midway przewijały się tysiące osób personelu wojskowego. W 1981 roku lotnisko na Midway ponownie udostępniono lotom cywilnym, redukując obecność wojskową.
Rezerwat.
W 1988 marynarka zaproponowała United States Fish and Wildlife Service utworzenie tu rezerwatu przyrody. W 1996 prezydent Bill Clinton przekazał władzę nad Midway w ręce Departamentu Zasobów Wewnętrznych Stanów Zjednoczonych i atol stał się rezerwatem (National Wildlife Refuge). Marynarka wojenna usunęła wiele budynków, anten, oświetlenie i skażoną glebę, po czym w 1997 oficjalnie opuściła Midway. W 2006 roku prezydent George W. Bush ustanowił Północno-Zachodnie Wyspy Hawajskie pomnikiem narodowym, a w 2010 roku znalazły się one na liście światowego dziedzictwa UNESCO.
Przyroda.
Roślinność i entomofauna Midway uległy dużym zmianom przez sto lat ludzkiej ingerencji. Począwszy od budowy stacji komunikacji kablowej na początku XX wieku, ludzie zaczęli przekształcać jałową, piaszczystą Sand Island. Przywieziono tu ok. 9 tys. ton gleby z Honolulu, m.in. tworząc ogrody warzywne. Sprowadzono trawę piaskownicę zwyczajną z San Francisco, która ustabilizowała ruchome piaski i drzewa, w szczególności rzewnię skrzypolistną, dla osłony przed wiatrem i dla ozdoby. Sprowadzone zostały tu także obce dla Hawajów kanarki i pochodzące z niedalekiej wyspy Laysan ptaki: hawajka grubodzioba i karliczka hawajska. W 1943 roku na Midway dotarły szczury śniade, które doprowadziły do wymarcia tutejszych populacji karliczki i hawajki, a także sprawiły, że populacja petrela bonińskiego spadła z około 500 tysięcy osobników do poniżej 5 tysięcy w latach 1980.
Współcześnie podejście do zagospodarowania przyrody atolu uległo zmianie. United States Navy, United States Fish and Wildlife Service i Departament Rolnictwa Stanów Zjednoczonych wytępiły szczury na atolu; problemem wciąż pozostają zawleczone tu myszy domowe, które od 2015 roku zaczęły nocami atakować albatrosy, raniąc i zabijając ptaki. Z Eastern Island usunięto zagajnik rzewni, a nowe siewki są na bieżąco likwidowane. W 2008 ocenianio, że około 30% powierzchni wysp pokrywają struktury stworzone przez ludzi (lądowiska, budynki), 23% porastają trawy i zioła, 22% krzewy, 18% drzewa, a 7% piasek i goła ziemia. Tylko ok. 0,23% stanowią tereny podmokłe. 3/4 roślin na Midway to gatunki introdukowane.
Na Midway znajdują się największe kolonie lęgowe albatrosów ciemnolicych i albatrosów czarnonogich na świecie. Innymi mieszkańcami atolu są faeton czerwonosterny, atolówka, rybołówka brunatna i atolowa oraz burzykowate. Do rzadkich gości zalicza się albatros krótkosterny. Ogółem ocenia się, że na Midway gnieżdżą się prawie 2 miliony ptaków z 19 gatunków. W 2004 i 2005 roku na Midway sprowadzono z Laysan krytycznie zagrożone krzyżówki białookie.
W wodach otaczających Midway żyje ponad 250 gatunków ryb, w tym rzadki "Hyporthodus quernus". Poza rafami występują ryby pelagiczne, takie jak tuńczyki i żaglicowate. Stwierdzono tu 16 gatunków korali madreporowych; z dwóch gatunków traw morskich jeden jest endemitem, a drugi nie był wcześniej stwierdzony w archipelagu Hawajów.

</doc>
<doc id="13119" url="https://pl.wikipedia.org/wiki?curid=13119" title="Historia starożytna">
Historia starożytna



</doc>
<doc id="13120" url="https://pl.wikipedia.org/wiki?curid=13120" title="Historia średniowieczna">
Historia średniowieczna



</doc>
<doc id="13121" url="https://pl.wikipedia.org/wiki?curid=13121" title="Andron">
Andron

Andron (gr.: Ἀνδρῶν) – reprezentacyjne pomieszczenie dla mężczyzn w domu greckim, przeznaczone przede wszystkim na sympozjony. Sale tego rodzaju znajdowały się zarówno w domach prywatnych jak i w budynkach publicznych.

</doc>
<doc id="13122" url="https://pl.wikipedia.org/wiki?curid=13122" title="Anicet">
Anicet

Anicet – imię męskie pochodzące od "Anicetus", zlatynizowanej formy greckiego imienia "Aniketos". Wywodzi się ono od słowa oznaczającego „niezwyciężony, niepokonany”. Nosił je jeden z wczesnych papieży, św. Anicet.
Anicet imieniny obchodzi , i .
Znane osoby noszące imię Anicet:

</doc>
<doc id="13123" url="https://pl.wikipedia.org/wiki?curid=13123" title="Aniceta">
Aniceta

Aniceta – żeński odpowiednik imienia Anicet. Wywodzi się ono od słowa oznaczającego „niezwyciężona, niepokonana”. Jego patronem jest m.in. jeden z wczesnych papieży, św. Anicet.
Aniceta imieniny obchodzi 23 stycznia, 17 kwietnia i 12 sierpnia.

</doc>
<doc id="13124" url="https://pl.wikipedia.org/wiki?curid=13124" title="Angela">
Angela

Angela - imię pochodzi od łacińskiego imienia "Angel", które powstało od greckiego słowa ángelos "posłaniec". Imię to też zostało przyswojone w postaci Aniela, od niego powstały też imiona Angelika i Angelina. Jest żeńskim odpowiednikiem imienia Anioł (Angel). W ostatnich czasach zapis imienia Angela bywa spolszczany i występuje w formie Andżela lub nawet "Andrzela" (część osób błędnie wywodzi jej źródłosłów od imienia męskiego Andrzej). Ta druga wersja jest niepoprawna.
Angela imieniny obchodzi 27 stycznia.
Znane święte o imieniu Angela:
Znane osoby noszące imię Angela:

</doc>
<doc id="13181" url="https://pl.wikipedia.org/wiki?curid=13181" title="Kalendarium historii średniowiecza">
Kalendarium historii średniowiecza

Historia średniowiecza – część historii obejmująca okres w dziejach Europy i Bliskiego Wschodu pomiędzy starożytnością a czasami nowożytnymi. Okres ten zwany jest średniowieczem.
Granice czasowe średniowiecza nie są ściśle ustalone. Tradycyjnie przyjmuje się, że rozpoczyna się upadkiem imperium rzymskiego w 476 r.n.e., a kończy zdobyciem Konstantynopola przez Turków i upadkiem Cesarstwa Bizantyjskiego w 1453 r. lub odkryciem Ameryki przez Krzysztofa Kolumba w 1492. Kwestia granic czasowych średniowiecza omówiona jest dokładniej w artykule ramy czasowe średniowiecza.
Ważniejsze daty w historii średniowiecza:

</doc>
<doc id="13182" url="https://pl.wikipedia.org/wiki?curid=13182" title="33. ceremonia wręczenia Oscarów">
33. ceremonia wręczenia Oscarów

33. ceremonia rozdania Oscarów odbyła się 17 kwietnia 1961 w Santa Monica Civic Auditorium w Santa Monica.

</doc>
<doc id="13183" url="https://pl.wikipedia.org/wiki?curid=13183" title="Bachantki">
Bachantki



</doc>
<doc id="13185" url="https://pl.wikipedia.org/wiki?curid=13185" title="34. ceremonia wręczenia Oscarów">
34. ceremonia wręczenia Oscarów

34. ceremonia rozdania Oscarów odbyła się 9 kwietnia 1962 roku w Santa Monica Civic Auditorium w Santa Monica.

</doc>
<doc id="13187" url="https://pl.wikipedia.org/wiki?curid=13187" title="Babilon">
Babilon

Babilon (sum. ká.dingir.raki „brama boga”; akad. "Bāb-ilim" „brama boga” lub "Bāb-ilāni" „brama bogów”; gr. "Babylōn"; bibl. בָּבֶל "Bābel"; arab. بابل "Bābil") – starożytne miasto położone w Mezopotamii, nad Eufratem, w pobliżu obecnego miasta Al-Hilla, dawna stolica Babilonii; obecnie stanowisko archeologiczne "Atlal Babil" w Iraku.
Historia.
Pierwsza wzmianka o Babilonie pochodzi z czasów panowania Szar-kali-szarri, króla Akadu z XXIII w. p.n.e. W okresie monarchii III dynastii z Ur (2113–2005 p.n.e.) mieściła się tu siedziba ensich – zarządców niewielkiej prowincji. W roku 1894 p.n.e. Sumu-abum (1894–1881 p.n.e.), przywódca jednego z plemion amoryckich, obrał Babilon za swoją siedzibę, zakładając słynną I dynastię z Babilonu. Rola miasta wzrosła znacznie za panowania Hammurabiego (1792–1750 p.n.e.), szóstego władcy z tej dynastii, który stworzył duże imperium ze stolicą w Babilonie. W 1595 r. p.n.e. miasto zostało zdobyte, złupione i spalone przez Mursilisa I, króla hetyckiego, by następnie wpaść w ręce Kasytów, ludu z gór Zagros, którym w XVI w. p.n.e. udało się przejąć kontrolę nad Babilonią i utworzyć tu własne państwo o nazwie Karduniasz. Władali oni Babilonią przez następne 400 lat, a Babilon – stolica ich państwa – przeżywał w tym okresie zmienne koleje losu, m.in. padając dwukrotnie łupem agresorów z zewnątrz. W 1235 r. p.n.e. asyryjski król Tukulti-Ninurta I najechał Babilonię, pojmał jej kasyckiego władcę Kasztiliasza IV i zdobył Babilon, wywożąc z niego liczne skarby, w tym posąg boga Marduka. Ten sam los spotkał Babilon niemal sto lat później, w 1159 r. p.n.e., kiedy Babilonię najechał elamicki władca Szutruk-Nahhunte I, kładąc kres dynastii kasyckiej.
Wieki XI–VIII p.n.e. to okres zamieszania w Babilonii, związany z przybyciem i osiedlaniem się na jej obszarze plemion chaldejskich. Babilonem rządziło kolejno kilka różnych dynastii, których władcy, poza problemami wewnętrznymi, musieli też radzić sobie ze stałym zagrożeniem jakim stała się rosnąca w siłę Asyria. Ok. 730 r. p.n.e. jeden z asyryjskich władców, Tiglat-Pileser III, najechał Babilonię, zdobył Babilon i jako pierwszy z władców asyryjskich przyjął tytuł „króla Babilonu”, tworząc tym samym unię personalną Asyrii i Babilonii. W 689r. p.n.e. na rozkaz jednego z następców Tiglat-Pilesera III – Sennacheryba wojska asyryjskie zdobyły i splądrowały Babilon, mordując jego mieszkańców i paląc miasto. Babilon odzyskał dawną potęgę w pierwszej połowie VI wieku p.n.e., odbudowany przez Asarhaddona (syna Sennacheryba) i później za panowania dynastii nowobabilońskiej (z tych czasów pochodzą Brama Isztar, zrekonstruowany i powiększony ziggurat E-temenanki czy wiszące ogrody Semiramidy).
Zdobyte w 539 roku p.n.e. przez Persów, miasto powoli traciło na znaczeniu. W roku 482 p.n.e. miasto Babilon zbuntowało się, satrapę Zopyrosa zabito. Następca Dariusza, Kserkses I, za pośrednictwem Megabyzosa zdobył zbuntowane miasto, ograbił je, obłożył wysokimi podatkami. Żołnierzy wcielono do armii asyryjskiej i określano ich Chaldejczykami, gdyż nazwa związana z Babilonią została odtąd urzędowo zakazana.
W Babilonie zmarł w 323 roku p.n.e. Aleksander Wielki, który zamierzał uczynić je stolicą swojej uniwersalnej monarchii. Po jego śmierci miasto zaczęło podupadać w wyniku licznych wojen i masowych wywózek ludności (m.in. w roku 275 p.n.e.). Ostateczny upadek miasta dokonał się za czasów panowania Partów w III wieku n.e. Został ponownie odkryty przez niemieckiego archeologa Roberta Koldeweya w 1899 roku.
Wykopaliska.
Na obecnym stanowisku archeologicznym, na którym od 1899 roku prowadzi się wykopaliska, odkryto między innymi:
Współczesność.
Babilon obecnie znajduje się w granicach administracyjnych Iraku. W roku 1985 prezydent Iraku Saddam Husajn rozpoczął odbudowę miasta z cegieł, na których umieszczono napis "Wybudowano przez Saddama Husajna, syna Nabuchodonozora, aby okryć chwałą Irak". W czasie II wojny w Zatoce Perskiej wojska amerykańskie zajęły teren starożytnego miasta. Po zakończeniu II wojny w Zatoce (2003) niedaleko częściowo zrekonstruowanych pozostałości Babilonu znajdowała się główna baza wojsk polskich w Iraku, tzw. Camp Babilon.
Wewnątrz zewnętrznych murów miejskich Babilonu irackie ministerstwo naftowe buduje stację pomiarową dla jednego z trzech rurociągów, które ułożono w ostatnich latach. W obrębie terenu mnożą się domy prywatne.

</doc>
<doc id="13188" url="https://pl.wikipedia.org/wiki?curid=13188" title="Kazimierz Odnowiciel">
Kazimierz Odnowiciel



</doc>
<doc id="13189" url="https://pl.wikipedia.org/wiki?curid=13189" title="Bolesław Śmiały">
Bolesław Śmiały



</doc>
<doc id="13190" url="https://pl.wikipedia.org/wiki?curid=13190" title="Władysław Herman">
Władysław Herman



</doc>
<doc id="13192" url="https://pl.wikipedia.org/wiki?curid=13192" title="Aszur (miasto)">
Aszur (miasto)

Aszur (akad. "aš-šurki" zapisywane w piśmie klinowym ) – starożytne miasto w północnej Mezopotamii; w III i II tysiącleciu p.n.e. główne miasto i stolica Asyrii, święte miasto boga Aszura z jego główną świątynią E-szara; obecnie stanowisko archeologiczne "Kalat asz-Szarkat" w północnym Iraku, nad zachodnim brzegiem Tygrysu, około 110 km (68 mil) na południe od Mosulu; w 2003 roku wpisane zostało na listę światowego dziedzictwa UNESCO.
Miasto.
Aszur wybudowane zostało na skalistym, niemal trójkątnym cyplu, utworzonym w miejscu połączenia dwóch odnóg Tygrysu. To położenie zapewniało miastu naturalną ochronę od strony wschodniej i północnej. Od strony lądu dostępu do miasta bronił system potężnych umocnień. Obszar objęty murami miał powierzchnię około 80 ha. Miasto podzielone było na dwie części: Stare Miasto i przyległe do niego od południa Nowe Miasto.
Stare Miasto.
Stare Miasto (akad. "libbi-āli", tłum. „"serce/wnętrze miasta"”) obejmowało obszar około 50 ha. To tu, w jego północnej części, znajdował się kompleks pałacowo-świątynny z najważniejszymi budynkami w mieście. Osobliwością tego kompleksu było jego „wtopienie” w strukturę miasta. W Aszur – w przeciwieństwie do innych stolic asyryjskich (Kalhu, Niniwa, Dur-Szarrukin) – nigdy nie powstała odrębna cytadela, odcięta murami od pozostałej zabudowy. Część świątyń przylegała do domów prywatnych, zaś pałace dostępne były bezpośrednio „z ulicy”, choć wiemy, że dostęp do nich był ściśle określony. Centralną i południową część Starego Miasta zajmowały domy prywatne. Stare Miasto otoczone było wewnętrznym murem, wzniesionym za czasów Salmanasara III w IX wieku p.n.e.
Nowe Miasto.
Nowe Miasto (akad. "alu eššu", tłum. „"nowe miasto"”) obejmowało obszar około 30 ha. Początkowo stanowiło ono południowe przedmieście Aszur. W obręb miasta weszło w XVI wieku p.n.e., kiedy to król asyryjski Puzur-Aszur III rozkazał otoczyć je murami. W „Nowym Mieście” znajdowały się najprawdopodobniej dzielnice handlowa i mieszkalna.
Mury miejskie.
Dostępu do miasta Aszur broniły dwa pasy umocnień: mur zewnętrzny (chroniący „Stare Miasto” i „Nowe Miasto”) oraz mur wewnętrzny (chroniący „Stare Miasto”). Przed murem zewnętrznym znajdowała się dodatkowo potężna fosa o szerokości 20 metrów i głębokości 15 metrów. Do miasta wiodło kilkanaście bram, z których najważniejszą była Brama Tabira („Brama Rękodzielników”) – główna brama wiodąca na zachód.
Wykopaliska.
Pierwsze niesystematyczne badania na stanowisku tym przeprowadzili jeszcze w XIX wieku Austen Henry Layard, Hormuzd Rassam i Victor Place. Pozwoliły one zidentyfikować "Kalat asz-Szarkat" jako miejsce, gdzie w starożytności istniała asyryjska stolica Aszur. Godnymi wzmianki zabytkami odkrytymi w czasie tych wczesnych wykopalisk są: posąg Salmanasara III (854–824 p.n.e.) i terakotowa pryzma Tiglat-Pilesera I (1115–1077 p.n.e.). Ta ostatnia odegrała ważną rolę w odczytaniu pisma klinowego będąc pierwszym w pełni odczytanym (w 1857 roku) tekstem asyryjskim. Naszą obecną wiedzę archeologiczną o Aszur zawdzięczamy jednak w dużej mierze pracy niemieckich archeologów, którzy pod kierunkiem Waltera Andrae prowadzili tu w latach 1903–1914 wykopaliska z ramienia Niemieckiego Towarzystwa Orientalnego (Deutsche Orient-Gesellschaft). Prace wykopaliskowe Andrae skoncentrowane były w pn i pn.-zach. części Starego Miasta, gdzie zlokalizowana była większość świątyń i pałaców. Ponieważ wielu królów asyryjskich przebudowywało i rozbudowywało te budowle, sekwencja chronologiczna warstw archeologicznych ustalona być mogła jedynie na podstawie związanych z nimi królewskich inskrypcji budowlanych. Pozwoliło to na przykład odkryć, iż niektóre z tych budowli były użytkowane przez ponad tysiąc lat, nawet po tym, jak Aszur przestało być już administracyjną stolicą państwa (początek I tysiąclecia p.n.e.). Najważniejszymi odkrytymi tu obiektami pochodzącymi z okresu istnienia państwa asyryjskiego (początek II tysiąclecia p.n.e. – 614 p.n.e.) okazały się być: świątynia Aszura, ziggurat Enlila/Aszura, Stary Pałac, świątynia Sina i Szamasza, świątynia Isztar, świątynia Anu i Adada, Nowy Pałac i fortyfikacje z bramami i nabrzeżami. Najpóźniejsze założenia architektoniczne odkryte w Aszur przez Andrae okazały się pochodzić z okresu partyjskiego (ok. 250 n.e.). Główne odsłonięte budowle z tego okresu to tzw. pałac partyjski (w płd części miasta) i świątynia Aszura-Szeruy (w północnej części miasta). Najstarszymi osiągniętymi warstwami w czasie wykopalisk lat 1903–1914 były te w wykopie sondażowym w świątyni Isztar, które wykazały, iż jej początki sięgały czasów „presargonidzkich” (przed 2300 p.n.e.). W latach siedemdziesiątych i osiemdziesiątych XX wieku prace wykopaliskowe związane z rekonstrukcjami na stanowisku prowadzili archeolodzy iraccy z ramienia Irackiego Departamentu Starożytności. Pod koniec lat osiemdziesiątych kampanie wykopaliskowe przeprowadzili tu archeolodzy niemieccy: w latach 1988–1989 pod kierunkiem Reinharda Dittmanna z ramienia Wolnego Uniwersytetu Berlińskiego (sondaże i badania geofizyczne) i w latach 1989–1990 pod kierunkiem Barthela Hroudy z ramienia Uniwersytetu Ludwika i Maksymiliana w Monachium (domy mieszkalne w centrum miasta). Ostatnie prace pozwoliły sporządzić nowy topograficzny plan stanowiska i po raz pierwszy ustalić sekwencję zmian w ceramice począwszy od okresu Ur III (2112–2004 p.n.e.) do okresu partyjskiego (250 p.n.e. – 256 n.e.). W latach 2000–2001 dalsze prace wykopaliskowe w centrum miasta prowadziła misja niemiecko-iracka pod kierunkiem Petera A. Miglusa. Brali w nich udział również archeolodzy polscy z Instytutu Archeologii Uniwersytetu Warszawskiego.
Historia.
Okres „przedasyryjski”.
Początki miasta nie są znane. Najwcześniejsze znaleziska odkryte w warstwie H wykopu sondażowego w świątyni Isztar pochodzą z okresu wczesnodynastycznego III (ok. 2500 p.n.e.). Materiał z tego okresu znaleziono też w warstwach poniżej Starego Pałacu. Styl wykonania kilku odnalezionych fragmentów posągów z tych warstw wykazuje duże podobieństwo do tych odkrytych w Mari i Kisz. Okres akadyjski (2334–2154 p.n.e.) reprezentują znaleziska z warstwy G świątyni Isztar, a także nieliczne pozostałości odkryte w innych częściach miasta. Ze źródeł pisanych wiadomo, iż miasto znajdowało się wówczas pod kontrolą Imperium Akadyjskiego. Okresowi Ur III odpowiadają warstwy F i E w świątyni Isztar. Z okresu tego pochodzi kamienna płytka z inskrypcją niejakiego Zariquma, lokalnego władcy Aszur, który nazywa siebie w niej sługą Amar-Suena (ok. 2047–2038 p.n.e.), jednego z królów III dynastii z Ur. Na późniejszy okres datowana jest pieczęć cylindryczna odnaleziona w warstwie E świątyni Isztar, nosząca inskrypcję sługi Isi-Dagana, "šakkanakku" z miasta Mari. Isi-Dagan zaś zdaniem uczonych współczesny miał być Iszbi-Erze (2017–1985 p.n.e.), założycielowi I dynastii z Isin.
Okres staroasyryjski.
Na początku II tysiąclecia p.n.e. Asyria wyłania się z mroków historii jako miasto-państwo z miastem Aszur jako religijną oraz administracyjną stolicą. Aszur w tym okresie pełni funkcję ważnego ośrodka handlowego, którego kupcy – jak świadczą tysiące staroasyryjskich tabliczek klinowych odkrytych w Kanesz – docierali aż do Anatolii i zakładali tam kolonie handlowe. O samym mieście Aszur wiele nie wiadomo. Inskrypcje budowlane wczesnych władców asyryjskich z lokalnej dynastii założonej przez Puzur-Aszura I (XX w. p.n.e.) wspominają już o istnieniu w tym mieście świątyni boga Aszura. Nie jest wykluczone, że istniały już wówczas też mury miejskie i świątynie Adada i Isztar. Pierwszym ważniejszym królem asyryjskim był Szamszi-Adad I (1813–1781 p.n.e.), współczesny Hammurabiemu z Babilonu. Po pokonaniu władcy z lokalnej dynastii i przejęciu tronu w Aszur zaczął on poszerzać terytorium Asyrii tworząc w rezultacie rozległe i potężne królestwo. Władca ten znany jest ze swych prac budowlanych w mieście Aszur. To właśnie on wznieść miał Stary Pałac i ziggurat Enlila/Aszura. Na czasy jego panowania datowany jest też najstarszy znany plan świątyni boga Aszura. Z panowaniem Szamszi-Adada I związane jest też występowanie charakterystycznego rodzaju ceramiki malowanej, tak zwanej ceramiki chaburskiej, która znajdowana jest na stanowiskach w północnej Mezopotamii i pn.-zach. Iranie. Po śmierci Szamszi-Adada I kontrolę nad większością terytorium Asyrii przejął Hammutabi z Babilonu. Po upadku dynastii starobabilońskiej (ok. 1595 p.n.e.) polityczną pustkę w pn Mezopotamii wypełnili władcy Mitanni, a Asyria stała się uzależnionym od nich państwem wasalnym. Niewiele wiadomo o historii i archeologii miasta Aszur w tym czasie. Warto jedynie wspomnieć, iż w tym to właśnie okresie, najprawdopodobniej za panowania Aszur-nirari I (ok. 1545-1520 p.n.e.), wzniesiona została świątynia Sina i Szamasza, a za czasów Puzur-Aszura III (ok. 1519-1496 p.n.e.) otoczone zostało murem południowe przedmieście Aszur, które w ten sposób, pod nazwą Nowego Miasta, stało się jego częścią.
Okres średnioasyryjski.
Asyria uwolniła się spod panowania mitannijskiego za panowania Eriba-Adada I (1392–1366 p.n.e.) i jego następcy Aszur-uballita I (1365–1330 p.n.e.). Interesujące znalezisko z Aszur z tego okresu to tzw. "stelenreihe" („rząd stel”), rodzaj asyryjskiego kalendarium (ustawione w rzędach stele, z których każda wymienia imię asyryjskiego króla, królowej lub wysokiego urzędnika państwowego, począwszy od Eriba-Adada I, a na żonie Aszurbanipala kończąc). Ponieważ jeden zdolny władca asyryjski zaczął następować po drugim, na pocz. XIII w. p.n.e. Asyria ponownie zaczęła nabierać znaczenia, by pod koniec tego wieku stać się jedną z największych potęg na Bliskim Wschodzie. Asyryjscy królowie związani z utworzeniem tzw. Imperium Środkowoasyryjskiego to Adad-nirari I (1307–1275 p.n.e.), jego syn Salmanasar I (1274–1245 p.n.e.) i wnuk Tukulti-Ninurta I (1244–1208 p.n.e.). Wszyscy oni prowadzili prace budowlane i restauracyjne w Aszur. Za panowania Adad-nirari I Stary Pałac został odbudowany, a prace restauracyjne przeprowadzono w świątyniach Aszura oraz Sina i Szamasza. Salmanasar I przebudował częściowo świątynię Aszura. Tukulti-Ninurta I zainicjował nowy program budowlany. Za jego panowania powstała nowa świątynia Isztar, wykopano przed murami miejskimi głęboką fosę, a w pn.-zach. rogu Starego Miasta wzniesiono wielki sztuczny taras, na którym zbudowano jego Nowy Pałac. Niestety z powodu późniejszych prac budowlanych kolejnych władców po tym ostatnim pozostało niewiele śladów. Tukulti-Ninurta I rozpoczął też budowę nowej rezydencji królewskiej w Kar-Tukulti-Ninurta, około 3 km na północ od Aszur, po przeciwnej stronie Tygrysu. Z okresu środkowoasyryjskiego pochodzą znalezione w Aszur: tzw. ołtarz Tukulti-Ninurty I z reliefem przedstawiającym go w czasie modlitwy przed symbolem bóstwa, a także pewna liczba pieczęci cylindrycznych w charakterystycznym środkowoasyryjskim stylu. Niewiele wiadomo o tym, co działo się w Aszur po śmierci Tukulti-Ninurty I. Chociaż Aszur najprawdopodobniej nie straciło na znaczeniu, to dalsze prace budowlane w tym mieście poświadczone są dopiero z czasów panowania Aszur-resza-iszi I (1133–1116 p.n.e.) i jego następców. Aszur-resza-iszi wzniósł nową świątynię Isztar. Jemu też przypisuje się wzniesienie podwójnej świątyni Anu i Adada, której cechą charakterystyczną był mały ziggurat przyległy do każdego z sanktuariów. Dwaj kolejni władcy Aszurnasirpal I (1049–1031 p.n.e.) i Salmanasar II (1030–1019 p.n.e.) prowadzili prace budowlane przy zigguracie Enlila/Aszura.
Okres nowoasyryjski.
Początek X wieku p.n.e. w Asyrii wyznacza początek okresu, w którym państwo to stanęło u szczytu potęgi. W tym czasie Aszur przestaje być administracyjną stolicą państwa, która za czasów Aszurnasirpala II (883–859 p.n.e.) przeniesiona zostaje do Kalhu. Nie oznacza to jednak końca prac budowlanych w samym Aszur. Aszurnasirpal II lub jeden z jego poprzedników przebudowuje i przekształca Stary Pałac w mauzoleum, w którym znaleziono komory grobowe i sarkofagi królów asyryjskich. Salmanasar III (858–824 p.n.e.) wzmacnia fortyfikacje miasta (obwiedzenie Starego Miasta murem wewnętrznym), przebudowuje świątynię Anu i Adada i wznosi nową świątynię Isztar. Podczas gdy administracyjna stolica przeniesiona zostaje do Dur-Szarrukin przez Sargona II (721–705 p.n.e.), a następnie do Niniwy przez Sennacheryba (704–681 p.n.e.), o tym co działo się w Aszur w VIII i na początku VII wieku p.n.e. wiemy niewiele. W czasie panowania Sennacheryba na zachód od miasta, poza murami, wzniesiony został tzw. dom akitu, który odgrywał ważną rolę w czasie święta Nowego Roku. Na terenie miasta wzniesiony natomiast zostaje tzw. pałac następcy tronu i przebudowane zostają świątynia Sina i Szamasza oraz świątynia Aszura. Jedynym godnym uwagi znaleziskiem z tego okresu jest mocno uszkodzony kultowy basen odkryty w Starym Pałacu. Kolejni władcy, Asarhaddon (680–669 p.n.e.) i Aszurbanipal (668–627 p.n.e.) prowadzili prace restauracyjne przy świątyni Aszura i zigguracie Enlila/Aszura. W okresie panowania Sin-szar-iszkuna zostaje wzniesiona ostatnia asyryjska budowla w Aszur – podwójna świątynia Isztar i Nabu. W 614 roku p.n.e. armia medyjska zdobywa i niszczy kompletnie miasto. Ślady poasyryjskiego zasiedlenia są niemal niezauważalne.
Okres partyjski.
Z początkiem I wieku p.n.e. stanowisko to odzyskało pewne znaczenie jako rezydencja partyjskiego satrapy. Partyjska nazwa miasta wciąż pozostaje nieznana. Najważniejsze budowle z tego okresu to świątynia Aszura-Szeruy wzniesiona na ruinach asyryjskiej świątyni Aszura oraz pałac partyjski w płd części miasta. Partyjskie miasto zniszczone zostało w III wieku n.e. przez Szapura I (241–272). Miasto nigdy nie zostało ponownie odbudowane ani zasiedlone.
Gubernatorzy Aszur.
W tekstach asyryjskich z okresów średnio- i nowoasyryjskiego wspominani są gubernatorzy Aszur noszący tytuły "šakin māti" („gubernatora kraju”) i "šakin Libbi-āli" („gubernatora Libbi-ali”). Najstarszymi tekstami z okresu nowoasyryjskiego, w których wzmiankowani są gubernatorzy Aszur, są inskrypcje króla Adad-nirari II (911-891 p.n.e.): w jednej z nich, datowanej na 909 r. p.n.e., wzmiankowany jest gubernator Aszur ("šakin Libbi-āli") o imieniu Gabbija-ana-Aszur, natomiast w innej mowa jest o Adad-ahu-iddinie, gubernatorze Aszur ("šakin Libbi-āli") i eponimie (897 r. p.n.e.). Począwszy od panowania Adad-nirari III (810-783 p.n.e.) gubernatorzy Aszur zaczynają pojawiać się regularnie w asyryjskich listach i kronikach eponimów jako urzędnicy "limmu". I tak eponimami byli: Ilu-issija ("šakin māti") w 804 roku p.n.e., Pan-Aszur-lamur ("šakin māti") w 776 roku p.n.e., Adad-belu-ka’’in ("šakin māti") w 748 i 738 roku p.n.e. oraz Tab-sil-Eszarra ("šakin Libbi-āli") w 716 roku p.n.e.

</doc>
<doc id="13195" url="https://pl.wikipedia.org/wiki?curid=13195" title="Kultura kreteńska">
Kultura kreteńska



</doc>
<doc id="13196" url="https://pl.wikipedia.org/wiki?curid=13196" title="Historia sztuki">
Historia sztuki

Historia sztuki (, ) – dyscyplina nauk humanistycznych, której przedmiotem poznania są sztuki wizualne w ujęciu historycznym; działami historii sztuki są historia architektury, historia malarstwa, historia rzeźby oraz historia sztuki użytkowej (sztuki stosowanej). 
Klasyczna zachodnia historia sztuki ogranicza się do zagadnień malarstwa, grafiki, rzeźby i architektury Europy od paleolitu do współczesności oraz obu Ameryk po 1494 r. Należy odróżnić historię sztuki od krytyki artystycznej czy estetyki, która jest dziedziną filozoficzną skupiającą się na pojęciu piękna.
Pochodzenie dziedziny.
Początki piśmiennictwa zajmującego się sztuką sięgają starożytności. Pierwsze zachowane zapiski o sztuce to teksty Ksenokratesa z Sykionu (III wiek p.n.e.) i Durisa z Samos (IV wiek p.n.e.). O rozwoju rzeźby i malarstwa greckiego pisał Pliniusz Starszy w swojej encyklopedycznej "Historii naturalnej". W średniowieczu zaś swoistą analizę porównawczą architektury możemy znaleźć w XIII-wiecznej "Kronice Gerwazego z Canterburry", w której porównywano stary spalony kościół z nowym, odbudowanym.
Giorgio Vasari i historie artystów.
Za jednego z pierwszych autorów biografii artysty uznać można Antonio Manettiego, twórcy manuskryptu o Filippo Brunelleschim. Swoją autobiografię napisał prawdopodobnie Lorenzo Ghiberti. Zaś za pierwsze pełnoprawne opracowanie historii sztuki uważa się "Żywoty najsławniejszych architektów, malarzy i rzeźbiarzy włoskich, od czasów Cimabuego do naszych czasów" florenckiego malarza Giorgia Vasariego, wydane po raz pierwszy w 1550 r. we Florencji na zlecenie Kosmy I Medyceusza, księcia Toskanii. Dzieło ugruntowywało pozycję Florencji jako głównego ośrodka odrodzenia sztuki oraz rodu Medyceuszy jako jej mecenasów. Vasari przedstawił w nim liniową koncepcję upadku sztuki (zgodnej z paradygmatem mimesis) w średniowieczu i jej stopniowego odradzania przez trecento, quattrocento i ostatecznie cinquecento, gdzie znaleźć miała kulminację w osobie Michała Anioła. Poza cykliczną naturą sztuki i jej wstępną periodyzacją, Vasari ustanowił również wzór formalny dla opracowań historii sztuki jako historii artystów. "Żywoty..." są de facto zbiorem biografii od Cimabuego do Michała Anioła. Dzieło miało być ściśle związane z charakterem autora, dlatego ważne było przedstawienie faktów z jego życia, które obrazowałyby i uzasadniały jego usposobienie.
Opracowanie Vasariego okazało się być bardzo wpływowym i inspirującym dla kolejnych badaczy sztuki. Wzorowali się na nim m.in. Karel van Mander pisząc "Het Schilder-Boeck" z biografiami artystów niemieckich i holenderskich, czy Joachim von Sandrart, autor "Teutsche Akademie der edlen Bau-, Bild- und Malereikuenste". Sto lat po Vasarim swoje "Żywoty nowoczesnych malarzy, rzeźbiarzy i architektów" napisał antykwariusz Gian Pietro Bellori, porzucając jednak zasadę komplementarności i bardziej ukierunkowując wybór artystów. Uważa się go również za prekursora ikonografii. 
Winckelmann i krytyka artystyczna.
Do sposobu Vasariego krytycznie odniósł się Johann Joachim Winckelmann, badacz Pompei i Herkulanum, kładąc większy nacisk nie na charakter autora dzieła, a erudycję odbiorcy, co odczytywać można jako początki krytyki artystycznej. Jego "Geschichte der Kunst des Altertums" z 1764 r. (wyd. polskie ze zmianami Stanisława Kostki Potockiego "O sztuce u dawnych, czyli Winkelman polski" opublikowano w 1815 r.) na długi czas wpłynęła na widzenie sztuki greckiej i rzymskiej, a także sztuki w ogóle, przyczyniając się do rozwoju klasycyzmu w sztuce. Winckelmann uważał, że szczytem sztuki jest osiągnięcie piękna, czego dokonać może tylko artysta, który sam sobie narzuci rygorystycznie przestrzeganą koncepcję dzieła z "edle Einfalt und stille Größe" (szlachetną prostotą i spokojną wielkością). Przedstawiając sztukę starożytnej Grecji nakreślił również obraz ówczesnych warunków ekonomicznych, politycznych i społecznych, które miały przyczynić się do jej artystycznego rozwoju.
W tym samym okresie pisał również włoski architekt Giovanni Battista Piranesi, badając i rysując głównie rzymską architekturę. Ostatecznie jednak to wpływ Winckelmanna okazał się decydujący, w efekcie czego historia sztuki zdominowana została przez niemieckojęzyczne centra intelektualne. Jego dzieła zainspirowały Goethe i Schillera do własnych rozmyślań o sztuce. Niezwykle wpływowe były poglądy na sztukę Kanta, który rozpropagował figurę „artysty-geniusza” oraz Hegla i jego „Ducha Czasu”. W duchu tego drugiego powstały prace Karla Schnaase, które stały się podwalinami dla historii sztuki jako nowoczesnej dyscypliny naukowej. Pierwsza katedra historii sztuki powstaje w 1813 na uniwersytecie w Getyndze.
Wölfflin i analiza formalna.
Na przełomie XIX i XX wieku wiodącymi ośrodkami historii sztuki pozostawał Berlin z dużymi wpływami heglizmu, Bazylea i Zurych z kluczową osobą Jacoba Burckhardta, który heglizm odrzucał, oraz Wiedeń. Dużą rolę zyskał formalizm, zwłaszcza teoria formy i stylu Heinricha Wölfflina. W przeciwieństwie do Vasariego, nie przykładał on większej uwagi do życiorysów artystów. Będąc uczniem Burckhardta, który ukuł współczesne pojęcie renesansu, skupił się na wykazaniu różnic między renesansem a barokiem. Były one dla niego przejawem niezmiennych cykli, przez które przechodzi sztuka, od fazy wczesnej przez klasyczną i barokową. Owe zmiany stylistyczne można było rozpoznać tylko przez analizę formalną, opartą na opozycji pięciu par pojęć:
Na tej podstawie Wölfflin próbował skonstruować pojęcie stylu jako zespołu powtarzających się form powiązanych logicznie w większą strukturę. Roger Fry zaś rozszerzył później formalizm na sztukę nowoczesną. Sam Wölfflin w późniejszym okresie badał również "style narodowe", wyodrębniając styl "włoski" i "niemiecki" na podstawie swoich badań nad twórczością Dürera. Jako jeden z pierwszych używał na swoich zajęciach ówczesnych projektorów - magicznych latarni, do pokazywania i porównywania dzieł.
Wiedeńska szkoła historii sztuki.
Równocześnie z Wölfflinem działali badacze skupieniu wokół wiedeńskiej szkoły historii sztuki. Starali się nadać dyscyplinie bardziej naukowego rygoru, dystansując ją od osobistych osądów i gustów. Dzięki pracom Moritza Thausinga udało się ukonstytuować historię sztuki jako kierunek odrębny od estetyki, zaś jego uczniowie, Alois Riegl i Franz Wickhoff określani są "pierwszym pokoleniem wiedeńskiej szkoły". Riegl i Wickhoff rozwinęli metodę porównywania stylistycznego, wychodząc z pozytywistycznego nastawienia odrzucenia wszelkich przejawów metafizyki i skupieniu się na aspektach formalnych dzieła. Dokonali ponownej oceny sztuki późnego antyku, dowartościowując ów okres, wcześniej uważany za etap regresu. Przeciwstawiali się burzeniu zabytków, przez co uznawani są za prekursorów ich ochrony. 
Do tzw. "drugiego pokolenia" szkoły wiedeńskiej zalicza się m.in. Maxa Dvořáka, Juliusa von Schlossera, Hansa Tietze, Karla Marię Swobodę czy Josefa Strzygowskiego. W tym samym czasie w Wiedniu uczył się także Ernst Gombrich. Dvořák kontynuował badania nad sztuką wczesnochrześcijańską, odszedł jednak od formalizmu Riegla. W duchu Hegla stworzył koncepcję "Geistesgeschichte" - historii idei, wedle której sztuka była emanacją ducha epoki. Pozostawał również pod silnym wrażeniem współczesnego dla niego ekspresjonizmu. Schlosser skupił się na analizach stylistycznych, wzorując się na metodach językoznawczych i zbliżając historię sztuki do strukturalizmu, zachowując przy tym szeroko humanistyczne nastawienie. Opozycję do Dvoraka i Schlossera stanowił Strzygowski, który zajmując się sztuką bizantyjską, koptyjską i islamską, rozwinął teorie orientalne, upatrując we wpływie kultur wschodnich źródło degradacji sztuki rzymskiej, czym atakował wcześniejsze prace Riegla i Wickhoffa. Prace Strzygowskiego ujawniają jednak jego rasistowskie i pangermańskie nastawienie. 
Po przejęciu władzy przez nazistów w Austrii, wielu historyków sztuki zostało zmuszonych do opuszczenia kraju. Wiedeńską szkołę zdominował Hans Sedlmayr, który odrzucał kontekstualizację sztuki, skupiając się niemal wyłącznie na wartościach estetycznych dzieła. Krytykowano go za skrajny formalizm oraz rasizm i aktywną przynależność do partii nazistowskiej. Po wojnie władzę nad instytutem historii sztuki przejął Karl Maria Swoboda, starający się pogodzić wcześniejsze teorie Shlossera i Strzygowskiego. 
Metodologie historii sztuki.
Korzenie współczesnych metod dyscypliny sięgają już XVIII i XIX wieku. Celem tzw. "pierwszej" historii sztuki jest określenie miejsca i czasu powstania dzieła, a także przypisanie dzieła konkretnemu artyście (atrybucja) jeśli nie jest on znany. Objaśnienie treści dzieła (ikonografii) i jego interpretacja (analiza ikonologiczna) należy natomiast do tzw. "drugiej" historii sztuki. Poza kwestiami formalnymi, historycy sztuki badać mogą także kontekst, postrzeganie dzieła, role galerii i muzeów, władzy i ideologii oraz warunków wytwarzania. W przeciwieństwie do nauk ścisłych, używanie różnych metodologii nie będzie prowadzić do udowodnienia danej teorii i wyczerpania tematu, lecz pozwoli lepiej zdefiniować pytania badawcze, generując często kolejne zagadnienia lub doprowadzając do reinterpretacji dzieła i znalezienia nowych znaczeń. Z racji swej dość interdyscyplinarnej natury, historia sztuki często wykorzystuje teorie i metodologie powstałe na gruncie innych dziedzin, szczególnie filozofii i literaturoznawstwa.
Ikonografia i ikonologia Panofsky'ego.
W przeciwieństwie do wielu innych teorii, które historia sztuki zaadoptowała z innych dziedzin, metody ikonograficzne i ikonologiczne powstały oryginalnie na łonie dziedziny i można je wywieźć od Pilniusza Starszego przez Giovanniego Pietro Bellori i Winckelmanna. Nowoczesną metodę ikonograficzną rozwinął m.in. Aby Warburg, kontynuując niejako formalizm Wölfflina, ale przykładając większą uwagę do wpływów religii, polityki i życia społecznego. Jego uczniem był Erwin Panofsky, który określił konkretne etapy analizy ikonograficzno-ikonologicznej:
Sposób ten porównywalny był do wcześniejszych teorii Dvořáka, jednak do jego analizy formalnej i treściowej Panofsky dodał również tematyczną. Metoda Panofsky'ego miała wielki wpływ na rozwój historii sztuki aż do lat 50. XX wieku. W Polsce propagował ją Jan Białostocki, rozwijając o termin "grawitacji ikonograficznej", określającej proces, w którym znane motywy zmieniały znaczenia. Podobnie jak toposy w literaturze, tak w sztuce istnieć mają "tematy ramowe", które są niezwykle trwałe mimo zmieniających się warunków społecznych i kulturowych, np. wizerunek matki z dzieckiem.
Analiza Panofsky'ego została poddana większej krytyce dopiero w latach 60., po wykształceniu się krytycznej "New Art History", dla której formalistyczne metody zwracały zbyt małą uwagę na rolę widza i kontekst społeczny.
Psychoanaliza.
Badanie wrażenia, jakie dzieło sztuki wywołuje w umyśle odbiorcy, wywieźć można już od starożytnej ekfrazy. Współczesne metody psychoanalizy zapożyczone zostały zaś od Zygmunta Freuda. Chociaż jego prace były później wielokrotnie krytykowane (zwłaszcza z pozycji feministycznych) idea stłumionego pożądania odkładanego w podświadomości i wyrażanego później przez sublimację w twórczości, stała się dla historyków sztuki bardzo inspirująca. Tzw. "metoda topograficzna" pomija szerszy kontekst powstania dzieła, a skupia się na znaczeniach, które artysta, świadomie bądź nie, w nim zawarł.
Rozwinięciem psychoanalizy na polu sztuki były również teorie Jacquesa Lacana, dla którego dzieło nie było prostym przedstawieniem. Według niego, sztuka przedstawia obecność rzeczy jako ich nieobecność, przez co pomaga społeczeństwu radzić sobie z jej brakiem. Pozwoliło to metodom psychoanalizy na badanie nie tylko psychiki artysty, ale i sublimacji w szerszym, społecznym zakresie, które dokonywać się ma za pomocą sztuki.
Jeszcze większą uwagę na widza przeniosły teorie recepcji Ernsta Krisa i Ernsta Gombricha. Wedle Krisa, artysta zapewnia widzowi pośrednio gratyfikację przez dzieło sztuki, poprzez proces regresji, która w takich warunkach nie pojawia się jako mechanizm obronny. Dla Gombricha zaś dzieło sztuki było zapisem postrzegania, które u artysty kształtują wcześniejsze widziane przez niego reprezentacje, należące do jego tradycji kulturowej. Zwracał przez to dużą uwagę na rolę gruntu społecznego w powstawaniu dzieła i zdawał sobie sprawę, że sama psychoanaliza jest niewystarczająca dla pogłębionych badan. Bardziej niż określanie cech danego stylu zajmował go problem tego, jak styl w ogóle powstaje.
Recepcją zajmował się także Rudolf Arnheim, będący również psychologiem Gestalt. Skupiał się na doznaniach sensorycznych, badając, jak wzrok zwraca uwagę na takie wzorce jak równowaga, kolory, ruch, światło, przestrzeń czy forma. Dla Arnheima artystyczna ekspresja to sposób twórców na wyrażanie ich myśli.
Inną interpretację lacanowskiego terminu "spojrzenia" historia sztuki przejęła od teorii filmu. Reżyserka i teoretyczka Laura Mulvey zwróciła uwagę na istnienie tzw. "male gaze". Posługując się psychoanalizą, uznała, że odbiorcy dzieł czerpią przyjemność przez oglądanie (swoisty voyeuryzm) oraz identyfikację. Na przykładzie kina hollywoodzkiego pokazała, iż filmy wspierają głównie patriarchalne podejście i punkt widzenia białego, heteroseksualnego mężczyzny. To właśnie oni są standardowymi bohaterami dzieł, co przyczyniać się może do tłumienia tożsamości kobiet czy osób nieheteronormatywnych. Teoria spojrzenia wniosła do historii sztuki głębsze badanie indywidualnego doświadczenia postrzegania.
Hermeneutyka.
Dla nowoczesnej hermeneutyki niebiblijnej kluczowe były prace Martina Heideggera i Hansa-Georga Gadamera. Wedle Heideggera, człowiek "istnieje w świecie" i nie może siebie zrozumieć z perspektywy dystansu czy racjonalizmu, lecz przez jako część świata. Doprowadziło to do stworzenia pojęcia "przed-zrozumienia" w kategorii poznania. W tzw. kole hermeneutycznym, zanim interpretator podejmie się interpretacji dzieła, już coś sobie o nim wyobraża, dlatego niemożliwa jest interpretacja "od zera". W efekcie zrozumienie każdej poszczególnej części oznacza zrozumienie całości. Gadamer rozwinął tę teorię, jeszcze mocniej akcentując rolę osadzenia artysty, dzieła i badacza w danej kulturze. Artysta i interpretator zawsze będą ograniczeni różnymi horyzontami kulturowymi czy intelektualnymi, dlatego interpretacja sztuki to dialog, w rezultacie którego ani dzieło ani interpretacja nie pozostają takie same. Nie ma więc jednego prawidłowego zrozumienia, wszystkie interpretacje są relatywne i zależne od miejsca i czasu. Zbliżało to rozważania Gadamera do psychologii postaci i teorii recepcji.
Chociaż hermeneutyka powstała do badania literatury, z powodzeniem znalazła zastosowanie także przy sztukach plastycznych. Historycy sztuki przejęli od niej większy sceptycyzm w stosunku do intencji autora dzieła. Oskar Bätschmann przesunął uwagę z ikonografii na doświadczanie dzieła sztuki przez nie samo. Badał wzajemne relacje między doświadczeniem estetycznym a wiedzą historii sztuki oraz działalnością artysty. Gottfried Boehm, czerpiąc także z historii idei i fenomenologii, ukuł z kolei pojęcie "zwrotu ikonicznego", które miało objaśniać proces masowego rozprzestrzeniania się przedstawień wizualnych w XX wieku. W Polsce dużym ośrodkiem badań hermeneutycznych jest Instytut Kulturoznawstwa Uniwersytetu Adama Mickiewicza w Poznaniu.
Marksizm.
W tekstach Karola Marksa i Fryderyka Engelsa sztuka należała do "nadbudowy" społeczeństwa, w przeciwieństwie do "bazy", którą stanowiła ekonomia i relacje klasowe. Marks zaliczał sztukę do "form ideologicznych", którymi klasa burżuazyjna utrzymuje korzystne dla siebie warunki społeczne. Równocześnie jednak sztuka sama mogła stać się formą dla rewolucyjnej klasy robotniczej, którą podważyłaby relacje władzy. W przeciwieństwie do wielu obowiązujących wówczas filozofii sztuki (np. kantowskiej czy heglowskiej), Marks i Engels nie czynili większego rozróżnienia między pracą a sztuką, przez co nie postrzegali artystów jako genialnych jednostek. 
Późniejszy teoretyk marksistowski, Antonio Gramsci, nadawał sztuce i kulturze większą rolę - nie siła czy prawo, lecz sztuka miała być głównym narzędziem, przez które burżuazja oddziałuje na resztę społeczeństwa i podtrzymuje system korzystny tylko dla niej. György Lukács, rozwijając teorię fetyszyzacji Marksa, stwierdził, iż kapitalizm sprowadził rzeczy, w tym dzieła sztuki, wyłącznie do przedmiotów wymiany, np. pieniędzy czy prestiżu. To właśnie sztuka miała być jedynym sposobem na zatrzymanie ogólnego urzeczowienia, jako że pośredniczy między jednostką a ogółem, przez co zacieśnia relacje społeczne i ubogaca, a nie wyobcowuje.
Problematyką sztuki zajmowali się także badacze krytycznej Szkoły Frankfurckiej, jak Max Horkheimer i Theodor Adorno, badając sztukę ludową czy industrialną. Wedle nich, społeczeństwo kapitalistyczne wytwarzać miało tanią, otępiającą sztukę, używaną w celu zaspokojenia fałszywych, konsumpcyjnych pragnień. Odwracać to miało uwagę od takich wartości jak równość, wolność czy twórczość. Adorno bronił trudnej w odbiorze nowoczesnej sztuki czy muzyki, upatrując w niej możliwość prowokowania radykalnych zmian oraz pogodzenia klas pracujących w celu osłabienia dominującej ideologii.
Guy Debord w swoim "Społeczeństwie spektaklu" rozważał, w jakim stopniu sztuka pomaga władzy kapitalistycznej, a w jakim może przyczynić się do jej osłabienia. Sam był członkiem Międzynarodówki Sytuacjonistycznej, dążącej do zatarcia granic między życiem a sztuką i przygotowaniem gruntu pod przyszłą rewolucję.
Materialistyczna i społeczna historia sztuki postrzega sztukę bardziej jako produkt skomplikowanych relacji politycznych, ekonomicznych i społecznych, niż "artystów-geniuszów". Arnold Hauser w swojej "Społecznej historii sztuki i literatury" skupiał się na związkach sztuki z gospodarką i klasami społecznymi. Michael Baxandall, uczeń Gombricha w Instytucie Warburga, w swoim dziele "Painting and Experience in Fifteenth-Century Italy" przedstawił renesansową sztukę włoską jako "relikt życia gospodarczego", badając złożone relacje między artystami a fundatorami, cenniki dzieł i ceny używanych materiałów.
Strukturalizm i poststrukturalizm.
Strukturalizm wywieźć można z prac Claude Lévi-Straussa, który przeniósł analizę systemów językowych na inne zjawiska kulturowe, szczególnie na interpretację mitów. Mity miały dawać sprowadzić się do podstawowych elementów, a do tego wyjaśniać logicznie istniejące w świecie opozycje binarne: piękno i brzydota, altruizm i egoizm, itd. Podobnie jak w teorii recepcji, strukturaliści sceptycznie podchodzili do idei autorstwa i postaci "artysty-geniusza", podkreślając znaczenie systemów (struktur) językowych czy kulturowych, które istnieją zanim autor stworzy dane dzieło. Artyści bowiem mogą komunikować pewne rzeczy bez świadomej intencji. Myślenie to doprowadziło do "śmierci autora" Rolanda Barthes'a, według którego: "śmierć autora jest ceną za narodziny czytelnika". Dzieło sztuki zbierać ma różnorodne kody z danej kultury, co świadczy o jego intertekstualności.
Na krytyce strukturalizmu, głównie jego ahistoryczności i założeniu "idealnego widza", wyrósł poststrukturalizm. Wedle Michaiła Bachtina, język zawsze jest ideologiczny a ponadczasowe struktury nie istnieją. Julia Kristeva zaś określiła kulturę nie mianem struktury, lecz procesu ciągłej "strukturalizacji". Kluczowe w rozwoju teorii były prace Michela Foucaulta, dla którego historia zawsze badana była, by wyjaśnić przyczyny teraźniejszości. Skupiał się na analizie relacji władzy, jej oddziaływaniu na społeczeństwo i ludzkie ciało, co rozwinęło jego badania w stronę nie poruszanych wcześniej tematów, takich jak historia seksualności, więziennictwa, szaleństwa. Rozwinął pojęcie dyskursu, który miał skupiać w sobie m.in. teksty, obrazy, praktyki kulturowe czy idee, oraz służyć władzy do określenia ram rzeczywistości. 
Elementy myśli strukturalnej, takie jak binarne opozycje, pojawiały się w historii sztuki już dawniej, np. u Wölfflina. Sam poststrukturalizm zaś istotnie zmienił historię sztuki - jak twierdzi Norman Bryson, interpretacja historyków nie może opierać się wyłącznie na zebranej dokumentacji czy świadectwach. Często jest ich tak dużo, że opcje interpretacji są w zasadzie nieograniczone, dlatego kluczowe staje się wybranie przez badacza danej metody. Historia "nie czeka po prostu na odkrycie", a ważna jest nie tylko przeszłość ale i teraźniejszość, która warunkuje sposób interpretacji.
Poststrukturalizm zmienił również myślenie o mimesis: formy wizualne nie są ujęciem istoty świata przez artystę, lecz są jego wartościującymi interpretacjami, różnymi w zależności od miejsca i czasu. Zamiast skupiać się na pojedynczych okresach czy artystach, badania poststrukturalne częściej wybierają za swój temat jeden motyw, pytając o cel, w jakim artysta ponownie wykonywał dane przedstawienie, o jego rezultat czy o oddziaływanie innych dzieł. Idee Foucaulta dotyczące władzy i politycznej technologii ciała zainspirowały z kolei badania nad instytucjami muzeów i galerii.
Feminizm.
Początki tej metody związane są z drugą falą feminizmu i artykułem Lindy Nochlin: "Dlaczego w sztuce nie było wielkich artystek?" Wg Nochlin kobietom trudniej było kształcić się w artystycznych zawodach - nie mogły chociażby uczyć się anatomii rysując nagiego męskiego modela. Również historycy sztuki mogli nie dostrzegać nielicznych artystek, gdyż kanon "wielkich artystów" promował model "artysty-geniusza", do którego z definicji łatwiej pasowali mężczyźni. Wg Nochlin metodologia feministyczna nie powinna więc skupiać się ściśle na dodawaniu żeńskich nazwisk do "kanonu", lecz zmieniać sam paradygmat myślenia o wybitnych artystach.
W Wielkiej Brytanii czołową przedstawicielką feministycznej historii sztuki pozostaje Griselda Pollock zajmująca się kwestią genderową w sztuce artystek i w ukazywaniu kobiet. Wraz z Rozsiką Parker wydała "Old Mistresses: Women, Art and Ideology," w której, wspierając się na teoriach marksistowskich i studiach kulturowych, badają, w jaki sposób artystki negocjują swój status kobiety oraz przedstawiają swoją kobiecość. Do rozwoju metodologii feministycznej w znacznym stopniu przyczyniły się prace Normy Broude i Mary Garrard, które poza własnymi badaniami (zwłaszcza o artystce Artemisii Gentileschi) sukcesywnie publikowały zbiory feministycznych tekstów
Feministyczna historia sztuki bada więc, w jaki sposób fakt identyfikowania się twórcy jako kobiety miał wpływ na przebieg jej kariery bądź formę dzieła, lub sposobu, w którym postacie kobiece zostały w danym dziele przedstawione. Badaczka Patricia Matthews wyróżnia trzy cele feministycznej teorii:
Według Alice Walker konieczne jest także poszerzenie badanych dziedzin sztuki. Oprócz takich tradycyjnych, jak malarstwo, rzeźba czy architektura, które były łatwiej dostępne mężczyznom, należy także badać ceramikę, tkaninę bądź ogrody, gdyż były to często jedyne pola, na których kobiety (zwłaszcza czarne) mogły wyrażać się artystycznie. Według Pollock i Parker podział na sztukę "niską" i "wysoką" w wielu miejscach pokrywa się właśnie ze sztuką wykonywaną tradycyjnie przez mężczyzn i kobiety. O roli męskiego spojrzenia, które łączy kobiety i ich ciało tradycyjnie z naturą a nie "sztuką wysoką" pisała zaś Amelia Jones, zajmująca się sztuką ciała.
Wraz z rozwojem trzeciej fali feminizmu, feministyczna historia sztuki poszerzyła się o zagadnienia lesbijek i kolorowych kobiet. O nieustannym przenikaniu się tych wątków pisała w swoich pracach m.in. bell hooks. Z kolei Freida High Wasikhongo Tesfagiorgis zwróciła uwagę na "pół-niewidzialny" status czarnoskórych artystek, które nie znajdują się ani w sferze badaczy feministycznych, ani afroamerykańskich.
LGBTI Studies, Teoria Queer.
Podobnie jak w przypadku teorii feministycznej, początkowym celem LGBTI Studies było poszukiwanie artystów i artystek homoseksualnej orientacji, badanie dzieł sztuki o tematyce homoerotycznej oraz dokumentowanie gejowskiej i lesbijskiej tożsamości. Teoria Queer zaś skupiała się bardziej na tzw. "przymusowym heteroseksualizmie" i tego, jak organizuje on społeczeństwo, spychając inne identyfikacje seksualne i genderowe. Historia LGBTI Studies i Queer Theory ściśle związana jest z rozwojem ruchu równouprawnienia społeczności LGBT, z wydarzeniami takimi jak zamieszki na Stonewall czy epidemią AIDS. Kluczowe role w rozwoju teorii odegrały dzieła Michela Foucaulta, jak "Historia seksualności" czy Judith Butler i "Uwikłani w płeć". Butler znacząco rozwinęła gender studies, wprowadzając takie pojęcia jak "performatywność płci" czy "heteromatriks". Jak przyznaje Jonathan Weinberg, spośród nauk humanistycznych to historia sztuki najpóźniej zaczęła zwracać uwagę na związek między dziełami a orientacją seksualną.
W praktyce większość badaczy łączy podejścia LGBTI Studies i teorii Queer. Ważnymi opracowaniami korzystającymi z tych teorii jest m.in. "Gay and Lesbian Studies Art History" Whitneya Davisa, czy "Speaking for Vice: Homosexuality in the Art of Charles Demuth, Marsden Hartely, and The first American Avant-Garde" Weinberga. W Polsce do badaczy zajmujących się tymi zagadnieniami należą m.in. Paweł Leszkowicz, kurator pierwszej homoerotycznej wystawy w Muzeum Narodowym w Warszawie "Ars Homo Erotica", czy artysta Karol Radziszewski, założyciel Queer Archives Institute.
Postkolonializm.
Postkolonializm oznaczać może "każdą kulturę dotkniętą procesem ideologii imperialistycznej od momentu kolonizacji do dnia dzisiejszego". Badacze zwracają uwagę na różnorodność zależności kolonialnych, ze względu na rasę, klasę społeczną, religię czy płeć. W rozwoju teorii postkolonialnej kluczowe były prace Edwarda Saida, który opierając się na teoriach Foucaulta dotyczących dyskursu i władzy, badał jak Zachód używał pojęcia "orientalizmu", by uczynić Wschód "egzotycznym" w celu jego podporządkowania. Stuart Hall zaś podkreślał, że systemy kolonialne są na tyle silne, że kolonizowani sami zaczynają postrzegać siebie jako niecywilizowanych i innych.
Postkolonialna historia sztuki bada głównie przedstawienia kolonizowanych narodów, najczęściej na filmach, plakatach czy pocztówkach. Ważne są także zagadnienia architektury kolonialnej czy hybrydyzacji - łączeniu przez artystów różnych kultur i tradycji.
Historia sztuki w Polsce.
Początki historii sztuki w Polsce wiążą się z tzw. starożytnictwem (np. publikacje i artykuły Ambrożego Grabowskiego, poświęcone głównie Krakowowi), pracami inwentaryzatorskimi i gromadzeniem materiałów biograficznych. Jednak te pierwsze dzieła teoretyczne i przewodniki, powstające od XVII wieku nie były jeszcze dziełami historii sztuki. Nowoczesna historia sztuki na ziemiach polskich zaczęła się kształtować około 1870 roku. Nauką uniwersytecką stała się pod koniec XIX wieku - w 1882 na Uniwersytecie Jagiellońskim powstała pierwsza Katedra Historii Sztuki w Polsce (obecnie Instytut Historii Sztuki Uniwersytetu Jagiellońskiego), którą objął Marian Sokołowski. Druga katedra została stworzona na Uniwersytecie Lwowskim.
W 1920 powołano w Krakowie Związek Polskich Historyków Sztuki pod przywództwem Jerzego Mycielskiego, z oddziałami w Warszawie i Lwowie, zaś od lat 30. również w Poznaniu. Ważniejsze zmiany w tym okresie dokonały się na zjeździe w październiku w 1934 roku, gdzie przemianowano związek na Stowarzyszenie Historyków Sztuki i Kultury o celach związanych ściśle z ochroną zabytków i popularyzacją sztuki.
W czasie II wojny światowej działalność związku zeszła do podziemia. Po wojnie główną siedzibę Stowarzyszenia przeniesiono do Warszawy, zaś jego prezesem został prof. Stanisław Lorentz. Działalność członków skupiła się na rewindykacji zagrabionych dzieł sztuki i odbudowie zabytków. Polscy historycy sztuki byli silnie reprezentowani na Kongresie Kultury Polskiej w 1981 roku, na którym środowiska twórcze odrzuciły zależność od polityki kulturalnej PZPR. Kongresowi przewodniczył jeden z bardziej rozpoznawalnych historyków sztuki, prof. Jan Białostocki. Z końcem lat 80., w wyniku transformacji ustrojowej, Stowarzyszenie Historyków Sztuki uległo większej decentralizacji, co zwiększyło znaczenie lokalnych oddziałów.
Studia na kierunku historia sztuki prowadzą liczne uczelnie w Polsce.

</doc>
<doc id="13197" url="https://pl.wikipedia.org/wiki?curid=13197" title="Paleolit">
Paleolit

Paleolit (gr. "παλαιός", "palaiós" 'stary', "λίθος", "líthos" 'kamień'), starsza epoka kamienia, epoka kamienia łupanego – pierwszy okres epoki kamienia, jedna z epok prehistorii, najstarszy i najdłuższy etap w dziejach rozwoju społeczności ludzkiej. Rozpoczyna się z chwilą pojawienia się form przedludzkich zdolnych do wytwarzania prymitywnych narzędzi (otoczaki, pięściaki i rozłupce). W historii geologicznej odpowiada epoce plejstocenu (2,58 mln – 11,7 tys. lat temu) i początkowi holocenu.
Termin „paleolit” wprowadził w 1865 angielski etnolog John Lubbock.
Paleolit dzieli się na:
Paleolit dolny (ok. 2,5 mln lat – ok. 120 tys. lat temu).
Paleolit dolny to okres trwający ok. 3 mln lat. W tym czasie, ok. 2,5 mln lat temu, przedstawiciele form przedludzkich zaczynają wytwarzać prymitywne narzędzia kamienne (narzędzia otoczakowe). Najstarsza znana kultura to kultura Olduvai rozwijająca się w północno-zachodniej Tanzanii; tam otoczaki i rozłupce znaleziono obok szczątków "Homo habilis".
Znaleziska w Lomekwi 3 nad Jeziorem Turkana w Kenii dokonane w 2015 r. przesuwają okres wytwarzania narzędzi znacznie wcześniej. Wykopano około 20 dobrze zachowanych artefaktów, w tym kowadła, rdzenie i odłupki pochodzące z okresu 3 mln 300 tys. lat temu. Na powierzchni znaleziono dodatkowe 130 artefaktów. W jednym przypadku zespół Soni Harmand był w stanie dopasować płatek do jego rdzenia, sugerując, że wczesny człowiek wykonał i wyrzucił narzędzie na miejscu. Narzędzia były ogólnie dość duże – większe niż najstarsze znane narzędzia kamienne, odkryte w 1992 r. w Gona oraz w regionie Afar w Etiopii. Największe waży 15 kg i mogło być używane jako kowadło. Według Soni Harmand okazało się, że twórcy narzędzi celowo wybrali duże, ciężkie bloki mocnego kamienia, ignorując mniejsze bloki z tego samego materiału znalezionego w okolicy. Wykluczyła możliwość, że narzędzia były w rzeczywistości naturalnymi formacjami skalnymi, mówiąc: „Artefakty były wyraźnie obstukiwane, nie były wynikiem przypadkowego pęknięcia skał”. Analiza sugeruje, że rdzenie były obracane, gdy odpadały płatki. Cel narzędzi znalezionych w Lomekwi 3 jest niejasny, ponieważ kości zwierzęce znalezione w tym miejscu nie noszą żadnych oznak aktywności wczesnych ludzi.
W Etiopii w 1992 r. znaleziono narzędzia otoczakowe wyprodukowane prawdopodobnie ok. 2,5 mln lat temu przez "Australopithecus afarensis". Świadczyłoby to o tym, że obok gatunków "Homo" także australopiteki posiadały umiejętność wytwarzania narzędzi. Prawdopodobnie już 1,6 mln lat temu człowiek posiadł umiejętność wykorzystywania ognia. Kultura Olduvai przetrwała ok. 2-1,5 mln lat i została zastąpiona przez kulturę aszelską. Z kulturą aszelską wiąże się umiejętność wznoszenia pierwszych schronień mieszkalnych. Ok. 1 mln lat temu znikają z powierzchni Ziemi ostatnie australopiteki, od tego momentu Ziemię zamieszkuje szybko rozprzestrzeniający się rodzaj "Homo".
W 2018 r. opublikowano kolejne znaleziska, które przesuwają okres migracji i wytwarzania narzędzi znacznie wstecz. W Chinach odkryto narzędzia datowane na 2 mln 100 tys. lat temu. Robin Dennell, archeolog z Uniwersytetu w Sheffield w Anglii stwierdził: „Wykazaliśmy, że najwcześniejsze dowody spoza Afryki mają co najmniej 2,1 miliona lat, a zatem są starsze o 250 tys. lat – czyli o 10 tys. pokoleń – niż Dmanisi w Gruzji”.
Paleolit środkowy (ok. 250 lub 200 tys. – ok. 40 tys. lat temu).
W paleolicie środkowym paleoantropy ("Homo neanderthalensis") udoskonaliły techniki obróbki kamienia, używały broni miotanej (dzidy, oszczepy) i stworzyły zalążki kultury duchowej, obrządek pogrzebowy, przechowywanie czaszek przodków, rytualny kanibalizm.
Według najnowszych badań datowany jest na 200 tysięcy lat.
Paleolit górny (ok. 40 tys. – ok. 14 tys. lat p.n.e.).
W paleolicie górnym pojawiły się neoantropy ("Homo sapiens fossilis") odpowiadające zarówno pod względem budowy fizycznej, jak i potencjalnych możliwości umysłowych człowiekowi współczesnemu.
Nastąpił wówczas gwałtowny rozwój technik krzemieniarskich, rozkwitł przemysł rogowy i kościany, rozpoczęto stosowanie wyszukanych strategii myśliwskich (m.in. zaczęto używać łuku do polowania) i nowych form budownictwa mieszkalnego. Powstała sztuka, plastyka figuralna, zdobnictwo i ornamentacja na narzędziach.
Paleolit późny (ok. 14 tys. lat p.n.e. do 8 tys. lat p.n.e.).
Ostatni etap paleolitu, ograniczony do Niżu Środkowoeuropejskiego i sąsiadującego z nim pasma wyżyn. Cofnięcie się lądolodu skandynawskiego pobudziło wówczas żyjące na tym obszarze grupy ludzi do ekspansji na obszary położone na nizinach. Doszło do wykształcenia nowych kultur:
Około 12 tysięcy lat temu dochodzi do udomowienia psa, 10 tysięcy lat temu zaczyna się rozwijać rolnictwo i hodowla zwierząt, a 8 tysięcy lat temu powstają pierwsze miasta, dając początek wielkim cywilizacjom, a tym samym kończąc prehistoryczny etap rozwoju ludzkości.

</doc>
<doc id="13198" url="https://pl.wikipedia.org/wiki?curid=13198" title="Mezolit">
Mezolit

Mezolit (gr. "mesos" „średni” i "lithos" „kamień”), środkowa epoka kamienia, epipaleolit – środkowy okres epoki kamienia trwający od około 11000–7000 p.n.e. na Bliskim Wschodzie i około 8000–4800 p.n.e. na terenach Niżu Środkowoeuropejskiego, stanowiący stopniowe przejście od paleolitu do neolitu i związany z postępującymi przemianami klimatycznymi (schyłek zlodowacenia).
W mezolicie wyróżnia się trzy fazy (okresy) klimatyczne:
Okres ten cechuje przejście z gospodarki łowiecko-zbierackiej do gospodarki wytwarzającej. Moment pojawienia się elementów gospodarki wytwarzającej wyznacza koniec gospodarki łowiecko-zbierackiej. Podstawowe źródła wyżywienia w okresie mezolitu stanowiły zbieractwo, łowiectwo, rybołówstwo i początkowe rolnictwo, nastąpiło udomowienie owcy i świni. Wynalezione zostały: siekiera, łuk, czółno, rozpoczęto wydobycie krzemienia w kopalniach odkrywkowych (w Polsce – Orońsko), pojawiają się wyroby mikrolityczne, początki plecionkarstwa i tkactwa. Ludność mezolityczna prowadziła jeszcze na ogół koczowniczy tryb życia (okresowe osady otwarte i schronienia skalne).
Mezolit jest najlepiej poznany na terenie Europy, gdzie wydziela się trzy podstawowe zespoły kultur: krąg zachodni (zob.gł. kultura tardenuaska), krąg północny (czasami błędnie utożsamiony z kulturą maglemoską) i północno-wschodni (którego zachodnim odłamem jest kultura kundajska).
Pod koniec mezolitu pojawiają się najwcześniejsze świadectwa przechodzenia do gospodarki wytwórczej na obszarze Bliskiego Wschodu, w rejonie tzw. żyznego półksiężyca (Lewant, góry Taurus, Anatolia, Kurdystan, pn. Mezopotamia, góry Zagros, Chuzestan). Zalążki kształtowania się tej gospodarki wywodzą się z: kultury natufskiej i kultury zarzyjskiej. Tam właśnie znaleziono pierwsze osiedla (m.in. Jerycho, Murajbat, Bajda, Nemrik, Dżarmo, Çayönü Tepesi).
Mezolit jest zjawiskiem regionalnym, związanym ze sposobem adaptacji wczesnych społeczności ludzkich do nowych warunków środowiskowych holocenu.
Mezolit w Polsce.
Na ziemiach polskich znaleziska z okresu mezolitu są nieliczne. Wyróżnić można cztery kultury archeologiczne mezolitu na ziemiach polskich: kultura komornicka, kultura janisławicka, kultura kundajska, kultura chojnicko-pieńkowska. W okresie mezolitu na ziemiach polskich wystąpiła mikrolityzacja i geometryzacja kształtów narzędzi czyli tendencja do zmniejszania wielkości ostrych narzędzi i broni krzemiennych. Mikrolityzację zainicjowała lepsza technika delikatnego retuszu, także brak i trudności z dostępem do krzemienia.
Na ziemiach polskich znanych jest kilka pochówków mezolitycznych. Najbardziej znanym jest pochówek z miejscowości Janisławice. Jest to grób mężczyzny w wieku między 30 a 40 rokiem życia bogato wyposażony, zawierający ponad 50 wyrobów kościanych i tyleż wyrobów krzemiennych. Ciało posypano hematytem i ułożono w pozycji siedzącej z wyprostowanymi nogami i plecami opartymi o ścianę jamy grobowej. W rękach mężczyzna trzymał łuk i kołczan ze strzałami, z których zachowały się jedynie groty. Posiadał także naszyjnik z zębów jelenia i wisiorki z kłów dzika. Znane są także pochówki z okolic Giżycka, skromniejsze, z mężczyznami spoczywającymi w pozycji leżącej.

</doc>
<doc id="13199" url="https://pl.wikipedia.org/wiki?curid=13199" title="Neolit">
Neolit

Neolit (gr. "néos" „nowy” i "líthos" „kamień”), młodsza epoka kamienia, epoka kamienia gładzonego – ostatni okres epoki kamienia (poprzedzający epokę brązu). Jego charakterystyczne cechy to uprawa roślin i hodowla zwierząt oraz stałe osady. Proces ten nazwano „rewolucją neolityczną”. W neolicie rozwijały się też nowe techniki obróbki kamienia, takie jak gładzenie powierzchni i wiercenie otworów.
Termin "neolit" (ang. "Neolithic") został wprowadzony w 1865 przez Johna Lubbocka na oznaczenie nowej pradziejowej techniki wytwarzania narzędzi kamiennych: gładzenia, które wyparło starszą technikę ich wytwarzania: łupanie, stosowaną w paleolicie. Postęp ten był możliwy dzięki odkryciu sposobów kontrolowania i rozwoju hodowli zwierząt i uprawy roślin, które jednocześnie umożliwiły osiadły tryb życia człowieka rozumnego i w konsekwencji powstawanie miast.
Chronologia i występowanie.
Neolit najwcześniej rozpoczął się w obszarach Żyznego Półksiężyca (Izraela, Syrii, Palestyny) na początku IX tysiąclecia p.n.e. Później około 8 tys. lat p.n.e. na terenach Turcji, Iraku i Iranu, 7500 lat p.n.e. w Chinach, 7 tys. p.n.e. w Pakistanie i Europie południowo-wschodniej, 6200 lat p.n.e. w Dolinie Gangesu, 5500 lat p.n.e. w Europie Środkowej, 4500 lat p.n.e. w Europie Północnej. W Ameryce Środkowej rolnictwo i osiadły tryb życia rozpoczął się 5000–4500 lat p.n.e., jednak nazywa się ten okres Archaicznym.
Innowacje neolityczne.
W neolicie zaczęto uprawiać takie rośliny jak samopszę (archaiczną pszenicę), proso, jęczmień, groch, soczewicę i żyto w oparciu o gospodarkę żarowo-kopieniaczą (zobacz rolnictwo). Najstarsze znaleziska osad z gatunkami jęczmienia i samopszy datowane są na 8350 p.n.e. (za pomocą węgla C14). Pod koniec neolitu następuje wprowadzenie orki sprzężajnej. Początkowo hodowla ograniczała się do kóz i owiec (były to pierwsze udomowione zwierzęta oprócz psa, którego udomowiono już w paleolicie). Około 7000 lat p.n.e. udomowiono bydło i świnie, pojawiły się stałe osady i ceramika. Odkryte w Bronocicach naczynie gliniane datowane na 3491–3060 p.n.e., na którym widnieje wyryte wyobrażenie pojazdu, uznane jest za najstarsze na świecie wyobrażenie wozu na kołach. Odkryte na terenie północnych Niemiec konstrukcje drogowe z pni drzew prawdopodobnie przeznaczone były właśnie dla potrzeb transportu drogowego na tych bagiennych obszarach. Inne ślady budownictwa drogowego z drewnianych pni odkryto na obszarach bagiennych w okolicach Nieuv-Dordrecht- datowana metodą radiowęglową konstrukcja pochodzi z ok. 2610 p.n.e. i ma około 1 km długości.
Kultura.
Upowszechnia się ceramika, choć np. w Japonii używano jej już w mezolicie (wczesne fazy kultury Jōmon). Powstają naczynia, misy, figurki, garnki itp. Zaczynają się rozwijać nowe technologie: tkactwo, górnictwo krzemienia, dalekosiężna wymiana różnorodnych surowców.
Rozwijają się kulty religijne – prawdopodobnie kult Wielkiej Matki jako bóstwa płodności (figurki kobiece) i kult słońca (toporki, motywy krzyża wpisanego w koło). W tym okresie powstają także monumentalne budowle związane z tzw. „ideą megalityczną”; menhiry, np. w Carnac, dolmeny, np. w Holandii i w Borkowie na Pomorzu oraz kromlechy, np. w Stonehenge. W Polsce specyficznym przejawem tej idei były tzw. grobowce kujawskie.
Od około 4500 p.n.e. rozwija się kultura megalityczna w Europie (zobacz: megalit). Powstają rozległe osiedla (w Polsce o powierzchni 6-12 ha), niekiedy o charakterze obronnym.
Do ważniejszych kultur tego okresu zalicza się kulturę badaryjską i kulturę Halaf.
Irokezi, Pueblo, Majowie, Maorysi są przykładami ludów używających w czasach nowożytnych narzędzi kamiennych.
Neolit w Europie.
Pierwsze wzorce i impulsy neolityczne zostały przeniesione do Europy z Azji Przedniej przez Bałkany. Jako najstarsze można wymienić: Sesklo, zespół Koranowo-Koros-Krisz-Starčevo (kultura starczewska), następnie młodsze kultury Vinča, Bojan (Boian), wreszcie zespół Cucuteni-Trypole (zob. też kultura trypolska).
Do najwcześniejszych kultur neolitycznych Europy Zachodniej można zaliczyć: kulturę ceramiki impresso-cardium.
Neolit w Polsce.
Na terenach Polski neolit trwał w latach 5200–1900 p.n.e. Do kultur tej epoki zalicza się:
Umiejętność uprawy rośliny i hodowli zwierząt, na tereny Polski przyniosła ludność kultury ceramiki wstęgowej rytej w V tysiącleciu p.n.e. To ona przyniosła ze sobą z okolic środkowego Dunaju umiejętność wyrobu ceramiki. Należała do kultur naddunajskich i przenikała na północ przez Bramę Morawską i przełęcze Karpat i Sudetów. Do tej kultury zalicza się między innymi stanowisko archeologiczne w Olszanicy w Krakowie i w Brześciu Kujawskim. W IV tysiącleciu p.n.e. pojawiła się na terenach polskich ludność z kręgu kultur lendzielskich. W III tysiącleciu p.n.e. napłynęła ludność z kręgu kultur nadcisańskich, a po niej ludność z kręgu kultur ceramiki promienistej.
Na terenach Warmii i Mazur, w III tysiącleciu p.n.e. rozprzestrzeniła się ludność kultury ceramiki dołkowo-grzebykowej. Między latami 3500–1900 p.n.e. pojawiła się kultura pucharów lejkowatych, do niej zalicza się odkryte ślady zamieszkania na Ostrowie Lednickim. Na ten okres przypada początek eksploatacji kopalni krzemienia w Krzemionkach w Górach Świętokrzyskich. W połowie III tysiąclecia p.n.e. pojawiła się ludność kultury ceramiki sznurowej, zajmująca się głównie pasterstwem. Między latami 2700–2000 p.n.e. pojawiła się kultura amfor kulistych. Pod koniec neolitu, na tereny południowej Polski, dotarła z Czech i Moraw ludność kultury pucharów dzwonowatych.

</doc>
<doc id="13201" url="https://pl.wikipedia.org/wiki?curid=13201" title="Epoka żelaza">
Epoka żelaza

Epoka żelaza – okres dziejów ludzkości następujący po epoce brązu, w której żelazo stało się głównym surowcem w wytwarzaniu narzędzi. Ramy czasowe epoki żelaza są różne i uzależnione
od stref geograficznych, zróżnicowania kulturowego i rozwoju społeczno-gospodarczego. W znaczeniu historycznym trwa do dziś (w sensie archeologicznym skończyła się w XIII w.).
Żelazo jest materiałem znacznie bardziej dostępnym niż brąz. Najpopularniejszym surowcem do wytwarzania żelaza w starożytności były tzw. rudy darniowe oraz błotne, w których zawartość żelaza wahała się od 30% do 50%. Występowały one przy powierzchni, więc były bardzo łatwe w eksploatacji. Rzadko sięgano do głębszych pokładów rud żelaza, gdyż wiązało się to z czasochłonnymi metodami górniczymi. Żelazo otrzymywano poprzez termiczną redukcję tlenków zawartych w rudzie i oddzielenie czystego surowca od zanieczyszczeń, w tym celu po wydobyciu rudy segregowano oraz oczyszczano konkrecje następnie poddając je procesowi prażenia z węglem drzewnym. W najwcześniejszym okresie wytopu dokonywano w ogniskach otwartych, a dopiero z biegiem czasu stosowano do wytopu dymarki. Żelazo umieszczano w piecu warstwowo na przemian z węglem drzewnym. Następnie podgrzewano piec do temperatury 1300 stopni, ponieważ wtedy dochodziło do redukcji tlenków i utworzenia się metalu. W wyniku tego procesu otrzymywano metal w postaci łupki, zanieczyszczonej węglem drzewnym. Następnie w celu pozbycia się zanieczyszczeń przekuwano i podgrzewano łupki. Żelazo poddawano dalszej obróbce.
Bardzo ważne w późniejszym procesie obróbki żelaza było nawęglanie oraz hartowanie.
Najstarsze wyroby z kutego żelaza (głównie pochodzenia meteorytowego), pochodzą z XV i XIV wieku p.n.e. z terenów państwa Hetytów (Azja Mniejsza), skąd po roku 1180 p.n.e. żelazo przez Palestynę dotarło do Egiptu, i dalej do Mezopotamii i Iranu. Następnie na Kaukaz, w XII w p.n.e. do Grecji oraz w XI–X w. p.n.e. do Italii. Do dalszych części Europy żelazo dotarło przez Półwysep Bałkański oraz Kaukaz.
Kultury epoki żelaza.
Do najważniejszych europejskich kultur epoki żelaza należą:
Chronologia epoki żelaza.
Na terenach dzisiejszej Polski, wyróżnia się podział epoki żelaza na następujące okresy:
1. Okres halsztacki – zwany wczesną epoką żelaza dzieli się na podokres
2. Okres lateński – zwany też przedrzymskim dzieli się na podokresy:
3. Okres wpływów rzymskich – zwany też rzymskim dzieli się na podokresy:
4. Okres wędrówek ludów – okres uznawany za kontynuację okresu rzymskiego dlatego wyróżniamy podokres:

</doc>
<doc id="13204" url="https://pl.wikipedia.org/wiki?curid=13204" title="Australopitek">
Australopitek

Australopitek ("Australopithecus"; dosłownie ‘małpa południowa’ – od ‘południowy’, i ‘małpa’) – rodzaj ssaków naczelnych z rodziny człowiekowatych (podrodzina Homininae), którego przedstawiciele żyli w południowej, wschodniej i centralnej Afryce od ok. 4,2 ("Australopithecus anamensis") do ok. 1 mln lat temu. Australopiteki masywne są grupowane niekiedy w odrębny rodzaj "Paranthropus" (dosł. „obok człowieka” albo „prawie człowiek”), gdyż były boczną gałęzią ewolucyjną, która nie ma bliskiego związku z rodzajem "Homo". Australopiteki pochodziły prawdopodobnie od żyjących ok. 5,8–4,5 mln lat temu ardipiteków. Większość naukowców zgadza się, że rodzaj "Homo" wyewoluował z australopiteków, nie ma jednak pewności, z którego z ich gatunków.
Opis.
Żyły od ok. 4,2 do ok. 1 mln lat temu (pliocen i wczesny plejstocen), początkowo w Afryce Wschodniej w rejonie Wielkich Rowów Afrykańskich – tam naukowcy doszukują się kolebki ludzkości ("East Side Story") – później także w Afryce Południowej i Środkowej. Charakteryzowały się masywną szczęką, mocnym uzębieniem, ale już krótkimi kłami – umożliwiało to poziomy ruch trący i świadczy o przewadze twardego pokarmu roślinnego w ich pożywieniu. Miały stopy o nieprzeciwstawnym paluchu (jak u człowieka), były przystosowane do chodzenia w pozycji pionowej, czyli do dwunożności, o czym świadczyć może m.in. budowa podstawy czaszki i położenie "foramen magnum" w odniesieniu do płaszczyzny przechodzącej przez górny i dolny brzeg oczodołu (tzw. kąt alfa), struktura uzębienia, czy budowa pasa biodrowego.
Odkrycia.
Pierwszego odkrycia dokonał Raymond Dart w roku 1924 w jaskini Taung w południowej Afryce (RPA; czaszka gatunku "Australopithecus africanus", raport z 1925 roku). Spenetrowano zaledwie 5% terenów, więc można się spodziewać dalszych odkryć. Australopiteki rozprzestrzeniły się w sporej części Afryki już ok. 4 mln lat temu. Dotychczasowa rekonstrukcja procesów biologicznych, które doprowadziły do powstania gatunków dwunożnych istot o wyprostowanej sylwetce nie daje jeszcze pełnego obrazu antropogenezy.
Systematyka.
W rodzaju "Australopithecus", wchodzącym w skład rodziny Hominidae, można wyróżnić gatunki:
Początkowo rodzaj "Australopithecus" zaliczono do odrębnej podrodziny Australopithecinae w obrębie orangowatych (Pongidae), jednak obecnie wiadomo, że jest bliżej spokrewniony z ludźmi niż z innymi żyjącymi współcześnie naczelnymi. Australopiteki klasyfikuje się w jednym rodzaju ("Australopithecus") albo w dwóch – kiedy formy gracylne (wysmukłe) stanowią rodzaj "Australopithecus", a formy masywne są wydzielane w odrębny rodzaj "Paranthropus". Zatem można się spotkać w literaturze z nazwami typu: "A. robustus", "A. boisei", "A. aethiopicus", jak i "Paranthropus robustus", "P. boisei" czy "P. aethiopicus."
Ewolucja.
Najstarsze odkryte ślady przodków człowieka prowadzą do trzeciorzędu (65–1,8 mln lat temu). W paleogenie ewoluowały naczelne (Primates), od nich pochodzą małpy wąskonose (Catarrhini). W neogenie żyły parapiteki ("Parapithecus") i driopiteki (Dryopithecidae) – antenaci małp człekokształtnych (Pongidae). Około 14 mln lat temu żyły ramapiteki ("Ramapithecus"). Linia człowiekowatych (Hominidae) oddzieliła się od nich nie mniej niż 10 mln lat temu, a nastąpiło to w Afryce.
Pierwszym prawdopodobnym przodkiem rodziny hominidae był "Sahelanthropus tchadensis". Jego szczątki datowane są na niecałe 7 mln lat. Kolejny to "Ardipithecus ramidus", znaleziony w latach 70. XX w. w Aramis (Etiopia) sprzed ok. 4,4 mln lat (pliocen). W roku 2001 Yohannes Haile-Selassie z uniwersytetu Berkeley odkrył w Etiopii najstarszego przedstawiciela tego rodzaju, początkowo sklasyfikowanego jako podgatunek "A. ramidus", a obecnie jako odrębny gatunek "Ardipithecus kadabba". Jest on datowany na 5,6–5,8 mln lat.
Ok. 4,5 mln lat temu pojawiły się także australopiteki, uważane za bezpośrednich przodków ludzi.
W roku 2000 Brigitte Senut i Martin Pickford odkryli w Kenii "Orrorin tugenensis" datowanego na 5,7–6,1 mln lat. Prasa nazwała go „człowiekiem milenijnym” ("Millennium Man"). Wydaje się, że był on bardziej zaawansowany ewolucyjnie od ardipiteka. Możliwe, że to odkrycie przesunie początek paleolitu o milion lat wstecz.
Równolegle z australopitekami, ok. 3,5–3,2 mln lat temu, żyły także "Kenyanthropus", odkryte w roku 1999 nad jeziorem Turkana przez zespół badawczy pod kierownictwem Meave Leakey. Ok. 2,5 mln lat temu pojawiły się pierwsze osobniki rodzaju "Homo". Po ostatnich odkryciach przyjmuje się, że do hominidów należą:
Obecnie większość naukowców zgadza się, że rodzaj "Homo" wyewoluował z australopiteków, nie ma jednak pewności, z którego gatunku – jeśli pierwsze "Homo" powstały we wschodniej Afryce, ich przodkami mógł być "A. afarensis" lub "A. garhi", natomiast jeśli powstały w południowej Afryce – "A. africanus" lub "A. sediba".
Synonimy.
("A." oznacza "Australopithecus", a "P." oznacza "Paranthropus"):

</doc>
<doc id="13205" url="https://pl.wikipedia.org/wiki?curid=13205" title="Działo pancerne">
Działo pancerne

Działo pancerne – rodzaj działa samobieżnego – działo artyleryjskie umieszczone na silnie opancerzonym podwoziu gąsienicowym. Jego zadaniem było wspieranie ogniem artyleryjskim piechoty i czołgów. Zazwyczaj działa pancerne budowano na podwoziach takich samych jak czołgi.
Historia dział pancernych jest stosunkowo krótka. Pierwsze działa pancerne pojawiły się w 1939 roku (niemiecki Sturmgeschütz III). Podczas II wojny światowej były masowo produkowane przez Niemcy i Związek Radziecki.
Przyczyną ich popularności była uproszczona w porównaniu z czołgami konstrukcja (działo umieszczano w kadłubie zamiast w wieży). Takie rozwiązanie pozwalało zmniejszyć cenę pojedynczego pojazdu, zwiększyć wytrzymałość pancerza poprzez jego większe pochylenie i zastosowanie grubszych płyt dzięki oszczędnościom na ciężarze oraz montować działa większego kalibru (działa w kadłubie mogą mieć większą siłę odrzutu niż te w wieży). Zlikwidowanie wieży czyniło też pojazd niższym i tym samym trudniejszym do trafienia oraz łatwiejszym do ukrycia.
Prostota konstrukcji była jednak jednocześnie największą wadą dział pancernych – aby skierować działo w bok trzeba było obrócić cały pojazd, a nie tylko wieżę. Spowodowało to, że ich historia skończyła się niedługo po zakończeniu II wojny światowej. Po wojnie produkowano już nieliczne konstrukcje dział pancernych, w małych seriach, głównie w ZSRR. Powstawały też całkowicie opancerzone samobieżne działa przeciwpancerne (niszczyciele czołgów) o układzie konstrukcyjnym i sylwetce dział pancernych, lecz znacznie słabszym opancerzeniu, chroniącym jedynie przed pociskami małego kalibru (jak ASU-85). Wyjątkiem jest szwedzki Stridsvagn 103 – wyglądający jak działo pancerne czołg.
Najbardziej znane działa pancerne:

</doc>
<doc id="13207" url="https://pl.wikipedia.org/wiki?curid=13207" title="Człowiekowate">
Człowiekowate

Człowiekowate (Hominidae) – rodzina ssaków naczelnych z nadrodziny człekokształtnych (Hominoidea) obejmująca największe wśród naczelnych gatunki wykazujące dużą inteligencję, skłonność do przyjmowania spionizowanej, dwunożnej postawy oraz zdolność do wytwarzania i używania narzędzi. Gatunkiem typowym rodziny jest "Homo sapiens" . Najstarszy znany z zapisów kopalnych hominid "Sahelanthropus tchadensis" pochodzi z miocenu, 7 mln lat temu.
Historia klasyfikacji.
Kryteria klasyfikowania gatunków do rodziny Hominidae są kontrowersyjne. Przez wiele lat za główne kryteria odróżniające ludzi od małp przyjmowano dwunożność, różnie rozumianą inteligencję, zdolność do wytwarzania narzędzi, mowy i kultury. Niedostateczna wiedza o ekologii i etologii poszczególnych gatunków małp powodowała, że w historii taksonomii zwierząt ścierały się dwa poglądy.
Charakterystyka.
Człowiekowate są dużymi ssakami lądowymi. Najmniejsze bonobo ważą 30–60 kg, a największe osobniki goryli zachodnich osiągają do 275 kg masy ciała. Od pozostałych człekokształtnych odróżnia je skłonność do przyjmowania postawy wyprostowanej (pionowej) i dwunożnej lokomocji, długotrwały rozwój osobniczy, a przede wszystkim znacznie bardziej rozwinięty mózg.
Ciało człowiekowatych jest masywne, z dobrze rozwiniętymi ramionami i barkami, których budowa umożliwia zawieszanie się na gałęziach. Większość gatunków (poza człowiekiem) dobrze się wspina po drzewach, ale jedynie orangutan prowadzi w pełni nadrzewny tryb życia. Spionizowana postawa wymusiła szereg modyfikacji szkieletu, głównie esowaty kształt kręgosłupa, wydłużenie tylnych kończyn, przekształcenie miednicy, zmianę funkcji rąk. Kciuk i paluch są przeciwstawne (z wyjątkiem człowieka, u którego paluch utracił przeciwstawność, przez co palce stopy straciły pierwotną chwytność). Wszystkie palce są zakończone płaskimi paznokciami. Żaden z gatunków człowiekowatych nie ma ogona ani nagniotów pośladkowych, wszystkie natomiast mają dużą puszkę mózgową. Najważniejszymi zmysłami człowiekowatych są wzrok i słuch. Oczy przesunięte na przednią część głowy umożliwiają widzenie stereoskopowe.
Pomiędzy samcem a samicą większości człowiekowatych wyraźnie zaznaczony jest dymorfizm płciowy. Np. u goryli samce są znacznie większe i masywniejsze od samic, i w grupie jest zwykle jeden dominujący samiec, wokół którego skupionych jest kilka samic. Tak wyraźny dymorfizm nie występuje u szympansów i człowieka, natomiast w trakcie wykopalisk w 2007 r. w Ileret w Kenii odkryto ją u hominida "Homo erectus", uznawanego do tej pory za najbliższego ludziom. U samic występuje menstruacja.
Człowiekowate są wszystkożerne, żywią się głównie owocami i liśćmi, niektóre również owadami, a szympansy i ludzie – także mięsem upolowanych przez siebie dużych kręgowców. Wszyscy przedstawiciele rodziny wyróżniają się wśród naczelnych złożonością zachowań socjalnych. Żyją w grupach rodzinnych, budują gniazda. Ciąża trwa 8-9 miesięcy. Samice rodzą zazwyczaj jedno młode, rzadko więcej. Nowo narodzony osobnik jest bezradny, nieprzystosowany do samodzielnego życia i przez długi okres wymaga opieki matki.
Umiejętność wytwarzania narzędzi – do niedawna przypisywana wyłącznie człowiekowi – została potwierdzona badaniami terenowymi u przedstawicieli wszystkich współcześnie żyjących wielkich małp.
Systematyka.
W rodzinie człowiekowatych wyróżniane są podrodziny Ponginae i Homininae. (Według niektórych systematyków do rodziny człowiekowatych należy zaliczyć cztery podrodziny: Ponginae, Gorillinae, Paninae i Homininae). Do pierwszej zaliczany jest tylko jeden rodzaj – orangutan, do drugiej pozostałe 3 rodzaje żyjące współcześnie i kilka wymarłych. Do żyjących współcześnie zaliczono szympansa, goryla i człowieka. Wszystkie wymienione rodzaje były wcześniej klasyfikowane w randze gatunków. Badania wykazały jednak istotne różnice pomiędzy populacjami każdego z nich, co doprowadziło do rewizji w systematyce, w wyniku której obecnie wyróżnia się po dwa gatunki orangutanów, goryli i szympansów (łącznie sześć), natomiast klasyfikacja gatunków z rodzaju "Homo" nie została jednoznacznie ustalona.
Do rodziny należą następujące występujące współcześnie podrodziny:
Opisano również podrodziny wymarłe:
oraz rodzaje wymarłe o niepewnej pozycji systematycznej:
Pochodzenie.
Odkrycia paleoantropologiczne i badania molekularne wskazują, że człowiekowate pochodzą z Afryki. Większość skamieniałości hominidów znaleziono w Afryce wschodniej, ale w roku 2002 francuski paleontolog Michel Brunet wraz z międzynarodowym zespołem badaczy odkrył w suchych pokładach dna jeziora Czad (leżącego w centralnej Afryce) skamieniałości datowane na 6-7 mln lat. Mogą one należeć do najwcześniejszego znanego hominida. Nie wiemy jeszcze, w jakim stopniu człowiekowate żyjące w Afryce były ze sobą skoligacone. Nie wiemy też, czy znamy już wszystkie żyjące tam gatunki. W ciągu 4,5 milionów lat swej historii hominidy uczłowieczyły się, stały się w pełni dwunożne, zaczęły zespołowo uprawiać łowiectwo, korzystać w razie potrzeby z jaskiń, posługiwać się systematycznie prymitywnymi narzędziami i w końcu je produkować. Stopniowo wywędrowały z Afryki do Azji (najstarsze znaleziska pochodzą sprzed 1,6 mln lat), Europy (najstarsze znaleziska pochodzą sprzed 1,3 mln lat) i na inne kontynenty tworząc pierwsze kultury myśliwsko-zbierackie. W ciągu ostatniego miliona przyswoiły sobie umiejętność rozniecania ognia i budowania domostw. Z czasem usprawniły techniki zbieracko-łowieckie, nauczyły się rybołówstwa, produkcji broni, odzieży, ceramiki, tkactwa, aż ostatecznie przeszły do gospodarki opierającej się na rolnictwie i pasterstwie, udomowiły najpierw psa, a później inne zwierzęta, zdobyły umiejętność rozpoznawania minerałów, praktykowania górnictwa, wytwarzania sztuki i muzyki.

</doc>
<doc id="13208" url="https://pl.wikipedia.org/wiki?curid=13208" title="Jagdpanzer 38(t)">
Jagdpanzer 38(t)

Jagdpanzer 38(t) (Sd.Kfz 138/2), potocznie znany jako Hetzer – niemieckie działo pancerne z okresu II wojny światowej budowane na podwoziu czołgu PzKpfw 38(t) (czechosłowackiego LT vz. 38).
Konstrukcja i produkcja.
Jagdpanzer 38(t) został opracowany w 1943 w zakładach BMM w Pradze, na zlecenie generała Heinza Guderiana. Od kwietnia 1944 produkowany seryjnie. We współczesnej literaturze popularnie nazywany jest Hetzer (z niem. „Podżegacz”), aczkolwiek nie była to oficjalna nazwa (miała być przeznaczona dla niewyprodukowanego czołgu E-10). Niemniej, była ona stosowana także podczas II wojny światowej i jest spotykana w części dokumentów.
Największymi zaletami pojazdu była szybka i tania produkcja, niska sylwetka oraz silnie pochylone płyty pancerza, co sprzyjało rykoszetowaniu pocisków. Głównym minusem było umieszczenie armaty z prawej strony, gdyż ta była zaprojektowana do ładowania z prawej strony, lecz ładowniczy w pojeździe znajdował się z lewej strony. Sprawiało to problemy dla celowniczego i ładowniczego, przez co obniżało szybkostrzelność.
Niemcom udało się wykorzystać dosyć już stare podwozie PzKpfw 38(t) do taniej masowej produkcji pojazdu, który był skuteczny w ostatnim okresie wojny. Od kwietnia 1944 do końca wojny w Europie w maju 1945 Niemcy wybudowali 2584 wozy, głównie w czeskich zakładach Škody.
Jeden Hetzer z 743 Batalionu Niszczycieli Czołgów został 2 sierpnia 1944 zdobyty przez powstańców warszawskich i nazwany „Chwat”, jednakże nie został użyty w walce. W 1945 zdobyczne i wyremontowane egzemplarze wśród innych zdobycznych pojazdów pancernych znajdowały się w uzbrojeniu polskiej 6 Dywizji Piechoty, w jej 5 samodzielnym dywizjonie artylerii samobieżnej jako 75 mm działa samobieżne T-38. Do lat 50. XX wieku produkcję kontynuowała Czechosłowacja (pod nazwą ST-1). Część pojazdów ST-1 służyła także do lat 70. w armii szwajcarskiej (jako G-13) i stamtąd pochodzi większość zachowanych do dzisiaj egzemplarzy.

</doc>
<doc id="13209" url="https://pl.wikipedia.org/wiki?curid=13209" title="Elefant">
Elefant

Elefant (wcześniej nazywany Ferdinand) – ciężkie działo pancerne – niszczyciel czołgów używane przez armię niemiecką w czasie II wojny światowej. Pełne oficjalne oznaczenie pojazdu to Panzerjäger Tiger(P) (Sd.Kfz. 184).
Opis pojazdu.
Został on zaprojektowany w oparciu o podwozie nieprzyjętego do produkcji prototypu czołgu Tiger, konstrukcji Ferdinanda Porsche, znanego jako Tiger (P) lub VK 4501(P) (litera P oznaczała konstrukcję Porsche). Ponieważ na uzbrojenie przyjęto alternatywny wariant czołgu Tiger (VK 4501(H)) z podwoziem konstrukcji firmy Henschel, zaszła potrzeba wykorzystania zaczętej już w zakładach Nibelungenwerke partii 90 podwozi konstrukcji Porschego. Dlatego Porsche zaproponował skonstruowanie na ich bazie ciężkiego niszczyciela czołgów. Pod koniec 1942 roku firma Alkett zaprojektowała działo pancerne na podwoziu Tiger(P). Sam Adolf Hitler zaaprobował budowę pojazdu, który 6 lutego 1943 nazwał „Ferdinand” na cześć zasług prof. Porsche. 90 zbudowanych Ferdynandów oddano wojsku w kwietniu i maju 1943. Nowy pojazd został uzbrojony w armatę 88 mm PaK 43/2 L/71 (o długości lufy 71 kalibrów). Pociski wystrzelone z tego działa umożliwiały przebicie czołowego pancerza każdego czołgu alianckiego, nawet z odległości 1,5 km. Armata była zamontowana w pancernej nadbudówce umieszczonej z tyłu pojazdu, ale z powodu swojej długości i tak wystawała poza jego przód. Ponieważ nie była zamontowana w obrotowej wieży, ale bezpośrednio w nadbudówce, miała dość ograniczoną możliwość ruchu: 28° w płaszczyźnie poziomej i 22° w pionowej. Przedni pancerz Ferdynanda miał grubość 200 mm, co czyniło go praktycznie nieprzebijalnym od przodu dla wszystkich dział alianckich z odległości większej niż 500 m, boczny pancerz o grubości 80 mm również nie był łatwy do przebicia.
Cały pojazd miał ponad 8 metrów długości i prawie 3,5 metra szerokości i ważył 65 ton (wersja Ferdinand) lub 70 ton (wersja Elefant). Napędzany był silnikiem Maybach HL 120 o mocy 530 KM, jego maksymalna prędkość wynosiła jedynie 20 km/h, a zasięg to 135 km. Wnętrze pojazdu było przedzielone na dwa osobne pomieszczenia. W przedniej części siedzieli kierowca i radiotelegrafista, a z tyłu znajdowali się: dowódca, celowniczy i dwóch ładowniczych.
Każdy z ferdynandów został złożony w zakładach Nibelungenwerke w 1943.
Historia operacyjna.
Wszystkie ferdynandy zostały przydzielone do 656. pułku ciężkich dział pancernych, w składzie 653. i 654. dywizjonów dział pancernych.
Ferdinandy były zazwyczaj przydzielane na poziomie kompanii, czasami były dzielone na plutony. Zazwyczaj działały wspierane dodatkowymi oddziałami piechoty i czołgami chroniącymi ich flanki. W czasie ataku pojazdy były używane jako broń pierwszego uderzenia, a w czasie obrony zazwyczaj stanowiły mobilną rezerwę gotową do zniszczenia czołgów przeciwnika.
Po raz pierwszy zostały użyte operacyjnie w czasie bitwy na łuku kurskim. Pomimo że zniszczyły one 320 rosyjskich czołgów, okazało się, że mają także wiele wad, np. zawodny silnik i elektryczny układ przeniesienia napędu, czy delikatny hydropneumatyczny system kierowania.
Część zniszczonych ferdynandów padła ofiarą piechoty, co według niektórych zostało spowodowane brakiem broni przeciwpiechotnej (np. karabinów maszynowych) w tych pojazdach. Należy jednak pamiętać, że niektóre rosyjskie działa pancerne (SU-76, SU-85) także nie były wyposażone w karabiny maszynowe, gdyż zaplanowane dla nich zadania nie przewidywały bezpośredniej styczności z piechotą wroga. Ponadto karabin maszynowy o ograniczonym stopniu ostrzału, zamontowany w mało ruchliwym pojeździe, nie byłby w stanie wyeliminować zagrożenia ze strony piechoty. Fakt, że wiele Ferdynandów zostało zniszczonych przez piechurów radzieckich oraz działa polowe strzelające z zasadzek w boczny pancerz, świadczy raczej o nieprawidłowym użyciu tych pojazdów do ataku, w niesprzyjających im warunkach taktycznych i bez odpowiedniej osłony, a nie o jakiejś fundamentalnej wadzie tych dział. Należy także pamiętać, że część zniszczonych pojazdów została już wcześniej unieruchomiona przez awarie silników lub zawieszenia. Poważnymi wadami Ferdynandów, oprócz zawodności układu napędowego, była duża masa i mała moc silnika, z którymi wiązała się słaba ruchliwość i duży nacisk jednostkowy. Zaletą nie była też duża wysokość pojazdu. Mimo to używany w obronie, na dużych dystansach prowadzenia ognia, był trudnym do pokonania przeciwnikiem.
Ferdynandy, które nie zostały zniszczone w czasie bitwy na łuku kurskim, zostały wysłane do Niemiec, gdzie poddano je modyfikacjom. Dodano między innymi zimmerit, karabin maszynowy i dodatkowe opancerzenie. Zmodyfikowano w ten sposób 48 pojazdów, w tym samym czasie też od końca 1943 zmieniono nazwę pojazdu na Elefant („słoń”).
Służyły one w składzie 653. dywizjonu dział pancernych na froncie wschodnim, a następnie w czasie obrony Niemiec. Jedna kompania dywizjonu walczyła także na froncie we Włoszech od lutego do czerwca 1944. Pod koniec 1944 roku ocalałe Elefanty zgrupowano w 614. samodzielnej kompanii ciężkich dział pancernych. Pod koniec wojny, przy całkowitym panowaniu aliantów w powietrzu, okazały się bardzo łatwym łupem dla samolotów. Ostatnie Elefanty wzięły udział w walkach Kampfgruppe Ritter na południe od Berlina.
Zachowane egzemplarze.
Tylko dwa egzemplarze zachowały się do dzisiaj. Pierwszy, przechwycony przez Sowietów, znajduje się w Muzeum Czołgów w Kubince, a drugi, zdobyty przez Amerykanów, w United States Army Ordnance Museum.

</doc>
<doc id="13210" url="https://pl.wikipedia.org/wiki?curid=13210" title="Jagdpanzer IV">
Jagdpanzer IV

Jagdpanzer IV (Sd.Kfz.162) – niemieckie działo pancerne z okresu II wojny światowej. Powstało jako nowa, zmodyfikowana wersja pojazdu StuG III na podwoziu czołgu PzKpfw IV.
Produkcja.
Pojazd oznaczony jako L/48 (z armatą 7,5cm PaK 39 L/48) produkowany był od stycznia do listopada 1944 przez zakłady Vomag w Plauen (wyprodukowano ok. 769 egzemplarzy). W sierpniu 1944 weszły do produkcji nowe wersje - IV/70(V) (projektu zakładów Vomag) i IV/70(A) projektu Alkett (obie nosiły też oznaczenie Sd.Kfz.162/1). Uzbrojone były w czołgową wersję armaty 7,5 cm PaK 42 L/70. Za produkcję nowej wersji odpowiedzialne były zakłady Vomag oraz Nibelungenwerke w St. Valentin w Austrii. Od sierpnia 1944 do kwietnia 1945 w zakładach Vomag wyprodukowano łącznie ok. 930-940 pojazdów w wersji IV/70 (V), w zakładach Nibelungenwerke wyprodukowano do marca 1945 tylko 278 pojazdów w wersji IV/70(A).
W oparciu o ten pojazd skonstruowano w RFN podobny niszczyciel czołgów: Kanonenjagdpanzer - w latach 1966-1967 wyprodukowano w sumie 770 sztuk.
Konstrukcja.
Do konstrukcji Jagdpanzer IV użyto podstawowego podwozia i napędu czołgu PzKpfw IV, jedynie w przedniej części kadłuba pionową płytę (50 mm) pancerza zastąpiono dwiema (50-60 mm) tworzącymi ostry klin. Dodatkowo zmieniono położenie niektórych elementów we wnętrzu kadłuba: zbiorników paliwa, amunicji oraz włazu ewakuacyjnego. Usunięto także (zbędny w tego rodzaju konstrukcji) napęd wieżyczki.
Działo, wizjer oraz dwa karabiny maszynowe MG 42 zostały zamontowane w przedniej płycie kadłuba. Zakres wychyłu działa w pionie wynosił +15/-8 stopni. Boczny pancerz miał 30 mm grubości (w późniejszym czasie pancerz przedni pogrubiono do 80 mm, a boczny do 40 mm). Wiele pojazdów wyposażono także w boczne ekrany dodatkowo chroniące pojazd przed pociskami.
W późniejszym czasie zastosowano kilka poprawek, oprócz zwiększenia grubości pancerza, usunięto z lufy armaty hamulec wylotowy, jeden z karabinów itp. Wiele pojazdów zostało także pokrytych "Zimmeritem".
Historia operacyjna.
Niszczyciele czołgów typu Jagdpanzer IV przydzielano do jednostek zmechanizowanych (w tym Dywizji Grenadierów Pancernych) od 17 marca 1944 roku. Pierwsze działania bojowe pojazdy podjęły we Włoszech w ramach Dywizji Spadochronowo-Pancernej "Hermann Göring", następnie na froncie wschodnim, w ramach 4. i 5. Dywizji Pancernej. Tuż przed aliancką inwazją w Normandii 62 takie pojazdy znalazły się w stacjonujących tam dywizjach niemieckich. Największą ich liczbę (137 sztuk) użyto podczas ofensywy w Ardenach. Końca wojny doczekało w sumie około 285 pojazdów.

</doc>
<doc id="13211" url="https://pl.wikipedia.org/wiki?curid=13211" title="Tybet (region)">
Tybet (region)

Tybet (tyb.: བོད, Wylie: "Bod" [], ZWPY: "Poi"; chiń.: 西藏, pinyin: "Xīzàng") – kraina historyczna w Azji obejmująca Wyżynę Tybetańską i jej przyległości, obecnie w większości w granicach Chin.
Tybet dawniej składał się z trzech prowincji (Amdo, Kham, Ü-Tsang) i miał powierzchnię około 2,5 mln km². Tybet położony jest na średniej wysokości około 4000-5000 metrów nad poziomem morza. Od południa i zachodu jest ograniczony przez Himalaje, Karakorum oraz masyw Pamiru, od północy przez Kunlun, Ałtyn-tag oraz Qilian Shan. Rozciągłość równoleżnikowa Tybetu wynosi około 2500 km. Na jego terenie biorą początek takie wielkie rzeki jak Jangcy, Brahmaputra, Indus, Mekong, Irawadi oraz mniejsze – Saluin, Satledź, Kali Gandaki, Trisuli, Manas-czʽu, Subansuri. Stolicą Tybetu jest Lhasa. Tybetańczycy posługują się językiem tybetańskim, w większości są buddystami, mają wielowiekową kulturę i tradycję.
Historia Tybetu.
Początki i dynastia z Jarlungu.
Tybet był zamieszkany przez człowieka już w paleolicie, a najważniejszymi pomnikami jego prehistorii są odkryte na jego terenie megality. Przodków dzisiejszych Tybetańczyków poszukuje się często wśród ludu Qiang. Qiangowie byli koczownikami hodującymi owce, zamieszkującymi pierwotnie dzisiejszy północno-wschodni Tybet, region Kuku-noru i zachodnie pogranicze Gansu. Być może Tybetańczycy wywodzą się od grup Qiangów, które powędrowały na zachód, w kierunku doliny górnej Brahmaputry (tyb. Jarlung).
Tradycyjna tybetańska historiografia opisuje dzieje tego kraju z punktu widzenia buddyzmu, dzieląc je na trzy epoki: „wczesne rozpowszechnienie” buddyzmu, „ciemny” okres, cechujący się nieobecnością buddyzmu i „późniejsze rozpowszechnienie” buddyzmu. Tybet jawi się w niej jako kraj, w którym zachowała się czysta nauka Buddy, a tybetański, religijny porządek świata zostaje podniesiony do wymiaru uniwersalnego. Jednak zachowane podanie na temat pierwszego króla Tybetu ma wyraźnie niebuddyjski charakter. Niatri Cenpo miał być „boskim synem”, który zstąpił z niebios za pomocą „niebiańskiego sznura” na świętą górę Jarlha Szampo w dolinie Jarlungu. Pierwszym po całym szeregu mitycznych królów władcą dynastii z Jarlungu, co do którego stoimy na pewniejszym historycznym gruncie, był Namri Lontsen (ok. 570 – ok. 618), któremu udało się zjednoczyć większość Tybetu. Jego syn, Songcen Gampo (ok. 618 – ok. 649), podporządkował sobie królestwa Szangszung oraz Tuyuhun i prowadził pomyślne wojny z Chinami. Polityka ekspansji była kontynuowana przez jego następców, zaś szczyt potęgi Tybet osiągnął za panowania Trisong Decena (755-797), kiedy Tybetańczycy wykorzystali osłabienie Chin rebelią An Lushana i w 763 roku zdobyli stolicę cesarstwa, Chang’an. Tybetańsko-chiński układ pokojowy z 783 roku potwierdzał panowanie Tybetu nad Chińskim Turkiestanem, Gansu i większą częścią Syczuanu. Tybetańskie imperium zaczęło się załamywać, kiedy za panowania Ralpaczena (815 – ok. 836) w rządzie królestwa coraz większe wpływy zaczęli uzyskiwać buddyjscy mnisi, co spotkało się ze sprzeciwem tradycyjnej arystokracji, która doprowadziła do zamachu na króla. Wskutek wewnętrznych napięć za jego następcy, Langdarmy (ok. 836-842), „wielkie królestwo” Tybetu uległo dezintegracji.
Zmitologizowany obraz „wielkiego królestwa” stał się podstawą tożsamości kulturowej Tybetańczyków, przy czym w ich tradycji okres ten jest uważany przede wszystkim za czas „wczesnego rozpowszechnienia” buddyzmu. Songcen Gampo, który miał założyć Lhasę, patronować stworzeniu tybetańskiego pisma i sprowadzić pierwszych buddyjskich mnichów z Indii, co najmniej od XII wieku był przez Tybetańczyków ujmowany jako emanacja Bodhisattwy Awalokiteśwary. W tradycji buddyjskiej jest on jednym z trzech wielkich „królów religii”, obok Trisong Decena i Ralpaczena. Przechowała się w niej także pamięć o buddyjskich mnichach z Indii, propagujących tę religię w Tybecie, takich jak Śantarakszita i półlegendarny Padmasambhava, którzy w roku 779 mieli wspólnie założyć pierwszy buddyjski klasztor w Samje. Ten drugi w kulturowej pamięci Tybetańczyków stał się „bohaterem, który sprawił, że kraina Tybetu wraz ze swymi mieszkańcami – ludźmi i demonami – została wprowadzona w buddyzm”. Wydaje się jednak, że wbrew późniejszej tybetańskiej historiografii buddyzm nie stał się wówczas religią panującą Tybetu, mimo iż cieszył się królewskim poparciem. Współistniał on z tradycyjnymi wierzeniami i nawet taki protektor nowej religii jak Trisong Decen w swoich inskrypcjach występuje zarówno jako obrońca i bóstwo starej wiary, jak i „przebudzony” czciciel nowej.
Ciemne wieki i „późniejsze rozpowszechnienie” buddyzmu.
Upadek dynastii z Jarlungu doprowadził do podziału Tybetu na niewielkie państwa, z których najważniejszymi były położone na zachodzie Guge i Purang oraz wschodnie Congkha. Ze względu na szczupłość źródeł okres ten to swoiste „ciemne wieki” historii Tybetu. Także według tradycji buddyjskiej był to „ciemny” okres, charakteryzujący się nieobecnością buddyjskiej nauki, która zanikła w rezultacie prześladowań ze strony zwolenników bönu. W rzeczywistości jednak buddyjskie instytucje raczej dotkliwie ucierpiały w wyniku wstrząsających krajem wojen, niż prześladowań ze strony bönu, który wówczas jeszcze się nie ukształtował. Nie było także tak, żeby buddyzm zanikł całkowicie, lecz początkowo ocaleni mnisi nie byli zdolni do odbudowy jego potęgi z braku możnych protektorów. Za początek „późniejszego rozpowszechnienia” buddyzmu na zachodzie Tybetu można uznać dekret króla Guge Songne (zm. 1024) z 986 roku, w którym potępił on dosłownie rozumiane tantryczne praktyki rytualne, nakazując ludowi kierować się naukami mahajany. Pod jego patronatem działał wykształcony w Indiach tłumacz z sanskrytu Rinczen Sangpo, a dzieła nawrócenia zachodniego Tybetu dokończył przybyły na zaproszenie następcy Songne bengalski mnich Atiśa. Wcześniej głosił on swe nauki w Tybecie Wschodnim, gdzie początki „późniejszego rozpowszechnienia” tradycja buddyjska wiąże jednak z działalnością mnicha Gongpa Rabsela (żył w latach 892-975).
Od czasu misji Atiśy „panowania buddyzmu w tybetańskim życiu społecznym nigdy [...] poważnie niekwestionowano”. Jednocześnie wraz z upadkiem możnych rodów związanych z dynastią z Jarlungu „tybetańska historia jako całość zmieniła swój bieg i stała się historią grup i sekt religijnych”. Większość najważniejszych szkół tybetańskiego buddyzmu ukształtowała się w XI i XII w. Niejako w odpowiedzi na wzmocnienie się w wyniku działalności Atiśy monastycznego buddyzmu, mającego oparcie w nowo przełożonych z sanskrytu usystematyzowanych tekstach, zaczęli się organizować zwolennicy starszych form buddyzmu, sięgających czasów „wczesnego rozpowszechnienia” i silnie związanych z praktykami tantrycznymi. Tak doszło do powstania tradycji ningma. Inne tradycje powstały wokół klasztorów i były najczęściej związane z dziedzicznymi „dynastiami mnichów”. I tak szkoła sakja, która swoją nazwę wzięła od klasztoru założonego w roku 1073, była ściśle związana z wywodzącym swoje pochodzenie od dynastii z Jarlungu rodem Khon. Pochodzący z niego pierwsi lamowie sakja dziedziczyli stanowisko po swoim ożenionym bracie, potem zaś opat klasztoru zazwyczaj był żonaty. Inne powstałe wówczas szkoły to kadam, żalu i kagju, z której wywodziły się takie tradycje jak karma, phagmodru i drigung.
W tym samym okresie ukształtowała się także religia bön. Bön „różni się nieznacznie od buddyzmu pod względem koncepcji metafizycznych, doktryn filozoficznych, jak również form organizacji monastycznej”. Bonpowie wierzą jednak, że historycznym Buddą naszej ery był nie Budda Siakjamuni, ale mityczny założyciel ich religii, Tonpa Sienrab Mibo. Bön miał być obecny w Tybecie na długo przed buddyzmem i cieszyć się opieką jego władców aż do czasów Trisong Decena. W przeciwieństwie do większości Tybetańczyków bonpowie budują zatem swą tożsamość w opozycji do buddyzmu, ponieważ o ile dla tych pierwszych „wczesne rozpowszechnienie” jest początkiem tybetańskiej historii zbawienia, dla wyznawców bönu jest ono początkiem katastrofy.
Panowanie mongolskie.
W roku 1240 do Tybetu dotarły oddziały Mongołów wysłane przez Godana, syna Ugedeja (1229-1241), i tym samym Tybetańczycy stanęli w obliczu konfrontacji z mongolskim imperium. Mongołowie zgodnie ze swoją zwykłą praktyką dążyli do ustanowienia w Tybecie wasalnego władcy, który rządziłby w ich imieniu. Ich wybór padł na przywódcę potężnej szkoły sakja, Sakję Panditę, który dawał nadzieję na ustanowienie w rozdrobnionym Tybecie stabilnej władzy. Sakja Pandita w roku 1247 został zmuszony do złożenia hołdu Godanowi i zgodnie z późniejszą tybetańską tradycją w wyniku tego aktu doszło do przekazania mu w imieniu mongolskim władzy nad krajem. W rzeczywistości efektywną kontrolę nad Tybetem Mongołowie rozciągnęli jednak dopiero w roku 1265, kiedy przybył do niego dotychczas przebywający przy chanie Kubilaju (1259-1294) następca Sakji Pandity, jego bratanek Phagpa. Cieszył on się osobistym zaufaniem chana, który ustanowił go przełożonym buddyjskiego kleru w imperium. W roku 1268 w Tybecie został przeprowadzony spis ludności, który posłużył do ustanowienia obciążeń podatkowych na rzecz imperium, wprowadzono w nim także nowy podział administracyjny. Od początku ustanowiona za obcym pośrednictwem dominacja sakjapy spotykała się z oporem innych szkół. W roku 1287-1290 wybuchło wielkie powstanie wzniecone przez drigungpę, które ostatecznie zostało jednak stłumione przy pomocy wojsk mongolskich. Kiedy w XIV wieku władza Mongołów w Chinach uległa osłabieniu ich kontrola nad Tybetem stawała się coraz bardziej iluzoryczna, a kraj pogrążył się w wewnętrznych walkach. Ostatecznie wygrała je powiązana z rodem Lang szkoła phagmodru, której przewodził Czangczub Gjelcen. W roku 1354 obalił on władzę sakjapy i trzy lata później uzyskał uznanie tego faktu przez cesarza dynastii Yuan. Wraz z upadkiem jej władzy w Chinach w roku 1368 panowanie mongolskie w Tybecie dobiegło końca.
W okresie panowania mongolskiego doszło do zebrania i uporządkowania przetłumaczonych na tybetański tekstów buddyjskich, które stworzyły tzw. "Kandżur", czyli zbiór autorytatywnych wypowiedzi Buddy. Tybetański kanon buddyjski ma jednak charakter otwarty – istnieją różniące się pomiędzy sobą edycje, które mogą zawierać inny zestaw inaczej uporządkowanych tekstów. W redakcji "Tandżuru", równie ważnego zbioru autorytatywnych komentarzy do "Kandżuru", wielką rolę odegrał sławny tybetański uczony Buton. To także w tej epoce w buddyzmie tybetańskim istotne znaczenie zaczęła odgrywać koncepcja "tulku", czyli „przejawionego ciała” buddy lub bodhisattwy, które przyjmuje postać jakiegoś dziecka. Uległo ono powiązaniu z pojęciem "jangsi", „ponownych narodzin” jakiejś znaczącej postaci historycznej. Takie ponowne narodziny były odnajdywane i potwierdzane w toku skomplikowanej procedury identyfikacyjnej, a ich rezultatem było przejęcie majątku i urzędu poprzednika. Jangsi zostało po raz pierwszy zaświadczone historycznie w przypadku Karma Pakszi, który został uznany za następcę założyciela karmapy. Koncepcja jangsi stopniowo zastąpiła sukcesję rodzinną w poszczególnych szkołach tybetańskiego buddyzmu, z wyjątkiem sakjapy, która pozostała przy modelu rodowym.
Od phagmodrupy do gelugpy.
Zarówno Czangczub Gjelcen, jak i jego następcy prowadzili politykę usuwania śladów panowania mongolskiego, przywracając tybetańskie prawo, administrację i tytuły. Lata panowania phagmodrupy w Tybecie były czasami względnej stabilności politycznej, która jednak zakończyła się wraz ze śmiercią w roku 1432 ich ostatniego wybitnego władcy, Drakpy Gjelcena. Wykorzystując walki wewnątrz phagdmodrupy w roku 1435 jej dotychczasowy minister, książę z Rinpung, zdobył Samdrub Ce (dzis. Xigazê) i tym samym najważniejszą siłą polityczną w Tybecie Środkowym stała się Rinpungpa. Książęta z Rinpung sprzymierzyli się początkowo z sakjapą, a później z karmapą, i w roku 1498 temu sojuszowi udało się zająć nawet region Lhasy. Mimo to phagmodrupa nie została do końca pokonana i w roku 1517 odbiła miasto.
W tym samym czasie w Tybecie powstała nowa szkoła buddyzmu, która swoje korzenie miała w działalności Congkhapy (żył w latach 1357-1419), myśliciela i reformatora życia zakonnego. W roku 1409 utworzył on klasztor Ganden w Lhasie, zaś jego dwaj kolejni następcy założyli odpowiednio w latach 1416 i 1419 klasztory Drepung i Sera. Te tzw. „trzy rezydencje” stanowiły podstawę przyszłej potęgi szkoły gelug, która ostatecznie uformowała się kiedy trzeci następca Congkhapy, Gendun Drubpa, przyjął sukcesję za pomocą „ponownych narodzin”. Działalność gelugpy początkowo miała charakter czysto religijny i odbywała się pod protektoratem phagmodrupy. Sytuacja zmieniła się kiedy piąty następca Congkhapy, Sonam Gjaco (1543-1588), w roku 1578 przyjął zaproszenie mongolskiego władcy Altan-chana i rozpoczął nawracanie jego poddanych na buddyzm. Otrzymał on od chana tytuł Dalajlamy, pod którym odtąd byli znani przywódcy gelugpy. Kiedy Sonam Gjaco zmarł jego inkarnację odnaleziono w prawnuku Altan-chana, Jonten Gjaco (1589-1616). „Dzięki tej sztuczce dyplomatycznej” Mongołowie „stali się teraz częścią wspólnej buddyjskiej kultury, nierozerwalnie związanej ze szkołą (zakonem) gelugpa, ponieważ jej najwyższy religijny dostojnik ucieleśnił się pośród nich”.
Tymczasem w roku 1565 książąt z Rinpung obalił ich minister, Karma Ceten, i sprzymierzeni z Karmapą książęta Cang stali się najpotężniejszą siłą w Tybecie. Ponieważ jednocześnie phagmodrupa podzieliła się na dwie walczące ze sobą frakcje, jedynym zagrożeniem dla ich dominacji była rosnąca w siłę gelugpa. W roku 1611 książę z Cang pokonał siły phagmodrupy w Ü i w geście dobrej woli oddał zarząd Lhasy gelugpom oraz poprosił ich o udzielenie religijnej inicjacji. Spotkał się jednak z odmową i w odpowiedzi rozpoczął działania wojskowe, które w roku 1616 doprowadziły do opanowania przez niego większości Środkowego Tybetu. W tej sytuacji gelugpa poprosiła o pomoc Mongołów, którzy w roku 1621 pokonali siły Cang i oblegli je w Lhasie. Wysocy duchowni gelugpy nie chcieli jednak zniszczenia księcia Cang rękami Mongołów i doprowadzili do mediacji, w wyniku której Mongołowie wycofali się, a gelugpa odzyskała utracone wcześniej klasztory. Nie zakończyło to jednak konfliktu. W roku 1634 dominację wśród Mongołów uzyskał władca Choszutów, Guszri-chan (1642-1655), który był żarliwym wyznawcą nauk gelugpy. Kilka lat później został on wezwany przez jej dostojników przeciwko księciu z Cang i ostatecznie w roku 1642 wziął go do niewoli i zabił.
Czasy dalajlamów.
Po swoim zwycięstwie Guszri-chan przyjął tytuł „króla Tybetu”, jednak faktyczna władza nad krajem przeszła w ręce V Dalajlamy, Ngałanga Lobsanga Gjaco (1617-1682), który jako „duchowy nauczyciel” chana zajmował w stosunku do niego nadrzędną pozycję. Na początku swojego panowania w Tybecie V Dalajlama przekształcił wiele klasztorów karmapy i dżonangpy w klasztory gelugpy oraz pozamykał klasztory bonpów. Później jednak pozwolił niektórym klasztorom karmapy zorganizować się ponownie. W konsolidacji władzy V Dalajlamy pomagało podkreślanie przez niego, że dalajlama jest nie tylko reinkarnacją swojego poprzednika, ale także "tulku" bodhisattwy Awalokiteśwary. Ponieważ miał nim być także Songcen Gampo, dalajlamowie jawili się jako usankcjonowani spadkobiercy dynastii z Jarlungu. „Autorytet Dalajlamy, który przede wszystkim uwydatniał się przez nadawanie tytułu «chana» mongolskim książętom, był widocznie tak duży, że Lhasa stała się jednym z najważniejszych ośrodków politycznych Azji w XVII wieku.”. To ze względu na jego wpływy wśród Mongołów w roku 1652 V Dalajlama został zaproszony do Pekinu. Świadectwem rozkwitu Lhasy jako centrum tybetańsko-mongolskiego buddyzmu i ważnego ośrodka azjatyckiego handlu była budowa nowej siedziby Dalajlamów, Pałacu Potala.
Po śmierci V Dalajlamy w roku 1682 władzę w Tybecie przejął regent Sangje Gjaco. Aż do roku 1696 udawało mu się ukrywać śmierć V Dalajlamy i sprawować władzę w jego imieniu. W tymże roku tajemnica wyszła jednak na jaw i Sangje Gjaco osadził na tronie Cangjang Gjaco (1683-1706), VI Dalajlamę. Tymczasem kolejny następca Guszri-chana, Lhazang-chan (1697-1717), zamierzał objąć stanowisko „króla Tybetu” nie tylko formalnie. Popierany przez cesarza Kangxi, który uważał zatajenie śmierci V Dalajlamy za akt wrogości w stosunku do siebie, Lhazang-chan w roku 1705 dokonał inwazji Tybetu i zabił Sangje Gjaco. W następnym roku chan ogłosił iż Cangjang Gjaco nie jest prawdziwą inkarnacją Awalokiteśwary i wywiózł go do Pekinu. W czasie podróży Cangjang Gjaco zmarł. Większość Tybetańczyków i Mongołów nie uznała nowego VI Dalajlamy przedstawionego przez Lhazang-chana i kilka lat później reinkarnacją Cangjanga Gjaco ogłoszono urodzonego w 1708 roku we Wschodnim Tybecie Kelsanga Gjaco (1708-1757). Lhazang-chan i jego VI Dalajlama byli natomiast uznawani przez Kangxi, w zamian za co musieli mu dostarczać coroczną daninę. W 1717 roku Tybet zaatakowali Dżungarowie, którzy zabili Lhazang-chana. Tybetańczycy przywitali ich jak wyzwolicieli, jednak ich nastawienie szybko się zmieniło pod wpływem Dżungarskich okrucieństw i grabieży. W rezultacie kiedy w roku 1720 do Tybetu wkroczyła przysłana przez Kangxi armia, a wraz z nią Kelsang Gjaco, została ona przywitana z prawdziwym entuzjazmem. Tybet stał się teraz protektoratem dynastii Qing.
Po wycofaniu się chińskich wojsk w Tybecie wybuchła wojna domowa, w której zwyciężył Polhane, arystokrata z prowincji Cang. W roku 1728 cesarz Yongzheng (1722-1735) ustanowił urząd cesarskich rezydentów w Lhasie, tzw. ambanów. Podczas rządów Polhane pełnili oni jednak jedynie rolę obserwatorów. Jednocześnie Amdo i Kham stały się formalnie częścią imperium Qingów, co zmniejszyło terytorium tradycyjnego Tybetu niemal o połowę. Trwające do roku 1747 rządy Polhane przyniosły Tybetowi wewnętrzny pokój, jednak antymandżurska polityka jego syna, Gjurme Namgjela, doprowadziła do jego zamordowania przez ambanów w roku 1751 i kolejnej chińskiej interwencji. W jej rezultacie zniesiono urząd „króla” Tybetu, a Dalajlama stał się świeckim i duchowym zwierzchnikiem tybetańskiego rządu. Po śmierci Kelsanga Gjaco w roku 1757 cesarz jednak ponownie wprowadził urząd regenta, którym odtąd miał być duchowny zastępujący dalajlamę w jego funkcjach administracyjnych w okresie małoletniości. Odtąd przez ponad sto trzydzieści lat faktyczną władzę w Tybecie sprawowali regenci, a instytucja dalajlamów odgrywała rolę jedynie formalną. VIII Dalajlama, Dżampel Gjaco (1758-1804), pozostawił sprawy administracyjne w rękach swojego regenta, a dalajlamowie od IX do XII umierali młodo śmiercią naturalną, bądź, jak często mówiono, w wyniku morderstwa.
W latach 1788–1792 Tybet stał się ofiarą inwazji Gurkhów z Nepalu, którzy zostali ostatecznie odparci jedynie dzięki pomocy chińskiej. Po tym wydarzeniu w roku 1793 cesarz Qianlong (1736-1795) nadał ambanom prawo do kontrolowania lokalnego rządu tybetańskiego. Dalajlama i panczenlama mieli się odtąd trzymać ich zarządzeń, a wszelkie sprawy Tybetu podlegały chińskiemu Urzędowi ds. Terytoriów Zależnych. W ten sposób Tybet stał się formalnie częścią cesarstwa dynastii Qing. Jednocześnie Chińczycy zaczęli prowadzić politykę izolacji Tybetu, w czym popierała ich część tybetańskiego rządu i kleru, tak że w XIX wieku Tybet stał się „ziemią zakazaną” dla cudzoziemców. Jednak po śmierci Qianlonga Chiny pogrążyły się w kryzysie i „wewnętrzne problemy, z którymi borykała się dynastia Qing w XIX wieku, a także rosnąca presja ze strony mocarstw kolonialnych, oznaczały dla Tybetu de facto polityczną niezależność”. Po wcześniejszym zajęciu Ladakhu w roku 1842 pochodzący z Dżammu Dogrowie zaatakowali Tybet Zachodni, zostali jednak odparci przez wojska tybetańskie i ostatecznie oba kraje ustaliły pomiędzy sobą granice i relacje handlowe. W 1854 roku Tybet ponownie najechali nepalscy Gurkhowie i po dwóch latach walk zmusili Tybetańczyków do płacenia wysokiego trybutu i uznaniu Nepalu za protektora Tybetu. Mimo prób ratowania wpływów dynastii Qing w Tybecie przez ambanów, kiedy w roku 1862 władzę regenta obalił minister Szetra, właśnie do Nepalu zwrócił się o potwierdzenie swojego urzędu. XIII Dalajlamie, Thubtenowi Gjaco (1875-1933), udało się uniknąć zamachu przygotowywanego przez regenta Demo Rinpocze i w roku 1895 podjąć funkcje rządowe. Tym samym tzw. „wiek regentów” dobiegł końca.
Tybet w pierwszej połowie XX w..
Na przełomie XIX i XX wieku Tybet stał się jednym z obiektów tzw. „Wielkiej Gry”, to jest rywalizacji rosyjsko-brytyjskiej o wpływy w Azji. Obawiając się sojuszu Tybetu z Rosją rząd brytyjski wysłał do tego pierwszego 3-tysięczny oddział pod dowództwem Francisa Younghusbanda, który po pokonaniu źle uzbrojonych wojsk tybetańskich 3 sierpnia 1904 roku wkroczył do Lhasy. Dalajlama uciekł do mongolskiej Urgi (dzis. Ułan Bator), w odpowiedzi na co cesarz odwołał go z urzędu. Tymczasem rząd tybetański zawarł z Brytyjczykami umowę zezwalającą im m.in. na utrzymywanie stosunków handlowych i dyplomatycznych. Zlekceważenie w tej tzw. „Konwencji lhaskiej” formalnej zwierzchności Chin nad Tybetem spowodowało ich oburzenie. Po wycofaniu się Younghusbanda Tybetańczycy poprosili cesarza o przywrócenie Dalajlamy na urząd. Ten zgodził się, ale wcześniej nadał Dalajlamie poniżający tytuł „Naszego lojalnego i podporządkowanego wiceregenta”, niedwuznacznie wskazując mu jego podporządkowaną pozycję. W roku 1909 Dalajlama wrócił do Tybetu, jednak już dwa miesiące potem uciekł do Indii Brytyjskich przed armią chińskiego generała Zhao Erfenga, który po brutalnym podporządkowaniu Chinom Khamu wkroczył do Tybetu Środkowego.
Po tym jak w roku 1911 w wyniku Rewolucji Xinhai upadło cesarstwo chińskie Dalajlama wszczął zbrojną rebelię przeciwko Chińczykom, którzy zostali pokonani i latem 1912 roku wycofali się z Tybetu. Po powrocie do Lhasy, kiedy prezydent Republiki Chińskiej chciał go zatwierdzić we wszystkich jego tradycyjnych funkcjach, Dalajlama odmówił i ogłosił niepodległość Tybetu. W roku 1914 Chiny, Wielka Brytania i Tybet ustaliły tekst tzw. porozumienia z Simli, które „gwarantowało autonomię Tybetu Środkowego i Zachodniego, aczkolwiek pod chińskim zwierzchnictwem, podczas gdy środkowotybetański rząd w Khamie miał przyznaną autonomię tylko w sprawach religijnych”, ostatecznie zostało jednak ono podpisane tylko przez Tybet i Wielką Brytanię. W sumie Dalajlamie nie udało się osiągnąć porozumienia z Chinami i do końca jego rządów dochodziło do utarczek zbrojnych z nimi na obszarach wschodniotybetańskich. Po pobycie w Indiach Dalajlama przystąpił do modernizacji Tybetu, budując elektrownię, linię telegraficzną, organizując urząd pocztowy i wprowadzając papierowy pieniądz, tworząc szkołę na wzór angielski i modernizując armię. Reformy te spotkały się ze sprzeciwem konserwatywnego kleru buddyjskiego. Szkoła została wkrótce zamknięta, a Dalajlama został przekonany, że nowoczesna armia stanowi zagrożenie dla buddyzmu, a tym samym jego władzy, i jej modernizacja została zaniedbana.
Po śmierci Thubtena Gjaco do momentu uzyskania dojrzałości przez jego następcę Tybetem miał rządzić młody i niedoświadczony regent Reting Rinpocze wraz z bratankiem zmarłego dalajlamy i najwyższym urzędnikiem rządowym Langdünem. Reting Rinpocze w krótkim czasie wyrósł na bezwzględnego i żądnego władzy polityka i w kwietniu 1939 roku zmusił Langdüna do dymisji. W tym samym roku do Lhasy przybył sprowadzony z Amdo nowy dalajlama, Tenzin Gjaco (ur. 1935), a w roku następnym regent niespodziewanie podał się do dymisji, prawdopodobnie dlatego, że jako nieprzestrzegający ślubów czystości nie mógłby odebrać od nowego dalajlamy ślubów nowicjatu. W roku 1944 Reting Rinpocze powrócił jednak do Lhasy i próbował nakłonić regenta Taktrę Rinpoczę do ustąpienia, a kiedy ten odmówił próbował zorganizować spisek na jego życie. W rezultacie jednak w roku 1947 trafił do więzienia, gdzie zmarł, prawdopodobnie otruty.
W roku 1947 Tybet był głęboko podzielony pomiędzy stronnictwa Retinga i Taktry – kiedy aresztowano tego pierwszego wybuchły walki pomiędzy siłami popierających go klasztorów a armią, a niektórzy zwolennicy Retinga popierali nawet atak Chińczyków na jego korzyść. W tym samym roku Indie Brytyjskie uzyskały niepodległość i wbrew nadziejom Tybetańczyków nie kontynuowały one brytyjskiej polityki nieoficjalnego wspierania niezależności Tybetu. Jesienią 1949 roku komuniści wygrali chińską wojnę domową i w październiku 1950 roku zajęli wschodni Tybet. 23 maja 1951 roku, mimo braku stosownych pełnomocnictw, tybetańska delegacja w Pekinie podpisała siedemnastopunktowe porozumienie, na mocy którego miało dojść do reintegracji Tybetu z Chinami, przy przyznaniu mu autonomii, zachowaniu w nim dotychczasowego systemu politycznego, oraz zapewnieniu wolności religijnej i utrzymaniu klasztorów. Zdając sobie sprawę, że odrzucenie porozumienia oznacza natychmiastową inwazję chińską, „24 października 1951 roku rząd w Lhasie ostatecznie zaaprobował porozumienie i tym samym zakończył trwającą od 1911 roku faktyczną niepodległość Tybetu, który teraz wcielony został do Chińskiej Republiki Ludowej”.
Tybet częścią Chińskiej Republiki Ludowej.
Pierwsze lata okupacji chińskiej w Tybecie Środkowym przebiegały spokojnie. W roku 1955 został założony „Komitet Przygotowawczy Tybetańskiego Regionu Autonomicznego”, który później stał się właściwym organem władzy w Tybecie, mimo że rząd w Lhasie nadal funkcjonował. Przewodniczącym komitetu był Dalajlama, ale to Chińczycy wyznaczali jego politykę. W Tybecie Wschodnim przymusowa kolektywizacja ziemi i osiedlanie nomadów doprowadziły w zimie 1955/1956 roku do wybuchu ogólnokrajowej rebelii. Po jej klęsce Khampowie uformowali ruch oporu „Czuszi Gangdrug”, który uzyskał wsparcie USA, i zaczęła się do niego przyłączać rosnąca liczba Tybetańczyków, tak że zarówno Chiny, jak i rząd centralny w Lhasie coraz bardziej traciły kontrolę nad sytuacją w kraju. W tej napiętej sytuacji w marcu 1959 roku zaproszenie Dalajlamy na występ zespołu tanecznego w chińskim sztabie wojskowym, na które miał on przybyć sam, spowodowało pojawienie się pogłosek o jego planowanym przez Chińczyków porwaniu i wywołało ogólnonarodowe powstanie. Zostało ono krwawo stłumione, a Dalajlama uciekł do Indii, gdzie wkrótce dołączyło do niego wiele tysięcy uciekinierów.
Po upadku powstania Chiny przeprowadziły reformę rolną, która zmusiła klasztory „do oddania ziemi, co było równoznaczne ze zniszczeniem podstawy ich egzystencji materialnej. To była prawdopodobnie najbardziej drastyczna zmiana tybetańskiego społeczeństwa od czasu wprowadzenia buddyzmu w VII wieku”. Ci, którzy sprzeciwiali się Chińczykom, zostali zamordowani bądź zaginęli w obozach, gdzie znalazło się wiele tysięcy mnichów, którzy często uciekali także za granicę. Nowy podział ziemi doprowadził do wytworzenia się nowych klas społecznych, zaś wraz z napływem Chińczyków do Tybetu Wschodniego wywołał tam głód i spadek liczby ludności tybetańskiej. Kulminacją procesu transformacji Tybetu było ustanowienie w roku 1965 Tybetańskiego Regionu Autonomicznego. Kiedy w Chinach wybuchła Rewolucja kulturalna, w Tybecie w sierpniu 1966 Czerwona Gwardia ogłosiła jako jej cel zniesienie wszelkich świąt religijnych oraz zniszczenie zewnętrznych przejawów buddyzmu, takich jak stupy, flagi modlitewne, kadzidła oraz wszystkie zdjęcia Dalajlamy i Panczenlamy. W rezultacie „kolejne lata były świadkami wymazywania całej istniejącej kultury. Prawie wszystkie z niespełna 6 tysięcy klasztorów i świątyń zostały splądrowane i zniszczone. Szał destrukcji nie zatrzymał się nawet przed posągiem "Jowo" w Jokhangu. Najcenniejsze przedmioty ze złota wysłano do Pekinu, gdzie je przetopiono. Rewolucja Kulturalna oznaczała dla Tybetu próbę zniweczenia jego tożsamości kulturowej”.
Po ucieczce z Tybetu Dalajlama zorganizował w Indiach tybetański rząd na uchodźstwie z siedzibą w Dharamsali, próbując ustanowić wspólną tożsamość wszystkich Tybetańczyków, dotychczas bardzo zróżnicowanych pod względem kulturowym, religijnym, etnicznym i językowym. Na poziomie religijnym Dalajlama i rząd emigracyjny nawiązują do powstałego w XIX wieku ruchu Rime, który dążył do jedności wszystkich tradycji buddyzmu tybetańskiego. „Tworzenie na nowo historii Tybetu jest podstawą polityki Dalajlamy” i tybetański rząd na uchodźstwie przedstawia go jako kraj, który „postawił sobie za zadanie zachowanie buddyzmu w jego pierwotnej postaci, w jakiej został przekazany z Indii, a którego jedyny potencjał konfliktu zdawał się polegać na tym, że odpierał wewnętrzne ataki na swoją czystość; Tybet jako kraj klasztorów i świątyń, w którym większość ludności stanowili mnisi i mniszki, w którym również świeccy zajmowali się przede wszystkim praktykami religijnymi i w którym nawet władza sprawowana była przez pobożnych mężczyzn zupełnie nieznających powszechnego na świecie dążenia do władzy”. Ten zmitologizowany obraz Tybetu okazał się bardzo pociągający dla opinii światowej.
Po przejęciu władzy w Chinach przez Deng Xiaopinga w Tybecie rozpoczął się okres politycznej odwilży. Z obozów zwalniano więźniów, zezwolono na odprawianie praktyk religijnych na ograniczoną skalę, w klasztorach i świątyniach przeprowadzono remonty i powrócili do nich mnisi, zaś w szkołach znowu nauczano tybetańskiego. W roku 1987 Dalajlama zaproponował pięciopunktowy plan pokojowy, w którym rezygnował z niepodległości Tybetu proponując przeobrażenie go w samorządną strefę pokojową, przy czym Chiny miały odpowiadać ze jego politykę zagraniczną. Propozycja ta została jednak odrzucona przez Chiny i wywołała silne kontrowersje wśród samych Tybetańczyków. Po śmierci Panczenlamy w 1989 roku w Lhasie doszło do antychińskich demonstracji i po trzydniowych walkach ulicznych Chińczycy ogłosili stan wyjątkowy, który został zawieszony dopiero pod koniec kwietnia 1990 roku. Po tych wydarzeniach Chiny w pewnym stopniu powróciły do polityki tłumienia religii, m.in. reglamentując liczbę mnichów w klasztorach i starając się poddawać nowicjuszy politycznej indoktrynacji. Jednocześnie ciągle wspiera się imigrację Chińczyków do Tybetu. Do kolejnych masowych protestów w Tybecie doszło w roku 2008.
Środowisko geograficzne.
Większą część Tybetu zajmuje Wyżyna Tybetańska – najbardziej rozległy płaskowyż świata, wzniesiony średnio powyżej 4000 m n.p.m. Naturalną jej granicę od południa tworzy łańcuch Himalajów, którego głównymi grzbietami biegnie w zasadzie faktyczna granica państwowa Chińskiej Republiki Ludowej. Wzniesione w niektórych miejscach powyżej 8000 m n.p.m. góry tworzą dużą barierę klimatyczną i komunikacyjną. W obrębie samej Wyżyny Tybetańskiej wyróżnia się zazwyczaj trzy części: zachodnią, południową i wschodnią.
Południowa część Wyżyny Tybetańskiej rozciąga się pomiędzy Himalajami a łańcuchem Transhimalajów. Panują tam najbardziej korzystne warunki dla gospodarki człowieka. Główną „osią” tej części Tybetu jest dolina Brahmaputry. W dolinie tej rzeki oraz w szerokich dolinach jej dopływów skupia się praktycznie cały obszar uprawny Tybetu (ok. 0,5% powierzchni regionu) i większa część jego ludności. Klimat jest stosunkowo chłodny, ze względu na duże wzniesienie nad poziom morza, jakkolwiek łagodniejszy niż w północnej i centralnej części wyżyny, gdzie dużą rolę odgrywa bariera Transhimalajów, przekraczających 6000–7000 m (najwyższy szczyt Nienczen Tangla) i osłaniających dolinę Brahmaputry od północy. W Lhasie, położonej na wysokości 3600 m n.p.m. średnia temperatura w styczniu wynosi 0 °C, w lipcu 17 °C, w dolinach temperatury są wyższe. Ilość opadów, około 1500 mm rocznie (w Lhasie 1630 mm), jest wystarczająca dla potrzeb rolnictwa. Dominuje tam uboga roślinność wysokogórska. Jedynie w dolinach rzek występują nieduże lasy i zarośla.
Zachodnie rejony południowego Tybetu odwadniane są przez górny bieg Indusu i jego dopływu Satledżu, biorącego początek z górskiego, polodowcowego jeziora Mapam Yumco.
Prawie cała wschodnia część Wyżyny Tybetańskiej znajduje się w granicach administracyjnych prowincji Qinghai – jej rejony południowe wchodzą w granice Tybetańskiego Regionu Autonomicznego. Cechuje je bardzo duże zróżnicowanie rzeźby terenu. Przebiegają tędy w głębokich na 2000 m i więcej wąwozach górne odcinki Jangcy, Saluinu i Mekongu, jak również przełomowy odcinek Brahmaputry, skręcającej na południe, przełamującej się największym i najgłębszym przełomem rzecznym świata przez Himalaje. Ciągnące się między tymi dolinami pasma sięgają 7000 m i więcej, występują w nich liczne lodowce. Ta część Tybetu ma cieplejszy i wilgotniejszy klimat niż reszta regionu, z dużymi opadami monsunowymi w okresie letnim. Konsekwencją tego jest znacznie bujniejsza roślinność, zróżnicowana piętrowo – od roślinności wysokogórskiej i łąk alpejskich poprzez lasy świerkowo-jodłowe i zarośla rododendronów aż do roślinności subtropikalnej w głębi dolin, z występowaniem dużych paproci i zarośli bambusa.
Zachodnia część Wyżyny Tybetańskiej stanowi ponad połowę powierzchni Tybetu. Jest to płaskowyż z szeregiem ciągów wzniesień, na których w wyższych rejonach występują liczne lodowce. Między nimi leżą bezodpływowe kotliny, w dnach których znajdują się słone jeziora. Klimat tej części Tybetu jest chłodny, suchy i skrajnie kontynentalny. Średnie temperatury letnie wynoszą na ogół poniżej 15 °C, zimowe wahają się od –10 do –15 °C. Czasami mrozy sięgają –40 °C. Występują przy tym duże amplitudy dobowe – w lecie na przykład od temperatur 35 °C i więcej w południe do poniżej zera w nocy. Roczne sumy opadów oscylują około 200 mm. W związku z tym ta część Tybetu ma charakter pustyni wysokogórskiej. Tylko wzdłuż niewielkich rzek, spływających z lodowców i wpadających do słonych jezior, występują miejscami zarośla drzewiaste.
Tybet w popkulturze.
Szczątkowa wiedza i brak informacji o rzeczywistej sytuacji w Tybecie na Zachodzie przyczyniły się w XX wieku do jego idealizacji, jako krainy duchowego azylu. Najwięcej przyczyniły się do tego: powieść oraz zrealizowany na jej podstawie hollywoodzki film „Zaginiony Horyzont”.
Po wojnie furorę zrobiła powieść „Siedem lat w Tybecie”, którą napisał Heinrich Harrer, austriacki himalaista internowany przez Brytyjczyków w Indiach. Harrer zbiegł do Tybetu, gdzie został nauczycielem obecnego Dalajlamy. Kiedy pół wieku później w Hollywood przystąpiono do ekranizacji powieści, okazało się, że był w członkiem partii i bojowcem SS.
W 1997 roku Martin Scorsese nakręcił film „Kundun” pokazujący dzieciństwo i młodość Dalajlamy od chwili, gdy został uznany za ostatnie wcielenie Bodhisattwy Awalokiteśwara, przez okres edukacji, po dramatyczne wydarzenia związane z zajęciem Tybetu przez Chiny. W wieku 24 lat Dalajlama staje przed dylematem pozostania z Narodem i prawie pewną zagładę, lub na ucieczkę do Indii. Wybiera eksodus; cały ówczesny 'kulturalny świat' łącznie z ONZ pozostaje obojętny na los Tybetu.

</doc>
<doc id="13212" url="https://pl.wikipedia.org/wiki?curid=13212" title="Jagdpanther">
Jagdpanther

Jagdpanzer V „Jagdpanther” – niemiecki niszczyciel czołgów z czasów drugiej wojny światowej. Zbudowany na podwoziu czołgu Panther pojazd charakteryzował się skuteczną i sprawdzoną armatą 88 mm, bardzo dobrym pancerzem przednim i dobrą mobilnością.
Historia.
Niszczyciel czołgów Jagdpanther został opracowany w zakładach Kruppa (prowadzących wcześniej prace nad niszczycielem czołgów na podwoziu PzKpfw V) i Daimler-Benz zgodnie z zamówieniem z sierpnia 1943 roku na samobieżne działo przeciwpancerne. Uzbrojenie wozu stanowić miał czołgowy wariant niemieckiej armaty przeciwpancernej PaK 43 kal. 88 mm – KwK 43. Była to broń, zdolna przebić z odległości 1000 m pancerz 193 mm nachylony pod kątem 60°. Opancerzenie przedziału bojowego miało wynosić 40–80 mm, potem jednak wydano polecenie pogrubienia pancerza czołowego do 100 mm.
W listopadzie 1942 zaprezentowana została pełnowymiarowa, drewniana makieta wozu. Przygotowania do produkcji seryjnej w zakładach Daimler-Benz rozpoczęły się na początku 1943 roku. Rozpoczęcie produkcji seryjnej planowano na grudzień 1943, ale pierwsze Jagdpanthery ostatecznie opuściły taśmę produkcyjną w styczniu 1944. Od 1944 do końca wojny (produkcja ustała w marcu) Niemcy zdołali wyprodukować 392 wozy, z czego 350 trafiło do jednostek.
Zastosowanie bojowe.
W Jagdpanthery uzbrojone były samodzielne bataliony niszczycieli czołgów. Chrzest bojowy przeszły w Normandii (555. i 654. Panzerjagerabteilung) osiągając duże sukcesy, podobnie jak później w Ardenach. Na froncie wschodnim Jagdpanthery pojawiły się jesienią 1944 roku, skutecznie zwalczając radzieckie czołgi ciężkie IS-2. Pod koniec wojny walczyły w Niemczech.
Do końca wojny były najlepszymi niemieckimi niszczycielami czołgów, doskonale łączącymi dobrą manewrowość z potężną armatą nie mającą odpowiedników w uzbrojeniu alianckich pojazdów. Jednak pojazdy te pojawiły się zbyt późno i przede wszystkim w zbyt małej liczbie, aby w znaczący sposób wpłynąć na przebieg wojny.
Po wojnie pojazdy tego typu były używane przez Armię Francuską do lat 60.
Dodatkowe informacje.
30 VII 1944, w pobliżu normandzkiej wioski Les Longes, trzy pojazdy Jagdpanther z 654. schwere Heeres Panzerjäger Abteilung w ciągu dwóch minut zniszczyły w zasadzce cały szwadron czołgów Mk IV Churchill, czyli ok. 10-11 wozów.
W kulturze.
Jagdpanther wystąpił w kilku filmach i grach, takich jak:

</doc>
<doc id="13213" url="https://pl.wikipedia.org/wiki?curid=13213" title="Jagdtiger">
Jagdtiger

Panzerjäger Tiger für 12,8 cm Pak 44 L/55 (Sd.Kfz. 186) – niemiecki ciężki niszczyciel czołgów z okresu II wojny światowej.
Jagdtigera zbudowano na nieznacznie zmodyfikowanym podwoziu czołgu ciężkiego PzKpfw VI B Königstiger (Tiger II). Był ostatnim produkowanym seryjnie niemieckim niszczycielem czołgów i najcięższym pojazdem pancernym użytym bojowo podczas II wojny światowej. Dysponował potężnym uzbrojeniem w postaci armaty PaK 44/2 L/55 kalibru 128 milimetrów, umożliwiającej niszczenie pojazdów alianckich nawet z odległości 4000 metrów. Wyprodukowany został w niewielkiej serii, nieprzekraczającej osiemdziesięciu ośmiu pojazdów. W związku z niewielką mobilnością i silnym pancerzem bywał nazywany „samobieżnym bunkrem”.
Konstrukcja miała wiele wad, do których można zaliczyć między innymi małą mobilność, wynikającą z dużej masy i zbyt słabego silnika. Większość pojazdów stracono w wyniku usterek lub ataków alianckiego lotnictwa.
Historia.
22 lutego 1943 roku wydział "WaPrüf 4a" Urzędu Uzbrojenia Rzeszy zlecił opracowanie zakładom "Henschel" odpowiedniego pojazdu, na którym byłaby możliwa zabudowa działa PaK 44/2 L/55 kalibru 128 mm. Konstrukcję przyszłego niszczyciela czołgów oparto o podwozie Tiger II, w którym konieczne było m.in. wydłużenie wanny kadłuba o 300 mm. 20 października 1943 na poligonie w Orzyszu przedstawiono Hitlerowi drewnianą pełnowymiarową makietę. Führer podjął decyzję o produkcji 150 pojazdów w zakładach "Nibelungenwerke" w St. Valentin w Austrii. Pierwszy prototyp miał być gotowy w grudniu 1943, ale zakłady w St. Valentin były zajęte produkcją czołgów PzKpfw IV. W wyniku opóźnienia dwa pierwsze prototypy były gotowe dopiero w lutym 1944. Pierwszy pojazd o numerze "Fgst 305001" posiadał zawieszenie typu "Porsche". Kolejny prototyp o numerze "Fgst 305002" posiadał zawieszenie typu "Henschel". 6 kwietnia 1944 prototypy rozpoczęły próby na poligonie w Kummersdorfie. 20 kwietnia 1944 Jagdtiger został skierowany do produkcji seryjnej.
Produkcja.
Produkcję Jagdtigerów prowadziły zakłady Nibelungenwerke w St. Valentin, które kooperowały z wieloma innymi dostawcami. Pancerne nadbudowy pochodziły z zakładów Eisenwerken Oberdonau w Linzu, wanny kadłuba były produkowane przez Bergische Stahlindustrie w Remscheid, Bochumer Verein w Bochum, Fr. Krupp w Essen i przez Obeschleischische Hüttenwerke Oberhütten Malapane (dzisiejsza Huta Małapanew) w Ozimku koło Opola. Jarzma armaty pochodziły z zakładów Krupp-Bertha w dzisiejszym Wrocławiu.
Pierwsze seryjne pojazdy opuściły fabrykę w lipcu 1944. Całkowita liczba wyprodukowanych Jagdtigerów jest trudna do ustalenia, waha się w różnych opracowaniach od 74 do 88 ("Fgst 305001–305088").
Inne źródła podają:
Wersje.
Jagdtigery kolejnych serii produkcyjnych nieznacznie różniły się od siebie. W lipcu 1944 dodano blaszane osłony rur wydechowych zmniejszające odblask płomieni w nocy. W sierpniu 1944 zastosowano inną zewnętrzną blokadę lufy w położeniu marszowym. Od września 1944 zaprzestano pokrywania pojazdów "zimmeritem". W listopadzie natomiast zrezygnowano z montowania lewara o udźwigu 20 000 kg na tylnej części wanny kadłuba. W grudniu 1944 rozpoczęto montowanie na bokach nadbudowy sześciu zaczepów dla zapasowych ogniw gąsienic. Od lutego 1945 montowano zaczepy do montażu lekkiego dźwigu o udźwigu 2000 kg. Na niektórych pojazdach od 1945 na pokrywie silnikowej montowano gniazdo do mocowania stojaka karabinu maszynowego MG 42 służącego do prowadzenia ognia przeciwlotniczego.
Opis konstrukcji.
Kadłub Jagdtigera był spawany z płyt stalowych, walcowanych i utwardzanych powierzchniowo przez nawęglanie. Opancerzenie pojazdu wynosiło od 25 do 250 mm. Skuteczność zastosowanego opancerzenia zwiększał kąt nachylenia płyt pancernych wynoszący 40°–75°. Najgrubszy pancerz posiadała płyta czołowa nadbudowy kadłuba 250 mm (nachylenie 75°). Przód kadłuba miał opancerzenie od 150 mm (górna płyta pochylona pod kątem 40°) do 100 mm (dolna płyta pochylona pod kątem 40°). Opancerzenie boków i tyłu wynosiło 80 mm, góra 40–45 mm i dno pojazdu 25 mm.
Z przodu kadłuba mieścił się przedział transmisji i skrzynia przekładniowa, a za nimi przedział kierowania. Środkową część zajmował przedział bojowy nakryty stałą nadbudową. Przegroda ogniowa oddzielała przedział bojowy od przedziału silnikowego, który mieścił się z tyłu pojazdu.
Niszczyciel czołgów Jagdtiger posiadał dwa rodzaje zawieszenia. Pojazdy z zawieszeniem opracowanym przez zakłady "Henschel" posiadały dziewięć podwójnych całkowicie stalowych kół jezdnych z każdej strony. W podwoziu tego typu koła jezdne był zamocowane na osiemnastu niezależnie amortyzowanych drążkach skrętnych. Drugi typ podwozia został opracowany przez Ferdynanda Porsche. Podwozie składało się z każdej strony z czterech zdwojonych, niezależnie zawieszonych wózków. Podwozie "Porsche" miało wiele zalet: było lżejsze o 1200 kg, łatwiejsze w montażu, tańsze oraz zajmowało mniej miejsca we wnętrzu pojazdu. Z tyłu kadłuba znajdowały się koła napinające, a z przodu koła napędowe, które różniły się liczbą zębów napędowych w zależności od typu zawieszenia.
Napęd stanowił 12-cylindrowy, widlasty silnik gaźnikowy Maybach HL 230 P30 o pojemności 23 095 cm³ i mocy 700 KM przy 3000 obr./min, chłodzony cieczą. Silniki były produkowane w składach "Maybach" we Friedrichshafen i "Auto-Union AD" w Chemnitz. Skrzynia przekładniowa mechaniczna, półautomatyczna posiadała 8 biegów do przodu i 4 wsteczne.
Załoga Jagdtigera składała się z sześciu osób. Z przodu wanny kadłuba za przedziałem transmisji po lewej stronie zajmował miejsce kierowca dysponujący ruchomym peryskopem. Po prawej stronie znajdowało się stanowisko strzelca-radiotelegrafisty, który obsługiwał radiostację oraz kadłubowy karabin maszynowy. Do obserwacji posiadał stały peryskop. Kierowca i radiotelegrafista posiadali osobne włazy. W nadbudowie mieszczącej przedział bojowy były miejsca pozostałych czterech członków załogi. Z przodu po prawej dowódca, z lewej celowniczy, za nimi dwóch ładowniczych. Dowódca dysponował okrągłym włazem na wierzchu nadbudowy oraz dwoma stałymi i jednym ruchomym peryskopem.
Pojazd był uzbrojony w armatę "12,8 cm PaK 44" kalibru 128 mm. Długość lufy wynosiła 55 kalibrów (L/55). Armata przemieszczała się w pionie w zakresie –7° +15° oraz w poziomie 10° w prawo i 10° w lewo. Zapas amunicji wynosił 40 naboi dwudzielnych. Do armaty stosowano dwa rodzaje pocisków. Pociski przeciwpancerne "PzGr 43" o masie 28,3 kg i prędkości początkowej 920 m/s oraz pociski burzące "SpGr l/50" o masie 28,0 kg i prędkości początkowej 750 m/s. Pocisk przeciwpancerny przebijał z odległości 500 m pancerz o grubości 178 mm, a z odległości 2500 m pancerz 148 mm. Dodatkowe uzbrojenie stanowił karabin maszynowy "MG 34" lub "MG 42" kalibru 7,92 mm umieszczony w kadłubie pojazdu obok kierowcy w jarzmie kulistym "Kugelblende 80". Zapas amunicji wynosił 1500 naboi. W pojazdach późniejszych serii produkcyjnych montowano na osłonie silnika dodatkowy "MG 42" na specjalnej podstawie umożliwiającej prowadzenie ognia przeciwlotniczego. Jagdtigery wyposażono również w "Nahverteidigungswaffe". Urządzenie pozwalało na wystrzeliwanie granatów odłamkowych, dymnych, sygnałowych lub oświetlających.
Jagdtigery były wyposażone w celownik "Winkielzielfernrohr" 2/1. Celownik umożliwiał prowadzenie ostrzału do 4000 m dla pocisków przeciwpancernych i do 8000 m pociskami burzącymi. Kadłubowy karabin maszynowy posiadał celownik "Kfz 2" o 1,8 krotnym powiększeniu.
Pojazdy były wyposażone w radiostację "FuG 5", która zapewniała łączność do 6,4 km przy nadawaniu fonią i do 9,4 km kluczem.
Służba.
Jadtigery znalazły się na wyposażeniu dwóch batalionów ciężkich niszczycieli czołgów, jako sprzęt etatowy. 2 pojazdy przejęte 5 maja 1945 w St.Valentin przez załogi z 501. Batalionu Czołgów Ciężkich SS ("schwere SS-Panzerabteilung 501") zostały użyte do zabezpieczenia odwrotu niemieckich jednostek chcących się poddać Amerykanom. Pojazdy zostały utracone w walkach z czołgami radzieckimi. Jeden z pojazdów trafił w późniejszym czasie do muzeum w Kubince.
Pierwszą jednostką, która została wyposażona w Jagdtigery był 653. Batalion Ciężkich Niszczycieli Czołgów ("schwere Panzerjäger-Abteilung 653") posiadający wcześniej na uzbrojeniu niszczyciele czołgów typu Ferdinand. Etat przewidywał 42 niszczyciele w trzech kompaniach, w każdej 3 plutony po 4 Jagdtigery oraz 2 wozy w dowództwie kompanii. Dodatkowy 1 pojazd znajdował się w dowództwie batalionu.
Pierwszy pojazd o numerze "Fgst 305007" dotarł do batalionu 6 września 1944. Na skutek opóźnień w produkcji w październiku 1944 w jednostce było tylko 16 Jagdtigerów. Niszczyciele miały przejść chrzest bojowy w czasie ofensywy w Ardenach. Skierowano tam 1. kompanię liczącą 14 pojazdów, która jednak nie dotarła na miejsce na skutek zniszczonych szlaków kolejowych. Ostatecznie Jagdtigery zostały skierowane go Grupy Armii G, która przygotowywała się do ofensywy w Alzacji. W operacji Nordwind wzięły tylko 2 działa z 3. kompanii wspierające działania 17 Dywizji Gren. Panc. SS „Götz von Berlichingen”. 4 stycznia 1945 dołączyły kolejne 4 pojazdy z 1. kompanii. 26 stycznia po przybyciu 2. kompanii jednostka osiągnęła pełny skład przewidziany etatem. 
W lutym w związku z dużą liczbą niesprawnych niszczycieli batalion skoncentrowano na tyłach frontu, a pojazdy poddano naprawom. Dopiero w marcu 1945 Jagtigery sPzJgAbt. 653 skierowano w rejon lasu Haguenau, gdzie toczyły walki w rejonie Wissembourga, Bühl oraz Schwetzingen. W końcu marca 1945 batalion zajął pozycję obronną nad rzeką Neckar. W kolejnych dniach prowadził działania obronne w rejonie Klingenberg am Main przeciwko francuskiej 5. DPanc., a na początku kwietnia w Crailsheim by się wycofać do Nördlingen.
Przez cały czas batalion borykał się z usterkami Jagdtigerów. 1 lutego 1945 na 41 pojazdów, 16 było niesprawnych. Najwyższy stan gotowości jednostka osiągnęła 15 marca, kiedy na 41 niszczycieli tylko 3 wymagały napraw. Trzy dni później 18 marca w batalionie były 34 pojazdy, gotowych do użycia 18, 30 marca 28 pojazdów, ale tylko 6 sprawnych. W dniu 3 kwietnia zostały 23 Jagdtigery, z czego sprawny był tylko 1. Do 9 kwietnia stan sprawnych zwiększył się do 10 pojazdów. 15 kwietnia w sPzJgAbt. 653 było 17 niszczycieli, sprawnych 5, a 26 kwietnia na 14 posiadanych, aż 13 było w naprawie.
20 kwietnia 1945 wolne załogi zostały odesłane do St. Valentin po odbiór nowych pojazdów. Pozostałą część batalionu skierowano do Górnej Austrii do Grupy Armii Południe do Salzburga i Linzu, gdzie koło Liezen stracono ostatnie dwa pojazdy zdobyte przez Amerykanów. Grupa, która przybyła do "Nibelungenwerke" wysadziła 8 pojazdów, które znajdowały się na ostatnim etapie produkcji.
Drugą jednostką wyposażoną w Jagdtigery był 512. Batalion Ciężkich Niszczycieli Czołgów ("schwere Panzerjäger-Abteilung 512"). Kadra pochodziła z rozwiązanego 424. Batalionu Czołgów Ciężkich ("schwere Panzer-Abteilung 424") oraz częściowo z 503. Batalionu Czołgów Ciężkich ("schwere Panzer-Abteilung 503"). Pierwsze 16 pojazdów batalion otrzymał w połowie lutego 1945. Jednostka szkoliła się na poligonie w Döllersheim w Austrii, a następnie w Sennelager na przedmieściach Paderborn. Batalion nigdy nie walczył w pełnym składzie trzech kompanii.
1. kompania dowodzona przez asa pancernego kpt. Alberta Ernsta mającego przydomek "Tygrys z Witebska" przeszła chrzest bojowy 10 marca 1945 podczas niemieckiego kontrataku pod Remagen. Kompania liczyła 10 pojazdów (wóz dowódcy kompanii oraz po 3 pojazdy w trzech plutonach). Po tym debiucie bojowym w kompanii zostało 6 Jagdtigerów. W kolejnych dniach Ernst prowadził walki odwrotowe pod Siegen, a następnie poprzez Meinerzhagen i Lüdenscheid dotarł 8 kwietnia do Altena. 11 kwietnia kompania została skierowana do Unna, gdzie miała wziąć udział w próbie przerwania okrążenia, który Amerykanie zamknęli wokół Zagłębia Ruhry. Po przeprawie przez rzekę Ruhra koło Langschede doszło do starcia. Oddział Ernsta ostrzelał ze wzgórza amerykańską kolumnę pojazdów. W wyniku ostrzału Niemcy zniszczyli 50 pojazdów, w tym 11 Shermanów. Niektóre z nich niszcząc z odległości 4000 m. Straty niemieckie to 1 Jagdtiger zniszczony przez lotnictwo. 12 kwietnia kompania ubezpieczała lotnisko w Deilinghofen niszcząc 2 Shermany. Następnie wycofała się do Iserlohn, gdzie zniszczono kolejne 3 czołgi amerykańskie. 16 kwietnia Ernst skapitulował. Jego oddział liczył w tym momencie tylko 3 Jagdtigery.
Dowódcą 2. kompanii został inny niemiecki as pancerny Otto Carius. 8 marca kompania wyruszyła z Sennelager transportem kolejowym do Siegburga. Na skutek nalotów oraz błędnego skierowania części oddziału do Duisburga Carius nie wziął udziału w planowanym kontrataku na most pod Remagen. Stracono też dwa Jagdtigery zniszczone przez lotnictwo. Po wyładunku kompanię rozproszono wykorzystując niszczyciele jako statyczne punkty oporu wzdłuż linii frontu. W trakcie tych działań stracono następne dwa pojazdy. W kolejnych dniach wycofując się wzdłuż rzeki Sieg oddział Cariusa dotarł poprzez Eitorf, Betzdorf i Kirchen do Siegen. W trakcie przemarszu utracono 2 Jagdtigery. 2. kompania została wraz z innymi niemieckimi oddziałami okrążona w Zagłębiu Ruhry. Koło Weidenau dysponując tylko 4 Jagdtigerami Carius dokonał udanego kontrataku niszcząc 1 czołg amerykański. Z Weidenau kompanię przetransportowano koleją do Unna, gdzie prowadziła działania obronne tracąc Jagdtigera. 15 kwietnia 1945 w Ergste Carius skapitulował wysadzając lufy ostatnich trzech niszczycieli.
3. kompania nie została do końca zorganizowana. W marcu dowódca kompanii porucznik Schrader wyruszył transportem kolejowym z czterema Jagdtigerami do Paderborn. W St.Valentin pozostał jeden z dowódców plutonu, który miał doprowadzić pozostałe pojazdy. 21 marca 1945 w wyniku nalotu linia montażowa została ciężko uszkodzona. W tej sytuacji zorganizowano transport ostatnich dwóch niszczycieli. Transport dotarł 4 kwietnia do Verliehausen nad Wezerą. Trzy dni później dotarł tam Schrader z jednym Jagdtigerem. Jeszcze w tym samym dniu Schrader zginął. W ciągu następnych dni pozostałe pojazdy zostały utracone.
Zachowane pojazdy.
Do czasów współczesnych zachowały się tylko 3 pojazdy: 2 Jagdtigery w Europie i 1 w Stanach Zjednoczonych.

</doc>
<doc id="13216" url="https://pl.wikipedia.org/wiki?curid=13216" title="Kultura olduwajska">
Kultura olduwajska

Kultura olduwajska (oldowajska) albo preaszelska, także: kultura Olduvai ("Kompleks Oldowajski – kultury o tradycji otoczakowej") – najstarsza kultura paleolitu, datowana na 2,6–1,7 mln lat temu, jej nazwa pochodzi od wąwozu Olduvai w północno-zachodniej Tanzanii, przy granicy Parku Narodowego Serengeti, w prowincji Arusza.
Kryteria wydzielenia.
Pierwszym etapem rozwoju kultury ludzkiej było wytwarzanie narzędzi rdzeniowych z otoczaków. Rodzaj surowca, z jakiego wykonywano pierwsze narzędzia, stanowi kryterium wydzielenia kultur, a stopień zaawansowania technologicznego obróbki wyznacza trzy stadia rozwojowe kultur na terenie Afryki.
Chronologia, geneza, zanik.
Pierwsze stadium rozwojowe kultur otoczakowych na terenie Afryki przypada na okres 2,61/2,4 – 2/1,9 mln lat temu. Najstarsze narzędzia kamienne pochodzą z terenu Etiopii oraz Kenii – dorzecze Auaszu, dolny bieg rzeki Omo i basen Jeziora Turkana.
Najstarsze, jak dotąd, artefakty – rdzenie otoczaków z odłupanymi fragmentami o wieku 2,61 mln lat znaleziono na stanowisku Bokol Dora 1 w Etiopii.
Drugie stadium rozwojowe określane jest mianem "oldowajenu". Nazwa pochodzi od stanowiska Olduvai, które w składa się z kompleksów stanowisk oznaczanych jako I, II. Wyniki badań z kompleksu I wyznaczają okres trwania tego stadium w przedziale 2,0–1,7 mln lat temu.
Stanowiska kompleksu I, II oraz wytwory narzędzi kamiennych w nich odnajdywane należą do tej samej tradycji technologicznej – oldowajenu. Mary D. Leakey, określa tę fazę jako „rozwinięty oldowajen”, którego początki wyznacza data ok. 1,7 mln temu, zaś jego zanik związany jest z rozpowszechnianiem się technologii aszelskiej, choć na wielu stanowiskach (m.in Olduvai) mamy do czynienia z równoczesnym występowaniem wytworów obu tradycji technologicznych.
Pierwsze ślady działalności praczłowieka na terenie Europy związane są z pierwsza migracją form praludzkich, które drogą przez Cieśninę Gibraltarską docierały na wybrzeża dzisiejszej Hiszpanii. W związku z tym na terenie Hiszpanii odkryto dwa stanowiska Fuente Nueva-3 w Andaluzji oraz Atapuerca-Gran Dolina. Ślady działalności praczłowieka na tych stanowiskach mieszczą się w przedziale 1 mln – 800 tys. lat temu.
Obszar występowania.
Zespoły oldowajskie znane są głównie z obszarów środkowo-wschodniej Afryki. Większość stanowisk znajduje się w granicach Wielkich Rowów Afrykańskich m.in. basen jeziora Baringo (dzisiejsze terytorium Kenii). Nieliczne znaleziska zaliczane do zespołów oldowajskich wykraczające poza granice Wielkich Rowów Afrykańskich sięgają z jednej strony wschodnich krańców Afryki – stanowisko Sterkfontein, z drugiej zaś do Maghrebu (głównie tereny dzisiejszej wschodniej Algierii – Ain Hanech koło Satif oraz atlantyckiego wybrzeża Maroka – Suk al-Arba al-Gharb).
Na terenie Półwyspu Iberyjskiego oprócz dwóch wyżej wymienionych stanowisk zaliczanych do przemysłów otoczakowych należy wspomnieć także o stanowiskach znajdujących się na terytorium dzisiejszej Portugalii – Magolito, Acofora. Na stanowiska zaliczane do tradycji otoczakowej natrafiono w południowej Francji np. jaskinia Vallonet koło Nicei. Nie mniej stanowisk, które można przypisać do tradycji otoczakowej, dostarczają tereny Półwyspu Apenińskiego – stanowiska Monte Poggiolo, Castelbolognese znajdujące się koło Bolonii oraz stanowiska Fontana Liri i Arce leżące na południe od Rzymu. W okresie 800–600 tys. lat temu pojawiły się inwentarze charakterystyczne dla tradycji otoczakowej na innych terenach europejskich, głównie środkowej i północnej części Francji – stanowisko Soleihac, Nadrenii – stanowisko Karlich, Czechach – stanowisko Prezletice koło Pragi, Ukrainie Zakarpackiej – stanowisko Korolewo I (położone w górnym biegu Cisy) i Morawach – stanowisko Černovice. Stanowiska z okresu 800–600 tys. lat temu nawiązują technologią produkcji narzędzi otoczakowych do tradycji oldowajskiej.
Charakterystyczne wytwory kulturowe.
Cechą charakterystyczną dla I fazy rozwojowej jest występowanie narzędzi otoczakowych z obróbką jednokierunkową, ewentualnie z jednym odbiciem – tzw. "choppery". Krawędzie najprymitywniejszych narzędzi otoczakowych były proste lub lekko wypukłe, zaś podstawowym surowcem do ich produkcji był kwarc, kwarcyt lub bazalt. Przy produkcji narzędzi otoczakowych powstawało wiele ostrych odłupków, dlatego należy przyjąć, że nie wszystkie były traktowane jako odpadki – niektóre z nich zapewne również służyły jako narzędzia.
W kompleksie I w Olduvai poświadczone jest występowanie narzędzi otoczakowych jednostronnych tzw. "chopperów" oraz bloków kamiennych niebędących otoczakami obrabianych dwustronnie z krawędzią zygzakowatą, a więc obrabianych naprzemiennie. Występują także dość płaskie narzędzia z obróbką wielokierunkową.
Cechą charakterystyczną inwentarzy rozwiniętego "oldowajenu" jest zwiększenie ilości narzędzi sferoidalnych i pojawienie się nowych typów narzędzi odłupkowych, tzw. przekłuwaczy. W kompleksie II pojawiają się formy określane przez Mary D. Leakey jako protopięściaki, jednak ich obecność w tym kompleksie podlega licznym dyskusjom w środowisku badaczy paleolitu. Na innych stanowiskach zaliczanych do rozwiniętego "oldowajenu", np. Koobi Fora, poświadczone jest obok "chopperów" i narzędzi typu "chopping-tool" występowanie skrobaczy i zgrzebła.
Cechą charakterystyczną europejskich przemysłów otoczakowych, podobnie afrykańskich, jest występowanie dużej ilości narzędzi otoczakowych dwukierunkowych obok narzędzi jednostronnych i odłupków wytwarzanych przy obróbce narzędzi otoczakowych. Obserwowany jest jednak stopniowy zanik narzędzi sferoidalnych.
Prymitywne techniki produkcji narzędzi.
Prymitywne narzędzia produkowane z otoczaków wykonywane były na jeden z trzech sposobów:
Formy osadnicze.
Pierwsze hominidy zamieszkiwały tereny położone w pobliżu cieków wodnych i nad jeziorami, co zapewniało im lepszą ochronę przed zwierzętami oraz dostęp do wody pitnej. Wówczas łatwiej mogli natrafić na padłe okazy zwierząt, np. słoni, które najczęściej padały w pobliżu wody. W dalszym rozwoju kompleksu oldowajskiego coraz wyraźniej zarysowuje się specjalizacja obozowisk.
Na stanowisku Omo 71 znajdującym się w delcie rzeki Omo poświadczone jest występowanie kości m.in. słonia i hipopotama, wokół których znajdują się narzędzia otoczakowe. W związku z tym stanowisko Omo 71 interpretowane jest jako krótkotrwałe obozowisko na brzegu jeziora, gdzie dokonywano wstępnej obróbki znalezionych w sąsiedztwie szczątków zwierząt, upolowanych przez drapieżniki bądź padłych. Podobnie funkcje spełniało stanowisko DK3, które znajduje się obrębie kompleksu I w Olduvai. Na stanowisku DK3 odkryto kamienny krąg o średnicy 5 m, w który mogły być wetknięte gałęzie. Owa konstrukcja mogła stanowić ochronę przed wiatrem i zabezpieczenie przed zwierzętami. Podobne konstrukcje chroniące przed wiatrem odnaleźć można także na terenie Europy, np. stanowisko Soleihac (Francja).
Specjalizacja obozowisk praludzi najpełniej widoczna jest w kompleksie II w Olduvai, gdzie odkryto ok. 15 stanowisk, na których poświadczona jest działalność praludzi. Pod względem funkcjonalności można je podzielić na 5 kategorii:
Gospodarka.
Obecnie większość badaczy, m.in. Lewis Binford, skłania się ku hipotezie, że pierwsze hominidy były padlinożercami. Badania eksperymentalne prowadzone przez Roberta Blumenschina pozwalają wywnioskować, że praczłowiek miał preferencyjny dostęp do padłych zwierząt. Niewykluczone jest także polowanie praczłowieka na mniejsze zwierzęta, np. antylopy.
Na stanowisku FxJj 20E (znajdującym się w rejonie Koobi Fora) odkryto sięgające ponad 1,4 mln lat temu najstarsze ślady ognia. Niemniej oswojenie ognia, które nastąpiło ok. 1 mln lat temu przypisuje się gatunkowi "Homo ergaster".

</doc>
<doc id="13217" url="https://pl.wikipedia.org/wiki?curid=13217" title="Angelina">
Angelina

Angelina – forma pochodna imion Aniela, Angela.
Angelina imieniny obchodzi 29 kwietnia i 14 lipca.
W ostatnich czasach zapis imienia Angelina bywa spolszczany i występuje w formie Andżelina lub nawet "Andrzelina". Ta druga wersja jest błędna. Po hiszpańsku czytane jako "Anhelina", po bułgarsku "Angielina".

</doc>
<doc id="13218" url="https://pl.wikipedia.org/wiki?curid=13218" title="Kultura łużycka">
Kultura łużycka

Kultura łużycka – kultura archeologiczna środkowej i młodszej epoki brązu oraz wczesnej epoki żelaza (ok. 1300 r. p.n.e – 400 r. p.n.e), występująca głównie na ziemiach Polski oraz przyległych do nich obszarów w innych państwach m.in. Czechach, Słowacji, Ukrainie, Niemczech. Należy do kręgu kultur pól popielnicowych, do którego kwalifikuje się między innymi ze względu na formę pochówku ciałopalnego w popielnicach zakopywanych w ziemi. Kultura łużycka nie jest tworem jednolitym, dzieli się na wiele grup różniących się inwentarzem, obrządkiem pogrzebowym bądź formami osadnictwa. Występowały w niej zarówno osady otwarte, jak i zamknięte, do których zalicza się osadę w Biskupinie. Natomiast wszystkie grupy kultury łużyckiej charakteryzują się tym samym modelem gospodarki oraz względnie zbliżonym modelem struktur osadniczych.
Pochodzenie nazwy.
Termin kultura łużycka został stworzony w drugiej połowie XIX wieku przez niemieckiego patologa, antropologa i prehistoryka Rudolfa Virchowa, początkowo jedynie do oddania zjawisk występujących na obszarach Łużyc, gdzie na przełomie epoki brązu i wczesnej epoki żelaza pojawiły się cmentarzyska składające się z grobów popielnicowych. Stopniowo jednak rozszerzano zasięg kultury łużyckiej na nowe ziemie, wpierw do Saksonii, Wielkopolski i Śląska, a także na tereny Czech i Moraw. Jej funkcjonowania dopatrywano się na coraz szerszych obszarach, identyfikując ją z występowaniem cmentarzysk, zwanych polami popielnicowymi. W XX wieku zaczęto precyzować znaczenie pojęcia. Polscy badacze mieli tendencję do rozszerzania zasięgu kultury łużyckiej, w odróżnieniu od archeologów niemieckich i czeskich. Wiele do dyskusji wniósł czeski archeolog Jan Filip, założyciel czasopisma „Pamatký archeologické”. Na określenie młodszych faz kultury łużyckiej w północnych i północno-wschodnich obszarach Czech używał terminów "kultura śląska" i "kultura platenicka". W dużym stopniu zgadzał się jednak z poglądami archeologów polskich. Archeolodzy niemieccy za kulturę łużycką uważają, odnośnie do obszarów Brandenburgii, Saksonii i Łużyc, wczesne fazy jej rozwoju, nazywając późniejsze mianem "kultury białowickiej", czy "kultury górzyckiej". Z poglądem tym zgadza się Aleksander Gardawski, który wyróżnił kulturę białowicką na obszarze całej kultury łużyckiej. Przyczyną są różne metody, którymi posługują się badacze przy dokonywaniu podziałów taksonomicznych. Badacze polscy kierują się występowaniem pól popielnicowych oraz charakterystycznych form ceramiki, natomiast badacze niemieccy największą wagę przywiązują do wyrobów brązowych, charakterystycznych często dla kultury nordyjskiej.
Kryteria wyróżnienia.
Kultura łużycka została wyróżniona na podstawie typu gospodarki, podobnych form osadniczych oraz cech budownictwa. Ponadto wiele wzajemnych powiązań można zauważyć w inwentarzu ceramicznym, różnym co prawda w poszczególnych grupach, wykazującym jednak wiele cech wspólnych, zarówno co do strony technicznej, jak i stylów w zdobnictwie. Ponadto czynnikiem, który zaważył na wyróżnieniu tej kultury, jest obrządek pogrzebowy, w którym zmarłych składano powszechnie na długo użytkowanych cmentarzach.
Geneza.
Historia badań nad początkami kultury łużyckiej.
Na przełomie XIX i XX wieku dominował pogląd, według którego ludność kultury łużyckiej przybyła na obszar dorzecza Odry i środkowej Łaby z ziem położonych w dorzeczu środkowego Dunaju. Wzrost zainteresowania tą problematyką miał miejsce w latach 20. XX wieku, kiedy zajęli się nią Józef Kostrzewski i Bolko von Richthofen, którzy zwrócili uwagę na istnienie grobów, które można nazwać formami przejściowymi, pomiędzy obrządkiem szkieletowym a obrządkiem ciałopalnym. Były to groby ciałopalne niezawierające popielnic, w których spalone resztki zwłok rozsypywano w jamach, wykopanych na długość ciała zmarłego. Ponadto wskazywano na obecność niektórych wyrobów ceramicznych i brązowych zarówno we wczesnych fazach kultury łużyckiej, jak i w poprzedzającej ją kulturze przedłużyckiej. W związku z tym uznano, że omawiana jednostka taksonomiczna wykształciła się na przełomie II i III epoki brązu, czyli około 1300 lat p.n.e. na bazie kultury przedłużyckiej. W 1928 roku Leon Kozłowski, zgadzając się z tą teorią, wyróżnił dla obszarów Dolnego Śląska, południowej Wielkopolski, Łużyc oraz wschodniej Saksonii, tak zwaną "kulturę starołużycką", uznając te ziemie za kolebkę kultury łużyckiej. Pogląd ten przyjął się wśród innych archeologów, jednak obecnie został odrzucony i nie funkcjonuje już w literaturze.
W latach 30. na skutek podjętych licznych badań na stanowiskach epoki brązu, zwrócono uwagę na rolę kultury trzcinieckiej w formowaniu się kultury łużyckiej. Polscy badacze zagadnieniem tym zajęli się zwłaszcza po drugiej wojnie światowej. Przecenianiano rolę kultury trzcinieckiej w formowaniu się kultury łużyckiej. Wysuwano wtedy pogląd, że kolebką mogła być strefa przemieszania się zespołów przedłużyckich i trzcinieckich. Ważne dla rozwoju myśli nad genezą kultury łużyckiej było wyróżnienie przez Aleksandra Gradawskiego fazy łódzkiej, datowanej na starszą część III okresu epoki brązu, którą wiązał z kulturą trzciniecką, która miałaby być kolebką wschodniej części kultury łużyckiej. Wiąże się to z wyraźnym podziałem na część zachodnią, gdzie większe powiązania można zauważyć z zespołami przedłużyckimi i na część wschodnią, gdzie dalej żywe były niektóre tradycje trzcinieckie. Również na obszarach Moraw i północno-zachodniej Słowacji badacze zwrócili uwagę na wpływy wcześniejszych kultur – kultury wieterzowskiej oraz kultury mogiłowej.
Współczesne spojrzenie na początki kultury łużyckiej.
Powstanie kultury łużyckiej nie jest uważane za jedno zjawisko występujące wszędzie w taki sam sposób. Nie wystarcza wyróżnienie grupy wschodniej i zachodniej, a rozważa się wiele grup, dla których proces formowania się nastąpił pod wpływem szeregu czynników. Proces ten zapewne nie przebiegał też równocześnie. Kształtowanie się kultury łużyckiej następowało w końcowej części II okresu epoki brązu (1700–1300 lat p.n.e.) i na początku III okresu (1300–1100 lat p.n.e.), według podziału chronologicznego dokonanego przez Oskara Monteliusa. Proces ten rozpoczął się najpierw w grupie śląskiej, sasko-łużyckiej i słowackiej. Wiązał się ze zmianą modelu życia ludności przyjętego w kulturze przedłużyckiej na zachodnich i w kulturze trzcinieckiej na wschodnich połaciach ziem objętych nową jednostką kulturową. Zmiany te zachodziły w gospodarce, osadnictwie, kulturze materialnej, a przede wszystkim w obrządku pogrzebowym. Nie wszystkie jednak elementy obrządku pogrzebowego zostały od razu przyjęte, na co wskazuje długotrwałe przeżywanie się niektórych tradycji mogiłowych, na przykład występowanie obok grobów płaskich, pochówków pod kurhanami, wewnątrz których chowano szczątki w obrządku ciałopalnym bądź współistnienie na tych samych cmentarzyskach grobów szkieletowych i ciałopalnych.
Chronologia.
Kultura łużycka rozwijała się od około 1700 lat p.n.e. do około 400 lat p.n.e. W jej rozwoju w okresie epoki brązu na podstawie szerokiego rozprzestrzenienia się niektórych stylów produkcji ceramicznej oraz niektórych typów ozdób wykonywanych z brązu, rozróżnia się dwa podstawowe horyzonty chronologiczne:
Wyróżnia się również fazę przypadającą na wczesną epokę żelaza, kiedy znaczne obszary kultury łużyckiej znalazły się pod wpływami kultury halsztackiej, a na obszarze Śląska można mówić wręcz o rozwijaniu się śląskiego typu stylu halsztackiego. Po raz pierwszy na ziemie polskie napłynęły liczne wyroby żelazne. Ponadto z tym okresem wiąże się powstawanie grodów typu biskupińskiego. Pojawienie się tej formy osadnictwa wiąże się najprawdopodobniej z najazdami na współczesne ziemie polskie Kimmerów. Kolejnym wartym wyróżnienia okresem w kulturze łużyckiej jest Hallstatt D, kiedy największym rozkwitem cieszyła się grupa wschodniowielkopolska, która przejęła od dominującej wcześniej grupy śląskiej, pośrednictwo w handlu bursztynem między obszarami Pomorza i południowej Europy. Na niektórych obszarach kultury łużyckiej, zwłaszcza na Kujawach, doszło do najazdów grup scytyjskich, których efektem było zniszczenie części osad. Na stanowiskach występują charakterystyczne dla Scytów grociki z trzema graniami. Innym dowodem na obecność Scytów na ziemiach polskich jest skarb z Witaszkowa, mający charakter wotywno-kultowy.
Obszar występowania i podział na grupy.
Zasięg występowania.
Zasięg kultury łużyckiej został najszerzej przyjęty przez badaczy polskich, wbrew opiniom archeologów czeskich i niemieckich. Obserwuje się coraz powszechniejsze przyjmowanie polskiego punktu widzenia co do zasięgu. Według tego poglądu kultura łużycka obejmuje niemal całe ziemie polskie, z wyjątkiem północno-wschodnich skrawków kraju, północno-zachodnią i środkową Słowację, północne i środkowe Morawy, północną i północno-wschodnią część Czech, Saksonię, Łużyce, wschodnią Turyngię oraz wschodnią Brandenburgię, zaś w kierunku wschodnim sięga zachodniej części Wołynia.
Podział na grupy.
Rozwijały się, różniące się w mniejszym lub większym zakresie, grupy.
Przynależność etniczna.
Największe emocje wśród archeologów budzi kwestia przynależności etnicznej ludności kultury łużyckiej. Wiąże się to z koncepcją autochtonicznej genezy Słowian oraz z powstaniem terminu "Prasłowianie". W okresie międzywojennym polska archeologia, której czołowym przedstawicielem był Józef Kostrzewski, dążyła do udowodnienia, że ziemie polskie były zasiedlone przez Słowian jeszcze w epoce brązu, a osadnictwo to miało charakter ciągły, aż do wczesnego średniowiecza. Według hipotezy Kostrzewskiego od ludności kultury łużyckiej mieli się wywodzić Słowianie. Koncepcja ta była obowiązującym paradygmatem polskiej archeologii w kilku następnych dziesięcioleciach, kiedy badacze mieli za zadanie dowieść przynależności ziem zachodnich do Słowian. Była ona po części odpowiedzią na teorie archeologów niemieckich, a zwłaszcza Gustafa Kossinny, który doszukiwał się w kulturze łużyckiej etnosu pragermańskiego. Badacze niemieccy widzieli również w kulturze łużyckiej lustrzane odbicie pobytu na omawianych ziemiach ludów iliryjskich. Wiąże się to z wypracowanym przez Kossinnę sposobem przyporządkowania kultur archeologicznych poszczególnym ludom i plemionom, znanym z relacji starożytnych. Dalej od Kostrzewskiego poszedł Aleksander Gardawski, który doszukiwał się istnienia Prasłowian w ramach kultury trzcinieckiej, na bazie której miała dopiero rozwinąć się kultura łużycka, natomiast najbardziej odważną hipotezę postawił Witold Hensel, który uważał, że pierwsze prasłowiańskie wspólnoty należy przypisywać do kultur z ceramiką sznurową. Zgodnie z tą hipotezą kultura trzciniecka i wschodnia część kultury łużyckiej odpowiadały plemionom słowiańskim, natomiast zachodnia część ziem w zasięgu kultury łużyckiej, dopiero później uległa slawizacji. Spośród grup etnicznych odnotowanych w źródłach piśmiennych podkreślić również należy prawdopodobny związek illyryjskich Wenetów z kręgiem kulturowym pól popielnicowych. U progu czasów historycznych ludy z tak zwanego wenetyjskiego ugrupowania etnicznego zepchnięte były jednak kolejnymi falami migracyjnymi na takie obszary, jak rejon ujścia Wisły, Bretania, Macedonia, a nawet Paflagonia w Azji Mniejszej. Obecnie podkreśla się słabość hipotezy autochtonicznego pochodzenia Słowian, wskazując na brak możliwości udowodnienia ciągłości osadniczej na ziemiach polskich. Zdaniem Kazimierza Godłowskiego geografia etniczna ówczesnej Europy była o wiele bardziej skomplikowana, niż uważają zwolennicy koncepcji autochtonistycznej i istniało z pewnością wiele ludów, których języków nie znamy ani z przekazów pisanych, ani z czasów nam współczesnych. Dlatego też niemożliwe do udowodnienia jest powiązanie niektórych grup etnicznych z określonymi grupami i kulturami kręgu kultur pól popielnicowych, w tym z grupami kultury łużyckiej. W związku z tym, jak podkreśla Piotr Kaczanowski, należy zachować szczególną ostrożność w identyfikowaniu grup taksonomicznych ze znanymi z przekazów pisanych grupami etnicznymi.
Niektórzy polscy badacze identyfikowali ludność kultury łużyckiej ze wspomnianymi przez Herodota Neurami, na co miałyby wskazywać liczne na obszarze Polski nazwy rzeczne o rdzeniu "*nur" / *"nyr" („mokry, wilgotny”): Nurzec, Ner, Narew. Ponieważ Herodot, umiejscawiający Neurów w dorzeczu Prypeci, Bohu i Dniestru, wspomniał, że przybyli tam z dawniejszych siedzib, byliby oni zatem ludnością łużycką, która wywędrowała na wschód.
Społeczeństwo i religia.
Pierwszą i najmniejszą jednostką podstawową w kulturze łużyckiej miała być rodzina pojedyncza. Rodziny te łączyły się następnie w wielkie rodziny bądź rody, na które składało się około 100–150 osób. Jedna taka wielka rodzina mogła wykorzystywać powierzchnię około 20–30 km². Największą, ale zapewne luźniejszą, formę organizacji społecznej miały sprawować plemiona składające się z 30–40 rodów, których próbuje się doszukiwać w podgrupach grup kultury łużyckiej.
Na podstawie grobów z wielkich cmentarzysk poznano strukturę wiekową chowanych osób. Dominowały trzy grupy: dzieci do 6 miesięcy, ludzie młodzi w wieku 15–20 lat oraz ludzie dojrzali w wieku 25–35 lat. Średnia długości życia ludności kultury łużyckiej wynosiła około 20 lat w wyniku wysokiej śmiertelności dzieci. Społeczności były raczej egalitarne, czego dowodem jest mała ilość grobów wyróżniających się pod względem wyposażenia. W niektórych grupach, zwłaszcza w fazach wczesnych, groby takie jednak występują, wskazując na uprzywilejowaną pozycję starszyzny rodowo-plemiennej. O akumulacji dóbr przez takie osoby świadczyć mogą występujące w początkowym okresie skarby brązowe.
Inaczej sytuacja wygląda w kwestii próby rekonstrukcji dawnych wierzeń i idei religijnych. Na cmentarzyskach brak jest grobów wskazujących na osoby pełniące funkcje kultowe lub obrzędowe. W niektórych grupach występują co prawda figurki ludzkie lub instrumenty muzyczne, jednak zdaniem Piotra Kaczanowskiego znaleziska te nie są dostatecznym argumentem na istnienie zinstytucjonalizowanych form obrzędowych. Z obszaru objętego zasięgiem kultury łużyckiej nie jest znany żaden obiekt, co do którego można przypuszczać, że pełnił funkcje kultowe. Z kultem solarnym łączy się co prawda niektóre znaki występujące na ceramice oraz przedstawienia ptaków, wiążą się one jednak dopiero z wczesną epoką żelaza. Przypuszcza się, że ówczesne wierzenia musiały dotyczyć sfery życia pośmiertnego i różnych aspektów rytuału grzebalnego.
Obrządek pogrzebowy.
Najpowszechniejszym oraz najbardziej charakterystycznym dla ogólnego zarysu kultury łużyckiej jest obrządek pogrzebowy ciałopalny popielnicowy. Zmarłych chowano w grobach płaskich, tworzonych na wielkich, używanych przez wiele pokoleń, cmentarzyskach. Z pojawieniem się takich cmentarzysk wiązało się formowanie kultury łużyckiej na bazie kultury mogiłowej oraz kultury trzcinieckiej. Jednak proces ten nie przebiegał wszędzie jednakowo, a ta forma pochówku nie jest jedyną występującą wśród form grzebania zmarłych. Stosunkowo długo utrzymywały się starsze tradycje mogiłowe, z którymi wiązało się istnienie w głąb II i nieraz IV epoki brązu grobów pod kurhanami. Było tak w Saksonii, na Łużycach, Pomorzu i Słowacji. Inną formą kontynuowania starszych tradycji są współwystępujące na tych samych cmentarzyskach, wraz z grobami ciałopalnymi, pochówki szkieletowe, zwłaszcza na obszarze Górnego Śląska oraz zachodniej Małopolski. Występowały także różne warianty pochówków ciałopalnych. W pierwszych fazach rozwoju, na cmentarzysku położonym w miejscowości Kietrz, odkryto wiele grobów przygotowanych jakby na przyjęcie całych, niespalonych zwłok (tzw. Grób typu kietrzańskiego), w których znajdowały się jedynie rozsypane po całej jamie szczątki zmarłego. Innym typem grobu są pochówki ciałopalne popielnicowe znajdujące się pod brukiem kamiennym. Cmentarzyska kultury łużyckiej funkcjonowały nawet kilkaset lat, przy czym zachowywano te same tendencje rozwoju nekropolii, nie naruszając grobów starszych.
O sile tradycji łużyckich w obrządku pogrzebowym świadczy niezmienienie się formy pochówku w grupie śląskiej, pomimo licznych wpływów kultury halsztackiej w wielu innych dziedzinach życia. W okresie tym pojawiły się w grupie śląskiej jedynie nieliczne, pojedyncze groby szkieletowe. Wpływami kultury halsztackiej tłumaczy się natomiast pojawienie się konstrukcji drewnianej w grobach, tworzącej tak zwane komory drewniane. Innym efektem tych wpływów jest występowanie w grobach dużych naczyń w kształcie wazy, niesłużących jako popielnice, lecz jako jedne z przystawek. Na uwagę zasługują cmentarzyska położone w miejscowościach Domasław oraz Gorszewice, które wiąże się najprawdopodobniej z istnieniem faktorii handlowej, o czym świadczy mnogość wyrobów obcego pochodzenia. W okresie halsztackim pojawiło się również obstawianie grobów kamieniami, występujące na przykład w grupie górzyckiej, groby wyposażone w broń i elementy uprzęży końskiej, głównie w grupie wschodniowielkopolskiej, obecność licznych grobów szkieletowych w okresie halsztackim C w grupie górnośląsko-małopolskiej, które zanikły już w okresie D oraz groby występujące jeden nad drugim w grupie słowackiej.
Gospodarka.
W zasadzie wszystkie grupy kultury łużyckiej cechują się stabilnym, osiadłym trybem życia, związanym z gospodarką typową dla tej kultury – głównie uprawą ziemi przy dużym znaczeniu hodowli zwierząt. Uprawiano na dużą skalę głównie zboża: pszenicę, jęczmień i proso. Znano także uprawiane kopieniaczo rośliny bobowate, mianowicie: groch, bób i soczewicę, a także len oraz mak. Jako narzędzia do uprawy roli służyły motyki wykonane z fragmentów poroża zwierząt, rogowe kopaczki i sadzaki oraz radła z drewna, którymi z pomocą zwierząt orano ziemię. Zachowane fragmenty radeł pochodzą z wczesnej epoki żelaza, jednak przypuszcza się, że były one używane również w epoce brązu.
Hodowano bydło rogate, owce, świnie i konie. W ramach gospodarstwa domowego funkcjonowała obróbka kości, drewna, gliny, poroża, krzemienia, kamienia, wytwórczość ceramiczna, tkacka oraz obróbka włókien. W okresie halsztackim D na obszarze Kujaw duże znaczenie osiągnęła eksploatacja źródeł słonych. Przez cały okres trwania kultury łużyckiej rozwinięte było odlewnictwo, najprawdopodobniej mające już wtedy status odrębnego rzemiosła. Świadczy to o dużej roli handlu, bowiem wytwórczość metalurgiczna bazowała najprawdopodobniej na surowcu importowanym. Największą rolę handel odegrał we wczesnej epoce żelaza, kiedy grupa śląska kultury łużyckiej najprawdopodobniej przejęła kontrolę nad paneuropejskim szlakiem bursztynowym wiodącym od północnych wybrzeży Morza Adriatyckiego, poprzez obszary naddunajskie, a następnie rzeką Morawą ku Bramie Morawskiej, lądem przez Śląsk, po czym Odrą do Morza Bałtyckiego.
Osadnictwo i budownictwo.
U schyłku II oraz w III i IV okresie epoki brązu dominowały osady otwarte, zakładane na terasach nadzalewowych rzek i potoków oraz na łąkach w pobliżu jezior. Wyjątkiem była grupa sasko-łużycka, w której od najwcześniejszych faz rozwoju występowały grody. Domy wznoszono najczęściej w konstrukcji słupowo-ramowej, chociaż stosowano również konstrukcję zrębową i konstrukcję sumikowo-łątkową. Chaty były budowane na planie prostokąta o dwóch lub trzech pomieszczeniach. W jednym pomieszczeniu było palenisko ułożone z kamieni. Poza budynkami naziemnymi w pozostałościach osad odkryto liczne jamy o charakterze gospodarczym lub produkcyjnym oraz paleniska.
W V okresie epoki brązu rozpoczęła się intensywna kolonizacja wewnętrzna, wiązana ze zwiększeniem gęstości zaludnienia, skłaniającego ludzi do szukania nowych miejsc dla osadnictwa. Zaowocowało to wkroczeniem kultury łużyckiej na tereny górskie w Sudetach i w zachodnich Karpatach. Zaczęto również wykorzystywać zalesione obszary dzielące dotąd poszczególne centra osadnicze. W następnej fazie rozwoju, zaliczanej już do okresu halsztackiego, zaczęto na południowych i zachodnich połaciach terytorium zajętego przez kulturę łużycką wznosić osiedla obronne – grody typu biskupińskiego. Poza Biskupinem, datowanym metodą dendrochronologiczną na 738 lub 737 rok p.n.e., grody takie znane są ze stanowisk położonych przy miejscowościach Izdebno, Smuszewo, Sobiejuchy, Jankowo i Kruszwica. Wszystkie były ulokowane na terenach bogatych w zbiorniki wodne, dążono do maksymalnego zagospodarowania zabudowanej powierzchni i wykorzystania naturalnych walorów obronnych. Wały tych grodów budowano w konstrukcji zrębowej, ich wnętrze wypełniając ziemią i kamieniami. Ich pojawienie się związane jest z tak zwanym horyzontem kimmeryjskim, czyli z przybyciem do Europy koczowniczych ludów, najeżdżających między innymi obszary objęte osadnictwem kultury łużyckiej. Osady ufortyfikowane charakteryzują grupę słowacką, gdzie istniały grody ufortyfikowane wałami drewniano-kamienno-ziemnymi, z rzędami domów porozdzielanych ulicami. Niektóre z chat w tej grupie były stawiane na podmurówkach kamiennych. Istnieje pogląd, według którego grody kultury łużyckiej były zaczątkiem procesów urbanizacyjnych na ziemiach polskich. Jednakże brak swobody architektonicznej wyrażający się w przestrzeganiu określonych zasad przy rozmieszczaniu nowych budynków, a także społeczny nacisk na egalitaryzm, brak miejsca centralnego i obiektów publicznych oraz samowystarczalność osady powodują, że we współczesnym rozumieniu słowa miasto nie można utożsamiać grodów typu biskupińskiego z procesami urbanizacyjnymi.
Inwentarz.
Wyroby ceramiczne.
W III okresie epoki brązu w grupie sasko-łużyckiej oraz w grupie śląskiej wykształcił się w ceramice styl guzowy. Na brzuścach naczyń tworzono guzy poprzez wyciskanie ich z wnętrza naczynia, przez co w przekroju przybierały kształty wieloboków. Powierzchnię wokół guzów zdobiono liniami dookolnymi albo żłobkami. Styl ten występował także w grupie brandenbursko-lubuskiej, gdzie powstał kolejny wariant, oraz w grupie górnośląsko-małopolskiej pod wpływem grupy śląskiej. Styl guzowy nie przyjął się na całości ziem objętych osadnictwem kultury łużyckiej, zwłaszcza na obszarach wschodnich oraz w grupie słowackiej. Inaczej było w IV okresie epoki brązu, kiedy w całej kulturze łużyckiej rozpowszechniły się naczynia dwustożkowate, o ostrych załomach brzuśców. W tym czasie przyjął się również motyw szerokich ukośnych żłobków. U schyłku epoki brązu rozpowszechnił się zwyczaj łagodzenia ostrych załomów brzuśców naczyń oraz przyjęcie się techniki grafitowania powierzchni naczyń. Dla tego okresu typowym był ornament geometryczny, na który składały się grupy rytych kresek, linii oraz trójkątów ukośnie zakreskowanych. Z kolei w grupie sasko-łużyckiej pojawiło się zdobienie naczyń szerokimi poziomymi żłobkami.
We wczesnej epoce żelaza nastąpiły zmiany w znajdującej się pod wpływami kultury halsztackiej grupie śląskiej, z której rozprzestrzeniały się na inne obszary objęte zasięgiem kultury łużyckiej. Rozwinęła się wyspecjalizowana produkcja garncarska, nastawiona na produkcję ceramiki typu halsztackiego. Doskonalono technikę grafitowania naczyń, wprowadzano nowe motywy zdobień, a również zastosowano nowe osiągnięcia w technice produkcji i zdobienia naczyń. Charakterystyczne jest zdobienie naczyń wyświeconymi kreskami lub pasmami na grafitowanej powierzchni. Na Śląsku pojawiło się w tym czasie zjawisko malowania wyrobów ceramicznych, oparte na halsztackich wzorcach. Występują liczne malowane motywy geometryczne składające się z kół, będących wyobrażeniami tarczy słonecznej, czy z trójkątów oraz trykwetrów. Niektóre z tych znaków mogą wskazywać na symbolikę solarną. Wyjątkowym znaleziskiem o charakterze kultowym jest wózek z Domasławia – niewielkie naczynie umieszczone na kółkach. Spotyka się również w grobach kultury łużyckiej tego okresu gliniane podstawki w kształcie półksiężyca, które ustawiane były na płaskich plackach glinianych. Poza tymi nowymi typami ceramiki w dalszym ciągu występowały dawniejsze rodzaje naczyń, używane zwłaszcza w gospodarstwach domowych.
Inaczej sytuacja wyglądała we wschodniej Wielkopolsce, czyli obszarze, który wiódł prym w okresie halsztackim D, kiedy załamaniu uległa grupa śląska kultury łużyckiej. Z grupy wschodniowielkopolskiej na inne obszary obejmowane zasięgiem kultury łużyckiej dostały się wpływy, których efektem była nowa technika zdobienia naczyń – inkrustacja białą masą. Poza tradycyjnymi, starszymi motywami pojawiły się wtedy schematyczne wyobrażenia ludzi i zwierząt, które czasem tworzą całe przedstawienia figuralne na naczyniach. Najczęściej występują sceny polowań na jelenie z udziałem jeźdźców pieszych i konnych oraz sceny z wozami, których interpretacja nastręcza badaczom problemów. Bierze się pod uwagę możliwość wyobrażania w ten sposób podróży w zaświaty. Figuralny styl w zdobnictwie naczyń jest efektem wpływów kultury wschodniohalsztackiej.
Wyroby metalowe.
W trzeciej fazie epoki brązu szeroko rozpowszechniły się wyroby brązowe, wśród których występowały charakterystyczne szpile brązowe, miecze z nitami do umocowania rękojeści, bransolety z tarczkami spiralnymi, różnego typu siekierki, zwłaszcza siekierki z piętką. W czwartym okresie epoki brązu wykształcił się styl, który szybko opanował cały niemal obszar kultury łużyckiej. Wyroby obejmują siekierki z tulejkami, miecze z rękojeściami brązowymi, ozdoby z tarczkami spiralnymi, występujące już wcześniej siekierki ze skrzydełkami, noże, bransolety, pierwsze zapinki. W schyłkowej epoce brązu pojawiły się nowe typy zapinek, sierpy z guzkiem, brzytwy i sztylety, naszyjniki oraz drobne ozdoby z drutu.
Sytuacja uległa zmianie w okresie halsztackim C, kiedy na obszarze zajmowanym przez grupę śląską kultury łużyckiej, pojawiły się wpływy kultury halsztackiej, prawdopodobnie poprzez szlak handlowy, wiodący z wybrzeża północnego Adriatyku nad Morze Bałtyckie. Dzięki tym wpływom w grupie śląskiej po raz pierwszy na ziemiach polskich zaczęły pojawiać się przedmioty żelazne. Wśród wyrobów importowanych występowały zapinki różnego typu, na przykład zapinki harfowate, naszyjniki, naczynia brązowe, klamry do pasa, siekierki żelazne z bocznymi występami, żelazne czekany, rzadziej spotykane już miecze. Ponadto wytwarzano liczne bransolety z kulkowato zgrubiałymi końcami i szpile z łabędzią szyjką. Najprawdopodobniej zmienił się w tym czasie również styl ubierania, ponieważ rozpowszechniły się zapinki i klamry do pasów.
Inne wyroby.
W użyciu były przedmioty wykonane z poroża zwierząt, kości, drewna oraz z kamienia, w szczególności krzemienia. Były to na przykład drewniane radła, służące do orania ziemi, rogowe kopaczki, sadzaki i motyki. Przez cały okres w użyciu były wykonane z kamienia topory. Wytwory krzemienne natomiast funkcjonowały najliczniej w grupach wschodnich, a zwłaszcza w grupie wschodniomazowiecko-podlaskiej, w której z krzemienia wytwarzano różnego typu narzędzia oraz grociki strzał. Znajduje się również niemetalowe ozdoby w postaci paciorków, wykonywanych niekiedy ze szkła.
Zanik.
U schyłku okresu halsztackiego doszło do znacznych zmian klimatycznych. Wiąże się to z nastaniem okresu subatlantyckiego. Był on chłodniejszy i wilgotniejszy od schyłku okresu poprzedniego, subborealnego. W efekcie nasilał się proces zabagniania coraz większych obszarów, w tym nawet zalewania terenów zasiedlonych (zmuszając np. do przebudowania grodu w Biskupinie). Problemem kluczowym było zaspokojenie potrzeb żywnościowych w wyniku koncentracji dużych grup ludności na małych obszarach, co przy mniejszej wydajności środowiska przyrodniczego doprowadziło do zmian w sposobach uprawy ziemi, co pociągnęło ze sobą reorganizację sieci osadniczej, a więc również zburzenie istniejących dotychczas struktur gospodarczo-społecznych. Dodatkowo do destabilizacji przyczyniły się najazdy zagonów scytyjskich, które już w czasach wcześniejszych doprowadziły do załamania się rozwoju grupy śląskiej, wcześniej zresztą uległej silnym wpływom halsztackim. Kryzys znajduje odzwierciedlenie również w danych palinologicznych, które świadczą o ograniczeniu gospodarki ludzkiej i regeneracji szaty leśnej. Na tle tych wydarzeń powstała nowa jednostka kulturowa, dla której bazą była grupa pomorska kultury łużyckiej, nazywana kulturą pomorską. Powstała w wyniku aktywizacji społeczności zasiedlających dotychczas trudniejsze warunki siedliskowe – obszary morenowe południowych pobrzeży Bałtyku. Te mniejsze, bardziej mobilne grupy w zmienionych warunkach stały się motorem przemian społeczno-kulturowych tej części Europy. Charakterystyczne dla nich rozproszone struktury osadnicze lokalizowane były na położonych wyżej i bardziej suchych glebach. Kultura ta szybko rozprzestrzeniła się na inne obszary zajmowane dotąd przez osadnictwo kultury łużyckiej i położyła jej kres. Pozostałości kultury łużyckiej w postaci mniejszych i większych enklaw przetrwały jednak do środkowego okresu lateńskiego. Do ostatecznej destrukcji kręgu kultur popielnicowych przyczyniło się ostatecznie rozprzestrzenienie się w Europie Środkowej żywiołu (proto-)germańskiego.

</doc>
<doc id="13219" url="https://pl.wikipedia.org/wiki?curid=13219" title="Kultura halsztacka">
Kultura halsztacka

Kultura halsztacka – kultura archeologiczna epoki żelaza, rozwijająca się w latach 800-450 p.n.e.
Chronologia, geneza i zanik.
Nazwa pochodzi od eponimicznego stanowiska Hallstatt, leżącego w Alpach Salzburskich, w krainie Salzkammergut, w Austrii, w której w II poł. XIX wieku odkryto wielkie cmentarzysko. Kultura halsztacka występowała w dwóch zespołach:
Zabytki kultury halsztackiej datowane są począwszy od 800 p.n.e. do 450 p.n.e. na zachodnim obszarze występowania oraz 350/300 p.n.e. na Wschodzie. Według systemu chronologicznego Paula Reineckego wyróżnia się halsztat C (HaC do 600 p.n.e.) oraz halsztat D (HaD do 450 p.n.e.).
Obszar występowania i kontekst kulturowy.
Stanowiska kultury zachodniohalsztackiej obejmowały wschodnią Francję, Niemcy i Szwajcarię, a zabytki nawiązywały do kultury pól popielnicowych epoki brązu. Natomiast stanowiska kultury wschodniohalsztackiej obejmowały: Bośnię, Hercegowinę, Siedmiogród, Słowację i wschodnie Alpy. Graniczyły one: od północy ze stanowiskami kultury nordyjskiej, od wschodu łużyckich, urn domkowych, vekerzug, basarabii, od południa ze stanowiskami kultur gollasecca, melaun, este oraz z koloniami greckimi, od zachodu ze stanowiskami katalońskiej kultury pól popielnicowych.
Charakterystyczne wytwory kulturowe.
Ludność tej kultury wytwarzała charakterystyczne naczynia z blachy brązowej – situle, często starannie i bogato dekorowane. Ornament przedstawiał sceny wojenne i ceremonialne, świat kultu, zachowania religijne oraz sceny z życia codziennego.
Charakterystyczne było też garncarstwo. Wytwarzano ceramikę ręcznie, z ornamentem geometrycznym malowanym czarną i brunatną farbą na czerwonym tle. Charakterystyczna była też ceramika o powierzchniach grafitowanych. Były to naczynia duże, dwustożkowate z rozchylonym wylewem i guzami na brzuścu (nawiązania do ceramiki gawskiej).
Osadnictwo.
Występowały silnie ufortyfikowane osiedla, które wyrastały z tradycji wielkich grodów epoki brązu. Osiedla te uważane są przez archeologów za siedziby lokalnych władców. Pełniły również rolę centrów gospodarczo-handlowo-społeczno-religijnych. Gród posiadał potężne kamienno-drewniane mury i wały, a w najwyższej części była potencjalna siedziba władcy oraz świątynia. Przykładem osiedli może być Heuneburg oraz gród w Smolenicach Molpír.
Obrządek pogrzebowy.
Ludność stosowała obrządek birytualny. Nierzadko zdarzało się, iż w jednym grobie mamy do czynienia z kremacją oraz inhumacją. Zmarłych wyposażano w zależności od pozycji społecznej. Pochówki arystokracji miały postać wielkich kurhanów o około 50 m średnicy zawierały południowoeuropejskie przedmioty luksusowe (najsłynniejszy krater z grobu książęcego w Vix, naczynia libacyjne, komplety oporządzenia wojennego, metalową i glinianą zastawę i elementy umeblowania. Najlepszym przykładem grobu arystokracji jest grób w Hochdorf. Skromnie wyposażano wojowników: broń w postaci długich mieczy ze zdobionymi rękojeściami umieszczanymi w pochwach zakończonymi charakterystycznie rozchylonymi „wąsami”, a także włócznie, zapinki, szpile, bransolety, klamry od pasa oraz elementy uździenicy.
Do grobów składano także narzędzia (płaskie siekierki, noże o sierpikowatym ostrzu i sierpy) oraz ceramikę i naczynia brązowe.
Wierzenia.
Wierzenia ilustruje najpewniej ornamentyka ornitomorficzna, uosabiająca wędrówkę pierwiastka duchowego uwolnionego podczas kremacji. 
Gospodarka i społeczeństwo.
Ludność owej kultury trudniła się hodowlą oraz rolnictwem. Specjalizowała się również w eksploatacji, przeróbce i dystrybucji soli (Hallstatt). Obserwujemy wyraźny rozwój produkcji rzemieślniczej oraz obróbki metali. Poświadczone są dalekosiężne kontakty handlowe, co wiąże się z przebieganiem przez tereny halsztackie licznych szlaków handlowych, w tym bursztynowego. Wydarzenia polityczne i gospodarcze (bogacenie się na handlu solą) mogły być przyczyną rozwoju wyższej klasy, czego dowodzą bardzo bogato wyposażone pochówki.

</doc>
<doc id="13220" url="https://pl.wikipedia.org/wiki?curid=13220" title="Kultura aszelska">
Kultura aszelska

Kultura aszelska – jedna z najstarszych kultur dolnego paleolitu, występująca na terenach Afryki, Azji i Europy.
Kryteria wydzielenia.
Nazwa tej kultury pochodzi od eponimicznego stanowiska Saint-Acheul nad Sommą. Za główne kryterium wydzielenia tej kultury posłużyła badaczom znacząca zmiana jakościowa w dziedzinie technologii obróbki kamienia, a mianowicie zastosowanie bifacjalnego retuszu stosowanego przy produkcji pięściaków, rozłupców i innych narzędzi inwentarza kamiennego.
Chronologia, geneza, zanik.
Geneza tej kultury nastręcza badaczom wiele problemów, gdyż na różnych stanowiskach proces krystalizacji tej kultury przebiegał różnie. Na stanowisku Olduvai mamy do czynienia z równoległym współwystępowaniem elementów rozwiniętej kultury olduwajskiej, jak i elementów charakterystycznych dla kultury aszelskiej. Okres współwystępowania obu przemysłów mieści się w przedziale między 1,5 mln–700 tys. lat temu, zaś na stanowiskach w rejonie Melka Kunture w Etiopii można zaobserwować sukcesywne przejście od technologii olduwajskiej do technologii aszelskiej; okres ten trwał od ok. 1,8 mln–500 tys. lat temu, gdzie zasadnicze przejście od jednej technologii w drugą odbyło się zapewne w przedziale między 1,5–1,2 mln lat temu.
Najstarsze narzędzia bifacjalne z terenu Europy odkryto na stanowisku Notarchirico, a wiek tych wyrobów wyznacza data 640 tys. lat. Znaleziska te znacznie wyprzedzałyby wszystkie inne pochodzące z terenu Europy, które w zasadzie nie przekraczają daty 500 tys. lat. Stanowisko Notarchirico jest jedynym zespołem tak wcześnie datowanym, dlatego wśród badaczy przeważa opinia, że to data 500 tys. lat wyznacza początek nowej tradycji technologicznej, stosowanej do produkcji narzędzi kamiennych na terenie Europy. Zanik kultur aszelskich wyznacza okres ok. 50 tys. lat temu. Na terenie Europy kultura aszelska współwystępuje z kompleksem o tradycji narzędzi mikroodłupkowych.
Obszar występowania.
Horyzont wyrobów kulturowych utożsamiany z kulturą aszelską obejmuje swym zasięgiem tereny środkowo-wschodniej Afryki. Świadczą o tym artefakty ze stanowisk Koobi Fora (Kenia), Olduvai (Tanzania) oraz z rejonu Melka Kunture (Etiopia). Zaś o ekspansji kultury aszelskiej na tereny południowej części Afryki świadczą znaleziska z Jaskini Ognisk (RPA, Prowincja Północna) oraz stanowiska Kalambo Falls (na granicy Zambii i Tanzanii). Kolejnym obszarem, na którym poświadczone są znaleziska utożsamiane z kulturą aszelską, są tereny północno-zachodniej części Afryki – stanowisko Tighenif (Algieria).
W Europie wydzielić można trzy prowincje aszelskie:
Charakterystyczne wytwory kulturowe.
Do przewodnich elementów inwentarza tej kultury należą pięściaki wykonywane techniką rdzeniowania z naturalnych fragmentów skał. W fazie wczesnoaszelskiej między 1,5–1 mln lat temu pięściaki w swojej formie są masywne i posiadają silnie sinusoidalną krawędź pracującą. Wiąże się to z zastosowaniem techniki opartej na tzw. „twardym tłuku”. Fazę środkowoaszelską (1 mln–600 tys.) cechuje doskonalsza technika obróbki narzędzi bifacjalnych oraz pojawienia się rozłupców odłupkowych w swojej pierwotnej formie. W fazie późnoaszelskiej (600–300/200 tys.) dochodzi do nowej innowacji technologicznej, a mianowicie zastosowanie tzw. miękkiego tłuka, wykonywanego z miękkich skał osadowych, jak również z fragmentów kości i rogów. Z tych ostatnich wykonywano również narzędzia pośredniczące. Dzięki tej innowacji krawędzie pięściaków aszelskich stają się bardziej regularne, a pięściaki w swej formie stają się cieńsze. W inwentarzach kultury aszelskiej spotkać można sporadycznie narzędzia odłupkowe, tj. zgrzebła i skrobacze. W schyłkowej fazie aszelenu dochodzi do kolejnych zmian jakościowych, prowadzących do produkcji odłupków o pożądanej formie. Nowa technologia była bardzo mało wydajna. W zasadzie z jednej bryły kamiennej powstawał jeden odłupek, do produkcji którego wymagane były bryły o odpowiedniej łupliwości.
Formy osadnicze.
W okresie trwania kultury aszelskiej nadal poświadczona jest specjalizacja stanowisk ludzkich podobnie jak to miało miejsce w kompleksie kultur o tradycji otoczakowej z tym zastrzeżeniem, iż na stanowiskach aszelskich częściej poświadczone jest występowanie ognia do produkcji pożywienia – o czym świadczą odnajdywane przepalone kości. Stanowisko Terra Amata datowane na okres 380 tys. lat temu stanowi przykład pierwszego zorganizowanego obozowiska dolnopaleolitycznego na terenie Europy. W zasadzie jest to kompleks obozowisk, które służyły łowcom kultury aszelskiej jako miejsca kilkudniowych, acz częstych pobytów. Łowcy kultury aszelskiej budowali głównie lekkie konstrukcje szałasowe wznoszone z żerdzi i gałęzi, których końce wbijano wokół owalnego placu. Cała ta konstrukcja wzmocniona była otaczającymi ją kamieniami. Ogień rozniecany był w zagłębieniach, bądź w obstawach kamiennych. Są to pierwsze ślady „oswojenia” ognia przez praczłowieka na terenie Europy.
Na terenie Apulii i Kalabrii występują aszelskie stanowiska jaskiniowe.
Gospodarka.
Twórcy kultury aszelskiej posługiwali się modelem gospodarki przyswajalnej, która miała charakter zbieracki uzupełniany przez szczątki padłych zwierząt. Jak już wspomniano, we wczesnym stadium rozwoju aszelenu człowiek jeszcze nie polował. Przemawiają za tym ślady pozostawione na kościach zwierzyny odnajdywanej na stanowiskach aszelskich. Kości te posiadają w dużej mierze ślady gryzienia przez drapieżniki. Wraz z rozwojem aszelenu diametralnie spada liczba śladów pozostawionych przez drapieżników, wzrasta za to liczba śladów pozostawionych przez narzędzia używane przez człowieka. Świadczyć to może o preferencyjnym dostępie człowieka do tusz padłej zwierzyny. Uzyskanie preferencyjnego dostępu do padłej zwierzyny wymagało zorganizowanych działań podjętych przez większe grupy ludzkie, które by pozwalały na odpędzenie większych drapieżników przy pomocy np. ognia. Pojawienie się w Afryce około 300 tys. lat temu pierwszej udokumentowanej broni łowieckiej służącej do miotania i zaopatrzonej w groty kamienne znacznie zwiększało efektywność działań myśliwskich podejmowanych przez praczłowieka. Na stanowisku JK w Olduvai odkryto system kanałów i basenów, które służyły do produkcji solanki, z której po odparowaniu otrzymywana była sól.

</doc>
<doc id="13307" url="https://pl.wikipedia.org/wiki?curid=13307" title="Franciszek la Perouse">
Franciszek la Perouse



</doc>
<doc id="13308" url="https://pl.wikipedia.org/wiki?curid=13308" title="Zasilacz">
Zasilacz

Zasilacz – urządzenie służące do dopasowania dostępnego napięcia do wymagań zasilanego urządzenia. Ze względu na sposób zmiany wielkości napięcia wyróżnić można:
Ze względu na jakość napięcia wyjściowego wyróżnia się:
Zasilacze budowane są jako uniwersalne lub specjalizowane do konkretnych zastosowań, np.:

</doc>
<doc id="13309" url="https://pl.wikipedia.org/wiki?curid=13309" title="Księstwo nyskie">
Księstwo nyskie

Księstwo nyskie (, ) – biskupie księstwo feudalne na Dolnym Śląsku z ośrodkiem w Nysie.
Historia.
Ziemie te przypadły w 1198 najstarszemu synowi księcia wrocławskiego Bolesława Wysokiego, Jarosławowi, od 1173 księciu opolskiemu i jednocześnie biskupowi wrocławskiemu w latach 1198–1201. Po jego śmierci w 1201 następca Bolesława Wysokiego Henryk Brodaty pozostawił we władaniu biskupstwa kasztelanię otmuchowską jako uposażenie stołu biskupiego oraz ziemię nyską.
Starania o utworzenie księstwa prowadzili następcy Jarosława. Biskup Wawrzyniec (1207–1232) dokonał lokacji Nysy i za zgodą Henryka I Brodatego zbudował osadę graniczną Cygenhals – obecne Głuchołazy. W XIII wieku w obrębie księstwa znajdowały się Zlaté Hory, Javorník, Jesionik i Bruntál. W XIV wieku doszły Ścinawa Mała, Paczków i Grodków. W XV wieku było to już 11 miast.
Biskupi prowadzili jednocześnie intensywną kolonizację swoich ziem także poprzez trzebienie należących do dóbr książęcych lasów Przesieki Śląskiej. Na tym tle doszło do zatargu z Henrykiem IV Probusem, który domagał się zwierzchności nad założonymi na terenach przesieki 65 wsiami. Mediacja legata papieskiego była niekorzystna dla księcia, który uzyskał jednak poparcie książąt śląskich. Ugoda z 1287 stanowiła, iż wsie należą się księciu, który natychmiast podarował je biskupowi. Do porozumienia, które ustanowiło podstawy prawne księstwa biskupiego, doszło w trzy lata później, w ostatnim roku panowania Henryka. 23 czerwca 1290 nadał mocą swego testamentu zarządzającym kasztelanią nyską biskupom wrocławskim niezależność na ziemi nysko-otmuchowskiej – "„daję pełne panowanie i doskonałe pod każdym względem prawo książęce w ziemi otmuchowskiej”". Hierarchowie otrzymali także władzę sądowniczą na terenie księstwa oraz prawo bicia monety.
Pierwszym biskupem wrocławskim posługującym się tytułem książęcym był Henryk z Wierzbna, książę nyski i biskup wrocławski w latach 1302–1319. Książęta świeccy uważający się za spadkobierców zmarłego starali się unieważnić nadany przywilej, jednak w 1333 ostatecznie potwierdził go Bolko II ziębicki. Od 1342 biskupi-książęta uznawali lenną zależność od królów czeskich. W 1430 książę Bolko V Wołoszek sprzymierzony z husytami obstawił swoim wojskiem miasto Prudnik oraz miejscowy zamek, traktując je jako bazę operacyjną w planowanym ataku na księstwo nyskie.
Siedzibą kasztelanii i stolicą księstwa pierwotnie był Otmuchów, ale już od XIII wieku biskupi częściej przebywali w Nysie. Kolegiatę z Otmuchowa do Nysy przeniesiono w 1477.
W 1622 roku biskup wrocławski Karol Habsburg sprowadził do Nysy jezuitów. Rozpoczęło to okres w XVII wieku gdy na terenie księstwa doszło do kilku fal procesów o czary i palenia kobiet (rzekomych czarownic). Procesy te osiągnęły niebywałe rozmiary w skali Europy Środkowej i Śląska. W największym nasileniu pogromy czarownic miały miejsce w latach 1622, 1639–1642, 1651–1652. W roku 1622 na torturach oskarżona kobieta przyznała się do winy, wymieniając pięć innych jako swoje wspólniczki. Wszystkie one zostały spalone. W latach 1639–1642 Johann Balthasar Liesch von Hornau, biskup pomocniczy wrocławski, wybudował specjalny piec do palenia czarownic. Zachowane akta dokumentują 27 egzekucji, jednak z umów zawieranych z katami wynika, że liczba ofiar była znacznie wyższa. W latach 1651–1652, na stosach spalono około 250 kobiet i dziewczynek. Ostatnie procesy o czary zakończone spaleniem miały miejsce w latach 1683–1684 gdy stracono dwie kobiety i mężczyznę. Ostatni proces o czary miał miejsce w roku 1715 i został zakończony umieszczeniem oskarżonej w szpitalu psychiatrycznym.
Po wojnach śląskich w 1742 większa część księstwa znalazła się w granicach Prus. Jedynie jego południową część wraz z letnią rezydencją biskupią na zamku Johannesberg (obecnie Jansky vrch) w Javorníku pozostała w granicach ziem habsburskich – obecnie w powiecie Jesenik. Pozostałe tereny księstwa, które przypadły Habsburgom, to Heřmanovice (niem. Hermannstadt) w powiecie Bruntál, a także Mnichov (niem. Einsiedel) i Železná (niem. Buchbergsthal), będące obecnie częścią gminy Vrbno pod Pradědem.
W czasie ostatniej wojny śląskiej biskup wrocławski Philipp Gotthard von Schaffgotsch skazany przez władze pruskie na banicję uciekł z Wrocławia do leżącej na ziemiach austriackich letniej rezydencji. Kres istnieniu księstwa położyła sekularyzacja przeprowadzona w Prusach w 1810. W 1818 włączono do rejencji opolskiej znaczną część dawnego księstwa biskupiego: powiaty nyski i grodkowski. Tym samym oderwano większość terenów księstwa od Dolnego Śląska i połączono administracyjnie z pruskim Górnym Śląskiem.
Część austriacką sekularyzowano w 1850, pozostawiając jednak majątki ziemskie w rękach biskupów wrocławskich. Stały się one miejscem schronienia biskupa Heinricha Förstera, który został wygnany z Prus w 1875 po wydrukowaniu encykliki Piusa IX krytykującej "Kulturkampf". W 1945 roku przeszły one na własność państwa czechosłowackiego. Obecnie w Polsce znajduje się 1231 km², a w Czechach 900 km² terenów dawnego księstwa.

</doc>
<doc id="13310" url="https://pl.wikipedia.org/wiki?curid=13310" title="Kurhan Mamaja">
Kurhan Mamaja

Kurhan Mamaja (ros. Мамаев курган) lub wzgórze 102 (ros. высотa 102) – najwyższy punkt Wołgogradu, nekropolia i miejsce pamięci radzieckich żołnierzy poległych w bitwie stalingradzkiej podczas II wojny światowej.
Nazwa.
Nazwę wzniesienia wywodzi się zazwyczaj od postaci tatarskiego wodza Mamaja, który był XIV-wiecznym przywódcą zachodniej części Złotej Ordy. Wbrew powszechnemu przekonaniu wzgórze to prawdopodobnie nie miało pierwotnie charakteru grzebalnego. Mianem „kurhanu” zostało po raz pierwszy określone dopiero w czasie trwania bitwy stalingradzkiej przez jednego z korespondentów wojennych, a imię Mamaja nadano mu już po wojnie. Przed 1942 rokiem miejscowa ludność zwała je po prostu „kopcem”, a na wojskowych mapach figurowało jako „wzgórze 102”.
Bitwa stalingradzka.
W czasie trwania bitwy stalingradzkiej (1942–1943) „wzgórze 102” było najważniejszym punktem strategicznym, gdyż można było kontrolować z niego cały odcinek rzeki Wołgi w obrębie miasta. W trakcie bardzo krwawych walk wielokrotnie przechodziło na przemian w ręce Wehrmachtu i Armii Czerwonej. Po zakończeniu bitwy we wnętrzu kopca złożono ciała ponad 34 tysięcy poległych w jego okolicach radzieckich żołnierzy.
Obecnie na Kurhanie Mamaja wznosi się powstały w latach 1959–1967 zespół architektoniczny „Bohaterom bitwy stalingradzkiej”, który upamiętnia radzieckich uczestników walk o miasto. Został zbudowany pod kierownictwem architekta Jewgienija Wuczeticza. Jego głównym elementem jest posąg Matka Ojczyzna Wzywa! Jest to postać kobiety trzymającej w ręku miecz i stojącej w pozie wzywającej do walki. Wysokość z mieczem wynosi 85 metrów, a bez miecza 52 metry.

</doc>
<doc id="13311" url="https://pl.wikipedia.org/wiki?curid=13311" title="Postrzyżyny">
Postrzyżyny

Postrzyżyny – w kulturze dawnych Słowian obrzęd polegający na rytualnym obcięciu włosów dziecku płci męskiej, zazwyczaj kończącemu 7 lat, połączony z nadaniem imienia. Rytuału postrzyżyn dokonywał ojciec lub osoba obca, wchodząca w ten sposób w sztuczne pokrewieństwo z dzieckiem. Od obcięcia włosów syn stawał się pełnoprawnym członkiem rodziny i przechodził spod opieki matki pod zwierzchnictwo ojca.
Podobną praktykę zaobserwował Gajusz Juliusz Cezar wśród Galów i opisał ją w pamiętniku o wojnie galijskiej. Mali chłopcy nie mogli pojawiać się publicznie w obecności ojca do czasu osiągnięcia wieku, w którym stawali się zdatni do wojny.
Postrzyżyny wpisują się w ogólnoludzkie praktyki symbolicznego przyjęcia młodzieńców do wspólnoty, takie jak obrzezanie, rytualne okaleczenia etc.
Zwyczaj postrzyżyn praktykowany jest do dzisiaj, powszechnie jako swoisty symbol poddania się władzy. Postrzyżeni są szeregowi idący do wojska, co jest dokładną kontynuacją rycerskiej tradycji. Do dziś w Kościele prawosławnym postrzygane są osoby wstępujące do zakonu (zob. postrzyżyny mnisze).

</doc>
<doc id="13312" url="https://pl.wikipedia.org/wiki?curid=13312" title="Przesieka Śląska">
Przesieka Śląska

Przesieka Śląska – niezasiedlony do późnego średniowiecza (XV w.) i trudny do przebycia pas gęstych lasów biegnący od okolic wsi Budzów i przez Dzbanów wzdłuż Gór Złotych w kierunku południowo-wschodnim między Głuchołazami i Prudnikiem, następnie wzdłuż górnego biegu Ścinawy Niemodlińskiej i dolnego biegu Nysy Kłodzkiej do Odry, którą przekraczała koło grodu w Ryczynie, dalej wschodnim brzegiem rzeki Stobrawy, a od jej środkowego biegu na północny wschód w pobliże Namysłowa i Byczyny.
Historia.
Początkowo stanowiła granicę plemienną między Ślężanami a Opolanami. W XII wieku stanowiła naturalną granicę pomiędzy księstwem Bolesława Wysokiego a dziedziną Mieszka Plątonogiego, którą od XV wieku zaczęto nazywać Górnym Śląskiem (pierwsza wzmianka pod tą nazwą w 1478 r.). Przesieka stała się tym samym naturalną i historyczną granicą między Dolnym Śląskiem a Górnym Śląskiem. Puszcz granicznych tworzących Przesiekę nie wolno było trzebić jeszcze w drugiej połowie XIII wieku.
Przesiekę przez długi czas wykorzystywano jako naturalną przeszkodę militarną, w zamierzeniu miała chronić przed nadchodzącymi z południa najazdami Morawian i Czechów – jednak w żaden sposób nie była w stanie powstrzymać wielkiego najazdu husytów z 1420 roku.
Według Benno Nietschego przesiekę o szerokości mili wzniósł książę Henryk I Brodaty przeciwko swojemu stryjowi Mieszkowi I Plątonogiemu, „w sposób, jaki kiedyś zastosowano przeciw Czechom w okolicy Przełęczy Bardzkiej, gdzie wycięto mnóstwo pni, a następnie pomiędzy stojącymi drzewami ułożono je w rodzaj palisady”.
Trzebienie lasów tworzących przesiekę było zabronione do końca XIII wieku, a ich resztki można zaobserwować do dziś. Na przełomie XIII i XIV wieku tereny przesieki zostały skolonizowane.
Przyroda.
Na terenie dawnej przesieki zachowało się do dnia dzisiejszego wiele enklaw leśnych, w tym drzewostanów o charakterze zbliżonym do naturalnego, z których cześć podlega ochronie rezerwatowej: Cisowa Góra, Cisy, Przyłek, Dębina, Kokorycz, Krzywiczyny i Komorzno. W linii przebiegu Przesieki Śląskiej położonych jest szereg obszarów Natura 2000 chroniących siedliska leśne: Góry Bardzkie, Przyłęk nad Białą Głuchołaską, Opolska Dolina Nysy Kłodzkiej i Teklusia, oraz Stobrawski Park Krajobrazowy.

</doc>
<doc id="13315" url="https://pl.wikipedia.org/wiki?curid=13315" title="Apoloniusz">
Apoloniusz

Apoloniusz – imię męskie pochodzenia greckiego. Wywodzi się od imienia greckiego boga Apollina. Nosili je między innymi grecki poeta żyjący w III wieku p.n.e. i matematyk Apoloniusz z Pergi. Istnieją liczni święci o tym imieniu (m.in. Ojcowie Kościoła Apoloniusz z Efezu i Apoloniusz senator). Jego żeńskim odpowiednikiem jest Apolonia.
Apoloniusz imieniny obchodzi 8 marca, 10 kwietnia, 18 kwietnia, 21 kwietnia, 7 lipca.
Znane osoby noszące imię Apoloniusz:

</doc>
<doc id="13317" url="https://pl.wikipedia.org/wiki?curid=13317" title="1 Dywizja Pancerna SS „Leibstandarte SS Adolf Hitler”">
1 Dywizja Pancerna SS „Leibstandarte SS Adolf Hitler”

1 Dywizja Pancerna SS „Leibstandarte SS Adolf Hitler” (Leibstandarte SS Adolf Hitler) (niem. "1. SS-Panzerdivision "Leibstandarte SS Adolf Hitler")" – Gwardia Przyboczna Adolfa Hitlera, w skrócie: LSSAH) – najbardziej elitarna spośród dywizji Waffen-SS, wyrosła z oddziału straży przybocznej Hitlera; przyjmowano do niej jedynie ochotników, którzy następnie byli poddawani starannej selekcji. Hasłem dywizji było – „Moim honorem jest wierność”.
Historia.
Dywizja wywodziła się z około 120-osobowego oddziału straży przybocznej (ochrony sztabu) Adolfa Hitlera SS-Stabswache Berlin, utworzonego 17 marca 1933 roku przez Josefa „Seppa” Dietricha, w celu zastąpienia oddziałów SA stanowiących dotychczasową ochronę Hitlera. Po przeniesieniu do dawnego korpusu kadetów w Berlin-Lichterfelde oddział otrzymał nazwę "SS-Sonderkommando Berlin" (Oddział Specjalny SS Berlin). 9 listopada tego samego roku liczącą już 835 „ochroniarzy” jednostkę przemianowano na Leibstandarte Adolf Hitler – LAH („SS” dodano później).
W lipcu 1934 roku żołnierze LAH brali udział w „Nocy długich noży”. Pod koniec tego roku jednostka została zmotoryzowana i z czasem osiągnęła siłę pułku. W marcu 1935 roku esesmani z LSSAH uczestniczyli w zajęciu Saary, w marcu 1936 roku w remilitaryzacji Nadrenii, a w 1938 roku w aneksji Austrii i Kraju Sudetów.
Podczas kampanii wrześniowej w 1939 jednostka walczyła pod Łodzią, Modlinem i Warszawą. Jeszcze jako pułk walczyła w Holandii i Francji. 28 maja 1940 r. żołnierze LAH zamordowali pod Wormhoudt niedaleko Dunkierki od 65 do 85 jeńców brytyjskich.
W sierpniu 1940 roku jednostkę rozbudowano do brygady i w lutym 1941 wysłano ją na Bałkany, by wzięła udział w ataku na Jugosławię. Już jako LSSAH, zdobyła Skopje, a następnie wkroczyła do Grecji, gdzie zajęła między innymi Janinę.
W sile prawie 11 000 ludzi LSSAH wzięła udział w operacji Barbarossa. W październiku 1941 znalazła w zdobytym Taganrogu ciała wziętych do niewoli 6 esesmanów zamordowanych przez czerwonoarmistów – w odwecie w ciągu trzech dni żołnierze LSSAH zabili około 4000 wziętych do niewoli Rosjan. Przez następne miesiące walczyła nad Donem.
W lipcu 1942 jednostkę wycofano do Francji i rozbudowano do dywizji grenadierów pancernych (LSSAH dostała wtedy jedne z pierwszych czołgów Tygrys).
W styczniu 1943 roku licząca prawie 21 000 żołnierzy LSSAH wróciła na Ukrainę, gdzie walczyła nad Donem i Dnieprem. W lutym jednostka oddała Armii Czerwonej Charków, ale wściekłość Hitlera spowodowała, że miesiąc później miasto zostało odbite po krwawych walkach. LSSAH zapłaciła jednak za ten sukces wysoką cenę – 4500 zabitych i rannych żołnierzy. W lipcu tego samego roku dywizja uczestniczyła w operacji „Cytadela” (tracąc w niej 474 zabitych i 2279 rannych).
Pod koniec miesiąca została wysłana do Włoch, broń zostawiając innym jednostkom. Przezbrojona, pełniła obowiązki okupacyjne w północnych Włoszech, zwalczając tamtejszą partyzantkę.
W październiku 1943 LSSAH przekształcono w dywizję pancerną i w sile prawie 20 000 ludzi ze 160 czołgami wysłano w rejon Żytomierza na Ukrainie. Po kilku miesiącach bardzo ciężkich walk, w lutym 1944 w dywizji pozostały jedynie 3 czołgi i 4 działa pancerne. W połowie marca, po walkach w rejonie Kamieńca Podolskiego LSSAH stopniała do stanu 1250 ludzi. Miesiąc później niedobitki elity SS wysłano do Belgii.
W czerwcu odtworzona LSSAH liczyła około 20 000 żołnierzy (nie byli oni już wtedy poddawani tak ostrej selekcji jak na początku wojny), którzy byli uzbrojeni w m.in. prawie 120 czołgów i ponad 40 dział pancernych. 6 czerwca 1944 w Normandii wylądowali alianci. Odnowiona LSSAH została skierowana przeciwko nim, ale na front dotarła w całości w miesiąc po desancie. Powstrzymywała ataki w rejonie Caen, tracąc w trzy tygodnie 1500 ludzi. W sierpniu została okrążona wraz z wieloma innymi dywizjami w rejonie Falaise i straciła cały ciężki sprzęt – z okrążenia wydostało się zaledwie 5000–6000 żołnierzy LSSAH.
Wycofana do Niemiec, do grudnia 1944 roku została ponownie odtworzona, osiągając stan 22 000 żołnierzy wyposażonych w 84 czołgi i 20 dział pancernych. W trakcie grudniowej ofensywy w Ardenach LSSAH miała stanowić szpicę głównego ugrupowania uderzeniowego, czyli 6 Armii Pancernej SS, ale utknęła w korkach na wąskich górskich drogach. Doszło też do zbrodni: w rejonie Malmedy esesmani zabili kilkuset jeńców amerykańskich i belgijskich cywilów (podobno za ukrywanie Amerykanów). Wcześniej dywizja dopuściła się wielu innych zbrodni wojennych na froncie wschodnim i we Włoszech.
W styczniu 1945 roku dywizję wycofano z Ardenów i skierowano na Węgry, gdzie 46 czołgami, wraz z innymi zdziesiątkowanymi dywizjami Waffen-SS, miała – według założeń niemieckiego dowództwa – odmienić losy wojny. Po 10 dniach walk, 25 lutego, miała już tylko 23 czołgi. Po klęsce kontrofensywy na Węgrzech próbowała zatrzymać marsz Armii Czerwonej na Austrię. Na początku kwietnia 1945 elitarną dywizję tworzyło mniej niż 1700 żołnierzy z 16 czołgami. Porzuciwszy ciężką broń resztki LSSAH wycofały się na zachód, aby poddać się aliantom.
Dowódcę i kilkudziesięciu innych oficerów dywizji Amerykanie poddali później osądowi trybunału wojennego w Dachau. Wielu skazano na karę śmierci, zamienioną później na kary więzienia.
Żołnierze dywizji uważali siebie za elitę, jednak przez aliantów uznawani byli za członków zbrodniczej organizacji SS. Po zakończeniu wojny Międzynarodowy Trybunał w Norymberdze uznał SS za organizację zbrodniczą, a wielu jej dowódców za zbrodniarzy wojennych.

</doc>
<doc id="13318" url="https://pl.wikipedia.org/wiki?curid=13318" title="Areta">
Areta

Areta – imię żeńskie niejasnego pochodzenia. Józef Bubak łączy je ze skróconą formą Małgorzaty (niem. "Margareta"), powstałą na gruncie niemieckim. Imię to nosiła także postać z mitologii greckiej, królowa Feaków, której imię stanowi przymiotnik odczasownikowy od wyrazu "αραομαι (araomai)" ("modlę się o coś, gorąco pragnę") i oznacza "dziecko upragnione" (por. Dezyderia, Aspazja). Można także spotkać się z poglądem, iż imię to pochodzi od greckiego słowa "αρετη (areté)" oznaczającego "cnotę", "męstwo"; Areta stanowiłaby wówczas żeński odpowiednik męskiego imienia Aretas.
Areta imieniny obchodzi 18 września i 24 października.
Znane osoby noszące imię Areta:
Zobacz też:

</doc>
<doc id="13320" url="https://pl.wikipedia.org/wiki?curid=13320" title="Ariel (imię)">
Ariel (imię)

Ariel (hebr. אֲרִיאֵל) – imię męskie pochodzenia biblijnego. Wywodzi się od hebrajskich słów oznaczających „lew Boga”. W Starym Testamencie używane było jako alternatywna nazwa miasta Jerozolima. 
Żeńska forma: Ariela
Ariel imieniny obchodzi 1 października i 16 listopada.

</doc>
<doc id="13321" url="https://pl.wikipedia.org/wiki?curid=13321" title="Ariela">
Ariela

Ariela – żeński odpowiednik imienia Ariel. Posiadaczka imienia imieniny obchodzi 16 listopada.
Znane postacie fikcyjne o tym imieniu:

</doc>
<doc id="13322" url="https://pl.wikipedia.org/wiki?curid=13322" title="2 Dywizja Pancerna SS „Das Reich”">
2 Dywizja Pancerna SS „Das Reich”

2 Dywizja Pancerna SS „Das Reich” (niem. "2. SS-Panzerdivision "Das Reich"") – dywizja Waffen-SS, odpowiedzialna za masakrę ludności cywilnej w Oradour-sur-Glane.
Historia.
Dywizja została utworzona w 1934 roku jako Die SS-Verfügungstruppe, w 1940 stała się formacją Waffen-SS. Jako dywizja Waffen-SS używała nazw: "SS-Division Verfügungstruppe", "SS-Division Deutschland", "SS-Division Reich", "SS-Division Das Reich", "SS-Panzergrenadier-Division Das Reich", i "2. SS-Panzer-Division Das Reich".
Dywizja "Das Reich" brała udział zarówno w ataku na Francję, jak i w inwazji na Bałkany, ale głównie walczyła na froncie wschodnim z Armią Czerwoną, docierając aż do stolicy ZSRR. Żołnierze z jednostek rozpoznawczych widzieli już dachy budynków w mieście. W początkowym okresie ataku na ZSRR, żołnierzom z Dywizji Das Reich, nie zapewniono transportu więc większą część drogi musieli pokonać pieszo. Ostra zima oraz radziecka kontrofensywa udaremniły niemiecki plan zajęcia Moskwy. W czasie tych walk dywizja poniosła znaczne straty. 
Dywizja brała też udział w bitwie pod Jelnią, pod Sokołowem (jej przeciwnikiem był 1 Czechosłowacki Samodzielny Batalion Polowy), pod Charkowem, na łuku kurskim oraz operacji nad Miusem.
W przededniu bitwy pod Kurskiem liczyła 163 czołgi, a więc dwa razy więcej od analogicznych formacji pancernych Wehrmachtu (np. 3 Dywizja Pancerna posiadała wtedy 90 czołgów, a 9 Dywizja Pancerna 83 czołgi). Po walkach na froncie wschodnim dywizja została wycofana do Francji w celu uzupełnienia strat w ludziach i sprzęcie. 
Po inwazji aliantów we Francję walczyła w Normandii. Po klęsce we Francji dywizja „Das Reich” wzięła udział w ofensywie w Ardenach, a potem przerzucona została na Węgry. Na Węgrzech uczestniczyła w nieudanej operacji Wiosenne Przebudzenie skierowanej przeciw Armii Czerwonej. Atak niemiecki został powstrzymany, a 16 marca 1945 armia radziecka przeszła do kontrataku, po którym dywizja „Das Reich” znalazła się w okrążeniu. Po wyjściu z okrążenia żołnierze "Das Reich" walczyli już tylko o przetrwanie. Pod koniec wojny udało im się przedrzeć na zachód, aby uniknąć rosyjskiej niewoli. Po okrążeniu pod Linzem, w maju 1945 roku poddali się armii amerykańskiej. 
Zbrodnia wojenna w Oradour-sur-Glane.
W kwietniu 1944 roku trafiła do Francji gdzie 10 czerwca popełniła jedną z najgłośniejszych zbrodni Waffen-SS na ludności cywilnej. Żołnierze w miasteczku Oradour-sur-Glane zamordowali 642 osoby, w tym 207 dzieci. 
Kobiety wraz z dziećmi zostały zamknięte w kościele, który został podpalony. Przez okna żołnierze dywizji "Das Reich" wrzucali granaty, a do próbujących uciekać strzelali z broni maszynowej.

</doc>
<doc id="13323" url="https://pl.wikipedia.org/wiki?curid=13323" title="Niniwa">
Niniwa

Niniwa (akad. "Ninūa") – starożytne miasto w północnej Mezopotamii, leżące nad wschodnim, lewym brzegiem Tygrysu; jedna ze stolic Asyrii. Obecnie stanowisko archeologiczne "Ninawa" w Iraku, na północny wschód od śródmieścia Mosulu.
Historia miasta.
Najstarsze ślady osadnictwa na terenie Niniwy datuje się na VI tysiąclecie p.n.e., a w III tysiącleciu p.n.e. istniało już w tym miejscu dość znaczne jak na tamte czasy miasto, znane jako miejsce kultu bogini Inany. U schyłku II tysiąclecia p.n.e. tacy królowie asyryjscy jak Assur-resza-iszi I i jego syn Tiglat-Pileser I, wybudowali tutaj swoje pałace.
Do dużego znaczenia doszła Niniwa w okresie nowoasyryjskim, kiedy to została obrana na stolicę Asyrii przez Sennacheryba, który władał tym państwem w latach 704–681 p.n.e. Z rozmachem rozbudował on miasto, którego powierzchnia sięgnęła niemal 8 km2, a długość murów miejskich w obwodzie wynosiła ok. 12 km. Za pierwszym murem z kamienia o wysokości 4,5 m z regularnie rozmieszczonymi wieżami (również kamiennymi) stał mur z suszonej cegły, który miał szerokość ok. 15 m i wysokość 25 m. Na zewnątrz murów znajdowała się fosa o szerokości ok. 55 m. Wprowadzono stałe nawodnienie fosy i zasilenie strumienia Chosr przecinającego miasto, poprzez rozbudowę systemu kanałów i akweduktów znajdujących się na północny wschód od miasta. Niektóre ze zbudowanych wtedy akweduktów są używane do dziś.
Miasto miało kształt klina skierowanego cieńszym końcem w kierunku południowo-wschodnim. Prowadziło do niego 15 bram (wymienione niżej od północno-wschodniego narożnika zgodnie z ruchem wskazówek zegara):
Nad miastem górowały dwie cytadele. W pierwszej, której pozostałości znane są jako tell Kujundżyk, znajdowały się świątynie i królewskie pałace. W drugiej – tell Nebi Junus – był arsenał Sanheriba.
Wykopaliska archeologiczne prowadzone na tell Kujundżyk odsłoniły liczne reliefy na ścianach przedstawiające dokonania Sanheriba i Aszurbanipala, gdyż to właśnie rozległe pałace tych dwóch władców znajdowały się na tym wzgórzu. Liczne reliefy stamtąd, z których niektóre zyskały światową sławę (np. sceny polowania króla Aszurbanipala na lwy), znajdują się w British Museum. Za czasów Sanheryba i Aszurbanipala Niniwa przeżyła największy rozkwit.
W roku 612 p.n.e. miasto zostało zdobyte i zniszczone przez Medów, Persów i Babilończyków. Na podstawie wykopalisk ustalono, że walki toczyły się niemal na całej długości murów, ale najbardziej zacięte u północno-zachodniej części miasta, gdzie też siły medyjsko-persko-babilońskie przełamały mury na odcinku między bramami Nergala i Adada, wdzierając się do środka. Chociaż Niniwa nigdy się nie podniosła z poczynionych wtedy zniszczeń i nie osiągnęła już takiej świetności jak dawniej, to jednak miasto dalej funkcjonowało. Władca państwa nowobabilońskiego Nabopolasar w jego murach przyjmował poselstwa podbitych krain. Król perski Cyrus II przywrócił świątyniom posągi bóstw, a w okresie hellenistycznym i partyjskim wznoszono tam jeszcze świątynie. Zapewne widoczne liczne reliefy w czasach perskich i późniejszych inspirowały artystów pracujących dla nowych władców, a ślady takich wpływów można znaleźć w dekoracjach miast imperium perskiego i to nawet w okresie sasanidzkim.
W Niniwie niektórzy badacze próbowali zlokalizować słynne wiszące ogrody Semiramidy, jeden z siedmiu cudów świata. Jakkolwiek trudno udowodnić istnienie tego konkretnego obiektu, to jednak kompleksy ogrodowe, bardzo okazałe, z pewnością w Niniwie były. Świadczą o tym m.in. teksty z czasów Sanheriba dotyczące budowy pałacu, jak również reliefy z czasów Aszurbanipala przedstawiające zespoły parkowo-ogrodowe, obficie nawadniane, z różnymi gatunkami roślin.
Prowincja Niniwa.
Niniwa ("Ninūa") już w okresie średnioasyryjskim wchodziła w skład państwa asyryjskiego i była siedzibą gubernatora prowincji noszącej tę samą nazwę. Począwszy od czasów panowania Salmanasara III (858-824 p.n.e.) gubernatorzy Niniwy zaczynają być wymieniani w asyryjskich listach i kronikach eponimów jako urzędnicy "limmu". Prowincja wzmiankowana jest w jednym z edyktów Adad-nirari III (810-783 p.n.e.), w listach do Sargona II (722-705 p.n.e.) i Asarhaddona (680-669 p.n.e.) oraz w tekstach administracyjnych z czasów Sargona II i Aszurbanipala (669-627? p.n.e.). W 717 r. p.n.e. ze wschodniej części prowincji Niniwa utworzono nową prowincję Dur-Szarrukin.
Asyryjscy gubernatorzy Niniwy znani z asyryjskich list i kronik eponimów:
Znany jest też gubernator Niniwy o imieniu Sin-szarru-usur, który pełnił urząd eponima po 648 r. p.n.e. (dokładna data nieznana).
Wykopaliska.
W czasach nowożytnych Niniwę odsłoniły wykopaliska archeologiczne. W 1820 r. starożytne miasto oglądał C.J.Rich, nie prowadząc co prawda wykopalisk, tylko dokonując „powierzchniowych oględzin”.
Niniwa stała się szerzej znana dzięki archeologicznym pracom wykopaliskowym prowadzonym w latach 1847–1851 przez Austena H. Layarda. Odkryto bogate znaleziska architektoniczne: 12 km murów obronnych, pałace królewskie (Sanheriba i Aszurbanipala), liczne przykłady sztuki asyryjskiej oraz bibliotekę Aszurbanipala – bogaty zbiór tekstów zapisanych pismem klinowym na glinianych tabliczkach, które pozwoliły lepiej poznać historię całej Mezopotamii. Zainspirowany tabliczkami G. Smith prowadził wykopaliska w latach 1873–1874, koncentrując się na odnalezieniu dalszych części odczytanych przez siebie tekstów, m.in. eposu o Gilgameszu. W toku prac znaleziono dalsze brakujące fragmenty eposu.
W latach 1927–1932 na terenie Niniwy prowadził wykopaliska R.C. Thompson, który odkopał pozostałości świątyń Nabu i Isztar. W 1954 r. odkopano bramę prowadzącą do arsenału Sanheryba. Z kolei w latach 1965-1984 Irakijczycy prowadzili na szeroką skalę prace wykopaliskowe i rekonstrukcyjne, odtwarzając m.in. część północno-zachodniego muru i znajdujących się tam bram (wtedy zauważono ślady intensywnych walk z 612 r. p.n.e.). Obecnie prace wykopaliskowe i rekonstrukcyjne trwają nadal, znacznie jednakże utrudnione przez sytuację polityczną w regionie.
Niniwa w tekstach biblijnych.
Według Księgi Rodzaju (10, 8–12) miasto założył Nimrod:
Ewangelia wg św. Mateusza (12, 39-42)Lecz On im odpowiedział: «Plemię przewrotne i wiarołomne żąda znaku, ale żaden znak nie będzie mu dany, prócz znaku proroka Jonasza. Albowiem jak Jonasz był trzy dni i trzy noce we wnętrznościach wielkiej ryby, tak Syn Człowieczy będzie trzy dni i trzy noce w łonie ziemi. Ludzie z Niniwy powstaną na sądzie przeciw temu plemieniu i potępią je; ponieważ oni wskutek nawoływania Jonasza się nawrócili, a oto tu jest coś więcej niż Jonasz. 
Według Biblii Niniwa została uratowana przez Jonasza przed gniewem Jahwe. Jednak po jakimś czasie Asyryjczycy wrócili do starych praktyk, dlatego dwóch izraelskich proroków (Nahum i Sofoniasz) z polecenia Jahwe zapowiedziało upadek Niniwy, co urzeczywistniło się w 612 r. p.n.e., kiedy połączone siły Nabopolassara, króla Babilonu, oraz Meda Kyaksaresa otoczyły i zdobyły Niniwę. Miasto najwyraźniej zostało spalone, gdyż na wielu płaskorzeźbach widać uszkodzenia od ognia lub ślady dymu. Pewna kronika babilońska tak opisuje to wydarzenie: 
Według relacji pism wtórnokanonicznych do Niniwy miał zostać uprowadzony przez Salmanasara V stary Tobiasz. Tam również miał mieszkać aż do śmierci rodziców młody Tobiasz, który następnie na przedśmiertne polecenie ojca, spodziewającego się upadku miasta, przeniósł się do Medii.
Niniwa w kulturze popularnej.
Angielski poeta George Gordon Byron napisał tragedię "Sardanapal", osadzoną w scenerii Niniwy.
Inny angielski poeta, Edwin Atherstone, napisał wielki epos "Upadek Niniwy", opowiadający o zdobyciu miasta przez wojska Medów, Babilończyków i innych podbitych przez Asyrię ludów.
Przyjaciel Edwina Atherstone’a malarz John Martin, zilustrował jego epos kompozycją pod tym samym tytułem.
Poeta John Masefield wspomina Niniwę w pierwszym wersie swojego utworu Cargoes.
Zniszczenie murów Niniwy przez Państwo Islamskie.
Z Niniwy do czasów nowożytnych ocalały starożytne mury okalające miasto. Ich długość wynosiła ok. 12 km. 27 stycznia 2015 zostały zniszczone przez bojowników Państwa Islamskiego.

</doc>
<doc id="13325" url="https://pl.wikipedia.org/wiki?curid=13325" title="3 Dywizja Pancerna SS „Totenkopf”">
3 Dywizja Pancerna SS „Totenkopf”

3 Dywizja Pancerna SS „Totenkopf” – dywizja pancerna uznawana za najbardziej fanatyczną spośród dywizji Waffen-SS.
Historia.
Dywizja została sformowana po kampanii wrześniowej w październiku 1939 roku. Jej żołnierze oraz dowódca Theodor Eicke w większości wywodzili się z jednostek wartowniczych z obozów koncentracyjnych: Buchenwald, Dachau, Mauthausen i Sachsenchausen. W 1942 roku nazwano ją „Dywizją Totenkopf” czyli Dywizją Trupiej Główki.
Indoktrynacja rekrutów wcielanych do dywizji, prowadzona była między innymi przez Theodora Eicke (dowódcę dywizji) i polegała na wpajaniu żołnierzom nienawiści do Kościoła katolickiego (wielu zerwało z religią i porzuciło chrześcijaństwo) oraz Rosjan. Podczas indoktrynacji starano się pozbawić ich cech ludzkich, wmawiając im że Rosjanie i inne narody słowiańskie to podludzie - dla których nie ma miejsca w świecie tworzonym przez III Rzeszę. 
Pierwszy raz wkroczyła do boju 16 maja 1940 roku podczas agresji na Francję. Walczyła dobrze ale podczas brytyjskiego kontrataku pod Arras wśród żołnierzy pojawiły się objawy paniki. Wielu w panice uciekło z pola bitwy. W rejonie Cambray dywizja wzięła do niewoli ok. 16 000 francuskich żołnierzy. Po walkach we Flandrii żołnierze dywizji Totenkopf wymordowali część wziętych do niewoli jeńców. Mordów dopuścili się na pojmanych żołnierzach marokańskich z francuskich oddziałów kolonialnych. Dokonali też co najmniej jednej zbrodni na Brytyjczykach.
W związku z planowaną agresją III Rzeszy na ZSRR dywizja został przerzucona na ziemie polskie. W walkach na froncie wschodnim żołnierze dywizji odnieśli wiele militarnych sukcesów ale też dopuścili się licznych okrucieństw. W rejonie Dźwiny i Dźwińska atakowała 21 Korpus Pancerny Armii Czerwonej, zadając mu znaczne straty. Prowadziła szczególnie ciężkie i zawzięte boje w tzw. kotle demiańskim, gdzie lutym 1942 roku zostało okrążonych ok. 90 tys. żołnierzy niemieckich. W kwietniu 1942 dywizja zdołała wyrwać się z okrążenia i dotrzeć do obszarów kontrolowanych przez armie niemieckie. Poniosła jednak tak duże straty, że 2 pułk piechoty zmotoryzowanej SS (taką wówczas nosił nazwę) musiał zostać rozwiązany. Do września 1942 roku wchodzące w skład dywizji pułki piechoty i artylerii, oraz bataliony (inżynieryjny, przeciwpancerny i rozpoznawczy) doznały strat rzędu 80 procent. W październiku dywizja została wysłana do Francji w celu uzupełnień i przekształcenia w dywizję pancerną SS. Reorganizację zakończono 9 listopada, do dywizji udało się wcielić 5000 rekrutów w miejsce 7000 żołnierzy zabitych i rannych na froncie wschodnim. 
W lutym 1943 roku dywizja ponownie została skierowana na front wschodni. W przededniu bitwy pod Kurskiem dywizja liczyła 139 czołgów, a więc znacznie więcej od analogicznych formacji pancernych Wehrmachtu (np. 3 Dywizja Pancerna posiadała wtedy 90 czołgów, a 9 Dywizja Pancerna 83 czołgi). We wspomnianej bitwie straciła około 50 procent posiadanych czołgów i innych pojazdów. Na przełomie lipca i sierpnia 1943 wzięła udział w ciężkich walkach nad Miusem. Następnie uczestniczyła w walkach o Krzywy Róg i Czerkasy. Po klęskach 4 i 9 Armii, została włączona do Grupy Armii Środek. Pod koniec lipca 1944 brała udział w bitwie o Siedlce oraz w walkach w rejonie Modlina i Warszawy. 
W sierpniu 1944 roku w wielkiej bitwie pancernej w rejonie Wołomina dywizja „Totenkopf” walcząc razem z Dywizją Pancerną Hermann Göring i 5 Dywizją Pancerną SS „Wiking” praktycznie unicestwiła 3 Korpus Pancerny Armii Czerwonej, jednak sama również poniosła znaczne straty.
W grudniu 1944 roku została przerzucona na Węgry, gdzie uczestniczyła w nieudanym kontrataku koło Budapesztu. Działania bojowe zakończyła w Austrii. Do niewoli oddała się armii amerykańskiej 8 maja 1945 roku w okolicach Linzu. Po tygodniu Amerykanie przekazali jeńców Armii Czerwonej. Niewolę rosyjską przeżyło niewielu.
Struktura organizacyjna.
w 1943 roku:

</doc>
<doc id="13328" url="https://pl.wikipedia.org/wiki?curid=13328" title="4 Dywizja Grenadierów Pancernych SS „Polizei”">
4 Dywizja Grenadierów Pancernych SS „Polizei”

4 Dywizja Grenadierów Pancernych SS „Polizei” (niem. 4. SS-Polizei-Panzergrenadier-Division) – dywizja Waffen-SS.
Historia.
4 Dywizja Grenadierów Pancernych SS „Polizei”, niemiecka jednostka wojskowa sformowana w październiku 1939 roku jako dywizja policyjna (Polizei-Division), której żołnierzami byli policjanci. Z założenia miała być jednostką drugoliniową, więc była gorzej wyposażona. Walczyła we Francji i na froncie wschodnim. W 1941 dywizja liczyła 17 347 członków. Od 1942 w Waffen-SS. Później wykonywała zadania okupacyjne w Polsce i na Bałkanach. W czerwcu 1943 roku została przekształcona w dywizję grenadierów pancernych. Zwalczała partyzantkę w Jugosławii i Grecji, dopuszczając się tam zbrodni wojennych, m.in. masakry w Distomo. Od końca września 1944 broniła Węgier przed Armią Czerwoną. W 1945 walczyła na Słowacji i Pomorzu. Resztki dywizji poddały się w Niemczech Amerykanom.
Odznaka.
Emblematem Dywizji Polizei była odmiana germańskiego i heraldycznego symbolu Wilczego Haka. W przeciwieństwie do emblematu Dywizji Das Reich, która posiadała taki sam znak dywizyjny, symbol Dywizji Polizei przedstawiony jest w pozycji pionowej. Znak ten znany jest także pod nazwą Donnerkeil (Grom). Odznakę Dywizja zaczęła używać dopiero od 1942 roku.

</doc>
<doc id="13330" url="https://pl.wikipedia.org/wiki?curid=13330" title="Kultura magdaleńska">
Kultura magdaleńska

Kultura magdaleńska (, ; ) – jedna z kultur późnego paleolitu, udokumentowana w Europie zachodniej i środkowej i datowana na przedział od 18 do 11 tys. lat wstecz. Nazwa wywodzi się od stanowiska Abri de la Madeleine, w departamencie Dordogne we Francji.
Kultura magdaleńska charakteryzowała się dość wyrafinowaną produkcją narzędzi z krzemienia, rogu i kości. Do kultury magdaleńskiej zaliczają się monumentalne przykłady malarstwa naskalnego odkryte w jaskiniach, głównie Francji i Hiszpanii, w tym: Altamira, Lascaux, Font-de-Gaume. Charakterystyczne dla kultury magdaleńskiej były między innymi specyficzne groty oszczepów, falliczne przedmioty kultowe oraz oprawy narzędzi krzemiennych, tzw. "navettes". Jednym z najważniejszych ośrodków kultury magdaleńskiej był ośrodek morawski.
W Polsce obozowisko ludzi kultury magdaleńskiej odkryto m.in. w Jaskini Maszyckiej w Ojcowskim Parku Narodowym. Zasięg znalezisk kultury magdaleńskiej we Wschodniej Europie korelował z zasięgiem występowania suhaków, na które najpewniej urządzano polowania. Przedstawiciele ludów magdaleńskich polowali też m.in. na bizony, konie czy renifery. W Brzoskiwini k. Krakowa odkryto liczne pracownie obróbki krzemienia pochodzące z czasów magdaleńskich.

</doc>
